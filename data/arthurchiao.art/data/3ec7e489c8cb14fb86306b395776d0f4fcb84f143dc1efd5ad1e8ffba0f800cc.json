{
  "Source": "arthurchiao.art",
  "Title": "[译] 深入理解 Cilium 的 eBPF 收发包路径（datapath）（KubeCon, 2019）",
  "Link": "https://arthurchiao.art/blog/understanding-ebpf-datapath-in-cilium-zh/",
  "Content": "\u003cdiv class=\"post\"\u003e\n  \n  \u003ch1 class=\"postTitle\"\u003e[译] 深入理解 Cilium 的 eBPF 收发包路径（datapath）（KubeCon, 2019）\u003c/h1\u003e\n  \u003cp class=\"meta\"\u003ePublished at 2020-09-04 | Last Update 2020-09-04\u003c/p\u003e\n  \n  \u003ch3 id=\"译者序\"\u003e译者序\u003c/h3\u003e\n\n\u003cp\u003e本文翻译自 2019 年 DigitalOcean 的工程师 Nate Sweet 在 KubeCon 的一篇分享: \u003ca href=\"https://kccncna19.sched.com/event/Uae7/understanding-and-troubleshooting-the-ebpf-datapath-in-cilium-nathan-sweet-digitalocean\"\u003eUnderstanding (and Troubleshooting) the eBPF Datapath\nin Cilium\u003c/a\u003e\n。\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e由于译者水平有限，本文不免存在遗漏或错误之处。如有疑问，请查阅原文。\u003c/strong\u003e\u003c/p\u003e\n\n\u003chr/\u003e\n\n\u003cul id=\"markdown-toc\"\u003e\n  \u003cli\u003e\u003ca href=\"#译者序\" id=\"markdown-toc-译者序\"\u003e译者序\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#1-为什么要关注-ebpf\" id=\"markdown-toc-1-为什么要关注-ebpf\"\u003e1 为什么要关注 eBPF？\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#11-网络成为瓶颈\" id=\"markdown-toc-11-网络成为瓶颈\"\u003e1.1 网络成为瓶颈\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#12-ebpf-无处不在\" id=\"markdown-toc-12-ebpf-无处不在\"\u003e1.2 eBPF 无处不在\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#13-性能就是金钱\" id=\"markdown-toc-13-性能就是金钱\"\u003e1.3 性能就是金钱\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#2-ebpf-是什么\" id=\"markdown-toc-2-ebpf-是什么\"\u003e2 eBPF 是什么？\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#3-为什么-ebpf-如此强大\" id=\"markdown-toc-3-为什么-ebpf-如此强大\"\u003e3 为什么 eBPF 如此强大？\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#31-快速\" id=\"markdown-toc-31-快速\"\u003e3.1 快速\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#32-灵活\" id=\"markdown-toc-32-灵活\"\u003e3.2 灵活\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#33-数据与功能分离\" id=\"markdown-toc-33-数据与功能分离\"\u003e3.3 数据与功能分离\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#4-ebpf-简史\" id=\"markdown-toc-4-ebpf-简史\"\u003e4 eBPF 简史\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#5-cilium-是什么为什么要关注它\" id=\"markdown-toc-5-cilium-是什么为什么要关注它\"\u003e5 Cilium 是什么，为什么要关注它？\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#6-内核默认-datapath\" id=\"markdown-toc-6-内核默认-datapath\"\u003e6 内核默认 datapath\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#61-l1---l2物理层---数据链路层\" id=\"markdown-toc-61-l1---l2物理层---数据链路层\"\u003e6.1 L1 -\u0026gt; L2（物理层 -\u0026gt; 数据链路层）\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#62-l2-续数据链路层---续\" id=\"markdown-toc-62-l2-续数据链路层---续\"\u003e6.2 L2 续（数据链路层 - 续）\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#step-1napi-poll\" id=\"markdown-toc-step-1napi-poll\"\u003eStep 1：NAPI poll\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#step-2xdp-程序处理\" id=\"markdown-toc-step-2xdp-程序处理\"\u003eStep 2：XDP 程序处理\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#step-3clean_rx创建-skb\" id=\"markdown-toc-step-3clean_rx创建-skb\"\u003eStep 3：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eclean_rx()\u003c/code\u003e：创建 skb\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#step-4gro_receive\" id=\"markdown-toc-step-4gro_receive\"\u003eStep 4：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003egro_receive()\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#step-5receive_skb\" id=\"markdown-toc-step-5receive_skb\"\u003eStep 5：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003ereceive_skb()\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#63-l2---l3数据链路层---网络层\" id=\"markdown-toc-63-l2---l3数据链路层---网络层\"\u003e6.3 L2 -\u0026gt; L3（数据链路层 -\u0026gt; 网络层）\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#step-6通用-xdp-处理gxdp\" id=\"markdown-toc-step-6通用-xdp-处理gxdp\"\u003eStep 6：通用 XDP 处理（gXDP）\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#step-7tap-设备处理\" id=\"markdown-toc-step-7tap-设备处理\"\u003eStep 7：Tap 设备处理\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#step-8tctraffic-classifier处理\" id=\"markdown-toc-step-8tctraffic-classifier处理\"\u003eStep 8：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003etc\u003c/code\u003e（traffic classifier）处理\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#step-9netfilter-处理\" id=\"markdown-toc-step-9netfilter-处理\"\u003eStep 9：Netfilter 处理\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#step-10l3-协议层处理ip_rcv\" id=\"markdown-toc-step-10l3-协议层处理ip_rcv\"\u003eStep 10：L3 协议层处理：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eip_rcv()\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#64-l3---l4网络层---传输层\" id=\"markdown-toc-64-l3---l4网络层---传输层\"\u003e6.4 L3 -\u0026gt; L4（网络层 -\u0026gt; 传输层）\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#step-11netfilter-l4-处理\" id=\"markdown-toc-step-11netfilter-l4-处理\"\u003eStep 11：Netfilter L4 处理\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#step-12ip_rcv_finish-处理\" id=\"markdown-toc-step-12ip_rcv_finish-处理\"\u003eStep 12：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eip_rcv_finish()\u003c/code\u003e 处理\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#step-13ip_routing-处理\" id=\"markdown-toc-step-13ip_routing-处理\"\u003eStep 13：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eip_routing()\u003c/code\u003e 处理\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#step-14目的是本机ip_local_deliver-处理\" id=\"markdown-toc-step-14目的是本机ip_local_deliver-处理\"\u003eStep 14：目的是本机：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eip_local_deliver()\u003c/code\u003e 处理\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#step-15xfrm4_policy-处理\" id=\"markdown-toc-step-15xfrm4_policy-处理\"\u003eStep 15：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003exfrm4_policy()\u003c/code\u003e 处理\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#65-l4传输层以-udp-为例\" id=\"markdown-toc-65-l4传输层以-udp-为例\"\u003e6.5 L4（传输层，以 UDP 为例）\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#step-16udp_rcv-处理\" id=\"markdown-toc-step-16udp_rcv-处理\"\u003eStep 16：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eudp_rcv()\u003c/code\u003e 处理\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#step-17xfrm4_policy-再次处理\" id=\"markdown-toc-step-17xfrm4_policy-再次处理\"\u003eStep 17：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003exfrm4_policy()\u003c/code\u003e 再次处理\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#step-18将包放入-socket_receive_queue\" id=\"markdown-toc-step-18将包放入-socket_receive_queue\"\u003eStep 18：将包放入 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003esocket_receive_queue\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#step-19通知-socket-收数据sk_data_ready\" id=\"markdown-toc-step-19通知-socket-收数据sk_data_ready\"\u003eStep 19：通知 socket 收数据：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003esk_data_ready()\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#网络栈下半部分小结\" id=\"markdown-toc-网络栈下半部分小结\"\u003e网络栈下半部分小结\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#66-l4---user-space\" id=\"markdown-toc-66-l4---user-space\"\u003e6.6 L4 - User Space\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#7-kubernetscilium-和-kernel原子对象对应关系\" id=\"markdown-toc-7-kubernetscilium-和-kernel原子对象对应关系\"\u003e7 Kubernets、Cilium 和 Kernel：原子对象对应关系\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#8-demo\" id=\"markdown-toc-8-demo\"\u003e8 Demo\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e以下是译文。\u003c/p\u003e\n\n\u003chr/\u003e\n\n\u003ch1 id=\"1-为什么要关注-ebpf\"\u003e1 为什么要关注 eBPF？\u003c/h1\u003e\n\n\u003ch2 id=\"11-网络成为瓶颈\"\u003e1.1 网络成为瓶颈\u003c/h2\u003e\n\n\u003cp\u003e大家已经知道网络成为瓶颈，但我是从下面这个角度考虑的：\u003cstrong\u003e近些年业界使用网络的方式\n，使其成为瓶颈\u003c/strong\u003e（it is the bottleneck in a way that is actually pretty recent）\n。\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\u003cstrong\u003e网络一直都是 I/O 密集型的\u003c/strong\u003e，但直到最近，这件事情才变得尤其重要。\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e分布式任务（workloads）业界一直都在用\u003c/strong\u003e，但直到近些年，这种模型才成为主流。\n虽然何时成为主流众说纷纭，但我认为最早不会早于 90 年代晚期。\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e公有云的崛起\u003c/strong\u003e，我认为可能是网络成为瓶颈的最主要原因。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e这种情况下，用于管理依赖和解决瓶颈的\u003cstrong\u003e工具都已经过时了\u003c/strong\u003e。\u003c/p\u003e\n\n\u003cp\u003e但像 eBPF 这样的技术使得网络调优和整流（tune and shape this traffic）变得简单很多。\n\u003cstrong\u003eeBPF 提供的许多能力是其他工具无法提供的，或者即使提供了，其代价也要比 eBPF 大\n的多\u003c/strong\u003e。\u003c/p\u003e\n\n\u003ch2 id=\"12-ebpf-无处不在\"\u003e1.2 eBPF 无处不在\u003c/h2\u003e\n\n\u003cp\u003eeBPF 正在变得无处不在，我们可能会争论这到底是一件好事还是坏事（eBPF 也确实带了一\n些安全问题），但当前无法忽视的事实是：Linux 内核的网络开发者们\u003cstrong\u003e正在将 eBPF 应用\n于各种地方\u003c/strong\u003e（putting it everywhere）。其结果是，eBPF \u003cstrong\u003e与内核的默认收发包路径（\ndatapath）耦合得越来越紧\u003c/strong\u003e（more and more tightly coupled with the default\ndatapath）。\u003c/p\u003e\n\n\u003ch2 id=\"13-性能就是金钱\"\u003e1.3 性能就是金钱\u003c/h2\u003e\n\n\u003cp\u003e\u003ca href=\"https://kernel-recipes.org/en/2019/metrics-are-money/\"\u003e“Metrics are money”\u003c/a\u003e，\n这是今年 Paris Kernel Recipes 峰会上，来自 Synthesio 的 Aurelian Rougemont 的\n精彩分享。\u003c/p\u003e\n\n\u003cp\u003e他展示了一些史诗级的调试（debugging）案例，感兴趣的可以去看看；但更重要的是，他\n从更高层次提出了这样一个观点：\u003cstrong\u003e理解这些东西是如何工作的，最终会产生资本收益\u003c/strong\u003e（\nunderstanding how this stuff works translates to money）。为客户节省金钱，为\n自己带来收入。\u003c/p\u003e\n\n\u003cp\u003e如果你能从更少的资源中榨取出更高的性能，使软件运行更快，那\n显然你对公司的贡献就更大。\u003cstrong\u003eCilium 就是这样一个能让你带来更大价值的工具\u003c/strong\u003e。\u003c/p\u003e\n\n\u003cp\u003e在进一步讨论之前，我先简要介绍一下 eBPF 是什么，以及为什么它如此强大。\u003c/p\u003e\n\n\u003ch1 id=\"2-ebpf-是什么\"\u003e2 eBPF 是什么？\u003c/h1\u003e\n\n\u003cp\u003e\u003cstrong\u003eBPF 程序有多种类型\u003c/strong\u003e，图 2.1 是其中一种，称为 XDP BPF 程序。\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eXDP 是 \u003cstrong\u003eeXpress DataPath\u003c/strong\u003e（特快数据路径）。\u003c/li\u003e\n  \u003cli\u003eXDP 程序可以直接\u003cstrong\u003e加载到网络设备上\u003c/strong\u003e。\u003c/li\u003e\n  \u003cli\u003eXDP 程序在数据包收发路径上\u003cstrong\u003e很前面的位置\u003c/strong\u003e就开始执行，下面会看到例子。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eBPF 程序开发方式：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003cstrong\u003e编写\u003c/strong\u003e一段 BPF 程序\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e编译\u003c/strong\u003e这段 BPF 程序\u003c/li\u003e\n  \u003cli\u003e用一个特殊的系统调用将编译后的代码\u003cstrong\u003e加载到内核\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e\u003cstrong\u003e这实际上就是编写了一段内核代码，并动态插入到了内核\u003c/strong\u003e（written kernel code and\ndynamically inserted it into the kernel）。\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/ebpf-sample.png\" width=\"90%\" height=\"90%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003e 图 2.1. eBPF 代码示例：丢弃源 IP 命中黑名单的 ARP 包\u003c/p\u003e\n\n\u003cp\u003e图 2.1 中的程序使用了一种称为 \u003cstrong\u003emap\u003c/strong\u003e 的东西，这是一种特殊的数据结构，可用于\n\u003cstrong\u003e在内核和用户态之间传递数据\u003c/strong\u003e，例如通过一个特殊的系统从用户态向 map 里插入数据。\u003c/p\u003e\n\n\u003cp\u003e这段程序的功能：丢弃所有源 IP 命中黑名单的 ARP 包。右侧四个框内的代码功能：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e初始化以太帧结构体（ethernet packet）。\u003c/li\u003e\n  \u003cli\u003e如果不是 ARP 包，直接退出，将包交给内核继续处理。\u003c/li\u003e\n  \u003cli\u003e至此已确定是 ARP，因此初始化一个 ARP 数据结构，对包进行下一步处理。例\n  如，提取出 ARP 中的源 IP，去之前创建好的黑名单中查询该 IP 是否存在。\u003c/li\u003e\n  \u003cli\u003e如果存在，返回丢弃判决（\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eXDP_DROP\u003c/code\u003e）；否则，返回允许通行判决（\n\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eXDP_PASS\u003c/code\u003e），内核会进行后续处理。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e你可能不会相信，就这样一段简单的程序，会让服务器性能产生质的飞跃，因为它此时已\n经拥有了一条极为高效的网络路径（an extremely efficient network path）。\u003c/p\u003e\n\n\u003ch1 id=\"3-为什么-ebpf-如此强大\"\u003e3 为什么 eBPF 如此强大？\u003c/h1\u003e\n\n\u003cp\u003e三方面原因：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e快速（fast）\u003c/li\u003e\n  \u003cli\u003e灵活（flexible）\u003c/li\u003e\n  \u003cli\u003e数据与功能分离（separates data from functionality）\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch2 id=\"31-快速\"\u003e3.1 快速\u003c/h2\u003e\n\n\u003cp\u003eeBPF 几乎总是比 iptables 快，这是有技术原因的。\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eeBPF 程序本身并不比 iptables 快，但 eBPF 程序更短。\u003c/li\u003e\n  \u003cli\u003eiptables 基于一个非常庞大的内核框架（Netfilter），这个框架出现在内核 datapath\n的多个地方，有很大冗余。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e因此，同样是实现 ARP drop 这样的功能，基于 iptables 做冗余就会非常大，导致性能很低。\u003c/p\u003e\n\n\u003ch2 id=\"32-灵活\"\u003e3.2 灵活\u003c/h2\u003e\n\n\u003cp\u003e这可能是最主要的原因。\u003cstrong\u003e你可以用 eBPF 做几乎任何事情\u003c/strong\u003e。\u003c/p\u003e\n\n\u003cp\u003eeBPF 基于内核提供的一组接口，运行 JIT 编译的字节码，并将计算结果返回给内核。例如\n\u003cstrong\u003e内核只关心 XDP 程序的返回是 PASS, DROP 还是 REDIRECT。至于在 XDP 程序里做什么，\n完全看你自己\u003c/strong\u003e。\u003c/p\u003e\n\n\u003ch2 id=\"33-数据与功能分离\"\u003e3.3 数据与功能分离\u003c/h2\u003e\n\n\u003cp\u003eeBPF separates data from functionality.\u003c/p\u003e\n\n\u003cp\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003enftables\u003c/code\u003e 和 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eiptables\u003c/code\u003e 也能干这个事情，但功能没有 eBPF 强大。例如，eBPF 可以使\n用 per-cpu 的数据结构，因此能取得更极致的性能。\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eeBPF 真正的优势\u003c/strong\u003e是将“数据与功能分离”这件事情做地\u003cstrong\u003e非常干净\u003c/strong\u003e（clean\nseparation）：可以在 eBPF 程序不中断的情况下修改它的运行方式。具体方式是修改它访\n问的配置数据或应用数据，例如黑名单里规定的 IP 列表和域名。\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/why-ebpf.png\" width=\"50%\" height=\"50%\"/\u003e\u003c/p\u003e\n\n\u003ch1 id=\"4-ebpf-简史\"\u003e4 eBPF 简史\u003c/h1\u003e\n\n\u003cp\u003e这里是简单介绍几句，后面 datapath 才是重点。\u003c/p\u003e\n\n\u003cp\u003e两篇论文，可读性还是比较好的，感兴趣的自行阅读：\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eSteven McCanne, et al, in 1993 - \u003cstrong\u003eThe BSD Packet Filter\u003c/strong\u003e\u003c/li\u003e\n  \u003cli\u003eJeffrey C. Mogul, et al, in 1987 - first open source implementation of a packet filter.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch1 id=\"5-cilium-是什么为什么要关注它\"\u003e5 Cilium 是什么，为什么要关注它？\u003c/h1\u003e\n\n\u003cp\u003e我认为理解 eBPF 代码还比较简单，多看看内核代码就行了，但配置和编写 eBPF 就要难多了。\u003c/p\u003e\n\n\u003cp\u003eCilium 是一个很好的 eBPF 之上的通用抽象，覆盖了分布式系统的绝大多数场景。Cilium\n封装了 eBPF，提供一个更上层的 API。如果你使用的是 Kubernetes，那你至少应该听说过\nCilium。\u003c/p\u003e\n\n\u003cp\u003eCilium 提供了 CNI 和 kube-proxy replacement 功能，相比 iptables 性能要好很多。\u003c/p\u003e\n\n\u003cp\u003e接下来开始进入本文重点。\u003c/p\u003e\n\n\u003ch1 id=\"6-内核默认-datapath\"\u003e6 内核默认 datapath\u003c/h1\u003e\n\n\u003cp\u003e本节将介绍\u003cstrong\u003e数据包是如何穿过 network datapath（网络数据路径）的\u003c/strong\u003e：包括从硬件到\n内核，再到用户空间。\u003c/p\u003e\n\n\u003cp\u003e这里将只介绍 \u003cstrong\u003eCilium 所使用的 eBPF 程序\u003c/strong\u003e，其中有 Cilium logo 的地方，都是\ndatapath 上 Cilium 重度使用 BPF 程序的地方。\u003c/p\u003e\n\n\u003cp\u003e本文不会过多介绍硬件相关内容，因为理解 eBPF 基本不需要硬件知识，但显然理解了硬件\n原理也并无坏处。另外，由于时间限制，我将只讨论接收部分。\u003c/p\u003e\n\n\u003ch2 id=\"61-l1---l2物理层---数据链路层\"\u003e6.1 L1 -\u0026gt; L2（物理层 -\u0026gt; 数据链路层）\u003c/h2\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-l1-l2.png\" width=\"60%\" height=\"60%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e网卡收包简要流程：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e网卡驱动初始化。\n    \u003col\u003e\n      \u003cli\u003e网卡获得一块物理内存，作用收发包的缓冲区（ring-buffer）。这种方式称为 DMA（直接内存访问）。\u003c/li\u003e\n      \u003cli\u003e驱动向内核 NAPI（New API）注册一个轮询（poll ）方法。\u003c/li\u003e\n    \u003c/ol\u003e\n  \u003c/li\u003e\n  \u003cli\u003e网卡从云上收到一个包，将包放到 ring-buffer。\u003c/li\u003e\n  \u003cli\u003e如果此时 NAPI 没有在执行，网卡就会触发一个硬件中断（HW IRQ），告诉处理器\nDMA 区域中有包等待处理。\u003c/li\u003e\n  \u003cli\u003e收到硬中断信号后，处理器开始执行 NAPI。\u003c/li\u003e\n  \u003cli\u003eNAPI 执行网卡注册的 poll 方法开始收包。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e关于 NAPI poll 机制：\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e这是 Linux 内核中的一种通用抽象，任何等待\u003cstrong\u003e不可抢占状态\u003c/strong\u003e发生（wait for a\npreemptible state to occur）的模块，都可以使用这种注册回调函数的方式。\u003c/li\u003e\n  \u003cli\u003e驱动注册的这个 poll 是一个\u003cstrong\u003e主动式 poll\u003c/strong\u003e（active poll），一旦执行就会持续处理\n，直到没有数据可供处理，然后进入 idle 状态。\u003c/li\u003e\n  \u003cli\u003e在这里，执行 poll 方法的是运行在某个或者所有 CPU 上的\u003cstrong\u003e内核线程\u003c/strong\u003e（kernel thread）。\n虽然这个线程没有数据可处理时会进入 idle 状态，但如前面讨论的，在当前大部分分布\n式系统中，这个线程大部分时间内都是在运行的，不断从驱动的 DMA 区域内接收数据包。\u003c/li\u003e\n  \u003cli\u003epoll 会告诉网卡不要再触发硬件中断，使用\u003cstrong\u003e软件中断\u003c/strong\u003e（softirq）就行了。此后这些\n内核线程会轮询网卡的 DMA 区域来收包。之所以会有这种机制，是因为硬件中断代价太\n高了，因为它们比系统上几乎所有东西的优先级都要高。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e我们接下来还将多次看到这个广义的 NAPI 抽象，因为它不仅仅处理驱动，还能处理许多\n其他场景。内核用 NAPI 抽象来做驱动读取（driver reads）、epoll 等等。\u003c/p\u003e\n\n\u003cp\u003eNAPI 驱动的 poll 机制将数据从 DMA 区域读取出来，对数据做一些准备工作，然后交给比\n它更上一层的内核协议栈。\u003c/p\u003e\n\n\u003ch2 id=\"62-l2-续数据链路层---续\"\u003e6.2 L2 续（数据链路层 - 续）\u003c/h2\u003e\n\n\u003cp\u003e同样，这里不会深入展开驱动层做的事情，而主要关注内核所做的一些更上层的事情，例如\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e分配 socket buffers（skb）\u003c/li\u003e\n  \u003cli\u003eBPF\u003c/li\u003e\n  \u003cli\u003eiptables\u003c/li\u003e\n  \u003cli\u003e将包送到网络栈（network stack）和用户空间\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"step-1napi-poll\"\u003eStep 1：NAPI poll\u003c/h3\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-highlight-driver-poll.png\" width=\"80%\" height=\"80%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e首先，NAPI poll 机制不断调用驱动实现的 poll 方法，后者处理 RX 队列内的包，并最终\n将包送到正确的程序。这就到了我们前面的 XDP 类型程序。\u003c/p\u003e\n\n\u003ch3 id=\"step-2xdp-程序处理\"\u003eStep 2：XDP 程序处理\u003c/h3\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-highlight-xdp.png\" width=\"80%\" height=\"80%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e如果驱动支持 XDP，那 XDP 程序将在 poll 机制内执行\u003c/strong\u003e。如果不支持，那 XDP\n程序将只能\u003cstrong\u003e在更后面执行\u003c/strong\u003e（run significantly upstack，见 Step 6），性能会变差，\n因此确定你使用的网卡是否支持 XDP 非常重要。\u003c/p\u003e\n\n\u003cp\u003eXDP 程序返回一个判决结果给驱动，可以是 PASS, TRANSMIT, 或 DROP。\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\n    \u003cp\u003eTransmit 非常有用，有了这个功能，就可以用 XDP \u003cstrong\u003e实现一个 TCP/IP 负载均衡器\u003c/strong\u003e。\nXDP \u003cstrong\u003e只适合对包进行较小修改\u003c/strong\u003e，如果是大动作修改，那这样的 XDP 程序的性能\n可能并不会很高，因为这些操作会\u003cstrong\u003e降低 poll 函数处理 DMA ring-buffer 的能力\u003c/strong\u003e。\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e更有趣的是 DROP 方法，因为一旦判决为 DROP，这个包就可以直接\u003cstrong\u003e原地丢弃\u003c/strong\u003e了，而\n无需再穿越后面复杂的协议栈然后再在某个地方被丢弃，从而节省了大量资源。如果本次\n分享我只能给大家一个建议，那这个建议就是：\u003cstrong\u003e在 datapath 越前面做 tuning 和\ndropping 越好\u003c/strong\u003e，这会显著增加系统的网络吞吐。\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e如果返回是 PASS，内核会继续沿着默认路径处理包，到达 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eclean_rx()\u003c/code\u003e 方法。\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"step-3clean_rx创建-skb\"\u003eStep 3：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eclean_rx()\u003c/code\u003e：创建 skb\u003c/h3\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-highlight-clean-rx.png\" width=\"80%\" height=\"80%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e如果返回是 PASS，内核会继续沿着默认路径处理包，到达 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eclean_rx()\u003c/code\u003e 方法。\u003c/p\u003e\n\n\u003cp\u003e这个方法\u003cstrong\u003e创建一个 socket buffer（skb）对象\u003c/strong\u003e，可能还会更新一些统计信息，对 skb\n进行硬件校验和检查，然后将其交给 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003egro_receive()\u003c/code\u003e 方法。\u003c/p\u003e\n\n\u003ch3 id=\"step-4gro_receive\"\u003eStep 4：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003egro_receive()\u003c/code\u003e\u003c/h3\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-highlight-gro.png\" width=\"80%\" height=\"80%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003eGRO 是一种较老的硬件特性（LRO）的软件实现，功能是\u003cstrong\u003e对分片的包进行重组然后交给更\n上层\u003c/strong\u003e，以提高吞吐。\u003c/p\u003e\n\n\u003cp\u003eGRO 给协议栈提供了一次\u003cstrong\u003e将包交给网络协议栈之前，对其检查校验和\n、修改协议头和发送应答包（ACK packets）的机会\u003c/strong\u003e。\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e如果 GRO 的 buffer 相比于包太小了，它可能会选择什么都不做。\u003c/li\u003e\n  \u003cli\u003e如果当前包属于某个更大包的一个分片，调用 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eenqueue_backlog\u003c/code\u003e 将这个分片放到某个\nCPU 的包队列。当包重组完成后，会交给 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ereceive_skb()\u003c/code\u003e 方法处理。\u003c/li\u003e\n  \u003cli\u003e如果当前包不是分片包，直接调用 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ereceive_skb()\u003c/code\u003e，进行一些网络栈最底层的处理。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch3 id=\"step-5receive_skb\"\u003eStep 5：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003ereceive_skb()\u003c/code\u003e\u003c/h3\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-highlight-receive-skb.png\" width=\"80%\" height=\"80%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003ereceive_skb()\u003c/code\u003e 之后会再次进入 XDP 程序点。\u003c/p\u003e\n\n\u003ch2 id=\"63-l2---l3数据链路层---网络层\"\u003e6.3 L2 -\u0026gt; L3（数据链路层 -\u0026gt; 网络层）\u003c/h2\u003e\n\n\u003ch3 id=\"step-6通用-xdp-处理gxdp\"\u003eStep 6：通用 XDP 处理（gXDP）\u003c/h3\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-highlight-gxdp.png\" width=\"100%\" height=\"100%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003ereceive_skb()\u003c/code\u003e 之后，我们又来到了另一个 XDP 程序执行点。这里可以通过\n\u003ccode class=\"language-plaintext highlighter-rouge\"\u003ereceive_xdp()\u003c/code\u003e \u003cstrong\u003e做一些通用（generic）的事情\u003c/strong\u003e，因此我在图中将其标注为 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e(g)XDP\u003c/code\u003e\u003c/p\u003e\n\n\u003cp\u003eStep 2 中提到，如果网卡驱动不支持 XDP，那 XDP 程序将延迟到更后面执行，这个\n\u003cstrong\u003e“更后面”的位置指的就是这里的 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e(g)XDP\u003c/code\u003e\u003c/strong\u003e。\u003c/p\u003e\n\n\u003ch3 id=\"step-7tap-设备处理\"\u003eStep 7：Tap 设备处理\u003c/h3\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-highlight-tap.png\" width=\"100%\" height=\"100%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e图中有个 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e*check_taps\u003c/code\u003e 框，但其实并没有这个方法：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003ereceive_skb()\u003c/code\u003e 会轮询所有的\nsocket tap，将包放到正确的 tap 设备的缓冲区。\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cmark\u003etap 设备监听的是三层协议\u003c/mark\u003e\u003c/strong\u003e（L3 protocols），例如 IPv4、ARP、IPv6 等等。\n如果 tap 设备存在，它就可以操作这个 skb 了。\u003c/p\u003e\n\n\u003ch3 id=\"step-8tctraffic-classifier处理\"\u003eStep 8：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003etc\u003c/code\u003e（traffic classifier）处理\u003c/h3\u003e\n\n\u003cp\u003e接下来我们遇到了第二种 eBPF 程序：tc eBPF。\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-highlight-tc.png\" width=\"100%\" height=\"100%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003etc（traffic classifier，流量分类器）是 Cilium 依赖的最基础的东西，它提供了多种功\n能，例如修改包（mangle，给 skb 打标记）、重路由（reroute）、丢弃包（drop），\u003cstrong\u003e这\n些操作都会影响到内核的流量统计，因此也影响着包的排队规则\u003c/strong\u003e（queueing discipline\n）。\u003c/p\u003e\n\n\u003cp\u003eCilium 控制的网络设备，至少被加载了一个 tc eBPF 程序。\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e译者注：如何查看已加载的 eBPF 程序，可参考 \u003ca href=\"/blog/cilium-network-topology-on-aws/\"\u003eCilium Network Topology and Traffic Path on AWS\u003c/a\u003e。\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch3 id=\"step-9netfilter-处理\"\u003eStep 9：Netfilter 处理\u003c/h3\u003e\n\n\u003cp\u003e如果 tc BPF 返回 OK，包会再次进入 Netfilter。\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-highlight-netfilter.png\" width=\"100%\" height=\"100%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003eNetfilter 也会对入向的包进行处理，这里包括 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003enftables\u003c/code\u003e 和 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eiptables\u003c/code\u003e 模块。\u003c/p\u003e\n\n\u003cp\u003e有一点需要记住的是：\u003cstrong\u003eNetfilter 是网络栈的下半部分\u003c/strong\u003e（the “bottom half” of the\nnetwork stack），因此 iptables 规则越多，给网络栈下半部分造成的瓶颈就越大。\u003c/p\u003e\n\n\u003cp\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003e*def_dev_protocol\u003c/code\u003e 框是二层过滤器（L2 net filter），由于 Cilium 没有用到任何 L2\nfilter，因此这里我就不展开了。\u003c/p\u003e\n\n\u003ch3 id=\"step-10l3-协议层处理ip_rcv\"\u003eStep 10：L3 协议层处理：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eip_rcv()\u003c/code\u003e\u003c/h3\u003e\n\n\u003cp\u003e最后，如果包没有被前面丢弃，就会通过网络设备的 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eip_rcv()\u003c/code\u003e 方法进入协议栈的三层（\nL3）—— 即 IP 层 —— 进行处理。\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-highlight-ip-rcv.png\" width=\"100%\" height=\"100%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e接下来我们将主要关注这个函数，但这里需要提醒大家的是，Linux 内核也支持除了 IP 之\n外的其他三层协议，它们的 datapath 会与此有些不同。\u003c/p\u003e\n\n\u003ch2 id=\"64-l3---l4网络层---传输层\"\u003e6.4 L3 -\u0026gt; L4（网络层 -\u0026gt; 传输层）\u003c/h2\u003e\n\n\u003ch3 id=\"step-11netfilter-l4-处理\"\u003eStep 11：Netfilter L4 处理\u003c/h3\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-highlight-netfilter-l4.png\" width=\"100%\" height=\"100%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eip_rcv()\u003c/code\u003e 做的第一件事情是再次执行 Netfilter 过滤，因为我们现在是从四层（L4）的\n视角来处理 socker buffer。因此，这里会执行 Netfilter 中的任何四层规则（L4 rules\n）。\u003c/p\u003e\n\n\u003ch3 id=\"step-12ip_rcv_finish-处理\"\u003eStep 12：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eip_rcv_finish()\u003c/code\u003e 处理\u003c/h3\u003e\n\n\u003cp\u003eNetfilter 执行完成后，调用回调函数 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eip_rcv_finish()\u003c/code\u003e。\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-highlight-ip-rcv-finish.png\" width=\"100%\" height=\"100%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eip_rcv_finish()\u003c/code\u003e 立即调用 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eip_routing()\u003c/code\u003e 对包进行路由判断。\u003c/p\u003e\n\n\u003ch3 id=\"step-13ip_routing-处理\"\u003eStep 13：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eip_routing()\u003c/code\u003e 处理\u003c/h3\u003e\n\n\u003cp\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eip_routing()\u003c/code\u003e 对包进行路由判断，例如看它是否是在 lookback 设备上，是否能\n路由出去（could egress），或者能否被路由，能否被 unmangle 到其他设备等等。\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-highlight-ip-routing.png\" width=\"100%\" height=\"100%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e在 Cilium 中，如果没有使用隧道模式（tunneling），那就会用到这里的路由功能。相比\n隧道模式，路由模式会的 datapath 路径更短，因此性能更高。\u003c/p\u003e\n\n\u003ch3 id=\"step-14目的是本机ip_local_deliver-处理\"\u003eStep 14：目的是本机：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eip_local_deliver()\u003c/code\u003e 处理\u003c/h3\u003e\n\n\u003cp\u003e根据路由判断的结果，\u003cstrong\u003e如果包的目的端是本机\u003c/strong\u003e，会调用 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eip_local_deliver()\u003c/code\u003e 方法。\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-highlight-ip-local-deliver.png\" width=\"100%\" height=\"100%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eip_local_deliver()\u003c/code\u003e 会调用 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003exfrm4_policy()\u003c/code\u003e。\u003c/p\u003e\n\n\u003ch3 id=\"step-15xfrm4_policy-处理\"\u003eStep 15：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003exfrm4_policy()\u003c/code\u003e 处理\u003c/h3\u003e\n\n\u003cp\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003exfrm4_policy()\u003c/code\u003e 完成对包的\u003cstrong\u003e封装、解封装、加解密\u003c/strong\u003e等工作。例如，IPSec 就是在这里完成的。\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-highlight-xfrm4-policy.png\" width=\"100%\" height=\"100%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e最后，根据四层协议的不同，\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eip_local_deliver()\u003c/code\u003e 会将最终的包送到 TCP 或 UDP 协议\n栈。这里必须是这两种协议之一，否则设备会给源 IP 地址回一个\n\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eICMP destination unreachable\u003c/code\u003e 消息。\u003c/p\u003e\n\n\u003cp\u003e接下来我将拿 UDP 协议作为例子，因为 TCP 状态机太复杂了，不适合这里用于理解\ndatapath 和数据流。但不是说 TCP 不重要，Linux TCP 状态机还是非常值得好好学习的。\u003c/p\u003e\n\n\u003ch2 id=\"65-l4传输层以-udp-为例\"\u003e6.5 L4（传输层，以 UDP 为例）\u003c/h2\u003e\n\n\u003ch3 id=\"step-16udp_rcv-处理\"\u003eStep 16：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eudp_rcv()\u003c/code\u003e 处理\u003c/h3\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-highlight-udp-rcv.png\" width=\"50%\" height=\"50%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eudp_rcv()\u003c/code\u003e 对包的合法性进行验证，检查 UDP 校验和。然后，再次将包送到\n\u003ccode class=\"language-plaintext highlighter-rouge\"\u003exfrm4_policy()\u003c/code\u003e 进行处理。\u003c/p\u003e\n\n\u003ch3 id=\"step-17xfrm4_policy-再次处理\"\u003eStep 17：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003exfrm4_policy()\u003c/code\u003e 再次处理\u003c/h3\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-highlight-xfrm4-policy-after-udp-rcv.png\" width=\"50%\" height=\"50%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e这里再次对包执行 transform policies 是因为，某些规则能指定具体的四层协议，所以只\n有到了协议层之后才能执行这些策略。\u003c/p\u003e\n\n\u003ch3 id=\"step-18将包放入-socket_receive_queue\"\u003eStep 18：将包放入 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003esocket_receive_queue\u003c/code\u003e\u003c/h3\u003e\n\n\u003cp\u003e这一步会拿端口（port）查找相应的 socket，然后将 skb 放到一个名为\n\u003ccode class=\"language-plaintext highlighter-rouge\"\u003esocket_receive_queue\u003c/code\u003e 的链表。\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-highlight-socket-receive-queue.png\" width=\"50%\" height=\"50%\"/\u003e\u003c/p\u003e\n\n\u003ch3 id=\"step-19通知-socket-收数据sk_data_ready\"\u003eStep 19：通知 socket 收数据：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003esk_data_ready()\u003c/code\u003e\u003c/h3\u003e\n\n\u003cp\u003e最后，\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eudp_rcv()\u003c/code\u003e 调用 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003esk_data_ready()\u003c/code\u003e 方法，标记这个 socket 有数据待收。\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/dp-highlight-sk-data-ready.png\" width=\"50%\" height=\"50%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e本质上，一个 socket 就是 Linux 中的一个文件描述符，这个描述符有一组相关的文件操\n作抽象，例如 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eread\u003c/code\u003e、\u003ccode class=\"language-plaintext highlighter-rouge\"\u003ewrite\u003c/code\u003e 等等。\u003c/p\u003e\n\n\u003ch3 id=\"网络栈下半部分小结\"\u003e网络栈下半部分小结\u003c/h3\u003e\n\n\u003cp\u003e以上 \u003cstrong\u003eStep 1~19 就是 Linux 网络栈下半部分（bottom half of the network stack）的全部内容\u003c/strong\u003e。\u003c/p\u003e\n\n\u003cp\u003e接下来我们还会介绍几个内核函数，但它们都是与进程上下文相关的。\u003c/p\u003e\n\n\u003ch2 id=\"66-l4---user-space\"\u003e6.6 L4 - User Space\u003c/h2\u003e\n\n\u003cp\u003e下图左边是一段 socket listening 程序，这里省略了错误检查，而且 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eepoll\u003c/code\u003e 本质上也\n是不需要的，因为 UDP 的 recv 方法以及在帮我们 poll 了。\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/ebpf-datapath-in-cilium/userspace-sample.png\" width=\"100%\" height=\"100%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e由于大家还是对 TCP 熟悉一些，因此在这里我假设这是一段 TCP 代码。\u003cstrong\u003e事实上当我们调\n用 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003erecvmsg()\u003c/code\u003e 方法时，内核所做的事情就和上面这段代码差不多\u003c/strong\u003e。对照右边的图：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e首先初始化一个 epoll 实例和一个 UDP socket，然后告诉 epoll 实例我们想\n监听这个 socket 上的 receive 事件，然后等着事件到来。\u003c/li\u003e\n  \u003cli\u003e当 socket buffer 收到数据时，其 wait queue 会被上一节的 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003esk_data_ready()\u003c/code\u003e\n方法置位（标记）。\u003c/li\u003e\n  \u003cli\u003eepoll 监听在 wait queue，因此 epoll 收到事件通知后，提取事件内容，返回给用户空间。\u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e用户空间程序调用 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003erecv\u003c/code\u003e 方法，它接着调用 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eudp_recv_msg\u003c/code\u003e 方法，后者又会\n调用 \u003cstrong\u003ecgroup eBPF 程序\u003c/strong\u003e —— 这是本文出现的第三种 BPF 程序。\u003cstrong\u003eCilium 利用\ncgroup eBPF 实现 socket level 负载均衡\u003c/strong\u003e，这非常酷：\u003c/p\u003e\n\n    \u003cul\u003e\n      \u003cli\u003e一般的客户端负载均衡对客户端并不是透明的，即，客户端应用必须将负载均衡逻辑内置到应用里。\u003c/li\u003e\n      \u003cli\u003e有了 cgroup BPF，客户端根本感知不到负载均衡的存在。\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e本文介绍的最后一种 BPF 程序是 \u003cstrong\u003esock_ops BPF，用于 socket level 整流\u003c/strong\u003e（traffic shaping\n），这对某些功能至关重要，例如客户端级别的限速（rate limiting）。\u003c/li\u003e\n  \u003cli\u003e最后，我们有一个用户空间缓冲区，存放收到的数据。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e以上就是 \u003cstrong\u003eCilium 基于 eBPF 的内核收包之旅\u003c/strong\u003e（traversing the kernel’s datapath）。太壮观了！\u003c/p\u003e\n\n\u003ch1 id=\"7-kubernetscilium-和-kernel原子对象对应关系\"\u003e7 Kubernets、Cilium 和 Kernel：原子对象对应关系\u003c/h1\u003e\n\n\u003ctable\u003e\n  \u003cthead\u003e\n    \u003ctr\u003e\n      \u003cth style=\"text-align: left\"\u003eKubernetes\u003c/th\u003e\n      \u003cth style=\"text-align: left\"\u003eCilium\u003c/th\u003e\n      \u003cth style=\"text-align: left\"\u003eKernel\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"text-align: left\"\u003eEndpoint (includes Pods)\u003c/td\u003e\n      \u003ctd style=\"text-align: left\"\u003eEndpoint\u003c/td\u003e\n      \u003ctd style=\"text-align: left\"\u003etc, cgroup socket BPF, sock_ops BPF, XDP\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"text-align: left\"\u003eNetwork Policy\u003c/td\u003e\n      \u003ctd style=\"text-align: left\"\u003eCilium Network Policy\u003c/td\u003e\n      \u003ctd style=\"text-align: left\"\u003eXDP, tc, sock-ops\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"text-align: left\"\u003eService (node ports, cluster ips, etc)\u003c/td\u003e\n      \u003ctd style=\"text-align: left\"\u003eService\u003c/td\u003e\n      \u003ctd style=\"text-align: left\"\u003eXDP, tc\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"text-align: left\"\u003eNode\u003c/td\u003e\n      \u003ctd style=\"text-align: left\"\u003eNode\u003c/td\u003e\n      \u003ctd style=\"text-align: left\"\u003eip-xfrm (for encryption), ip tables for initial decapsulation routing (if vxlan), veth-pair, ipvlan\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\n\u003cp\u003e以上就是 Kubernetes 的所有网络对象（the only artificial network objects）。什么意思？\n这就是 k8s CNI 所依赖的全部网络原语（network primitives）。例如，LoadBalancer\n对象只是 ClusterIP 和 NodePort 的组合，而后二者都属于 Service 对象，所以他们并不\n是一等对象。\u003c/p\u003e\n\n\u003cp\u003e这张图非常有价值，但不幸的是，实际情况要比这里列出的更加复杂，因为 Cilium 本身的\n实现是很复杂的。这有两个主要原因，我觉得值得拿出来讨论和体会：\u003c/p\u003e\n\n\u003cp\u003e首先，内核 datapath 要远比我这里讲的复杂。\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e前面只是非常简单地介绍了协议栈每个位置（Netfilter、iptables、eBPF、XDP）能执行的动作。\u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e这些位置提供的处理能力是不同的。例如\u003c/p\u003e\n\n    \u003col\u003e\n      \u003cli\u003eXDP 可能是能力最受限的，因为它只是设计用来做\u003cstrong\u003e快速丢包\u003c/strong\u003e（fast dropping）和\n\u003cstrong\u003e非本地重定向\u003c/strong\u003e（non-local redirecting）；但另一方面，它又是最快的程序，因为\n它在整个 datapath 的最前面，具备对整个 datapath 进行短路处理（short\ncircuit the entire datapath）的能力。\u003c/li\u003e\n      \u003cli\u003etc 和 iptables 程序能方便地 mangle 数据包，而不会对原来的转发流程产生显著影响。\u003c/li\u003e\n    \u003c/ol\u003e\n  \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e理解这些东西非常重要，因为\u003cstrong\u003e这是 Cilium 乃至广义 datapath 里非常核心的东西\u003c/strong\u003e。如\n果遇到底层网络问题，或者需要做 Cilium/kernel 调优，那你必须要理解包的收发/转发\n路径，有时你会发现包的某些路径非常反直觉。\u003c/p\u003e\n\n\u003cp\u003e第二个原因是，eBPF 还非常新，某些最新特性只有在 5.x 内核中才有。尤其是 XDP BPF，\n可能一个节点的内核版本支持，调度到另一台节点时，可能就不支持。\u003c/p\u003e\n\n\u003ch1 id=\"8-demo\"\u003e8 Demo\u003c/h1\u003e\n\n\u003cp\u003e略，视频见 \u003ca href=\"https://www.youtube.com/watch?v=Kmm8Hl57WDU\"\u003e油管\u003c/a\u003e。\u003c/p\u003e\n\n\n  \u003c!-- POST NAVIGATION --\u003e\n  \u003cdiv class=\"postNav clearfix\"\u003e\n     \n      \u003ca class=\"prev\" href=\"/blog/cilium-code-clustermesh/\"\u003e\u003cspan\u003e« Cilium: What the Agents Do When ClusterMesh Enabled\u003c/span\u003e\n      \n    \u003c/a\u003e\n      \n      \n      \u003ca class=\"next\" href=\"/blog/ebpf-and-k8s-zh/\"\u003e\u003cspan\u003e[译] 大规模微服务利器：eBPF + Kubernetes（KubeCon, 2020） »\u003c/span\u003e\n       \n      \u003c/a\u003e\n     \n  \u003c/div\u003e\n\u003c/div\u003e",
  "Date": "2020-09-04T00:00:00Z",
  "Author": "Arthur Chiao"
}