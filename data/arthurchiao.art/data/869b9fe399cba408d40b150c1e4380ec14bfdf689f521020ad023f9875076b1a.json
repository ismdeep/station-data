{
  "Source": "arthurchiao.art",
  "Title": "[译] Meta/Facebook 超大规模 AI/GPU 基础设施设计（2024）",
  "Link": "https://arthurchiao.art/blog/meta-ai-infra-zh/",
  "Content": "\u003cdiv class=\"post\"\u003e\n  \n  \u003ch1 class=\"postTitle\"\u003e[译] Meta/Facebook 超大规模 AI/GPU 基础设施设计（2024）\u003c/h1\u003e\n  \u003cp class=\"meta\"\u003ePublished at 2024-04-21 | Last Update 2024-04-21\u003c/p\u003e\n  \n  \u003cp\u003e本文翻译自 2024 年 Meta/Facebook 的一篇文章：\n\u003ca href=\"https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/\"\u003eBuilding Meta’s GenAI Infrastructure\u003c/a\u003e。\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e两个 GPU 集群，每个集群 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003e2.4w H100\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e，分别用 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eRoCE/InfiniBand\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e 网络；\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003eLLaMA3 就是在这两个集群上训练出来的\u003c/mark\u003e\u003c/strong\u003e；\u003c/li\u003e\n  \u003cli\u003e预计到 2024 年底，Meta AI 基础设施建设将拥有 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003e35w 张 H100\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e GPU，总算力相当于约 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003e60w 张 H100\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/meta-ai-infra/Meta-24K-GenAi-Clusters-hero.webp\" width=\"100%\" height=\"100%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e水平及维护精力所限，译文不免存在错误或过时之处，如有疑问，请查阅原文。\n\u003cstrong\u003e\u003cmark\u003e传播知识，尊重劳动，年满十八周岁，转载请注明\u003ca href=\"https://arthurchiao.art\"\u003e出处\u003c/a\u003e\u003c/mark\u003e\u003c/strong\u003e。\u003c/p\u003e\n\n\u003cp\u003e以下是译文。\u003c/p\u003e\n\n\u003chr/\u003e\n\n\u003cul id=\"markdown-toc\"\u003e\n  \u003cli\u003e\u003ca href=\"#1-第一代-gpu-集群16w-a100-rsc\" id=\"markdown-toc-1-第一代-gpu-集群16w-a100-rsc\"\u003e1 第一代 GPU 集群：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003e1.6w A100\u003c/code\u003e (RSC)\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#2-第二代-gpu-集群24w-h100\" id=\"markdown-toc-2-第二代-gpu-集群24w-h100\"\u003e2 第二代 GPU 集群：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003e2.4w H100\u003c/code\u003e\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#21-计算grand-teton-gpu-主机\" id=\"markdown-toc-21-计算grand-teton-gpu-主机\"\u003e2.1 计算：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eGrand Teton\u003c/code\u003e GPU 主机\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#22-网络\" id=\"markdown-toc-22-网络\"\u003e2.2 网络\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#221-集群一400gbps-roce--自研交换机\" id=\"markdown-toc-221-集群一400gbps-roce--自研交换机\"\u003e2.2.1 集群一：400Gbps RoCE + 自研交换机\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#222-集群二400gbps-infiniband\" id=\"markdown-toc-222-集群二400gbps-infiniband\"\u003e2.2.2 集群二：400Gbps InfiniBand\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#223-小结\" id=\"markdown-toc-223-小结\"\u003e2.2.3 小结\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#23-存储\" id=\"markdown-toc-23-存储\"\u003e2.3 存储\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#231-数据和-checkpoints-存储fuse--tectonic\" id=\"markdown-toc-231-数据和-checkpoints-存储fuse--tectonic\"\u003e2.3.1 数据和 checkpoints 存储：FUSE + Tectonic\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#232-交互式调试parallel-nfs\" id=\"markdown-toc-232-交互式调试parallel-nfs\"\u003e2.3.2 交互式调试：Parallel NFS\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#233-大容量-ssd--定制每个机柜的服务器数量\" id=\"markdown-toc-233-大容量-ssd--定制每个机柜的服务器数量\"\u003e2.3.3 大容量 SSD + 定制每个机柜的服务器数量\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#3-性能\" id=\"markdown-toc-3-性能\"\u003e3 性能\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#31-原则性能和易用性缺一不可\" id=\"markdown-toc-31-原则性能和易用性缺一不可\"\u003e3.1 原则：性能和易用性缺一不可\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#32-大集群优化\" id=\"markdown-toc-32-大集群优化\"\u003e3.2 大集群优化\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#4-对-open-ai-innovation-的承诺\" id=\"markdown-toc-4-对-open-ai-innovation-的承诺\"\u003e4 对 open AI innovation 的承诺\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#5-未来展望\" id=\"markdown-toc-5-未来展望\"\u003e5 未来展望\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003chr/\u003e\n\n\u003cp\u003e作为对未来人工智能的重要投资，Meta 打造了两个大规模 AI 集群，每个集群由 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003e2.4w 张 GPU\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e 组成，\n本文分享其计算、网络、存储等设计细节。\u003c/p\u003e\n\n\u003ch1 id=\"1-第一代-gpu-集群16w-a100-rsc\"\u003e1 第一代 GPU 集群：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003e1.6w A100\u003c/code\u003e (RSC)\u003c/h1\u003e\n\n\u003cp\u003eMeta 很早就开始构建 AI 基础设施，但第一次对外分享是在 2022 年，介绍了我们的\n\u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eResearch SuperCluster\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e\n（\u003ca href=\"https://ai.meta.com/blog/ai-rsc/\"\u003eRSC\u003c/a\u003e），它由 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003e1.6w 个 A100\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e GPU 组成。\u003c/p\u003e\n\n\u003cp\u003eRSC 支撑了 Meta 第一代先进 AI 模型的开发，在训练 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eLlama/llama2\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e、\n计算机视觉、NLP、语音识别、图像生成甚至编码等 AI 工作中发挥了重要作用。\u003c/p\u003e\n\n\u003ch1 id=\"2-第二代-gpu-集群24w-h100\"\u003e2 第二代 GPU 集群：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003e2.4w H100\u003c/code\u003e\u003c/h1\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e精确数字是每个集群 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003e24,576\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e 张 H100 GPU。\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003e我们的新一代 AI 集群充分吸收了 RSC 的成功和经验教训，这包括，\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e新集群致力于构建\u003cstrong\u003e\u003cmark\u003e端到端的 AI 系统\u003c/mark\u003e\u003c/strong\u003e，特别强调\u003cstrong\u003e\u003cmark\u003e研究人员和开发人员的用户体验和工作效率\u003c/mark\u003e\u003c/strong\u003e；\u003c/li\u003e\n  \u003cli\u003e新集群能支持更大、更复杂的模型，为 GenAI 产品开发和 AI 研究的进步铺平了道路。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eMeta 每天需要执行数以万亿计的 AI 任务，这就需要一个高度先进和灵活的基础设施。\n我们\u003cstrong\u003e\u003cmark\u003e自研了大部分硬件、软件和网络 fabric\u003c/mark\u003e\u003c/strong\u003e，使我们能进行端到端优化，确保数据中心的高效运行。\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/meta-ai-infra/Meta-24K-GenAi-Clusters-hero.webp\" width=\"100%\" height=\"100%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n左侧：\u003cmark\u003e计算机柜\u003c/mark\u003e，包括 GPU 服务器机框，置顶交换机，fabric 交换机等等；右侧：\u003cmark\u003e存储机柜\u003c/mark\u003e。\n\u003c/p\u003e\n\n\u003ch2 id=\"21-计算grand-teton-gpu-主机\"\u003e2.1 计算：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eGrand Teton\u003c/code\u003e GPU 主机\u003c/h2\u003e\n\n\u003cp\u003e两个新集群都使用了 \u003ca href=\"https://engineering.fb.com/2022/10/18/open-source/ocp-summit-2022-grand-teton/\"\u003eGrand Teton\u003c/a\u003e，\n这是 Meta 开发的\u003cstrong\u003e\u003cmark\u003e开放 GPU 硬件平台\u003c/mark\u003e\u003c/strong\u003e，我们已经将其贡献给了开放计算项目（OCP）。\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e从 2015 年的 \u003ca href=\"https://engineering.fb.com/2015/12/10/ml-applications/facebook-to-open-source-ai-hardware-design/\"\u003eBig Sur\u003c/a\u003e 平台开始，\n我们就一直在开放设计我们的 GPU 硬件平台。\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eGrand Teton 实物图如下，\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/meta-ai-infra/Meta-Grand-Teton.webp\" width=\"90%\" height=\"90%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003e\u003ca href=\"https://engineering.fb.com/2022/10/18/open-source/ocp-summit-2022-grand-teton/\"\u003eImage Source\u003c/a\u003e\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e将 CPU 机头、GPU、交换机同步系统、电源等等集成到一个机框中，以获得更好的整体性能；\u003c/li\u003e\n  \u003cli\u003e提供了快速可扩展性和灵活性，设计简化，可以快速部署到数据中心，并易于维护和扩展。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e结合 \u003ca href=\"https://engineering.fb.com/2022/10/18/open-source/ocp-summit-2022-grand-teton/\"\u003eOpen Rack\u003c/a\u003e 电源和机架架构\n等其他内部创新，我们能为 Meta 当前和未来应用程序快速量身定制新集群。\u003c/p\u003e\n\n\u003ch2 id=\"22-网络\"\u003e2.2 网络\u003c/h2\u003e\n\n\u003cp\u003e两个集群使用了不同的网络方案，但都是 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003e400Gbps\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e 接入。\u003c/p\u003e\n\n\u003ch3 id=\"221-集群一400gbps-roce--自研交换机\"\u003e2.2.1 集群一：400Gbps RoCE + 自研交换机\u003c/h3\u003e\n\n\u003cp\u003e基于 RoCE 网络，使用的交换机包括\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e自研置顶交换机（\u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eTOR\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e）\u003ca href=\"https://engineering.fb.com/2021/11/09/data-center-engineering/ocp-summit-2021/\"\u003eWedge400\u003c/a\u003e\n/ \u003ca href=\"https://www.arista.com/assets/data/pdf/Datasheets/7800R3-Data-Sheet.pdf\"\u003eArista 7800\u003c/a\u003e ，\u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e自研\u003cstrong\u003e\u003cmark\u003e模块化交换机\u003c/mark\u003e\u003c/strong\u003e \u003ca href=\"https://engineering.fb.com/2021/11/09/data-center-engineering/ocp-summit-2021/\"\u003eMinipack2\u003c/a\u003e。\u003c/p\u003e\n\n    \u003cul\u003e\n      \u003cli\u003eMinipack/Minipack2 在组网中能承担多种角色，例如作为 Spine 交换机，\u003c/li\u003e\n      \u003cli\u003e第一代 Minipack：\u003ca href=\"/blog/facebook-f16-minipack-zh/\"\u003e(译) 重新设计 Facebook 的数据中心网络（2019）\u003c/a\u003e。\u003c/li\u003e\n      \u003cli\u003e更早一点的数据中心网络：\u003ca href=\"/blog/facebook-f4-data-center-fabric-zh/\"\u003e(译) 数据中心 Fabric：Facebook 的下一代数据中心网络（2014）\u003c/a\u003e。\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"222-集群二400gbps-infiniband\"\u003e2.2.2 集群二：400Gbps InfiniBand\u003c/h3\u003e\n\n\u003cp\u003e使用 NVIDIA Quantum2 InfiniBand fabric。\u003c/p\u003e\n\n\u003ch3 id=\"223-小结\"\u003e2.2.3 小结\u003c/h3\u003e\n\n\u003cp\u003e两个方案作对比，使我们能够评估 RoCE/IB 在大规模训练中的适用性和可扩展性，\n为设计和构建更大规模的集群提供了宝贵经验。\n目前这两个不同组网类型的集群都能够运行大型生成式 AI 任务\n（例如在 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eRoCE\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e 集群上训练 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eLlama 3\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e），\n而没有遇到网络瓶颈。\u003c/p\u003e\n\n\u003ch2 id=\"23-存储\"\u003e2.3 存储\u003c/h2\u003e\n\n\u003cp\u003e存储在 AI 训练中扮演着重要角色，然而相关的讨论确非常少。\u003c/p\u003e\n\n\u003cp\u003e最近的发展趋势可以看出，GenAI 任务越来越多模态，需要处理大量图像、视频和文本，因此对高性能存储的需求越来越强烈。\n理想的存储方案\u003cstrong\u003e\u003cmark\u003e除了提供良好的性能，还要做到低能耗\u003c/mark\u003e\u003c/strong\u003e。\u003c/p\u003e\n\n\u003ch3 id=\"231-数据和-checkpoints-存储fuse--tectonic\"\u003e2.3.1 数据和 checkpoints 存储：FUSE + Tectonic\u003c/h3\u003e\n\n\u003cp\u003e我们 AI 集群的数据和 checkpoint 的存储方案：\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e上层是一个自研的 Linux 用户空间文件系统（FUSE）\u003c/li\u003e\n  \u003cli\u003e底层是 Meta 的名为 \u003ca href=\"https://www.usenix.org/conference/fast21/presentation/pan\"\u003eTectonic 的分布式存储解决方案\u003c/a\u003e，它针对闪存（Flash media）进行了优化。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e这个解决方案使得\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e数千个 GPU 能同步保存和加载 checkpoints（对任何存储解决方案来说都是一个\u003ca href=\"https://en.wikipedia.org/wiki/Thundering_herd_problem#:~:text=In%20computer%20science%2C%20the%20thundering,able%20to%20handle%20the%20event.\"\u003e挑战\u003c/a\u003e），\u003c/li\u003e\n  \u003cli\u003e同时还提供了 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eEB\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e 级存储系统所需的灵活性和高吞吐。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"232-交互式调试parallel-nfs\"\u003e2.3.2 交互式调试：Parallel NFS\u003c/h3\u003e\n\n\u003cp\u003e我们还与 \u003ca href=\"https://hammerspace.com/software/\"\u003eHammerspace\u003c/a\u003e 合作开发了一个并行网络文件系统（NFS），\n它使工程师能够使用\u003cstrong\u003e\u003cmark\u003e数千个 GPU 进行交互式调试\u003c/mark\u003e\u003c/strong\u003e，\n因为代码改动能立即同步到环境中的所有节点。\u003c/p\u003e\n\n\u003cp\u003eTectonic 分布式存储加上 Hammerspace，既能满足快速迭代，又不会限制规模。\u003c/p\u003e\n\n\u003ch3 id=\"233-大容量-ssd--定制每个机柜的服务器数量\"\u003e2.3.3 大容量 SSD + 定制每个机柜的服务器数量\u003c/h3\u003e\n\n\u003cp\u003e无论是 Tectonic 还是 Hammerspace 方案，都基于 \n\u003ca href=\"https://www.opencompute.org/documents/e1s-expansion-2ou-1s-server-design-specification-pdf\"\u003eYV3 Sierra Point server platform\u003c/a\u003e，\n使用了我们在市场上能够买到的最新高容量 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eE1.S SSD\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e。\u003c/p\u003e\n\n\u003cp\u003e除此之外，\u003cstrong\u003e\u003cmark\u003e每个机架塞的服务器数量\u003c/mark\u003e\u003c/strong\u003e也进行了定制，以在服务器吞吐量、机架数量和能效之间取得一个平衡。\u003c/p\u003e\n\n\u003cp\u003eOCP 服务器就像乐高积木，使我们的存储层能够灵活扩展到未来更大 AI 集群的需求，而且不影响日常基础设施的使用和维护操作。\u003c/p\u003e\n\n\u003ch1 id=\"3-性能\"\u003e3 性能\u003c/h1\u003e\n\n\u003ch2 id=\"31-原则性能和易用性缺一不可\"\u003e3.1 原则：性能和易用性缺一不可\u003c/h2\u003e\n\n\u003cp\u003e我们构建大规模 AI 集群的一个原则是，同时最大化性能和易用性，而不是为了一个而牺牲另一个。\n这是训练最佳 AI 模型的重要基础。\u003c/p\u003e\n\n\u003cp\u003e测试\u003cstrong\u003e\u003cmark\u003e系统设计的扩展性\u003c/mark\u003e\u003c/strong\u003e的最佳方法就是先构建出一个系统，然后不断优化它，并进行实际测试（模拟器有帮助，但作用有限）。\n通过这个过程，我们比较了小集群和大集群的性能，定位瓶颈在哪里。\n下图显示了当大量 GPU 相互通信时（at message sizes where roofline performance is expected）的 AllGather 性能（带宽归一化到 0-100），\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/meta-ai-infra/Meta-24K-GenAi-clusters-performance.webp\" width=\"70%\" height=\"70%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003e\nsmall cluster performance (overall communication bandwidth and\nutilization) reaches 90%+ out of the box, but an unoptimized large cluster\nperformance has very poor utilization, ranging from 10% to 90%. After we\noptimize the full system (software, network, etc.), we see large cluster\nperformance return to the ideal 90%+ range.\n\u003c/p\u003e\n\n\u003ch2 id=\"32-大集群优化\"\u003e3.2 大集群优化\u003c/h2\u003e\n\n\u003cp\u003e与优化过的小型集群性能相比，我们的大集群一开始性能是比较差的。\n为了解决这个问题，我们做了如下优化：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\n    \u003cp\u003e改进 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003ejob scheduler\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e，使其具备\u003cstrong\u003e\u003cmark\u003e网络拓扑感知能力\u003c/mark\u003e\u003c/strong\u003e，这带来的好处：\u003c/p\u003e\n\n    \u003col\u003e\n      \u003cli\u003e延迟降低\u003c/li\u003e\n      \u003cli\u003e转发到更上层网络（交换机）的流量减少。\u003c/li\u003e\n    \u003c/ol\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e结合 NVIDIA \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eNCCL\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e，优化了\u003cstrong\u003e\u003cmark\u003e网络路由策略\u003c/mark\u003e\u003c/strong\u003e，以实现最优的网络利用率。\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e以上两项优化使大集群的性能已经接近小集群。\u003c/p\u003e\n\n\u003cp\u003e除此之外，我们还\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\n    \u003cp\u003e与\u003cstrong\u003e\u003cmark\u003e训练框架和模型团队\u003c/mark\u003e\u003c/strong\u003e密切合作，不断改进基础设施。例如，\u003c/p\u003e\n\n    \u003col\u003e\n      \u003cli\u003e支持 NVIDIA H100 GPU 的\u003cstrong\u003e\u003cmark\u003e新数据类型\u003c/mark\u003e\u003c/strong\u003e FP8，这对训练性能大有帮助，\u003c/li\u003e\n      \u003cli\u003e并行技术优化，\u003c/li\u003e\n      \u003cli\u003e存储优化，\u003c/li\u003e\n    \u003c/ol\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e意识到\u003cstrong\u003e\u003cmark\u003e可调试性\u003c/mark\u003e\u003c/strong\u003e（debuggability）是大规模训练的主要挑战之一。\n  在大规模情况下，定位到哪个 GPU 卡顿导致的整个训练作业变慢是非常困难的。\n  为此，我们正在构建 desync debug 或分布式 flight recorder 之类的工具，\u003cstrong\u003e\u003cmark\u003e跟踪分布式训练的过程\u003c/mark\u003e\u003c/strong\u003e，以更快识别问题。\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e继续开发基础 AI 框架 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003ePyTorch\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e，使其能支持数万甚至数十万 GPU 进行训练。\n  例如，我们已经定位到进程组初始化方面的几个瓶颈，将启动时间从有时的几小时减少到几分钟。\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch1 id=\"4-对-open-ai-innovation-的承诺\"\u003e4 对 open AI innovation 的承诺\u003c/h1\u003e\n\n\u003cp\u003eMeta 保持对 AI 软件和硬件开放创新的承诺，我们始终相信\u003cstrong\u003e\u003cmark\u003e开源硬件和软件\u003c/mark\u003e\u003c/strong\u003e是帮助行业解决大规模问题的有用工具。\n我们将\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e继续作为 OCP 的创始成员支持\u003cstrong\u003e\u003cmark\u003e开放硬件创新\u003c/mark\u003e\u003c/strong\u003e，例如已经将 Grand Teton 和 Open Rack 等设计贡献给 OCP 社区。\u003c/li\u003e\n  \u003cli\u003e作为 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003ePyTorch\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e 的最大和主要贡献者，继续推动这一 AI 软件框架的开发和普及。\u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e继续致力于 AI 研究社区的开放创新。\u003c/p\u003e\n\n    \u003cul\u003e\n      \u003cli\u003e我们发起了开放\u003ca href=\"https://ai.meta.com/llama/open-innovation-ai-research-community\"\u003e创新 AI 研究社区\u003c/a\u003e，\n旨在深化我们对如何负责任地开发和共享 AI 技术（尤其是大模型）的理解。\u003c/li\u003e\n      \u003cli\u003e我们还推出了 \u003ca href=\"https://ai.meta.com/blog/ai-alliance/\"\u003eAI Alliance\u003c/a\u003e，这是一个由 AI 行业领先组织组成的小组，专注于在开放社区内加速负责任的 AI 创新。\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e我们的 AI 工作建立在开放科学和协力合作的哲学之上。\u003c/p\u003e\n\n\u003ch1 id=\"5-未来展望\"\u003e5 未来展望\u003c/h1\u003e\n\n\u003cp\u003e本文介绍的两个 AI 训练集群是我们未来 AI 路线图的一部分。\n预计到 2024 年底，Meta AI 基础设施建设将拥有 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003e35w 张 H100\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e GPU，总算力相当于约 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003e60w 张 H100\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e。\u003c/p\u003e\n\n\u003cp\u003e当前有效的方法可能不足以满足明天的需求，这也是为什么我们一直在各个方面不断评估和改进我们的基础设施，\n包括物理硬件层、虚拟层、软件层以及更上面的业务层等等。\n我们的目标是创建灵活可靠的系统，以支持日新月异的新模型和研究。\u003c/p\u003e\n\n\u003chr/\u003e\n\n\u003cp\u003e\u003ca href=\"https://notbyai.fyi\"\u003e\u003cimg src=\"/assets/img/Written-By-Human-Not-By-AI-Badge-white.svg\" alt=\"Written by Human, Not by AI\"/\u003e\u003c/a\u003e\n\u003ca href=\"https://notbyai.fyi\"\u003e\u003cimg src=\"/assets/img/Written-By-Human-Not-By-AI-Badge-black.svg\" alt=\"Written by Human, Not by AI\"/\u003e\u003c/a\u003e\u003c/p\u003e\n\n\n  \u003c!-- POST NAVIGATION --\u003e\n  \u003cdiv class=\"postNav clearfix\"\u003e\n     \n      \u003ca class=\"prev\" href=\"/blog/llm-inference-speed-zh/\"\u003e\u003cspan\u003e« [译] 大模型推理的极限：理论分析、数学建模与 CPU/GPU 实测（2024）\u003c/span\u003e\n      \n    \u003c/a\u003e\n      \n      \n      \u003ca class=\"next\" href=\"/blog/visual-intro-to-transformers-zh/\"\u003e\u003cspan\u003e[译] 什么是 GPT？Transformer 工作原理的动画展示（2024） »\u003c/span\u003e\n       \n      \u003c/a\u003e\n     \n  \u003c/div\u003e\n\u003c/div\u003e",
  "Date": "2024-04-21T00:00:00Z",
  "Author": "Arthur Chiao"
}