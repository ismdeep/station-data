{
  "Source": "arthurchiao.art",
  "Title": "[译] 流量控制（TC）五十年：从基于缓冲队列（Queue）到基于时间（EDT）的演进（Google, 2018）",
  "Link": "https://arthurchiao.art/blog/traffic-control-from-queue-to-edt-zh/",
  "Content": "\u003cdiv class=\"post\"\u003e\n  \n  \u003ch1 class=\"postTitle\"\u003e[译] 流量控制（TC）五十年：从基于缓冲队列（Queue）到基于时间（EDT）的演进（Google, 2018）\u003c/h1\u003e\n  \u003cp class=\"meta\"\u003ePublished at 2022-10-07 | Last Update 2023-02-11\u003c/p\u003e\n  \n  \u003ch3 id=\"译者序\"\u003e译者序\u003c/h3\u003e\n\n\u003cp\u003e本文组合翻译了 Google 2018 年两篇分享中的技术部分，二者讲的同一件事情，但层次侧重不同：\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eNetdev 2018: \u003ca href=\"https://www.youtube.com/watch?v=MAni0_lN7zE\"\u003eEvolving from AFAP: Teaching NICs about time\u003c/a\u003e，\n视角更宏观，因果关系和历史演进讲地较好；\u003c/li\u003e\n  \u003cli\u003eOCT 2018: \u003ca href=\"https://documents.pub/document/oct-2018-david-wetherall-presenter-nandita-dukkipati-talks2018davidwetherall.html\"\u003eFrom Queues to Earliest Departure Time\u003c/a\u003e，更技术和细节一些。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e另外翻译过程中适当补充了一些与 Linux/Cilium/BPF 相关的内容。\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e由于译者水平有限，本文不免存在遗漏或错误之处。如有疑问，请查阅原文。\u003c/strong\u003e\u003c/p\u003e\n\n\u003cp\u003e以下是译文。\u003c/p\u003e\n\n\u003chr/\u003e\n\n\u003cul id=\"markdown-toc\"\u003e\n  \u003cli\u003e\u003ca href=\"#译者序\" id=\"markdown-toc-译者序\"\u003e译者序\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#1-网络起源\" id=\"markdown-toc-1-网络起源\"\u003e1 网络起源\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#11-技术需求与网络起源\" id=\"markdown-toc-11-技术需求与网络起源\"\u003e1.1 技术需求与网络起源\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#12-私有协议和厂商锁定\" id=\"markdown-toc-12-私有协议和厂商锁定\"\u003e1.2 私有协议和厂商锁定\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#13-早期厂商网络方案的问题\" id=\"markdown-toc-13-早期厂商网络方案的问题\"\u003e1.3 早期厂商网络方案的问题\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#14-tcpip-协议模型\" id=\"markdown-toc-14-tcpip-协议模型\"\u003e1.4 TCP/IP 协议模型\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#141-ip尽力而为传输best-effort-delivery\" id=\"markdown-toc-141-ip尽力而为传输best-effort-delivery\"\u003e1.4.1 IP：尽力而为传输（best effort delivery）\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#142-tcp最终可靠传输eventual-delivery\" id=\"markdown-toc-142-tcp最终可靠传输eventual-delivery\"\u003e1.4.2 TCP：最终可靠传输（eventual delivery）\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#143-小结\" id=\"markdown-toc-143-小结\"\u003e1.4.3 小结\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#2-网络传输\" id=\"markdown-toc-2-网络传输\"\u003e2 网络传输\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#21-技术需求越快越好或尽可能快afap\" id=\"markdown-toc-21-技术需求越快越好或尽可能快afap\"\u003e2.1 技术需求：越快越好（或尽可能快，AFAP）\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#22-tcp-发送机制只限制发送多少未限制发送多快\" id=\"markdown-toc-22-tcp-发送机制只限制发送多少未限制发送多快\"\u003e2.2 TCP 发送机制：只限制发送多少，未限制发送多快\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#23-基于-queue-做流量整形\" id=\"markdown-toc-23-基于-queue-做流量整形\"\u003e2.3 基于 queue 做流量整形\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#231-流量整形器shaper原理以-token-bucket-queue-为例\" id=\"markdown-toc-231-流量整形器shaper原理以-token-bucket-queue-为例\"\u003e2.3.1 流量整形器（shaper）原理：以 token bucket queue 为例\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#232-afap-shaper-历史贡献支撑-tcpip-在过去-25-年速度-10000x\" id=\"markdown-toc-232-afap-shaper-历史贡献支撑-tcpip-在过去-25-年速度-10000x\"\u003e2.3.2 AFAP shaper 历史贡献：支撑 TCP/IP 在过去 25 年速度 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e10000x\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#233-面临的问题延迟和丢包\" id=\"markdown-toc-233-面临的问题延迟和丢包\"\u003e2.3.3 面临的问题：延迟和丢包\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#234-缓解避免丢包的方式2012-年之前\" id=\"markdown-toc-234-缓解避免丢包的方式2012-年之前\"\u003e2.3.4 缓解/避免丢包的方式（2012 年之前）\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#23-带宽摩尔定律失速2012-年之后\" id=\"markdown-toc-23-带宽摩尔定律失速2012-年之后\"\u003e2.3 带宽摩尔定律失速（2012 年之后）\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#3-google-网络团队的一些创新\" id=\"markdown-toc-3-google-网络团队的一些创新\"\u003e3 Google 网络团队的一些创新\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#31-思路转变从基于-queue-到基于-time\" id=\"markdown-toc-31-思路转变从基于-queue-到基于-time\"\u003e3.1 思路转变：从基于 queue 到基于 time\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#32-一些已发表论文\" id=\"markdown-toc-32-一些已发表论文\"\u003e3.2 一些已发表论文\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#4-从基于队列到基于时间戳qdiscedt-详解\" id=\"markdown-toc-4-从基于队列到基于时间戳qdiscedt-详解\"\u003e4 从基于队列到基于时间戳：qdisc/EDT 详解\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#41-基于-queue-的整流器\" id=\"markdown-toc-41-基于-queue-的整流器\"\u003e4.1 基于 queue 的整流器\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#411-示例一htb\" id=\"markdown-toc-411-示例一htb\"\u003e4.1.1 示例一：HTB\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#412-示例二fqpacing\" id=\"markdown-toc-412-示例二fqpacing\"\u003e4.1.2 示例二：FQ/Pacing\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#413-小结\" id=\"markdown-toc-413-小结\"\u003e4.1.3 小结\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#42-carousel基于-edt-的整流器\" id=\"markdown-toc-42-carousel基于-edt-的整流器\"\u003e4.2 Carousel：基于 EDT 的整流器\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#421-原理及特点\" id=\"markdown-toc-421-原理及特点\"\u003e4.2.1 原理及特点\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#422-life-of-a-packet-in-carousel\" id=\"markdown-toc-422-life-of-a-packet-in-carousel\"\u003e4.2.2 Life of a packet in Carousel\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#423-与基于-queue-的-shaper-的对比\" id=\"markdown-toc-423-与基于-queue-的-shaper-的对比\"\u003e4.2.3 与基于 queue 的 shaper 的对比\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#424-qdisc-功能变化\" id=\"markdown-toc-424-qdisc-功能变化\"\u003e4.2.4 qdisc 功能变化\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#43-小结\" id=\"markdown-toc-43-小结\"\u003e4.3 小结\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#5-linux-edt-支持与实践译注\" id=\"markdown-toc-5-linux-edt-支持与实践译注\"\u003e5 Linux EDT 支持与实践（译注）\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#51-cilium-pod-egress-限速\" id=\"markdown-toc-51-cilium-pod-egress-限速\"\u003e5.1 Cilium pod egress 限速\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003chr/\u003e\n\n\u003ch1 id=\"1-网络起源\"\u003e1 网络起源\u003c/h1\u003e\n\n\u003cp\u003e如果能对\u003cstrong\u003e\u003cmark\u003e网络协议和网卡之间的契约\u003c/mark\u003e\u003c/strong\u003e（contract between protocols and NICs）\n做出些许改动，就能解决很多问题。解释清这一点需要从历史讲起。\u003c/p\u003e\n\n\u003ch2 id=\"11-技术需求与网络起源\"\u003e1.1 技术需求与网络起源\u003c/h2\u003e\n\n\u003cp\u003e时间回到起点。如果你在上世纪 70 年代说“网络”这个词，那它大概长这下面这样：\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/traffic-control-from-queue-to-edt/ibm-3790-controller.png\" width=\"60%\" height=\"60%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig. IBM 3790 Controller (1974)\u003c/p\u003e\n\n\u003cp\u003e这是当时 IBM 新发布的网络架构，称为 SNA（Systems Network Architecture），\n可以看到其中\u003cstrong\u003e\u003cmark\u003e有很多打印机和终端，这就是当时所谓的网络\u003c/mark\u003e\u003c/strong\u003e。\u003c/p\u003e\n\n\u003cp\u003e左上角是一台 IBM 小型机（mainframe），它非常昂贵，只有高端企业才买得起。而另一方面，\nIBM 想把小型机打入更广阔市场，这就意味着他们需要\u003cstrong\u003e\u003cmark\u003e把小型机推销给一些小客户\u003c/mark\u003e\u003c/strong\u003e，\n比如那些只有几个分支机构的银行。\n要实现这个目标，在技术上就需要\u003cstrong\u003e\u003cmark\u003e实现分支机构和总部互连\u003c/mark\u003e\u003c/strong\u003e，但这一点在当时是做不到的：\n\u003cstrong\u003e\u003cmark\u003e当时的计算机都是围绕数据中心模型设计的\u003c/mark\u003e\u003c/strong\u003e，昂贵的外设都环绕在计算机附近，距离不过百尺。\u003c/p\u003e\n\n\u003cp\u003e因此，为了解决远程互连问题，他们设计了一些\u003cstrong\u003e\u003cmark\u003e远程控制器，能驱动显示控制器\u003c/mark\u003e\u003c/strong\u003e（display controller），\n这样客户的分支机构只需要安装相对便宜的显示终端，就能和总部的小型机连通，成本也就下来了。\n比如上图中，小型机的成本就可以被 12 个分支机构平摊；此后，大量的银行、金融机构和零售商开始购买 IBM 小型机。\u003c/p\u003e\n\n\u003cp\u003e这就是\u003cstrong\u003e\u003cmark\u003e网络（network）最初的样子\u003c/mark\u003e\u003c/strong\u003e，\n这一时期（70 年底早期和中期）各种网络协议互相竞争，但可以分为两类：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e政府资助研究项目\u003c/mark\u003e\u003c/strong\u003e：英国的 NPL 网络、美国的 ARPANET（互联网的前身）、法国的 CYCLADES 等；\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e计算机厂商私有\u003c/mark\u003e\u003c/strong\u003e：IBM 的 SNA、DEC 的 DECnet 等。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch2 id=\"12-私有协议和厂商锁定\"\u003e1.2 私有协议和厂商锁定\u003c/h2\u003e\n\n\u003cp\u003e计算机厂商开发计算机网络（computer network）的目的其实非常简单：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e通过卖设备（小型机和远程终端等）给企业客户赚钱；\u003c/li\u003e\n  \u003cli\u003e通过私有协议锁定客户（lock-in customers），卖更多设备给他们赚更多钱。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e计算机厂商的首要目的是卖硬件，不希望客户用竞争对手的产品，因此首先要做的是在产品上锁定客户。\n如果你认为网络的出发点是连接全世界，让每个人的每个设备都能彼此自由通信，那就太理想主义了；\n网络的起源没有这么高尚，而是纯商业行为：每个计算机厂商都希望客户购买自己的网络设备，\n并且只能和自己厂的设备通信，其他厂商的设备一概不能连接。\u003c/p\u003e\n\n\u003ch2 id=\"13-早期厂商网络方案的问题\"\u003e1.3 早期厂商网络方案的问题\u003c/h2\u003e\n\n\u003cp\u003e私有协议和厂商锁定导致的几个后果：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\n    \u003cp\u003e研发显示器、打印机、读卡器等等这些\u003cstrong\u003e\u003cmark\u003e外设\u003c/mark\u003e\u003c/strong\u003e（peripheral devices）的\n  \u003cstrong\u003e\u003cmark\u003e工程师主导了网络设计\u003c/mark\u003e\u003c/strong\u003e，这一点对后世影响深远。\u003c/p\u003e\n\n    \u003cp\u003e对此时的厂商来说，\u003cstrong\u003e\u003cmark\u003e外设和功能才是重要的，网络只是一个从属地位\u003c/mark\u003e\u003c/strong\u003e。\n 因此，我们会看到网络协议中包含很多直接与设备相关的东西，非常怪异，例如与打印机\n 通信时，需要考虑到它打印和弹出纸张的速度，可能是一条命令发送过去，然后传输\n 协议里规定等待两秒（等待打印过程），设计的非常傻（那时也没有多少内存可用，\n 内存非常稀缺和昂贵）。\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e\u003cstrong\u003e\u003cmark\u003e通信链路非常慢\u003c/mark\u003e\u003c/strong\u003e（\u003ccode class=\"language-plaintext highlighter-rouge\"\u003e300bps/2.4Kbps/56Kbps\u003c/code\u003e），导致\u003cstrong\u003e\u003cmark\u003e协议被过度简化\u003c/mark\u003e\u003c/strong\u003e。\u003c/p\u003e\n\n    \u003cp\u003e有钱的金融客户使用的可能才只是 2.4Kbps，如果真的非常非常有钱，才会考虑\n 56Kbps，这是当时的上限。由此导致的两个设计：\u003c/p\u003e\n\n    \u003cul\u003e\n      \u003cli\u003e尽量减小头开销（header），头越小越好；\u003c/li\u003e\n      \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e协议要精简/简化，不要太啰嗦\u003c/mark\u003e\u003c/strong\u003e。例如，避免明确回复对方说\n“包我收到了”，而是假设在大多数情况下，包都能在 timeout 之前正常被设备接收。\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e由于以上两点，需要针对不同设备/控制器型号有\u003cstrong\u003e\u003cmark\u003e不同的数据包封装格式\u003c/mark\u003e\u003c/strong\u003e。\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e不难猜到，这种架构和产品并不成功。\n我们关注的不应该是\u003cstrong\u003e\u003cmark\u003e什么人或什么设备在使用网络\u003c/mark\u003e\u003c/strong\u003e（what’s using the network），\n而是\u003cstrong\u003e\u003cmark\u003e如何使得网络可用和好用\u003c/mark\u003e\u003c/strong\u003e（making the network usable）。\n由此引出今天的事实标准 —— TCP/IP 协议 —— 的诞生。\u003c/p\u003e\n\n\u003ch2 id=\"14-tcpip-协议模型\"\u003e1.4 TCP/IP 协议模型\u003c/h2\u003e\n\n\u003cp\u003eTCP/IP 的设计吸取了以上教训。这里主要强调三点：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003eSimplicity\u003c/mark\u003e\u003c/strong\u003e：加到协议里的东西必须是有用、清晰、无异议的；\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003eExpressive abstractions\u003c/mark\u003e\u003c/strong\u003e：网络模型（抽象）必须有很强的表达能力，能用于解决不同的实际问题；\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003eImplementable contracts\u003c/mark\u003e\u003c/strong\u003e：协议层之间的契约可实现，不能过于理论导致落地困难。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eTCP/IP 最大的特点是\u003cstrong\u003e\u003cmark\u003e没有对周边（应用类型、协议效率、网络结构等）做出限制\u003c/mark\u003e\u003c/strong\u003e。\n有些东西理论上很美好，但实现起来会巨复杂，和当初设想的完全不一样；\n\u003cstrong\u003e\u003cmark\u003eTCP/IP 架构组的每个人都亲自实现过协议\u003c/mark\u003e\u003c/strong\u003e，在 ARPANET 工作过，经验丰富，因此避免了很多之前已经出现过的问题。\n最后，他们只设计了两个主要协议，构成了如今的 TCP/IP 模型：\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eIP：网络层协议\u003c/li\u003e\n  \u003cli\u003eTCP：传输层协议\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"141-ip尽力而为传输best-effort-delivery\"\u003e1.4.1 IP：尽力而为传输（best effort delivery）\u003c/h3\u003e\n\n\u003cp\u003eIP 层传输的是接口到接口的小消息（interface to interface small messages）。\u003c/p\u003e\n\n\u003cp\u003eIP（Internete Procotol）是不可靠的（unreliable）\u003cstrong\u003e\u003cmark\u003e尽力而为\u003c/mark\u003e\u003c/strong\u003e传输（best effort delivery）。\u003c/p\u003e\n\n\u003cp\u003e计算机厂商的私有网络方案和 IP 方案是竞争关系，因此他们看到这个方案时会说：你们这个 IP\n方案只有传输数据包的功能，我们的方案还能做 XX、YY、ZZ …，但我要强调的是，这些并不属于 best effort 的范畴：\n\u003cstrong\u003e\u003cmark\u003e网络层应该只有唯一功能，那就是传输数据包\u003c/mark\u003e\u003c/strong\u003e（deliver packets），\n如果你给一个包它无法传输，那唯一原因应该是它正在传输其他包，其中的竞争条件需要你等待。\n\u003cstrong\u003e\u003cmark\u003e“尽力而为”并不是什么都做，而是聚焦在一个功能点，尽最大职责把这个功能做好\u003c/mark\u003e\u003c/strong\u003e。\u003c/p\u003e\n\n\u003cp\u003e“尽力”的另一层意思是可能会有失败，因此需要想好应对方案。这就轮到 TCP 层出场了。\u003c/p\u003e\n\n\u003ch3 id=\"142-tcp最终可靠传输eventual-delivery\"\u003e1.4.2 TCP：最终可靠传输（eventual delivery）\u003c/h3\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cmark\u003eTCP 与 IP 层之间的契约\u003c/mark\u003e\u003c/strong\u003e：\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eIP 层尽力而为，\u003c/li\u003e\n  \u003cli\u003eTCP 在 IP 的基础上实现最终的可靠通信。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cmark\u003e最终可靠性\u003c/mark\u003e\u003c/strong\u003e很重要，因为我们不知道什么时候会失败，因此需要\n\u003cstrong\u003e\u003cmark\u003e重试等机制\u003c/mark\u003e\u003c/strong\u003e来保证传输结果最终是成功的。\u003c/p\u003e\n\n\u003ch3 id=\"143-小结\"\u003e1.4.3 小结\u003c/h3\u003e\n\n\u003cp\u003eTCP/IP 的成功\u003cstrong\u003e\u003cmark\u003e并不是因为它们规定了什么，而是它们没规定什么\u003c/mark\u003e\u003c/strong\u003e：\n没有对上层应用、协议效率、网络结构、代码实现做出任何假设。\n在设计方案时，做出某些假设、前提、限制很容易，但以后想把其中一些限制去掉时，\n就很难甚至不可能了，因此前期的设计非常重要。\u003c/p\u003e\n\n\u003cp\u003e网络有了，接下来进入本文正题：网络传输过程中的流量控制。\u003c/p\u003e\n\n\u003ch1 id=\"2-网络传输\"\u003e2 网络传输\u003c/h1\u003e\n\n\u003ch2 id=\"21-技术需求越快越好或尽可能快afap\"\u003e2.1 技术需求：越快越好（或尽可能快，AFAP）\u003c/h2\u003e\n\n\u003cp\u003e网络传输的需求是尽可能快（as fast as possible），这一点是显然的。\u003c/p\u003e\n\n\u003cp\u003e那我们看看 TCP 发送机制中，哪些因素会制约发送速率。\u003c/p\u003e\n\n\u003ch2 id=\"22-tcp-发送机制只限制发送多少未限制发送多快\"\u003e2.2 TCP 发送机制：只限制发送多少，未限制发送多快\u003c/h2\u003e\n\n\u003cp\u003eTCP 的设计机制是\u003cstrong\u003e\u003cmark\u003e可靠传输\u003c/mark\u003e\u003c/strong\u003e，它限制了\u003cstrong\u003e\u003cmark\u003e发送多少\u003c/mark\u003e\u003c/strong\u003e\n（how much is sent），但没有限制\u003cstrong\u003e\u003cmark\u003e发送多快\u003c/mark\u003e\u003c/strong\u003e（how fast）。\n理解这一点非常重要。越快越好是天然需求，既然 TCP 机制没对发送速率做出限制，那\n\u003cstrong\u003e\u003cmark\u003e发送端就自然就出现了“尽可能快”（AFAP）这样一种事实发送机制\u003c/mark\u003e\u003c/strong\u003e\n（即所谓的 \u003cstrong\u003e\u003cmark\u003e“work conserving”\u003c/mark\u003e\u003c/strong\u003e）。\u003c/p\u003e\n\n\u003cp\u003e那么，\u003cstrong\u003e\u003cmark\u003e怎么实现 AFAP\u003c/mark\u003e\u003c/strong\u003e 呢？一般是通过所谓的\u003cstrong\u003e\u003cmark\u003e流量整形/整流\u003c/mark\u003e\u003c/strong\u003e（traffic shaping）。\u003c/p\u003e\n\n\u003ch2 id=\"23-基于-queue-做流量整形\"\u003e2.3 基于 queue 做流量整形\u003c/h2\u003e\n\n\u003cp\u003e实际中，流量整形通常通过 \u003cstrong\u003e\u003cmark\u003edevice output queue\u003c/mark\u003e\u003c/strong\u003e（设备发送队列）实现；\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e最快发送速率\u003c/mark\u003e\u003c/strong\u003e就是队列的 drain rate；\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e传输中的最大数据量\u003c/mark\u003e\u003c/strong\u003e（inflight data） 由 RX window 或 queue length 决定。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e下面具体看怎么做整流。\u003c/p\u003e\n\n\u003ch3 id=\"231-流量整形器shaper原理以-token-bucket-queue-为例\"\u003e2.3.1 流量整形器（shaper）原理：以 token bucket queue 为例\u003c/h3\u003e\n\n\u003cp\u003e如下图所示，原理比较简单：\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/traffic-control-from-queue-to-edt/shaping-with-queues.png\" width=\"90%\" height=\"90%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig. 通过多个 token bucket queue 实现一个 shaper\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\n    \u003cp\u003e主机的\u003cstrong\u003e\u003cmark\u003e出向流量（egress traffic）\u003c/mark\u003e\u003c/strong\u003e经过一个\u003cstrong\u003e\u003cmark\u003e分类器（classifier）\u003c/mark\u003e\u003c/strong\u003e进行分类；\u003c/p\u003e\n\n    \u003cp\u003e这里的 egress 流量一般都来自 \u003cstrong\u003e\u003cmark\u003esocket buffer\u003c/mark\u003e\u003c/strong\u003e，可能是主机自己的流量，也可能是里面 VM/container 的流量。\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e分类之后的流量分别放到不同的 queue（缓冲队列），\u003cstrong\u003e\u003cmark\u003e各 queue 的发送速率限制\u003c/mark\u003e\u003c/strong\u003e可能是不同的；\u003c/li\u003e\n  \u003cli\u003e某个\u003cstrong\u003e\u003cmark\u003e调度器（scheduler）\u003c/mark\u003e\u003c/strong\u003e负责统一\u003cstrong\u003e\u003cmark\u003e调度以上所有 queue 的发包\u003c/mark\u003e\u003c/strong\u003e，将包从 queue 中取出\u003cstrong\u003e\u003cmark\u003e放到主机网卡的 TX queue 中\u003c/mark\u003e\u003c/strong\u003e；\u003c/li\u003e\n  \u003cli\u003e网卡将 TX queue 中包\u003cstrong\u003e\u003cmark\u003e无差别地发送出去\u003c/mark\u003e\u003c/strong\u003e。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e中间的\u003cstrong\u003e\u003cmark\u003e三件套\u003c/mark\u003e\u003c/strong\u003e：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e分类器（classifier）\u003c/li\u003e\n  \u003cli\u003e缓冲队列（queue）\u003c/li\u003e\n  \u003cli\u003e调度器（scheduler）\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e就组成了一个\u003cstrong\u003e\u003cmark\u003e流量整形器\u003c/mark\u003e\u003c/strong\u003e或称\u003cstrong\u003e\u003cmark\u003e整流器\u003c/mark\u003e\u003c/strong\u003e（shaper）。\u003c/p\u003e\n\n\u003ch3 id=\"232-afap-shaper-历史贡献支撑-tcpip-在过去-25-年速度-10000x\"\u003e2.3.2 AFAP shaper 历史贡献：支撑 TCP/IP 在过去 25 年速度 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e10000x\u003c/code\u003e\u003c/h3\u003e\n\n\u003cp\u003e以上这种 AFAP shaper 在过去 25 年支撑了 TCP/IP 从 10Mbps 演进到  100Gbps，\n速度快了一万倍，几乎完美贴合摩尔定律：\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/traffic-control-from-queue-to-edt/eth-bw-10000x.png\" width=\"70%\" height=\"70%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig. 以太网 25 年的带宽变化，从 10Mbps 增大到了 100Gbps\u003c/p\u003e\n\n\u003cp\u003e在这 25 年里，“多快”取决于 queue 的 drain rate，因此\u003cstrong\u003e\u003cmark\u003e发送速率上限取决于主机侧\u003c/mark\u003e\u003c/strong\u003e（local）；\n对于网线来说，限制是在上游（发送端主机是上游，交换机、路由器、接收端等等是下游）。\n当希望发送更快时，只需要将网卡及网线从 100Mbps 换成 1000Mbps，非常简单直接。\n主机外面的东西不用担心，自然会有人和技术能支撑主机的线速发送（下面会讨论）。\u003c/p\u003e\n\n\u003ch3 id=\"233-面临的问题延迟和丢包\"\u003e2.3.3 面临的问题：延迟和丢包\u003c/h3\u003e\n\n\u003cp\u003e刚才提到，这种机制的前提是\u003cstrong\u003e\u003cmark\u003e发送瓶颈在主机端\u003c/mark\u003e\u003c/strong\u003e，因此主机发送多快都没关系，\n不用担心会把主机外面的什么设备或网络路径打爆。\n这就意味着，\u003cstrong\u003e\u003cmark\u003e主机端（更准确地说是此时的瓶颈）\u003c/mark\u003e\u003c/strong\u003e有时 —— 甚至是长时间 —— \u003cstrong\u003e\u003cmark\u003e运行在 100%\u003c/mark\u003e\u003c/strong\u003e 的。\n更具体地说，你可能用的是线速 10Gbps 的网卡，但主机上的应用流量太大了，\n导致以上 shaper 长时间把速度限制在 10Gbps，\u003cstrong\u003e\u003cmark\u003e超过 queue 的包只能丢弃了\u003c/mark\u003e\u003c/strong\u003e。\n排队论（queuing theory）也从数学上告诉我们，这是不稳定的（e.g. for M/D/1）：\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/traffic-control-from-queue-to-edt/queue-bottleneck.png\" width=\"90%\" height=\"90%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig. 根据排队论，实际带宽接近瓶颈带宽时，延迟将急剧上升\u003c/p\u003e\n\n\u003cp\u003e因为这种情况下的到\u003cstrong\u003e\u003cmark\u003e达速率持续大于离开速率\u003c/mark\u003e\u003c/strong\u003e，队列爆了。\n\u003cstrong\u003e\u003cmark\u003e离开速率是网卡线速\u003c/mark\u003e\u003c/strong\u003e，没法调整了，因此只能调整到达速率，也就是从源头控制发包。\u003c/p\u003e\n\n\u003ch3 id=\"234-缓解避免丢包的方式2012-年之前\"\u003e2.3.4 缓解/避免丢包的方式（2012 年之前）\u003c/h3\u003e\n\n\u003cp\u003e这个问题比较棘手，因为实际上不止是主机侧，在网络传输路上上多个地方都有 buffer queue，\n有些地方并不受你控制：\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e可能是在距离你 9 跳之外的某个 buffer 非常小的交换机；\u003c/li\u003e\n  \u003cli\u003e或者是某个 ISP 与家庭的 buffer 非常小的连接处\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e因为他们都尽量用便宜的交换机。\u003c/p\u003e\n\n\u003cp\u003e如果满足以下几个条件之一，延迟/丢包就可以避免：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\n    \u003cp\u003e\u003cstrong\u003e\u003cmark\u003e带宽与延迟乘积\u003c/mark\u003e\u003c/strong\u003e（\u003ccode class=\"language-plaintext highlighter-rouge\"\u003ebw * delay\u003c/code\u003e，BDP，也就是正在传输中的数据量） 非常小；\u003c/p\u003e\n\n    \u003cp\u003e这一点在 1995 年之前是成立的，因为早期的内存非常昂贵，带宽也非常低（几 KB/s），因此这个乘积非常小。这种情况下没有大 queue 也不会丢包。\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e每个网络瓶颈处都有一个\u003cstrong\u003e\u003cmark\u003e大缓冲区路由器\u003c/mark\u003e\u003c/strong\u003e（fat-buffered router）；\u003c/p\u003e\n\n    \u003cp\u003e1995 年之后，路由器厂商开始制造大量的大内存（大缓冲区）路由器，（交换机）内存很便宜，交换机厂商也借此赚了不少钱。\n 如果每个可能的瓶颈点都放了 buffer 很大的路由器，能支撑很大 inflight BDP，也可以解决丢包问题。\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e服务器到置顶交换机（hosts to TORs）的速度比交换机之间（fabric）要慢。\u003c/p\u003e\n\n    \u003cp\u003e这一点类似通信厂商：\u003cstrong\u003e\u003cmark\u003e拉开接入带宽（access bw）和交换带宽（fabric bw）的差距\u003c/mark\u003e\u003c/strong\u003e。\n 例如，接入是 10Gbps，路由器之间的交换带宽是 100Gbps；或者接入 40Gbps，交换 400Gbps。\n 这种情况下服务器 AFSP 并不会有问题，因为上面有更快的交换网络（实际上是一个 fat pipe）。\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cmark\u003e第 2 点和第 3 点的缺点是会带来额外延迟\u003c/mark\u003e\u003c/strong\u003e（下游的路由器上），\n例如 Gbps 级别的路由器可能就会带来秒级的延迟。但这还不是最糟糕的，\n最糟糕的是\u003cstrong\u003e\u003cmark\u003e2012 年之后\u003c/mark\u003e\u003c/strong\u003e，即使愿意忍受更大的延迟也无法避免丢包了，\n因为摩尔定律失速了，这也意味着主机侧 \u003cstrong\u003e\u003cmark\u003eAFAP 模型\u003c/mark\u003e\u003c/strong\u003e\n（主机全速发送，不需要考虑外面的瓶颈和延迟）\u003cstrong\u003e\u003cmark\u003e走到头了\u003c/mark\u003e\u003c/strong\u003e。\u003c/p\u003e\n\n\u003ch2 id=\"23-带宽摩尔定律失速2012-年之后\"\u003e2.3 带宽摩尔定律失速（2012 年之后）\u003c/h2\u003e\n\n\u003cp\u003e技术层面上，从摩尔定律看以太网的发展，明显能看到两段曲线：\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e早期（2000 年之前）：每 12 个月带宽就能翻一番，明显快于标准摩尔定律的 18 个月；\u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e后期：需要 24 个月，也就是慢于标准摩尔定律，这种增长方式已经不可持续了；\u003c/p\u003e\n\n    \u003cp\u003e如果你年纪够大的话，应该记得 \u003cstrong\u003e\u003cmark\u003e计算机世界在 2000~2005 年发生了根本性变化\u003c/mark\u003e\u003c/strong\u003e：\n  之前我们已经习惯了处理器每 18 个月性能翻一番，但到了 2003 年\n  Intel 突然告诉我们下一代奔腾处理器不能快一倍了 ——甚至实际上还会慢一点，\n  然后通过多核来提升整体性能：给你 2 个或 4 个核。受限于物理限制，我们无法做\n  到更快了，此后提升应用整体性能的方式就是多核并行。\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/traffic-control-from-queue-to-edt/data-rate-growing-faster.png\" width=\"70%\" height=\"70%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig. 真实以太网演进速率与摩尔定律理论速率\u003c/p\u003e\n\n\u003cp\u003e这种不可持续性打破了园区网和数据中心网络建设的传统模型（“fabric 带宽永远比 access 带宽高一个数量级”），\n因为更高的带宽上不去了，或者能上去一些但是成本太高了，最后的结果就是\n\u003cstrong\u003e\u003cmark\u003e服务器的网卡带宽（access bw）追平了交换机之间的互联带宽（fabric bw）\u003c/mark\u003e\u003c/strong\u003e。\n这样一来，交换机就不再能 buffer 大量的服务器包了，尤其是多个主机访问同一个目的端、命中通过一个交换机端口的时候。\n不管是数据中心网络还是边缘网络都面临这个典型问题。\u003c/p\u003e\n\n\u003cp\u003e单核摩尔定律的突然终结\u003cstrong\u003e\u003cmark\u003e深刻影响了网络和计算，但对网络的影响更大\u003c/mark\u003e\u003c/strong\u003e。\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e这打破了之前的带宽层级（bandwidth hierarchy）模型，\n我们\u003cstrong\u003e\u003cmark\u003e无法造出速度永远比网卡快一个数量级的交换机了\u003c/mark\u003e\u003c/strong\u003e。\u003c/li\u003e\n  \u003cli\u003e原来单核或但主机能完成的事情，现在必须分散到大量机器上来并行处理，这给\u003cstrong\u003e\u003cmark\u003e交换网络\u003c/mark\u003e\u003c/strong\u003e造成了巨大挑战。\n之前只需要原地升级 CPU 就能解决，不需要动网络，该怎么连接到 fabric 的还是怎么连，\n现在只能\u003cstrong\u003e\u003cmark\u003e分发到多个 CPU、机器上去\u003c/mark\u003e\u003c/strong\u003e。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e网络模型发生了本质变化。\u003c/p\u003e\n\n\u003ch1 id=\"3-google-网络团队的一些创新\"\u003e3 Google 网络团队的一些创新\u003c/h1\u003e\n\n\u003cp\u003e以上讨论意味着，基于缓冲队列（queue）的机制已经不符合当前网络现状了，\n不能再简单基于网卡的最大工作速率来发包。\u003c/p\u003e\n\n\u003ch2 id=\"31-思路转变从基于-queue-到基于-time\"\u003e3.1 思路转变：从基于 queue 到基于 time\u003c/h2\u003e\n\n\u003cp\u003eGoogle 的解决思路是：\u003cstrong\u003e\u003cmark\u003e感知网络瓶颈，以瓶颈处的最大发送速率发送数据包\u003c/mark\u003e\u003c/strong\u003e（determine\nwhat’s AFAP at the bottleneck and run at that rate）。做到这一点，依赖的最重要\n因素不再是 queue，而是\u003cstrong\u003e\u003cmark\u003e时间\u003c/mark\u003e\u003c/strong\u003e（time）。\u003c/p\u003e\n\n\u003ch2 id=\"32-一些已发表论文\"\u003e3.2 一些已发表论文\u003c/h2\u003e\n\n\u003cp\u003e应用分散到多台机器并行计算再将结果汇总，这样跟之前的单机运算为主模型完全不同，\n对网络的影响非常大，对网络影响和问题数量是成倍的，例如我们在我们的 fabric 中遇\n到的问题，在 jupiter paper 中讨论了一些。\u003c/p\u003e\n\n\u003cp\u003e如果中间丢包太严重了，就只能将流量管理前移到主机上。此时网络可能已经是无缓冲区\n交换机了，因为你在发送大量随机流量，而多个突然流量重叠时，交换机根本没有能力缓冲。\n此时，你\u003cstrong\u003e\u003cmark\u003e唯一有能力缓冲也有能力控制的，就是发送端主机\u003c/mark\u003e\u003c/strong\u003e。\u003c/p\u003e\n\n\u003cp\u003e因此我们做的工作就是在源点主机，这些文章都是一个主题：让我们\u003cstrong\u003e\u003cmark\u003e回到源点来解决问题\u003c/mark\u003e\u003c/strong\u003e：\n哪里是瓶颈，瓶颈决定了 AFAP；不能拥塞 TOR，它已经在全速工作了。需要知道下游\n的一些状态，来控制本地发送速率，以避免给下游造成过大压力。\u003c/p\u003e\n\n\u003cp\u003eGoogle 近些年所做的一些工作：\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\n    \u003cp\u003eHULL (NSDI’12) – \u003ca href=\"https://www.usenix.org/conference/nsdi12/technical-sessions/presentation/alizadeh\"\u003eLess is more: trading a little bandwidth for ultra-low latency\u003c/a\u003e\u003c/p\u003e\n\n    \u003cp\u003eTraditional measures of network goodness—goodput, quality of service,\n  fairness—are expressed in terms of bandwidth. Network latency has rarely\n  been a primary concern because delivering the highest level of bandwidth\n  essentially entails driving up latency—at the mean and, especially, at the\n  tail. Recently, however, there has been renewed interest in latency as a\n  primary metric for mainstream applications. In this paper, we present the\n  HULL (High-bandwidth Ultra-Low Latency) architecture to balance two\n  seemingly contradictory goals: near baseline fabric latency and high\n  bandwidth utilization.\u003c/p\u003e\n\n    \u003cp\u003e用到了：\u003c/p\u003e\n\n    \u003cul\u003e\n      \u003cli\u003ePhantom Queues that deliver congestion signals before network links are fully utilized and queues form at switches\u003c/li\u003e\n      \u003cli\u003e\u003cstrong\u003e\u003cmark\u003eDCTCP\u003c/mark\u003e\u003c/strong\u003e, a recently proposed \u003cstrong\u003e\u003cmark\u003econgestion control algorithm\u003c/mark\u003e\u003c/strong\u003e\u003c/li\u003e\n      \u003cli\u003e\u003cstrong\u003e\u003cmark\u003ePacket pacing\u003c/mark\u003e\u003c/strong\u003e to counter burstiness caused by Interrupt Coalescing and Large Send Offloading\u003c/li\u003e\n    \u003c/ul\u003e\n\n    \u003cp\u003eOur implementation and simulation results show that\n  \u003cstrong\u003e\u003cmark\u003eby sacrificing a small amount (e.g., 10%) of bandwidth, HULL can dramatically reduce average and tail latencies\u003c/mark\u003e\u003c/strong\u003e\n  in the data center.\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003eBwE (Sigcomm’15) – \u003ca href=\"https://dl.acm.org/doi/10.1145/2785956.2787478\"\u003eFlexible, Hierarchical Bandwidth Allocation for WAN\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003eFQ/pacing\u003c/mark\u003e\u003c/strong\u003e (IETF88’13) – \u003ca href=\"https://www.ietf.org/proceedings/88/slides/slides-88-tcpm-9.pdf\"\u003eTSO, fair queuing, pacing: three’s a charm\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003eTimely (Sigcomm’15) – \u003ca href=\"https://dl.acm.org/doi/10.1145/2829988.2787510\"\u003eRTT-based congestion control for the datacenter\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003eBBR\u003c/mark\u003e\u003c/strong\u003e (CACM v60’17) – \u003ca href=\"\"\u003eCongestion-based congestion control\u003c/a\u003e，\u003ca href=\"{ % link _posts/2022-01-02-bbr-paper-zh.md % }\"\u003e\u003cstrong\u003e\u003cmark\u003e中文版\u003c/mark\u003e\u003c/strong\u003e\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003eCarousel (Sigcomm’17) – \u003ca href=\"https://dl.acm.org/doi/10.1145/3098822.3098852\"\u003eScalable traffic shaping at end hosts\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch1 id=\"4-从基于队列到基于时间戳qdiscedt-详解\"\u003e4 从基于队列到基于时间戳：qdisc/EDT 详解\u003c/h1\u003e\n\n\u003cp\u003e本节从技术层面介绍和分析两种模型。\u003c/p\u003e\n\n\u003ch2 id=\"41-基于-queue-的整流器\"\u003e4.1 基于 queue 的整流器\u003c/h2\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e更多关于 tc qdisc 的内容：\n\u003ca href=\"/blog/lartc-qdisc-zh/\"\u003e\u003cmark\u003e（译）《Linux 高级路由与流量控制手册（2012）》第九章：用 tc qdisc 管理 Linux 网络带宽\u003c/mark\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/traffic-control-from-queue-to-edt/shaping-with-queues.png\" width=\"90%\" height=\"90%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig. 通过多个 token bucket queue 实现一个 shaper\u003c/p\u003e\n\n\u003cp\u003e原理前面介绍过了。存在的问题：\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003eCPU 和内存开销\u003c/mark\u003e\u003c/strong\u003e：可能很大\u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e需要同时满足网络带宽策略和拥塞控制需求，例如 TCP\u003c/p\u003e\n\n    \u003cul\u003e\n      \u003cli\u003ePace packets\u003c/li\u003e\n      \u003cli\u003eProvide backpressure\u003c/li\u003e\n      \u003cli\u003eAvoid HOL blocking\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"411-示例一htb\"\u003e4.1.1 示例一：HTB\u003c/h3\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/traffic-control-from-queue-to-edt/htb-to-nic.png\" width=\"50%\" height=\"50%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig. HTB shaper 原理\u003c/p\u003e\n\n\u003cp\u003e问题：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003eCPU 开销随 queue 数量\u003cstrong\u003e\u003cmark\u003e线性增长\u003c/mark\u003e\u003c/strong\u003e；\u003c/li\u003e\n  \u003cli\u003e多个 CPU 共享多个 queue，导致 CPU 之间的\u003cstrong\u003e\u003cmark\u003e同步（锁/竞争）开销\u003c/mark\u003e\u003c/strong\u003e。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch3 id=\"412-示例二fqpacing\"\u003e4.1.2 示例二：FQ/Pacing\u003c/h3\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/traffic-control-from-queue-to-edt/fq-pacing-to-nic.png\" width=\"45%\" height=\"45%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig. FQ/pacing shaper 原理\u003c/p\u003e\n\n\u003cp\u003e性能开销问题和上面的 HTB 一样。\u003c/p\u003e\n\n\u003ch3 id=\"413-小结\"\u003e4.1.3 小结\u003c/h3\u003e\n\n\u003cp\u003e如果去掉 queue，就可以避免上面两项开销：我们的思路是把\u003cstrong\u003e\u003cmark\u003e时间\u003c/mark\u003e\u003c/strong\u003e\n（time）作为一个基础元素，同样能\u003cstrong\u003e\u003cmark\u003e实现整流目的，但所需开销非常低\u003c/mark\u003e\u003c/strong\u003e。\u003c/p\u003e\n\n\u003cp\u003e为此，引入了 EDT（earliest departure time）模型：\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e给每个包设置一个 EDT 时间戳\u003c/mark\u003e\u003c/strong\u003e，控制何时发送这个包；\u003c/li\u003e\n  \u003cli\u003e在\u003cstrong\u003e\u003cmark\u003e网卡前或网卡中\u003c/mark\u003e\u003c/strong\u003e执行调度机制（enforcement mechanism），根据时间戳控制 egress 发包。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eCarousel 正是这样一种机制。\u003c/p\u003e\n\n\u003ch2 id=\"42-carousel基于-edt-的整流器\"\u003e4.2 Carousel：基于 EDT 的整流器\u003c/h2\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/traffic-control-from-queue-to-edt/token-bucket-vs-edt.png\" width=\"100%\" height=\"100%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig. 传统基于 queue 的流量整形器 vs. 新的基于 EDT 的流量整形器\u003c/p\u003e\n\n\u003cp\u003e如上图所示，核心理念：用两项简单工作替换原来缓慢、脆弱、级联的排队系统：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e给\u003cstrong\u003e\u003cmark\u003e每个包\u003c/mark\u003e\u003c/strong\u003e（\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eskb\u003c/code\u003e）打上一个 Earliest Departure Time (EDT) 时间戳；\u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e用一个\u003cstrong\u003e\u003cmark\u003e时间轮调度器\u003c/mark\u003e\u003c/strong\u003e（timing-wheel scheduler）代替原来\n  \u003cstrong\u003e\u003cmark\u003e网卡前或网卡中的发包缓冲队列（queue）\u003c/mark\u003e\u003c/strong\u003e。\u003c/p\u003e\n\n    \u003cp\u003e时间轮模型，可参考 Hashed and Hierarchical Timing Wheels, Varghese \u0026amp; Lauck, SOSP 87.\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e下面再展开介绍一下。\u003c/p\u003e\n\n\u003ch3 id=\"421-原理及特点\"\u003e4.2.1 原理及特点\u003c/h3\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/traffic-control-from-queue-to-edt/ts-based-shaper.png\" width=\"60%\" height=\"60%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig. Design\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e调度复杂度：\u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eO(1)\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e，待发送的包都是按\u003cstrong\u003e\u003cmark\u003e时间戳排好序的\u003c/mark\u003e\u003c/strong\u003e；\u003c/li\u003e\n  \u003cli\u003e调度器能\u003cstrong\u003e\u003cmark\u003e直接给 socket 反压\u003c/mark\u003e\u003c/strong\u003e，控制 socket 发送速率；\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e每个 CPU 一个 shaper，无锁\u003c/mark\u003e\u003c/strong\u003e，开销低。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch3 id=\"422-life-of-a-packet-in-carousel\"\u003e4.2.2 Life of a packet in Carousel\u003c/h3\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/traffic-control-from-queue-to-edt/life-of-a-pkt-in-carousel.png\" width=\"60%\" height=\"60%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig. Life of packet in Carousel\u003c/p\u003e\n\n\u003ch3 id=\"423-与基于-queue-的-shaper-的对比\"\u003e4.2.3 与基于 queue 的 shaper 的对比\u003c/h3\u003e\n\n\u003cp\u003etiming wheel 能完成 queue 的功能，它不仅能做的事情更多，并且做的更快：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\n    \u003cp\u003e插入和删除操作都是 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eO(1)\u003c/code\u003e，复杂度和 queue 一样，但是开销更低，\u003c/p\u003e\n\n    \u003cul\u003e\n      \u003cli\u003ecache friendly (no pointer chains)\u003c/li\u003e\n      \u003cli\u003eRCU friendly (single slot to update) Driver (or NIC) gets to choose ‘event horizon’ (wheel length) so can do BQL-like tuning for long enough to fill wire but short enough to not blow away caches.\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003ePackets that would be sent after event horizon can get TSQ-like callback\nwhen they can be sent or get an ETooFar.  This replaces TSQ and fixes\nproblem of many simultaneous writers generating huge queues.\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003eIt also puts hard bounds # of active output bytes, increasing probability of L3 cache hits for systems that can DMA from L3.\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch3 id=\"424-qdisc-功能变化\"\u003e4.2.4 qdisc 功能变化\u003c/h3\u003e\n\n\u003cp\u003e有了 EDT， \u003cstrong\u003e\u003cmark\u003eqdisc 能做的事情更多，同时开销也更低了\u003c/mark\u003e\u003c/strong\u003e：\nqdisc 变成了一个纯计算模块，不再需要维护内部队列了（intermediate queues），\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003edriver gets to see all packets in its event horizon so can easily do informed interrupt mitigation, lazy reclaim, (wifi) endpoint aggregation…\u003c/li\u003e\n  \u003cli\u003esender learns packet send time on send() and can handle deadlines, seek alternatives, do phase correction…\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eIn essence, timing wheel is an in-memory representation of how packets will appear on wire. It can represent almost any causal scheduling policy.\u003c/p\u003e\n\n\u003cp\u003e(Policies like ‘Maximize Completion Rate’ are impossible to express with rates but easy with timestamps so we can finally make transactions ‘fair’ without stupidly slowing everything down.)\u003c/p\u003e\n\n\u003ch2 id=\"43-小结\"\u003e4.3 小结\u003c/h2\u003e\n\n\u003cul\u003e\n  \u003cli\u003e主机侧的网络模型应该从 AFAP 切换到 EDT 了；\u003c/li\u003e\n  \u003cli\u003eEDT 比 AFAP queue 更加高效和简洁；\u003c/li\u003e\n  \u003cli\u003e基于 EDT 不仅能实现传统基于 queue 的 shaper 的各种调度策略，而且还能实现更多新的调度策略。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch1 id=\"5-linux-edt-支持与实践译注\"\u003e5 Linux EDT 支持与实践（译注）\u003c/h1\u003e\n\n\u003cp\u003e较新的内核版本已经支持。\u003c/p\u003e\n\n\u003ch2 id=\"51-cilium-pod-egress-限速\"\u003e5.1 Cilium pod egress 限速\u003c/h2\u003e\n\n\u003cp\u003eCilium 用了 EDT 做容器 egress 限速：\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\u003ca href=\"/blog/advanced-bpf-kernel-features-for-container-age-zh/\"\u003e(译) 为容器时代设计的高级 eBPF 内核特性（FOSDEM, 2021）\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"/blog/bpf-datapath-extensions-for-k8s-zh/\"\u003e(译) 为 K8s workload 引入的一些 BPF datapath 扩展（LPC, 2021）\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\n  \u003c!-- POST NAVIGATION --\u003e\n  \u003cdiv class=\"postNav clearfix\"\u003e\n     \n      \u003ca class=\"prev\" href=\"/blog/trip-large-scale-cloud-native-networking-and-security-with-cilium-ebpf/\"\u003e\u003cspan\u003e« Trip.com: Large Scale Cloud Native Networking \u0026amp; Security with Cilium/eBPF (eBPFSummit, 2022)\u003c/span\u003e\n      \n    \u003c/a\u003e\n      \n      \n      \u003ca class=\"next\" href=\"/blog/better-bandwidth-management-with-ebpf-zh/\"\u003e\u003cspan\u003e[译] Cilium：基于 BPF+EDT+FQ+BBR 实现更好的带宽管理（KubeCon, 2022） »\u003c/span\u003e\n       \n      \u003c/a\u003e\n     \n  \u003c/div\u003e\n\u003c/div\u003e",
  "Date": "2022-10-07T00:00:00Z",
  "Author": "Arthur Chiao"
}