{
  "Source": "arthurchiao.art",
  "Title": "[译] Facebook 流量路由最佳实践：从公网入口到内网业务的全路径 XDP/BPF 基础设施（LPC, 2021）",
  "Link": "https://arthurchiao.art/blog/facebook-from-xdp-to-socket-zh/",
  "Content": "\u003cdiv class=\"post\"\u003e\n  \n  \u003ch1 class=\"postTitle\"\u003e[译] Facebook 流量路由最佳实践：从公网入口到内网业务的全路径 XDP/BPF 基础设施（LPC, 2021）\u003c/h1\u003e\n  \u003cp class=\"meta\"\u003ePublished at 2021-12-05 | Last Update 2021-12-11\u003c/p\u003e\n  \n  \u003ch3 id=\"译者序\"\u003e译者序\u003c/h3\u003e\n\n\u003cp\u003e本文翻译自 Facebook 在 LPC 2021 大会上的一篇分享：\n\u003ca href=\"https://linuxplumbersconf.org/event/11/contributions/950/\"\u003eFrom XDP to Socket: Routing of packets beyond XDP with BPF\u003c/a\u003e。\u003c/p\u003e\n\n\u003cp\u003e标题可直译为\u003cstrong\u003e\u003cmark\u003e《从 XDP 到 Socket 的（全路径）流量路由：XDP 不够，BPF 来凑》\u003c/mark\u003e\u003c/strong\u003e，因为 XDP 运行\n在网卡上，而且在边界和流量入口，再往后的路径（尤其是到了内核协议栈）它就管不\n到了，所以引入了其他一些 BPF 技术来“接力”这个路由过程。另外，\n这里的“路由”并非狭义的路由器三层路由，而是泛指 L3-L7 流量转发。\u003c/p\u003e\n\n\u003cp\u003e翻译时加了一些链接和代码片段，以更方便理解。\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e由于译者水平有限，本文不免存在遗漏或错误之处。如有疑问，请查阅原文。\u003c/strong\u003e\u003c/p\u003e\n\n\u003cp\u003e以下是译文。\u003c/p\u003e\n\n\u003chr/\u003e\n\n\u003cul id=\"markdown-toc\"\u003e\n  \u003cli\u003e\u003ca href=\"#译者序\" id=\"markdown-toc-译者序\"\u003e译者序\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#1-引言\" id=\"markdown-toc-1-引言\"\u003e1 引言\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#11-前期工作\" id=\"markdown-toc-11-前期工作\"\u003e1.1 前期工作\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#12-facebook-流量基础设施\" id=\"markdown-toc-12-facebook-流量基础设施\"\u003e1.2 Facebook 流量基础设施\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#13-面临的挑战\" id=\"markdown-toc-13-面临的挑战\"\u003e1.3 面临的挑战\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#2-选择后端主机数据中心内流量的一致性与无状态路由四层负载均衡\" id=\"markdown-toc-2-选择后端主机数据中心内流量的一致性与无状态路由四层负载均衡\"\u003e2 选择后端主机：数据中心内流量的一致性与无状态路由（四层负载均衡）\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#21-katran-l4lb-负载均衡机制\" id=\"markdown-toc-21-katran-l4lb-负载均衡机制\"\u003e2.1 Katran (L4LB) 负载均衡机制\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#22-一致性哈希的局限性\" id=\"markdown-toc-22-一致性哈希的局限性\"\u003e2.2 一致性哈希的局限性\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#221-容错性后端故障对非相关连接的扰动\" id=\"markdown-toc-221-容错性后端故障对非相关连接的扰动\"\u003e2.2.1 容错性：后端故障对非相关连接的扰动\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#222-tcp-长连接面临的问题\" id=\"markdown-toc-222-tcp-长连接面临的问题\"\u003e2.2.2 TCP 长连接面临的问题\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#223-quic-协议为什么不受影响\" id=\"markdown-toc-223-quic-协议为什么不受影响\"\u003e2.2.3 QUIC 协议为什么不受影响\u003c/a\u003e            \u003cul\u003e\n              \u003cli\u003e\u003ca href=\"#connection_id\" id=\"markdown-toc-connection_id\"\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003econnection_id\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n              \u003cli\u003e\u003ca href=\"#完全无状态四层路由\" id=\"markdown-toc-完全无状态四层路由\"\u003e完全无状态四层路由\u003c/a\u003e\u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#23-tcp-连接解决方案利用-bpf-将-backend-server-信息嵌入-tcp-header\" id=\"markdown-toc-23-tcp-连接解决方案利用-bpf-将-backend-server-信息嵌入-tcp-header\"\u003e2.3 TCP 连接解决方案：利用 BPF 将 backend server 信息嵌入 TCP Header\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#231-原理和流程\" id=\"markdown-toc-231-原理和流程\"\u003e2.3.1 原理和流程\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#232-开销\" id=\"markdown-toc-232-开销\"\u003e2.3.2 开销\u003c/a\u003e            \u003cul\u003e\n              \u003cli\u003e\u003ca href=\"#数据开销tcp-header-增加-6-个字节\" id=\"markdown-toc-数据开销tcp-header-增加-6-个字节\"\u003e数据开销：TCP header 增加 6 个字节\u003c/a\u003e\u003c/li\u003e\n              \u003cli\u003e\u003ca href=\"#运行时开销不明显\" id=\"markdown-toc-运行时开销不明显\"\u003e运行时开销：不明显\u003c/a\u003e\u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#233-实现细节\" id=\"markdown-toc-233-实现细节\"\u003e2.3.3 实现细节\u003c/a\u003e            \u003cul\u003e\n              \u003cli\u003e\u003ca href=\"#监听的-socket-事件\" id=\"markdown-toc-监听的-socket-事件\"\u003e监听的 socket 事件\u003c/a\u003e\u003c/li\u003e\n              \u003cli\u003e\u003ca href=\"#维护-tcp-flow---server_id-的映射\" id=\"markdown-toc-维护-tcp-flow---server_id-的映射\"\u003e维护 TCP flow -\u0026gt; server_id 的映射\u003c/a\u003e\u003c/li\u003e\n              \u003cli\u003e\u003ca href=\"#server_id-的分配和同步\" id=\"markdown-toc-server_id-的分配和同步\"\u003eserver_id 的分配和同步\u003c/a\u003e\u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#234-效果\" id=\"markdown-toc-234-效果\"\u003e2.3.4 效果\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#235-限制\" id=\"markdown-toc-235-限制\"\u003e2.3.5 限制\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#24-小结\" id=\"markdown-toc-24-小结\"\u003e2.4 小结\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#3-选择-socket服务的真正优雅发布七层负载均衡\" id=\"markdown-toc-3-选择-socket服务的真正优雅发布七层负载均衡\"\u003e3 选择 socket：服务的真正优雅发布（七层负载均衡）\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#31-当前发布方式及存在的问题\" id=\"markdown-toc-31-当前发布方式及存在的问题\"\u003e3.1 当前发布方式及存在的问题\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#311-发布流程\" id=\"markdown-toc-311-发布流程\"\u003e3.1.1 发布流程\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#312-存在的问题\" id=\"markdown-toc-312-存在的问题\"\u003e3.1.2 存在的问题\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#32-不损失容量快速且用户无感的发布\" id=\"markdown-toc-32-不损失容量快速且用户无感的发布\"\u003e3.2 不损失容量、快速且用户无感的发布\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#321-早期方案socket-takeover-or-zero-downtime-restart\" id=\"markdown-toc-321-早期方案socket-takeover-or-zero-downtime-restart\"\u003e3.2.1 早期方案：socket takeover (or zero downtime restart)\u003c/a\u003e            \u003cul\u003e\n              \u003cli\u003e\u003ca href=\"#发布流程\" id=\"markdown-toc-发布流程\"\u003e发布流程\u003c/a\u003e\u003c/li\u003e\n              \u003cli\u003e\u003ca href=\"#存在的问题\" id=\"markdown-toc-存在的问题\"\u003e存在的问题\u003c/a\u003e\u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#322-其他方案调研so_reuseport\" id=\"markdown-toc-322-其他方案调研so_reuseport\"\u003e3.2.2 其他方案调研：SO_REUSEPORT\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#323-思考\" id=\"markdown-toc-323-思考\"\u003e3.2.3 思考\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#33-新方案bpf_sk_reuseport\" id=\"markdown-toc-33-新方案bpf_sk_reuseport\"\u003e3.3 新方案：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003ebpf_sk_reuseport\u003c/code\u003e\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#331-方案设计\" id=\"markdown-toc-331-方案设计\"\u003e3.3.1 方案设计\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#332-好处\" id=\"markdown-toc-332-好处\"\u003e3.3.2 好处\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#333-发布过程中的流量切换详解\" id=\"markdown-toc-333-发布过程中的流量切换详解\"\u003e3.3.3 发布过程中的流量切换详解\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#334-新老方案效果对比\" id=\"markdown-toc-334-新老方案效果对比\"\u003e3.3.4 新老方案效果对比\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#335-小结\" id=\"markdown-toc-335-小结\"\u003e3.3.5 小结\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#4-讨论\" id=\"markdown-toc-4-讨论\"\u003e4 讨论\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#41-遇到的问题cpu-毛刺cpu-spikes甚至卡顿\" id=\"markdown-toc-41-遇到的问题cpu-毛刺cpu-spikes甚至卡顿\"\u003e4.1 遇到的问题：CPU 毛刺（CPU spikes）甚至卡顿\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#42-listening-socket-hashtable\" id=\"markdown-toc-42-listening-socket-hashtable\"\u003e4.2 Listening socket hashtable\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#43-bpf_sk_select_reuseport-vs-bpf_sk_lookup\" id=\"markdown-toc-43-bpf_sk_select_reuseport-vs-bpf_sk_lookup\"\u003e4.3 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ebpf_sk_select_reuseport\u003c/code\u003e vs \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ebpf_sk_lookup\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003chr/\u003e\n\n\u003ch1 id=\"1-引言\"\u003e1 引言\u003c/h1\u003e\n\n\u003cp\u003e用户请求从公网到达 Facebook 的边界 L4LB 节点之后，往下会涉及到两个阶段（每个阶\n段都包括了 L4/L7）的流量转发：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e从 LB 节点负载均衡到特定主机\u003c/li\u003e\n  \u003cli\u003e主机内：将流量负载均衡到不同 socket\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e以上两个阶段都涉及到流量的一致性路由（consistent routing of packets）问题。\n本文介绍这一过程中面临的挑战，以及我们如何基于最新的 BPF/XDP 特性来应对这些挑战。\u003c/p\u003e\n\n\u003ch2 id=\"11-前期工作\"\u003e1.1 前期工作\u003c/h2\u003e\n\n\u003cp\u003e几年前也是在 LPC 大会，我们分享了 Facebook \u003cstrong\u003e\u003cmark\u003e基于 XDP 开发的几种服务\u003c/mark\u003e\u003c/strong\u003e，例如\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e基于 XDP 的\u003cstrong\u003e\u003cmark\u003e四层负载均衡器（L4LB）\u003c/mark\u003e\u003c/strong\u003e\n  \u003ca href=\"https://engineering.fb.com/2018/05/22/open-source/open-sourcing-katran-a-scalable-network-load-balancer/\"\u003ekatran\u003c/a\u003e，\n  从 2017 年开始，每个进入 facebook.com 的包都是经过 XDP 处理的；\u003c/li\u003e\n  \u003cli\u003e基于 XDP 的\u003cstrong\u003e\u003cmark\u003e防火墙\u003c/mark\u003e\u003c/strong\u003e（挡在 katran 前面）。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/facebook-ipvs-vs-katran.jpg\" width=\"65%\" height=\"65%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFacebook 两代软件 L4LB 对比。\u003cbr/\u003e\n\u003cmark\u003e左：第一代，基于 IPVS\u003c/mark\u003e，L4LB 需独占节点；\u003cmark\u003e右：第二代，基于 XDP\u003c/mark\u003e，不需独占节点，与业务后端混部。\n\u003c/p\u003e\n\n\u003ch2 id=\"12-facebook-流量基础设施\"\u003e1.2 Facebook 流量基础设施\u003c/h2\u003e\n\n\u003cp\u003e从层次上来说，如下图所示，Facebook 的流量基础设施分为两层：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e边界层\u003c/mark\u003e\u003c/strong\u003e（edge tiers），位于 PoP 点\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e数据中心层\u003c/mark\u003e\u003c/strong\u003e，我们称为 Origin DC\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/traffic-infra-1.png\" width=\"70%\" height=\"70%\"/\u003e\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e每层都有一套\u003cstrong\u003e\u003cmark\u003e全功能 LB（L4+L7）\u003c/mark\u003e\u003c/strong\u003e\u003c/li\u003e\n  \u003cli\u003eEdge PoP 和 Origin DC 之间的 LB 通常是长链接\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e从功能上来说，如下图所示：\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/traffic-infra-2.png\" width=\"70%\" height=\"70%\"/\u003e\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e用户连接\u003c/mark\u003e\u003c/strong\u003e（user connections）\u003cstrong\u003e\u003cmark\u003e在边界终结\u003c/mark\u003e\u003c/strong\u003e，\u003c/li\u003e\n  \u003cli\u003eEdge PoP LB 将 L7 流量路由到终端主机，\u003c/li\u003e\n  \u003cli\u003eOrigin DC LB 再将 L7 流量路由到最终的应用，例如 HHVM 服务。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch2 id=\"13-面临的挑战\"\u003e1.3 面临的挑战\u003c/h2\u003e\n\n\u003cp\u003e总结一下前面的内容：公网流量到达边界节点后，接下来会涉及\n\u003cstrong\u003e\u003cmark\u003e两个阶段的流量负载均衡\u003c/mark\u003e\u003c/strong\u003e（每个阶段都是 L4+L7），\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e宏观层面：\u003cstrong\u003e\u003cmark\u003eLB 节点 -\u0026gt; 后端主机\u003c/mark\u003e\u003c/strong\u003e\u003c/li\u003e\n  \u003cli\u003e微观层面（主机内）：\u003cstrong\u003e\u003cmark\u003e主机内核 -\u0026gt; 主机内的不同 socket\u003c/mark\u003e\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e这两个阶段都涉及到流量的高效、\u003cstrong\u003e\u003cmark\u003e一致性路由\u003c/mark\u003e\u003c/strong\u003e（consistent routing）问题。\u003c/p\u003e\n\n\u003cp\u003e本文介绍这一过程中面临的挑战，以及我们是如何基于最新的 BPF/XDP 特性\n来解决这些挑战的。具体来说，我们用到了两种类型的 BPF 程序：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003ca href=\"https://lwn.net/Articles/827672/\"\u003eBPF TCP header options\u003c/a\u003e：解决主机外（宏观）负载均衡问题；\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"http://archive.lwn.net:8080/netdev/20180808080131.3014367-1-kafai@fb.com/t/\"\u003e\u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eBPF_PROG_TYPE_SK_REUSEPORT\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e\u003c/a\u003e\n  （及相关 map 类型 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eBPF_MAP_TYPE_REUSEPORT_SOCKARRAY\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e）：解决主机内（微观）负载均衡问题。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch1 id=\"2-选择后端主机数据中心内流量的一致性与无状态路由四层负载均衡\"\u003e2 选择后端主机：数据中心内流量的一致性与无状态路由（四层负载均衡）\u003c/h1\u003e\n\n\u003cp\u003e先看第一部分，从 LB 节点转发到 backend 机器时，如何来选择主机。\n这是四层负载均衡问题。\u003c/p\u003e\n\n\u003ch2 id=\"21-katran-l4lb-负载均衡机制\"\u003e2.1 Katran (L4LB) 负载均衡机制\u003c/h2\u003e\n\n\u003cp\u003e回到流量基础设施图，这里主要关注 Origin DC 内部 L4-L7 的负载均衡，\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/traffic-infra-3.png\" width=\"70%\" height=\"70%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003ekatran 是基于 XDP 实现的四层负载均衡器，它的内部机制：\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e实现了一个 \u003cstrong\u003e\u003cmark\u003eMaglev Hash\u003c/mark\u003e\u003c/strong\u003e 变种，通过一致性哈希选择后端；\u003c/li\u003e\n  \u003cli\u003e在一致性哈希之上，还维护了自己的一个\u003cstrong\u003e\u003cmark\u003e本地缓存\u003c/mark\u003e\u003c/strong\u003e来跟踪连接。\n这个设计是为了在\u003cstrong\u003e\u003cmark\u003e某些后端维护或故障时，避免其他后端的哈希发生变化\u003c/mark\u003e\u003c/strong\u003e，后面会详细讨论。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e用伪代码来表示 Katran \u003cstrong\u003e\u003cmark\u003e选择后端主机的逻辑\u003c/mark\u003e\u003c/strong\u003e：\u003c/p\u003e\n\n\u003cdiv class=\"language-c highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"nf\"\u003epick_host\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epacket\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003epkt\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eis_in_local_cache\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epkt\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003elocal_cache\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003epkt\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003econsistent_hash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epkt\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e%\u003c/span\u003e \u003cspan class=\"n\"\u003eserver_ring\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e这种机制非常有效，也非常高效（highly effective and efficient）。\u003c/p\u003e\n\n\u003ch2 id=\"22-一致性哈希的局限性\"\u003e2.2 一致性哈希的局限性\u003c/h2\u003e\n\n\u003ch3 id=\"221-容错性后端故障对非相关连接的扰动\"\u003e2.2.1 容错性：后端故障对非相关连接的扰动\u003c/h3\u003e\n\n\u003cp\u003e一致性哈希的一个核心特性是具备\u003cstrong\u003e\u003cmark\u003e对后端变化的容错性\u003c/mark\u003e\u003c/strong\u003e（resilience to backend changes）。\n当一\u003cstrong\u003e\u003cmark\u003e部分后端发生故障时，其他后端的哈希表项不受影响\u003c/mark\u003e\u003c/strong\u003e（因此对应的连接及主机也不受影响）。\nMaglev 论文中已经给出了评估这种容错性的指标，如下图，\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/maglev-perf.png\" width=\"50%\" height=\"50%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eResilience of Maglev hashing to backend changes\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003eMaglev: A fast and reliable software network load balancer. OSDI 2016\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cul\u003e\n  \u003cli\u003e横轴表示 \u003cstrong\u003e\u003cmark\u003ebackend 挂掉的百分比\u003c/mark\u003e\u003c/strong\u003e\u003c/li\u003e\n  \u003cli\u003e纵轴是\u003cstrong\u003e\u003cmark\u003e哈希表项（entries）变化\u003c/mark\u003e\u003c/strong\u003e的百分比，对应\u003cstrong\u003e\u003cmark\u003e受影响连接\u003c/mark\u003e\u003c/strong\u003e的百分比\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eGoogle 放这张图是想说明：一部分后端发生变化时，其他后端受影响的概率非常小；\n但从我们的角度来说，以上这张图说明：即使后端挂掉的比例非常小，\n\u003cstrong\u003e\u003cmark\u003e整个哈希表还是会受影响，并不是完全无感知\u003c/mark\u003e\u003c/strong\u003e —— 这就会\n\u003cstrong\u003e\u003cmark\u003e导致一部分流量被错误路由\u003c/mark\u003e\u003c/strong\u003e（misrouting）：\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e对于\u003cstrong\u003e\u003cmark\u003e短连接\u003c/mark\u003e\u003c/strong\u003e来说，例如典型的 HTTP 应用，这个问题可能\u003cstrong\u003e\u003cmark\u003e影响不大\u003c/mark\u003e\u003c/strong\u003e；\u003c/li\u003e\n  \u003cli\u003e但对于 \u003cstrong\u003e\u003cmark\u003etcp 长连接\u003c/mark\u003e\u003c/strong\u003e，例如持续几个小时的视频流，这种扰动就不能忍了。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"222-tcp-长连接面临的问题\"\u003e2.2.2 TCP 长连接面临的问题\u003c/h3\u003e\n\n\u003cp\u003e首先要说明，\u003cstrong\u003e\u003cmark\u003e高效 != 100% 有效\u003c/mark\u003e\u003c/strong\u003e。\n对于 TCP 长连接来说（例如视频），有两种场景会它们\u003cstrong\u003e\u003cmark\u003e被 reset\u003c/mark\u003e\u003c/strong\u003e：\u003c/p\u003e\n\n\u003cdiv class=\"language-c highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"nf\"\u003epick_host\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epacket\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003epkt\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eis_in_local_cache\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epkt\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e               \u003cspan class=\"c1\"\u003e// 场景一：ECMP shuffle 时（例如 LB 节点维护或故障），这里会 miss\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003elocal_cache\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003epkt\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003econsistent_hash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epkt\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e%\u003c/span\u003e \u003cspan class=\"n\"\u003eserver_ring\u003c/span\u003e \u003cspan class=\"c1\"\u003e// 场景二：后端维护或故障时，这里的好像有（较小）概率发生变化\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e解释一下：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e如果 \u003cstrong\u003e\u003cmark\u003eLB 升级、维护或发生故障\u003c/mark\u003e\u003c/strong\u003e，会导致路由器 ECMP shuffle，那原来路由到某个\nLB 节点的 flow，可能会被重新路由到另一台 LB 上；虽然我们维护了 cache，但它是\n\u003cstrong\u003e\u003cmark\u003eLB node local\u003c/mark\u003e\u003c/strong\u003e 的，因此会发生 cache miss；\u003c/li\u003e\n  \u003cli\u003e如果\u003cstrong\u003e\u003cmark\u003e后端节点升级、维护或发生故障\u003c/mark\u003e\u003c/strong\u003e，那么根据前面 maglev 容错性的实验结果，会有一\n部分（虽然比例不是很大）的 flow 受到影响，导致路由错误。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e以上分析可以看出，“持续发布” L4 和 L7 服务会导致连接不稳定，降低整体可靠性。\n除了发布之外，我们随时都有大量服务器要维护，因此哈希 ring 发生变化（一致性哈希\n发生扰动）是日常而非例外。任何时候发生 ECMP shuffle 和服务发布/主机维护，都会导\n致一部分 active 连接受损，虽然量很小，但会降低整体的可靠性指标。\u003c/p\u003e\n\n\u003cp\u003e解决这个问题的一种方式是\u003cstrong\u003e\u003cmark\u003e在所有 LB 节点间共享这个 local cache\u003c/mark\u003e\u003c/strong\u003e\n（类似于 L4LB 中的 session replication），但这是个\u003cstrong\u003e\u003cmark\u003e很糟糕的主意\n\u003c/mark\u003e\u003c/strong\u003e，因为这就需要去解决另外一大堆分布式系统相关的问题，尤其我们不希望引入任何\n会降低这个极快数据路径性能的东西。\u003c/p\u003e\n\n\u003ch3 id=\"223-quic-协议为什么不受影响\"\u003e2.2.3 QUIC 协议为什么不受影响\u003c/h3\u003e\n\n\u003cp\u003e但对于 QUIC 来说，这都不是问题。\u003c/p\u003e\n\n\u003ch4 id=\"connection_id\"\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003econnection_id\u003c/code\u003e\u003c/h4\u003e\n\n\u003cp\u003eQUIC 规范（RFC 9000）中允许 server 将任意信息嵌入到包的 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003econnection_id\u003c/code\u003e 字段。\u003c/p\u003e\n\n\u003cp\u003eFacebook 已经广泛使用 QUIC 协议，因此在 Facebook 内部，我们可以\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e在 server 端将路由信息（routing information）嵌入到 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003econnection_id\u003c/code\u003e 字段，并\u003c/li\u003e\n  \u003cli\u003e要求客户端必须将这个信息带回来。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch4 id=\"完全无状态四层路由\"\u003e完全无状态四层路由\u003c/h4\u003e\n\n\u003cp\u003e这样整条链路上都可以从包中提取这个 id，无需任何哈希或 cache 查找，最终实现的是一个\n\u003cstrong\u003e\u003cmark\u003e完全无状态的四层路由\u003c/mark\u003e\u003c/strong\u003e（completely stateless routing in L4）。\u003c/p\u003e\n\n\u003cp\u003e那能不能为 TCP 做类似的事情呢？答案是可以。这就要用到 BPF-TCP header option 了。\u003c/p\u003e\n\n\u003ch2 id=\"23-tcp-连接解决方案利用-bpf-将-backend-server-信息嵌入-tcp-header\"\u003e2.3 TCP 连接解决方案：利用 BPF 将 backend server 信息嵌入 TCP Header\u003c/h2\u003e\n\n\u003ch3 id=\"231-原理和流程\"\u003e2.3.1 原理和流程\u003c/h3\u003e\n\n\u003cp\u003e基本思想：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e编写一段 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eBPF_PROG_TYPE_SOCK_OPS\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e 类型的\n  BPF 程序，\u003cstrong\u003e\u003cmark\u003eattach 到 cgroup\u003c/mark\u003e\u003c/strong\u003e：\n    \u003cul\u003e\n      \u003cli\u003e在 LISTEN, CONNECT, CONN_ESTD 等事件时会触发 BPF 程序的执行\u003c/li\u003e\n      \u003cli\u003eBPF 程序可以获取包的 TCP Header，然后往其中写入路由信息（这里是 server_id），或者从中读取路由信息\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e在 L4LB 侧维护一个 server_id 缓存，记录仍然存活的 backend 主机\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e以下图为例，我们来看下 LB 节点和 backend 故障时，其他 backend 上的原有连接如何做到不受影响：\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/tcp-header-workflow.png\" width=\"70%\" height=\"70%\"/\u003e\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e1) 客户端发起一个 SYN；\u003c/li\u003e\n  \u003cli\u003e2) L4LB 第一次见这条 flow，因此通过一致性哈希为它选择一台 backend 主机，然后将包转发过去；\u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e3) 服务端应答 SYN+ACK，其中 \u003cstrong\u003e\u003cmark\u003e服务端 BPF 程序将 server_id 嵌入到 TCP 头中\u003c/mark\u003e\u003c/strong\u003e；\u003c/p\u003e\n\n    \u003cul\u003e\n      \u003cli\u003e图中这台主机获取到自己的 server_id 是 42，然后将这个值写到 TCP header；\u003c/li\u003e\n      \u003cli\u003e客户端主机收到包后，会解析这个 id 并存下来，后面发包时都会带上这个 server_id；\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e假设过了一会发生故障，前面那台 L4LB 挂了（这会导致 \u003cstrong\u003e\u003cmark\u003eECMP 发生变化\u003c/mark\u003e\u003c/strong\u003e）；\n另外，某些 backend hosts 也挂了（这会\n\u003cstrong\u003e\u003cmark\u003e影响一致性哈希\u003c/mark\u003e\u003c/strong\u003e，原有连接接下来有小概率会受到影响），那么接下来，\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e4) 客户端流量将被（数据中心基础设施）转发到另一台 L4LB；\u003c/li\u003e\n  \u003cli\u003e5) 这台新的 L4LB 解析客户端包的 TCP header，提取 server_id，\u003cstrong\u003e\u003cmark\u003e查询 server_id 缓存\u003c/mark\u003e\u003c/strong\u003e（\n注意不是 Katran 的 node-local 连接缓存）之后发现\n\u003cstrong\u003e\u003cmark\u003e这台机器还是 active 的\u003c/mark\u003e\u003c/strong\u003e，因此直接转发给这台机器。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e可以看到在 TCP Header 中引入了路由信息后，未发生故障的主机上的长连接就能够避免\n因 L4LB 和主机挂掉而导致的 misrouting（会被直接 reset）。\u003c/p\u003e\n\n\u003ch3 id=\"232-开销\"\u003e2.3.2 开销\u003c/h3\u003e\n\n\u003ch4 id=\"数据开销tcp-header-增加-6-个字节\"\u003e数据开销：TCP header 增加 6 个字节\u003c/h4\u003e\n\n\u003cdiv class=\"language-plaintext highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003estruct tcp_opt {\n    uint8_t  kind;\n    uint8_t  len;\n    uint32_t server_id;\n}; // 6-bytes total\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch4 id=\"运行时开销不明显\"\u003e运行时开销：不明显\u003c/h4\u003e\n\n\u003cp\u003e需要在 L4LB 中解析 TCP header 中的 server_id 字段，理论上来说，这个开销跟代码实\n现的好坏相关。我们测量了自己的实现，这个开销非常不明显。\u003c/p\u003e\n\n\u003ch3 id=\"233-实现细节\"\u003e2.3.3 实现细节\u003c/h3\u003e\n\n\u003ch4 id=\"监听的-socket-事件\"\u003e监听的 socket 事件\u003c/h4\u003e\n\n\u003cdiv class=\"language-c highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003eswitch\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eskops\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003eop\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ecase\u003c/span\u003e \u003cspan class=\"n\"\u003eBPF_SOCK_OPS_TCP_LISTEN_CB\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ecase\u003c/span\u003e \u003cspan class=\"n\"\u003eBPF_SOCK_OPS_PASSIVE_ESTABLISHED_CB\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ecase\u003c/span\u003e \u003cspan class=\"n\"\u003eBPF_SOCK_OPS_TCP_CONNECT_CB\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ecase\u003c/span\u003e \u003cspan class=\"n\"\u003eBPF_SOCK_OPS_ACTIVE_ESTABLISHED_CB\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ecase\u003c/span\u003e \u003cspan class=\"n\"\u003eBPF_SOCK_OPS_PARSE_HDR_OPT_CB\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ecase\u003c/span\u003e \u003cspan class=\"n\"\u003eBPF_SOCK_OPS_HDR_OPT_LEN_CB\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ecase\u003c/span\u003e \u003cspan class=\"n\"\u003eBPF_SOCK_OPS_WRITE_HDR_OPT_CB\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e.\u003c/span\u003e \u003cspan class=\"p\"\u003e.\u003c/span\u003e \u003cspan class=\"p\"\u003e.\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch4 id=\"维护-tcp-flow---server_id-的映射\"\u003e维护 TCP flow -\u0026gt; server_id 的映射\u003c/h4\u003e\n\n\u003cp\u003e在每个 LB 节点上用 bpf_sk_storage 来存储 \u003cstrong\u003e\u003cmark\u003eper-flow server_id\u003c/mark\u003e\u003c/strong\u003e。\n也就是说，\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e对于建连包特殊处理，\u003c/li\u003e\n  \u003cli\u003e建连之后会维护有 flow 信息（例如连接跟踪），\u003c/li\u003e\n  \u003cli\u003e对于建连成功后的普通流量，从 flow 信息就能直接映射到 server_id，\n  \u003cstrong\u003e\u003cmark\u003e不需要针对每个包去解析 TCP header\u003c/mark\u003e\u003c/strong\u003e。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch4 id=\"server_id-的分配和同步\"\u003eserver_id 的分配和同步\u003c/h4\u003e\n\n\u003cp\u003e前面还没有提到\u003cstrong\u003e\u003cmark\u003e如何分配 server_id\u003c/mark\u003e\u003c/strong\u003e，以及如何保证这些后端信息在负\n载均衡器侧的时效性和有效性。\u003c/p\u003e\n\n\u003cp\u003e我们有一个 \u003cstrong\u003e\u003cmark\u003eoffline 工作流\u003c/mark\u003e\u003c/strong\u003e，会给那些有业务在运行的主机随机分配\n一个 id，然后将这个信息\u003cstrong\u003e\u003cmark\u003e同步给 L4 和 L7 负载均衡器\u003c/mark\u003e\u003c/strong\u003e（Katran and Proxygen），\n后者拿到这些信息后会将其加载到自己的控制平面。因此这个系统不会有额外开销，只要\n\u003cstrong\u003e\u003cmark\u003e保证 LB 的元信息同步\u003c/mark\u003e\u003c/strong\u003e就行了。\u003c/p\u003e\n\n\u003cp\u003e由于这个机制同时适用于 QUIC 和 TCP，因此 pipeline 是同一个。\u003c/p\u003e\n\n\u003ch3 id=\"234-效果\"\u003e2.3.4 效果\u003c/h3\u003e\n\n\u003cp\u003e下面是一次发布，可以看到发布期间 connection reset 并没有明显的升高：\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/tcp-header-result.png\" width=\"40%\" height=\"40%\"/\u003e\u003c/p\u003e\n\n\u003ch3 id=\"235-限制\"\u003e2.3.5 限制\u003c/h3\u003e\n\n\u003cp\u003e这种方式要求 TCP \u003cstrong\u003e\u003cmark\u003e客户端和服务端都在自己的控制之内\u003c/mark\u003e\u003c/strong\u003e，因此\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e对典型的\u003cstrong\u003e\u003cmark\u003e数据中心内部访问\u003c/mark\u003e\u003c/strong\u003e比较有用；\u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e要用于数据中心外的 TCP 客户端，就要让后者将带给它们的 server_id 再带回来，但这个基本做不到；\u003c/p\u003e\n\n    \u003cp\u003e即使它们带上了，\u003cstrong\u003e\u003cmark\u003e网络中间处理节点（middleboxes）和防火墙（firewalls）\u003c/mark\u003e\u003c/strong\u003e也可能会将这些信息丢弃。\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2 id=\"24-小结\"\u003e2.4 小结\u003c/h2\u003e\n\n\u003cp\u003e通过将 server_id 嵌入 TCP 头中，我们实现了一种 stateless routing 机制，\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e这是一个\u003cstrong\u003e\u003cmark\u003e完全无状态\u003c/mark\u003e\u003c/strong\u003e的方案\u003c/li\u003e\n  \u003cli\u003e额外开销（CPU / memory）非常小，基本感知不到\u003c/li\u003e\n  \u003cli\u003e其他竞品方案都非常复杂，例如在 hosts 之间共享状态，或者将 server_id 嵌入到 ECR (Echo Reply) 时间戳字段。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch1 id=\"3-选择-socket服务的真正优雅发布七层负载均衡\"\u003e3 选择 socket：服务的真正优雅发布（七层负载均衡）\u003c/h1\u003e\n\n\u003cp\u003e前面介绍了流量如何从公网经过内网 LB 到达 backend 主机。\n再来看在主机内，如何路由流量来保证七层服务（L7 service）发布或重启时不损失任何流量。\u003c/p\u003e\n\n\u003cp\u003e这部分内容在 SIGCOMM 2020 论文中有详细介绍。想了解细节的可参考：\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003eFacebook,\n\u003ca href=\"https://dl.acm.org/doi/pdf/10.1145/3387514.3405885\"\u003e\u003cmark\u003eZero Downtime Release: Disruption-free Load Balancing of a Multi-Billion User Website\u003c/mark\u003e\u003c/a\u003e.\nSIGCOMM 2020\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch2 id=\"31-当前发布方式及存在的问题\"\u003e3.1 当前发布方式及存在的问题\u003c/h2\u003e\n\n\u003cp\u003eL7LB Proxygen 自身也是一个七层服务，我们以它的升级为例来看一下当前发布流程。\u003c/p\u003e\n\n\u003ch3 id=\"311-发布流程\"\u003e3.1.1 发布流程\u003c/h3\u003e\n\n\u003col\u003e\n  \u003cli\u003e\n    \u003cp\u003e\u003cstrong\u003e\u003cmark\u003e发布前状态\u003c/mark\u003e\u003c/strong\u003e：Proxygen 实例上有一些老连接，也在不断接受新连接，\u003c/p\u003e\n\n    \u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/traditional-restart-1.png\" width=\"60%\" height=\"60%\"/\u003e\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e\u003cstrong\u003e\u003cmark\u003e拉出\u003c/mark\u003e\u003c/strong\u003e：拉出之后的实例不再接受新连接，但在一定时间窗口内，继续为老连接提供服务；\u003c/p\u003e\n\n    \u003col\u003e\n      \u003cli\u003e这个窗口称为 \u003cstrong\u003e\u003cmark\u003egraceful shutdown（也叫 draining） period\u003c/mark\u003e\u003c/strong\u003e，例如设置为 5 或 10 分钟；\u003c/li\u003e\n      \u003cli\u003e拉出一般是通过\u003cstrong\u003e\u003cmark\u003e将 downstream service 的健康监测置为 false\u003c/mark\u003e\u003c/strong\u003e\n   来实现的，例如在这个例子中，就是让 Proxygen 返回给 katran 的健康监测是失败的。\u003c/li\u003e\n    \u003c/ol\u003e\n\n    \u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/traditional-restart-2.png\" width=\"60%\" height=\"60%\"/\u003e\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e\u003cstrong\u003e\u003cmark\u003e发布新代码\u003c/mark\u003e\u003c/strong\u003e：graceful 窗口段过了之后，不管它上面还有没有老连接，直接开始升级。\u003c/p\u003e\n\n    \u003col\u003e\n      \u003cli\u003e部署新代码，\u003c/li\u003e\n      \u003cli\u003e关闭现有进程，创建一个新进程运行新代码。\u003c/li\u003e\n    \u003c/ol\u003e\n\n    \u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/traditional-restart-3.png\" width=\"60%\" height=\"60%\"/\u003e\u003c/p\u003e\n\n    \u003cp\u003e一般来说，只要 graceful 时间段设置比较合适，一部分甚至全部老连接能够在这个\n 窗口内正常退出，从而不会引起用户可见的 spike；但另一方面，如果此时仍然有老\n 连接，那\u003cstrong\u003e\u003cmark\u003e这些客户端就会收到 tcp reset\u003c/mark\u003e\u003c/strong\u003e。\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e\u003cstrong\u003e\u003cmark\u003e监听并接受新连接\u003c/mark\u003e\u003c/strong\u003e：升级之后的 Proxygen 开始正常工作，\n最终达到和升级之前同等水平的一个连接状态。\u003c/p\u003e\n\n    \u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/traditional-restart-4.png\" width=\"60%\" height=\"60%\"/\u003e\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch3 id=\"312-存在的问题\"\u003e3.1.2 存在的问题\u003c/h3\u003e\n\n\u003cp\u003e很多公司都是用的以上那种发布方式，它的实现成本比较低，但也存在几个问题：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\n    \u003cp\u003e发布过程中，\u003cstrong\u003e\u003cmark\u003e系统容量会降低\u003c/mark\u003e\u003c/strong\u003e。\u003c/p\u003e\n\n    \u003cp\u003e\u003cstrong\u003e\u003cmark\u003e从 graceful shutdown 开始，到新代码已经接入了正常量级的流量\u003c/mark\u003e\u003c/strong\u003e，这段时间内\n \u003cstrong\u003e\u003cmark\u003e系统容量\u003c/mark\u003e\u003c/strong\u003e并没有达到\u003cstrong\u003e\u003cmark\u003e系统资源所能支撑的最大值\u003c/mark\u003e\u003c/strong\u003e，\n 例如三个 backend 本来最大能支撑 3N 个连接，那在升级其中一台的时间段内，系统能支撑的最大连接数就会小于 3N，在 2N~3N 之间。\n 这也是为什么很多公司都避免在业务高峰（而是选择类似周日凌晨五点这样的时间点）做这种变更的原因之一。\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e\u003cstrong\u003e\u003cmark\u003e发布周期太长\u003c/mark\u003e\u003c/strong\u003e\u003c/p\u003e\n\n    \u003cp\u003e假设有 100 台机器，分成 100 个批次（phase），每次发布一台，\n 如果 graceful time 是 10 分钟，一次发布就需要 1000 分钟，显然是不可接受的。\u003c/p\u003e\n\n    \u003cp\u003e本质上来说，这种方式\u003cstrong\u003e\u003cmark\u003e扩展性太差\u003c/mark\u003e\u003c/strong\u003e，主机或实例数量一多效率就非常低了。\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch2 id=\"32-不损失容量快速且用户无感的发布\"\u003e3.2 不损失容量、快速且用户无感的发布\u003c/h2\u003e\n\n\u003cp\u003e以上分析引出的核心问题是：如何在用户无感知的前提下，不损失容量（without losing\ncapacity）且非常快速（very high velocity）地完成发布。\u003c/p\u003e\n\n\u003ch3 id=\"321-早期方案socket-takeover-or-zero-downtime-restart\"\u003e3.2.1 早期方案：socket takeover (or zero downtime restart)\u003c/h3\u003e\n\n\u003cp\u003e我们在早期自己实现了一个所谓的 zero downtime restart 或称 socket takeover 方案。\n具体细节见前面提到的 LPC 论文，这里只描述下大概原理：\n相比于等待老进程的连接完全退出再开始发布，我们的做法是直接创建一个新进程，然后通过一个唯\n一的 local socket \u003cstrong\u003e\u003cmark\u003e将老进程中 TCP listen socket 和 UDP sockets 的文件描述符\u003c/mark\u003e\u003c/strong\u003e\n（以及 SCM rights）转移到新进程。\u003c/p\u003e\n\n\u003ch4 id=\"发布流程\"\u003e发布流程\u003c/h4\u003e\n\n\u003cp\u003e如下图所示，\u003cstrong\u003e\u003cmark\u003e发布前\u003c/mark\u003e\u003c/strong\u003e，实例正常运行，同时提供 TCP 和 UDP 服务，其中，\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eTCP socket 分为两部分：\u003cstrong\u003e\u003cmark\u003e已接受的连接\u003c/mark\u003e\u003c/strong\u003e（编号 1~N）和监听新连接的 \u003cstrong\u003e\u003cmark\u003elistening socket\u003c/mark\u003e\u003c/strong\u003e\u003c/li\u003e\n  \u003cli\u003eUDP socket，bind 在 VIP 上\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/socket-takeover-1.png\" width=\"60%\" height=\"60%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e接下来\u003cstrong\u003e\u003cmark\u003e开始发布\u003c/mark\u003e\u003c/strong\u003e：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e创建一个新实例\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e将 TCP listening socket 和 UDP VIP 迁移到新实例\u003c/mark\u003e\u003c/strong\u003e；老实例仍然 serving 现有 TCP 连接（\u003ccode class=\"language-plaintext highlighter-rouge\"\u003e1 ~ N\u003c/code\u003e），\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e新实例开始接受新连接\u003c/mark\u003e\u003c/strong\u003e（\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eN+1 ~ +∞\u003c/code\u003e），包括新的 TCP 连接和新的 UDP 连接\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e老实例等待 drain\u003c/mark\u003e\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e可以看到，这种方式：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e在发布期间不会导致系统容器降低，因为我们完全保留了老实例，另外创建了一个新实例\u003c/li\u003e\n  \u003cli\u003e发布速度可以显著加快，因为此时可以并发发布多个实例\u003c/li\u003e\n  \u003cli\u003e老连接被 reset 的概率可以大大降低，只要允许老实例有足够的 drain 窗口\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e那么，这种方式有什么缺点吗？\u003c/p\u003e\n\n\u003ch4 id=\"存在的问题\"\u003e存在的问题\u003c/h4\u003e\n\n\u003cp\u003e一个显而易见的缺点是：这种发布方式需要更多的系统资源，因为对于每个要升级的实例\n，它的新老实例需要并行运行一段时间；而在之前发布模型是干掉老实例再创建新实例，\n不会同时运行。\u003c/p\u003e\n\n\u003cp\u003e但我们今天要讨论的是另一个问题：\u003cstrong\u003e\u003cmark\u003eUDP 流量的分发或称解复用（de-multiplex）\u003c/mark\u003e\u003c/strong\u003e。\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eTCP 的状态维护在内核。\u003c/li\u003e\n  \u003cli\u003eUDP 协议 —— 尤其是维护连接状态的 UDP 协议，具体来说就是 QUIC —— 所有\n\u003cstrong\u003e\u003cmark\u003e状态维护在应用层而非内核\u003c/mark\u003e\u003c/strong\u003e，因此内核完全没有 QUIC 的上下文。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e由于 socket 迁移是在内核做的，而内核没有 QUIC 上下文（在应用层维护），因此\n当\u003cstrong\u003e\u003cmark\u003e新老进程同时运行时，内核无法知道对于一个现有 UDP 连接的包，应该送给哪个进程\u003c/mark\u003e\u003c/strong\u003e\n（因为对于 QUIC 没有 listening socket 或 accepted socket 的概念），因此有些包会到老进程，有些到新进程，如下图左边所示；\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/socket-takeover-2.png\" width=\"60%\" height=\"60%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e为解决这个问题，我们引入了用户空间解决方案。例如在 QUIC 场景下，会查看\nConnectionID 等 QUIC 规范中允许携带的元信息，然后根据这些信息，通过另一个 local\nsocket 转发给相应的老进程，如以上右图所示。\u003c/p\u003e\n\n\u003cp\u003e虽然能解决 QUIC 的问题，但可以看出，这种方式非常复杂和脆弱，涉及到大量进程间通信，需要维护许多状态。\n有没有简单的方式呢？\u003c/p\u003e\n\n\u003ch3 id=\"322-其他方案调研so_reuseport\"\u003e3.2.2 其他方案调研：SO_REUSEPORT\u003c/h3\u003e\n\n\u003cp\u003eSocket takeover 方案复杂性和脆弱性的根源在于：\u003cstrong\u003e\u003cmark\u003e为了做到客户端无感，我们在两个进程间共享了同一个 socket\u003c/mark\u003e\u003c/strong\u003e。\n因此要解决这个问题，就要避免在多个进程之间共享 socket。\u003c/p\u003e\n\n\u003cp\u003e这自然使我们想到了 \u003ca href=\"https://lwn.net/Articles/542629/\"\u003eSO_REUSEPORT\u003c/a\u003e:  它允许\n\u003cstrong\u003e\u003cmark\u003e多个 socket bind 到同一个 port\u003c/mark\u003e\u003c/strong\u003e。\n但这里仍然有一个问题：UDP 包的路由过程是非一致的（\u003cstrong\u003e\u003cmark\u003eno consistent routing for UDP packets\u003c/mark\u003e\u003c/strong\u003e），如下图所示：\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/reuseport-1.png\" width=\"60%\" height=\"60%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e如果新老实例的 UDP socket bind 到相同端口，那一个实例重启时，哈希结果就会发生变化，导致这个端口上的包发生 misrouting。\u003c/p\u003e\n\n\u003cp\u003e另一方面，SO_REUSEPORT 还有\u003cstrong\u003e\u003cmark\u003e性能问题\u003c/mark\u003e\u003c/strong\u003e，\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eTCP 是有一个\u003cstrong\u003e\u003cmark\u003e独立线程负责接受连接\u003c/mark\u003e\u003c/strong\u003e，然后\u003cstrong\u003e\u003cmark\u003e将新连接的文件描述符转给其他线程\u003c/mark\u003e\u003c/strong\u003e\n，这种机制在负载均衡器中非常典型，可以认为是在 socket 层做分发；\u003c/li\u003e\n  \u003cli\u003eUDP \u003cstrong\u003e\u003cmark\u003e状态在应用层\u003c/mark\u003e\u003c/strong\u003e，因此\u003cstrong\u003e\u003cmark\u003e内核只能在 packet 层做分发\u003c/mark\u003e\u003c/strong\u003e，\n负责\u003cstrong\u003e\u003cmark\u003e监听 UDP 新连接的单个线性不但要处理新连接，还负责包的分发\u003c/mark\u003e\u003c/strong\u003e，显然会存在瓶颈和扩展性问题。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/reuseport-2.png\" width=\"40%\" height=\"40%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e因此直接使用 SO_REUSEPORT 是不行的。\u003c/p\u003e\n\n\u003ch3 id=\"323-思考\"\u003e3.2.3 思考\u003c/h3\u003e\n\n\u003cp\u003e我们后退一步，重新思考一下我们的核心需求是什么。有两点：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e在内核中实现流量的无损切换，以便客户端完全无感知；\u003c/li\u003e\n  \u003cli\u003e过程能做到快速和可扩展，不存在明显性能瓶颈；\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e内核提供了很多功能，但并没有哪个功能是为专门这个场景设计的。\n因此要彻底解决问题，我们必须引入某种创新。\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e理论上：只要我们能\u003cstrong\u003e\u003cmark\u003e控制主机内包的路由过程\u003c/mark\u003e\u003c/strong\u003e（routing of the packets within a host），那以上需求就很容易满足了。\u003c/li\u003e\n  \u003cli\u003e实现上：仍然基于 SO_REUSEPORT 思想，但同时解决 UDP 的一致性路由和瓶颈问题。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e最终我们引入了一个 \u003cstrong\u003e\u003cmark\u003esocket 层负载均衡器\u003c/mark\u003e\u003c/strong\u003e bpf_sk_reuseport。\u003c/p\u003e\n\n\u003ch2 id=\"33-新方案bpf_sk_reuseport\"\u003e3.3 新方案：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003ebpf_sk_reuseport\u003c/code\u003e\u003c/h2\u003e\n\n\u003ch3 id=\"331-方案设计\"\u003e3.3.1 方案设计\u003c/h3\u003e\n\n\u003cp\u003e简单来说，\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e在 socket 层 attach 一段 BPF 程序，控制 TCP/UDP 流量的转发（负载均衡）:\u003c/li\u003e\n  \u003cli\u003e通过一个 BPF map 维护配置信息，业务进程 ready 之后自己配置流量切换。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch3 id=\"332-好处\"\u003e3.3.2 好处\u003c/h3\u003e\n\n\u003cp\u003e这种设计的好处：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e通用，能处理多种类型的协议。\u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e在 VIP 层面，能更好地控制新进程（新实例）启动后的流量接入过程，例如\u003c/p\u003e\n\n    \u003cp\u003eProxygen 在启动时经常要做一些初始化操作，启动后做一些健康检测工作，\n 因此在真正开始干活之前还有一段并未 ready 接收请求/流量的窗口 —— 即使它此时已经 bind 到端口了。\u003c/p\u003e\n\n    \u003cp\u003e在新方案中，我们无需关心这些，\u003cstrong\u003e\u003cmark\u003e应用层自己会判断新进程什么时候可以接受流量\u003c/mark\u003e\u003c/strong\u003e 并通知 BPF 程序做流量切换；\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e性能方面，也解决了前面提到的 UDP 单线程瓶颈；\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e在包的路由（packet-level routing）方面，还支持根据 CPU 调整路由权重（adjust weight of traffic per-cpu）。\n  例如在多租户环境中，CPU 的利用率可能并不均匀，可以根据自己的需要实现特定算法来调度，例如选择空闲的 CPU。\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e最后，未来迭代非常灵活，能支持多种新场景的实验，例如让每个收到包从 CPU 负责处理该包，或者 NUMA 相关的调度。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch3 id=\"333-发布过程中的流量切换详解\"\u003e3.3.3 发布过程中的流量切换详解\u003c/h3\u003e\n\n\u003cp\u003e用一个 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eBPF_MAP_TYPE_REUSEPORT_SOCKARRAY\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e 类型的 BPF\nmap 来配置转发规则，其中，\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003ekey：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003e\u0026lt;VIP\u0026gt;:\u0026lt;Port\u0026gt;\u003c/code\u003e\u003c/li\u003e\n  \u003cli\u003evalue：\u003cstrong\u003e\u003cmark\u003esocket 的文件描述符\u003c/mark\u003e\u003c/strong\u003e，与业务进程一一对应\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e如下图所示，即使新进程已经起来，但只要还没 ready（BPF map 中仍然指向老进程），\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/bpf-map-1.png\" width=\"50%\" height=\"50%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003eBPF 就继续将所有流量转给老进程，\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/bpf-sk-reuseport-1.png\" width=\"70%\" height=\"70%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e新进程 ready 后，更新 BPF map，告诉 BPF 程序它可以接收流量了：\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/bpf-map-2.png\" width=\"50%\" height=\"50%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003eBPF 程序就开始将流量转发给新进程了：\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/bpf-sk-reuseport-2.png\" width=\"70%\" height=\"70%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e前面没提的一点是：我们仍然希望将 UDP 包转发到老进程上，这里实现起来其实就非常简单了：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e已经维护了 flow -\u0026gt; socket 映射\u003c/li\u003e\n  \u003cli\u003e如果 flow 存在，就就转发到对应的 socket；不存在在创建一个新映射，转发给新实例的 socket。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e这也解决了扩展性问题，现在可以并发接收包（one-thread-per-socket），不用担心新进程启动时的 disruptions 或 misrouting 了：\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/one-thread-per-socket.png\" width=\"20%\" height=\"20%\"/\u003e\u003c/p\u003e\n\n\u003ch3 id=\"334-新老方案效果对比\"\u003e3.3.4 新老方案效果对比\u003c/h3\u003e\n\n\u003cp\u003e先来看\u003cstrong\u003e\u003cmark\u003e发布过程对业务流量的扰动程度\u003c/mark\u003e\u003c/strong\u003e。下图是我们的生产数据中心某次发布的统计，图中有两条线：\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e一条是已发布的 server 百分比，\u003c/li\u003e\n  \u003cli\u003e另一个条是同一时间的丢包数量，\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/no-packet-drop.png\" width=\"50%\" height=\"50%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e可以看到在整个升级期间，丢包数量没有明显变化。\u003c/p\u003e\n\n\u003cp\u003e再来看\u003cstrong\u003e\u003cmark\u003e流量分发性能\u003c/mark\u003e\u003c/strong\u003e，分别对 socket takeover 和 bpf_sk_reuseport 两种方式加压：\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/facebook-from-xdp-to-socket/no-packet-drop-2.png\" width=\"65%\" height=\"65%\"/\u003e\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e控制组/\u003cstrong\u003e\u003cmark\u003e对照组\u003c/mark\u003e\u003c/strong\u003e（左边）：3x 流量时开始丢包，\u003c/li\u003e\n  \u003cli\u003e实验组（右边）：30x，因此还没有到分发瓶颈但 CPU 已经用满了，但即使这样丢包仍然很少。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"335-小结\"\u003e3.3.5 小结\u003c/h3\u003e\n\n\u003cp\u003e本节介绍了我们的基于 BPF_PROG_TYPE_SK_REUSEPORT 和 BPF_MAP_TYPE_REUSEPORT_SOCKARRAY\n实现的新一代发布技术，它能实现\u003cstrong\u003e\u003cmark\u003e主机内新老实例流量的无损切换\u003c/mark\u003e\u003c/strong\u003e，优点：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e简化了运维流程，去掉脆弱和复杂的进程间通信（IPC），减少了故障；\u003c/li\u003e\n  \u003cli\u003e效率大幅提升，例如 UDP 性能 10x；\u003c/li\u003e\n  \u003cli\u003e可靠性提升，例如避免了 UDP misrouting 问题和 TCP 三次握手时的竞争问题。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch1 id=\"4-讨论\"\u003e4 讨论\u003c/h1\u003e\n\n\u003ch2 id=\"41-遇到的问题cpu-毛刺cpu-spikes甚至卡顿\"\u003e4.1 遇到的问题：CPU 毛刺（CPU spikes）甚至卡顿\u003c/h2\u003e\n\n\u003cp\u003e生产环境遇到过一个严重问题：新老进程同时运行期间，观察到 \u003cstrong\u003e\u003cmark\u003eCPU spike 甚至 host locking\u003c/mark\u003e\u003c/strong\u003e；\n但测试环境从来没出现过，而且在实现上我们也没有特别消耗 CPU 的逻辑。\u003c/p\u003e\n\n\u003cp\u003e排查之后发现，这个问题跟 BPF 程序没关系，直接原因是\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e在同一个 netns 内有大量 socket，\u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e新老实例同时以支持和不支持 bpf_sk_reuseport 的方式 bind 到了同一端口，\u003c/p\u003e\n\n    \u003cdiv class=\"language-plaintext highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e bind(\u0026#34;[::1]:443\u0026#34;); /* without SO_REUSEPORT. Succeed. */\n bind(\u0026#34;[::2]:443\u0026#34;); /* with    SO_REUSEPORT. Succeed. */\n bind(\u0026#34;[::]:443\u0026#34;);  /* with    SO_REUSEPORT. Still Succeed */\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e    \u003c/div\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003ebind() 实现中有一个 spinlock 会遍历一个 hashtable bucket，这个哈希表\u003cstrong\u003e\u003cmark\u003e只用 dst_port 作为 key 去哈希\u003c/mark\u003e\u003c/strong\u003e，\u003c/p\u003e\n\n    \u003cp\u003e如果有大量 http endpoints，由于它们的 \u003cstrong\u003e\u003cmark\u003edst_port 很可能都是 443 和 80\u003c/mark\u003e\u003c/strong\u003e，\n 因此会导致对应哈希槽上的链表特别长，在遍历时就会导致 CPU 毛刺甚至机器卡住。\n 这一问题下一小节专门介绍。\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e这个问题花了很长时间排查，因此有人在类型场景下遇到类似问题，很可能跟这个有关。\n相关内核\u003ca href=\"https://github.com/torvalds/linux/blob/v5.10/net/ipv4/inet_connection_sock.c#L376\"\u003e代码\u003c/a\u003e，\n修复见 \u003ca href=\"https://lore.kernel.org/lkml/20200601174049.377204943@linuxfoundation.org/\"\u003epatch\u003c/a\u003e。\u003c/p\u003e\n\n\u003ch2 id=\"42-listening-socket-hashtable\"\u003e4.2 Listening socket hashtable\u003c/h2\u003e\n\n\u003cp\u003e进一步解释上一小节提到的 hashtable 导致的 CPU 毛刺甚至卡顿问题以及 Facebook 的改进。\n这个问题在 Cloudflare 2016 年的分享\n\u003ca href=\"https://blog.cloudflare.com/revenge-listening-sockets/\"\u003eThe revenge of the listening sockets\u003c/a\u003e\n中有详细介绍。\u003c/p\u003e\n\n\u003cdiv class=\"language-c highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e// include/net/inet_hashtables.h\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003estatic\u003c/span\u003e \u003cspan class=\"kr\"\u003einline\u003c/span\u003e \u003cspan class=\"k\"\u003estruct\u003c/span\u003e \u003cspan class=\"n\"\u003esock\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"nf\"\u003e__inet_lookup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003estruct\u003c/span\u003e \u003cspan class=\"n\"\u003enet\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003enet\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                     \u003cspan class=\"k\"\u003estruct\u003c/span\u003e \u003cspan class=\"n\"\u003einet_hashinfo\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003ehashinfo\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                     \u003cspan class=\"k\"\u003estruct\u003c/span\u003e \u003cspan class=\"n\"\u003esk_buff\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003eskb\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003edoff\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                     \u003cspan class=\"k\"\u003econst\u003c/span\u003e \u003cspan class=\"n\"\u003e__be32\u003c/span\u003e \u003cspan class=\"n\"\u003esaddr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003econst\u003c/span\u003e \u003cspan class=\"n\"\u003e__be16\u003c/span\u003e \u003cspan class=\"n\"\u003esport\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                     \u003cspan class=\"k\"\u003econst\u003c/span\u003e \u003cspan class=\"n\"\u003e__be32\u003c/span\u003e \u003cspan class=\"n\"\u003edaddr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003econst\u003c/span\u003e \u003cspan class=\"n\"\u003e__be16\u003c/span\u003e \u003cspan class=\"n\"\u003edport\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                     \u003cspan class=\"k\"\u003econst\u003c/span\u003e \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003edif\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003econst\u003c/span\u003e \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003esdif\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                     \u003cspan class=\"n\"\u003ebool\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003erefcounted\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eu16\u003c/span\u003e \u003cspan class=\"n\"\u003ehnum\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003entohs\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edport\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n    \u003cspan class=\"k\"\u003estruct\u003c/span\u003e \u003cspan class=\"n\"\u003esock\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003esk\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 查找是否有 ESTABLISHED 状态的连接\u003c/span\u003e\n    \u003cspan class=\"n\"\u003esk\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003e__inet_lookup_established\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003enet\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehashinfo\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esaddr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esport\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edaddr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehnum\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edif\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esdif\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esk\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003esk\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 查找是否有 LISTENING 状态的连接\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003e__inet_lookup_listener\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003enet\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehashinfo\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eskb\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edoff\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esaddr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esport\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edaddr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehnum\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edif\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esdif\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e如以上代码所示，查找一个包对应的 socket 时，\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e首先会查找是否有 ESTABLISHED 状态的 socket，如果没有\u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e再确认是否有 LISTENING 状态的 socket；这一步会查一下 listen hashtable，\u003c/p\u003e\n\n    \u003cul\u003e\n      \u003cli\u003e它的 bucket 数量非常小，内核\u003ca href=\"https://github.com/torvalds/linux/blob/v5.10/include/net/inet_hashtables.h#L122\"\u003e宏定义为 32\u003c/a\u003e，此外，\u003c/li\u003e\n      \u003cli\u003e这个哈希表 \u003cstrong\u003e\u003cmark\u003e只根据目的端口（dst_port）来做哈希\u003c/mark\u003e\u003c/strong\u003e，因此\n\u003cstrong\u003e\u003cmark\u003eIP 不同但 dst_port 相同的 socket 都会哈希到同一个 bucket\u003c/mark\u003e\u003c/strong\u003e\n （在 Cloudflare 的场景中，有 16K entry 会命中同一个 bucket，形成一个非常长的链表）。\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003e__inet_lookup_listener()\u003c/code\u003e 老代码就不看了，直接看 5.10 的新代码，这已经包含了 Facebook 的 BPF 功能：\u003c/p\u003e\n\n\u003cdiv class=\"language-c highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e// net/ipv4/inet_hashtables.c\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003estruct\u003c/span\u003e \u003cspan class=\"n\"\u003esock\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"nf\"\u003e__inet_lookup_listener\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003estruct\u003c/span\u003e \u003cspan class=\"n\"\u003enet\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003enet\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                    \u003cspan class=\"k\"\u003estruct\u003c/span\u003e \u003cspan class=\"n\"\u003einet_hashinfo\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003ehashinfo\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                    \u003cspan class=\"k\"\u003estruct\u003c/span\u003e \u003cspan class=\"n\"\u003esk_buff\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003eskb\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003edoff\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                    \u003cspan class=\"k\"\u003econst\u003c/span\u003e \u003cspan class=\"n\"\u003e__be32\u003c/span\u003e \u003cspan class=\"n\"\u003esaddr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003e__be16\u003c/span\u003e \u003cspan class=\"n\"\u003esport\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                    \u003cspan class=\"k\"\u003econst\u003c/span\u003e \u003cspan class=\"n\"\u003e__be32\u003c/span\u003e \u003cspan class=\"n\"\u003edaddr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003econst\u003c/span\u003e \u003cspan class=\"kt\"\u003eunsigned\u003c/span\u003e \u003cspan class=\"kt\"\u003eshort\u003c/span\u003e \u003cspan class=\"n\"\u003ehnum\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                    \u003cspan class=\"k\"\u003econst\u003c/span\u003e \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003edif\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003econst\u003c/span\u003e \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003esdif\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"k\"\u003estruct\u003c/span\u003e \u003cspan class=\"n\"\u003einet_listen_hashbucket\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003eilb2\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"k\"\u003estruct\u003c/span\u003e \u003cspan class=\"n\"\u003esock\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003eNULL\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"kt\"\u003eunsigned\u003c/span\u003e \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ehash2\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 如果这里 attach 了 BPF 程序，直接让 BPF 程序来选择 socket\u003c/span\u003e\n    \u003cspan class=\"cm\"\u003e/* Lookup redirect from BPF */\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003estatic_branch_unlikely\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003ebpf_sk_lookup_enabled\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003einet_lookup_run_bpf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003enet\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehashinfo\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eskb\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edoff\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esaddr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esport\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edaddr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehnum\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n        \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n            \u003cspan class=\"k\"\u003egoto\u003c/span\u003e \u003cspan class=\"n\"\u003edone\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 没有 attach BPF 程序或 BPF 程序没找到 socket： fallback 到常规的内核查找 socket 逻辑\u003c/span\u003e\n\n    \u003cspan class=\"n\"\u003ehash2\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eipv4_portaddr_hash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003enet\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edaddr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehnum\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eilb2\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003einet_lhash2_bucket\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehashinfo\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehash2\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\n    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003einet_lhash2_lookup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003enet\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eilb2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eskb\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edoff\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esaddr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esport\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edaddr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehnum\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edif\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esdif\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"k\"\u003egoto\u003c/span\u003e \u003cspan class=\"n\"\u003edone\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\n    \u003cspan class=\"cm\"\u003e/* Lookup lhash2 with INADDR_ANY */\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehash2\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eipv4_portaddr_hash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003enet\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehtonl\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eINADDR_ANY\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003ehnum\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eilb2\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003einet_lhash2_bucket\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehashinfo\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehash2\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\n    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003einet_lhash2_lookup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003enet\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eilb2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eskb\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edoff\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esaddr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esport\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehtonl\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eINADDR_ANY\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003ehnum\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edif\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esdif\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"nl\"\u003edone:\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eIS_ERR\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"nb\"\u003eNULL\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch2 id=\"43-bpf_sk_select_reuseport-vs-bpf_sk_lookup\"\u003e4.3 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ebpf_sk_select_reuseport\u003c/code\u003e vs \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ebpf_sk_lookup\u003c/code\u003e\u003c/h2\u003e\n\n\u003cp\u003e这种两种类型的 BPF 程序，分别是 Facebook 和 Cloudflare （根据各自需求）引入内核的，\n功能有些相似，因此拿来对比一下。\u003c/p\u003e\n\n\u003cp\u003e先看一段 Cloudflare 引入 \u003ca href=\"https://lwn.net/Articles/825103/\"\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003ebpf_sk_lookup\u003c/code\u003e\u003c/a\u003e 时的 commit message，\u003c/p\u003e\n\n\u003cdiv class=\"language-plaintext highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003eThis series proposes a new BPF program type named BPF_PROG_TYPE_SK_LOOKUP,\nor BPF sk_lookup for short.\n\nBPF sk_lookup program runs when transport layer is looking up a listening\nsocket for a new connection request (TCP), or when looking up an\nunconnected socket for a packet (UDP).\n\nThis serves as a mechanism to overcome the limits of what bind() API allows\nto express. Two use-cases driving this work are:\n\n(1) steer packets destined to an IP range, fixed port to a single socket\n\n192.0.2.0/24, port 80 -\u0026gt; NGINX socket\n\n(2) steer packets destined to an IP address, any port to a single socket\n\n198.51.100.1, any port -\u0026gt; L7 proxy socket\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e更多信息，可参考他们的论文：\u003c/p\u003e\n\n  \u003cp\u003eThe ties that un-bind: decoupling IP from web services and sockets for robust addressing agility at CDN-scale, SIGCOMM 2021\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003e可以看到，它也允许多个 socket bind 到同一个 port，因此与 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ebpf_sk_select_reuseport\u003c/code\u003e\n功能有些重叠，因为二者都源于这样一种限制：\u003cstrong\u003e\u003cmark\u003e在收包时，缺少从应用层直接命令内核选择哪个 socket 的控制能力\u003c/mark\u003e\u003c/strong\u003e。\u003c/p\u003e\n\n\u003cp\u003e但二者也是有区别的：\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003esk_select_reuseport\u003c/code\u003e 与 IP 地址所属的 socket family 是紧耦合的\u003c/li\u003e\n  \u003cli\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003esk_lookup\u003c/code\u003e 则\u003cstrong\u003e\u003cmark\u003e将 IP 与 socket 解耦\u003c/mark\u003e\u003c/strong\u003e —— lets it pick any / netns\u003c/li\u003e\n\u003c/ul\u003e\n\n\n  \u003c!-- POST NAVIGATION --\u003e\n  \u003cdiv class=\"postNav clearfix\"\u003e\n     \n      \u003ca class=\"prev\" href=\"/blog/bpf-datapath-extensions-for-k8s-zh/\"\u003e\u003cspan\u003e« [译] 为 K8s workload 引入的一些 BPF datapath 扩展（LPC, 2021）\u003c/span\u003e\n      \n    \u003c/a\u003e\n      \n      \n      \u003ca class=\"next\" href=\"/blog/trip-first-step-towards-cloud-native-security/\"\u003e\u003cspan\u003eTrip.com: First Step towards Cloud Native Security »\u003c/span\u003e\n       \n      \u003c/a\u003e\n     \n  \u003c/div\u003e\n\u003c/div\u003e",
  "Date": "2021-12-05T00:00:00Z",
  "Author": "Arthur Chiao"
}