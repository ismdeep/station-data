{
  "Source": "arthurchiao.art",
  "Title": "大模型 RAG 基础：信息检索、文本向量化及 BGE-M3 embedding 实践（2024）",
  "Link": "https://arthurchiao.art/blog/rag-basis-bge-zh/",
  "Content": "\u003cdiv class=\"post\"\u003e\n  \n  \u003ch1 class=\"postTitle\"\u003e大模型 RAG 基础：信息检索、文本向量化及 BGE-M3 embedding 实践（2024）\u003c/h1\u003e\n  \u003cp class=\"meta\"\u003ePublished at 2024-08-04 | Last Update 2024-08-19\u003c/p\u003e\n  \n  \u003cp\u003e本文整理一些文本向量化（embedding）和信息检索的知识，它们是如今大模型生成文本时常用的技术 —— “增强检索生成”（RAG）—— 的基础：\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/rag-basis-bge/bert-embedding-similarity.svg\" width=\"100%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig. Similarity score based on BERT embedding. \u003ca href=\"https://docs.kolena.com/metrics/bertscore/\"\u003eImage source\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e水平及维护精力所限，文中不免存在错误或过时之处，请酌情参考。\n\u003cstrong\u003e\u003cmark\u003e传播知识，尊重劳动，年满十八周岁，转载请注明\u003ca href=\"https://arthurchiao.art\"\u003e出处\u003c/a\u003e\u003c/mark\u003e\u003c/strong\u003e。\u003c/p\u003e\n\n\u003chr/\u003e\n\n\u003cul id=\"markdown-toc\"\u003e\n  \u003cli\u003e\u003ca href=\"#1-信息检索information-retrieval技术三大发展阶段\" id=\"markdown-toc-1-信息检索information-retrieval技术三大发展阶段\"\u003e1 信息检索（information retrieval）技术三大发展阶段\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#11-基于统计信息和关键词匹配1970s-2010s\" id=\"markdown-toc-11-基于统计信息和关键词匹配1970s-2010s\"\u003e1.1 基于统计信息和关键词匹配（\u003ccode class=\"language-plaintext highlighter-rouge\"\u003e1970s-2010s\u003c/code\u003e）\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#111-典型算法tf-idfbm25\" id=\"markdown-toc-111-典型算法tf-idfbm25\"\u003e1.1.1 典型算法：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eTF-IDF\u003c/code\u003e、\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eBM25\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#112-原理\" id=\"markdown-toc-112-原理\"\u003e1.1.2 原理\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#113-优缺点\" id=\"markdown-toc-113-优缺点\"\u003e1.1.3 优缺点\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#12-基于深度学习和上下文语义\" id=\"markdown-toc-12-基于深度学习和上下文语义\"\u003e1.2 基于深度学习和上下文语义\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#121-word2vec-google-2013\" id=\"markdown-toc-121-word2vec-google-2013\"\u003e1.2.1 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eWord2Vec\u003c/code\u003e (Google, 2013)\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#122-bert-google-2019\" id=\"markdown-toc-122-bert-google-2019\"\u003e1.2.2 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eBERT\u003c/code\u003e (Google, 2019)\u003c/a\u003e            \u003cul\u003e\n              \u003cli\u003e\u003ca href=\"#核心设计和优点\" id=\"markdown-toc-核心设计和优点\"\u003e核心设计和优点\u003c/a\u003e\u003c/li\u003e\n              \u003cli\u003e\u003ca href=\"#局限性领域外out-of-domain信息检索效果差\" id=\"markdown-toc-局限性领域外out-of-domain信息检索效果差\"\u003e局限性：领域外（Out-of-Domain）信息检索效果差\u003c/a\u003e\u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#13-学习型组合前两种的优点\" id=\"markdown-toc-13-学习型组合前两种的优点\"\u003e1.3 学习型：组合前两种的优点\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#131-原理传统-sparse-vector-与上下文化信息的融合\" id=\"markdown-toc-131-原理传统-sparse-vector-与上下文化信息的融合\"\u003e1.3.1 原理：传统 sparse vector 与上下文化信息的融合\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#132-与传统-sparse-embedding-的区别\" id=\"markdown-toc-132-与传统-sparse-embedding-的区别\"\u003e1.3.2 与传统 sparse embedding 的区别\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#133-优点\" id=\"markdown-toc-133-优点\"\u003e1.3.3 优点\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#2-信息检索三种-embedding-的对比\" id=\"markdown-toc-2-信息检索三种-embedding-的对比\"\u003e2 信息检索：三种 embedding 的对比\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#21-sparse-embedding-lexical-matching\" id=\"markdown-toc-21-sparse-embedding-lexical-matching\"\u003e2.1 Sparse embedding (lexical matching)\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#22-dense-embedding-eg-bert-based\" id=\"markdown-toc-22-dense-embedding-eg-bert-based\"\u003e2.2 Dense embedding (e.g. BERT-based)\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#23-learned-sparse-embedding\" id=\"markdown-toc-23-learned-sparse-embedding\"\u003e2.3 Learned sparse embedding\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#3-embedding--retrieval-工作原理详解\" id=\"markdown-toc-3-embedding--retrieval-工作原理详解\"\u003e3 Embedding \u0026amp; retrieval 工作原理详解\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#31-bert-是如何工作的\" id=\"markdown-toc-31-bert-是如何工作的\"\u003e3.1 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eBERT\u003c/code\u003e 是如何工作的\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#311-理论基础\" id=\"markdown-toc-311-理论基础\"\u003e3.1.1 理论基础\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#312-bert-dense-embedding-工作流\" id=\"markdown-toc-312-bert-dense-embedding-工作流\"\u003e3.1.2 BERT dense embedding 工作流\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#32-基于-bert-dense-embedding-的文档检索是如何工作的\" id=\"markdown-toc-32-基于-bert-dense-embedding-的文档检索是如何工作的\"\u003e3.2 基于 BERT dense embedding 的文档检索是如何工作的\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#33-bge-m3bert-based-learned-sparse-embedding是如何工作的\" id=\"markdown-toc-33-bge-m3bert-based-learned-sparse-embedding是如何工作的\"\u003e3.3 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eBGE-M3\u003c/code\u003e（BERT-based learned sparse embedding）是如何工作的？\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#331-设计--特点\" id=\"markdown-toc-331-设计--特点\"\u003e3.3.1 设计 \u0026amp; 特点\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#332-bge-m3-生成-learned-sparse-embedding-的过程\" id=\"markdown-toc-332-bge-m3-生成-learned-sparse-embedding-的过程\"\u003e3.3.2 BGE-M3 生成 learned sparse embedding 的过程\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#4-bge-m3-实战\" id=\"markdown-toc-4-bge-m3-实战\"\u003e4 BGE-M3 实战\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#41-相似度判断检索\" id=\"markdown-toc-41-相似度判断检索\"\u003e4.1 相似度判断（检索）\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#42-精调fine-tune\" id=\"markdown-toc-42-精调fine-tune\"\u003e4.2 精调（fine-tune）\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#421-官方文档\" id=\"markdown-toc-421-官方文档\"\u003e4.2.1 官方文档\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#422-训练数据格式及要求\" id=\"markdown-toc-422-训练数据格式及要求\"\u003e4.2.2 训练数据格式及要求\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#423-精调命令及参数配置\" id=\"markdown-toc-423-精调命令及参数配置\"\u003e4.2.3 精调命令及参数配置\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#424-测试精调之后的效果\" id=\"markdown-toc-424-测试精调之后的效果\"\u003e4.2.4 测试精调之后的效果\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#43-cpu-运行速度优化将模型转-onnx-格式\" id=\"markdown-toc-43-cpu-运行速度优化将模型转-onnx-格式\"\u003e4.3 CPU 运行速度优化：将模型转 onnx 格式\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#5-rerank-增强对-bge-m3-的检索结果进行重排序\" id=\"markdown-toc-5-rerank-增强对-bge-m3-的检索结果进行重排序\"\u003e5 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ererank\u003c/code\u003e 增强：对 BGE-M3 的检索结果进行重排序\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#51-rerankreranker-是什么\" id=\"markdown-toc-51-rerankreranker-是什么\"\u003e5.1 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ererank/reranker\u003c/code\u003e 是什么？\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#511-另一种相似度模型\" id=\"markdown-toc-511-另一种相似度模型\"\u003e5.1.1 另一种相似度模型\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#512-与-bge-m3-等模型的差异cross-encoder-vs-bi-encoder\" id=\"markdown-toc-512-与-bge-m3-等模型的差异cross-encoder-vs-bi-encoder\"\u003e5.1.2 与 BGE-M3 等模型的差异：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003ecross-encoder vs. bi-encoder\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#52-embedding-和-reranker-工作流\" id=\"markdown-toc-52-embedding-和-reranker-工作流\"\u003e5.2 embedding 和 reranker 工作流\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#53-bge-m3-得到相似分之后为什么要通过-reranker-再计算一遍\" id=\"markdown-toc-53-bge-m3-得到相似分之后为什么要通过-reranker-再计算一遍\"\u003e5.3 BGE-M3 得到相似分之后，为什么要通过 reranker 再计算一遍？\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#6-总结\" id=\"markdown-toc-6-总结\"\u003e6 总结\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#参考资料\" id=\"markdown-toc-参考资料\"\u003e参考资料\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003chr/\u003e\n\n\u003cp\u003eRAG (Retrieval-Augmented Generation，检索增强生成)，是一种利用信息检索（Information Retrieval）\n技术增强大模型生成效果（generation）的技术。RAG 在步骤上很简单，\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e搭建高质量文档数据库\u003c/mark\u003e\u003c/strong\u003e\n    \u003cul\u003e\n      \u003cli\u003e对优质文档进行某种格式的转换（或称编码），例如基于 BERT 将文本段落转换成\n\u003cstrong\u003e\u003cmark\u003e数值格式的向量\u003c/mark\u003e\u003c/strong\u003e（这个过程称为 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eembedding\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e），然后\u003c/li\u003e\n      \u003cli\u003e将这些 embeddings 存储到合适的数据库（例如 ES 或\u003cstrong\u003e\u003cmark\u003e向量数据库\u003c/mark\u003e\u003c/strong\u003e）；\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e针对用户输入进行数据库检索\u003c/mark\u003e\u003c/strong\u003e\n    \u003cul\u003e\n      \u003cli\u003e对用户输入的 query 进行相同的转换（embedding），然后\u003c/li\u003e\n      \u003cli\u003e利用最近邻等相似性算法，在文档库中\u003cstrong\u003e\u003cmark\u003e寻找最相似的文本段落\u003c/mark\u003e\u003c/strong\u003e（与给定问题最相关的段落）；\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e大模型生成返回给用户的内容\u003c/mark\u003e\u003c/strong\u003e\n    \u003cul\u003e\n      \u003cli\u003e将找到文本段落送到大模型，辅助生成最终的输出文本，返回给用户。\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e本文主要关注以上 1 \u0026amp; 2 步骤中的 embedding \u0026amp; retrieval 阶段。\u003c/p\u003e\n\n\u003ch1 id=\"1-信息检索information-retrieval技术三大发展阶段\"\u003e1 信息检索（information retrieval）技术三大发展阶段\u003c/h1\u003e\n\n\u003cp\u003e信息检索的技术发展大致可分为三个阶段：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\n    \u003cp\u003e\u003cstrong\u003e\u003cmark\u003e基于统计信息\u003c/mark\u003e\u003c/strong\u003e的\u003cstrong\u003e\u003cmark\u003e关键字匹配\u003c/mark\u003e\u003c/strong\u003e（statistical keyword matching）\u003c/p\u003e\n\n    \u003cul\u003e\n      \u003cli\u003e是一种 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003esparse embedding\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e —— embedding 向量的大部分字段都是 0；\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e基于\u003cstrong\u003e\u003cmark\u003e深度学习\u003c/mark\u003e\u003c/strong\u003e模型的\u003cstrong\u003e\u003cmark\u003e上下文和语义理解\u003c/mark\u003e\u003c/strong\u003e，\u003c/p\u003e\n\n    \u003cul\u003e\n      \u003cli\u003e属于 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003edense embedding\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e —— embedding 向量的大部分字段都非零；\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e所谓的“学习型”表示，组合上面两种的优点，称为 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003elearned sparse embedding\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e\u003c/p\u003e\n\n    \u003cul\u003e\n      \u003cli\u003e既有深度学习模型的上下文和语义理解能力；\u003c/li\u003e\n      \u003cli\u003e又具备稀疏表示的可解释性（interpretability of sparse representations）和低计算复杂度。\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e下面分别来看。\u003c/p\u003e\n\n\u003ch2 id=\"11-基于统计信息和关键词匹配1970s-2010s\"\u003e1.1 基于统计信息和关键词匹配（\u003ccode class=\"language-plaintext highlighter-rouge\"\u003e1970s-2010s\u003c/code\u003e）\u003c/h2\u003e\n\n\u003ch3 id=\"111-典型算法tf-idfbm25\"\u003e1.1.1 典型算法：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eTF-IDF\u003c/code\u003e、\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eBM25\u003c/code\u003e\u003c/h3\u003e\n\n\u003cp\u003e早期信息检索系统主要是\u003cstrong\u003e\u003cmark\u003e基于统计信息\u003c/mark\u003e\u003c/strong\u003e + \u003cstrong\u003e\u003cmark\u003e匹配关键词\u003c/mark\u003e\u003c/strong\u003e，算法包括，\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Tf%E2%80%93idf\"\u003eTF-IDF\u003c/a\u003e (term frequency - inverse document frequency), 1970s\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Okapi_BM25\"\u003eBM25\u003c/a\u003e (Best Matching), 1980s\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"112-原理\"\u003e1.1.2 原理\u003c/h3\u003e\n\n\u003cp\u003e分析\u003cstrong\u003e\u003cmark\u003e语料库的词频和分布\u003c/mark\u003e\u003c/strong\u003e（term frequency and distribution），\n作为评估\u003cstrong\u003e\u003cmark\u003e文档的相关性\u003c/mark\u003e\u003c/strong\u003e（document relevance）的基础。\u003c/p\u003e\n\n\u003ch3 id=\"113-优缺点\"\u003e1.1.3 优缺点\u003c/h3\u003e\n\n\u003cul\u003e\n  \u003cli\u003e优点：方法简单，效果不错，所以使用很广泛。\u003c/li\u003e\n  \u003cli\u003e缺点：单纯根据词频等统计和关键字检索做判断，不理解语义。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2 id=\"12-基于深度学习和上下文语义\"\u003e1.2 基于深度学习和上下文语义\u003c/h2\u003e\n\n\u003ch3 id=\"121-word2vec-google-2013\"\u003e1.2.1 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eWord2Vec\u003c/code\u003e (Google, 2013)\u003c/h3\u003e\n\n\u003cp\u003e2013 年，谷歌提出了 \u003ca href=\"https://zilliz.com/learn/transforming-text-the-rise-of-sentence-transformers-in-nlp\"\u003eWord2Vec\u003c/a\u003e，\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e首次尝试\u003cstrong\u003e\u003cmark\u003e使用高维向量来表示单词\u003c/mark\u003e\u003c/strong\u003e，能分辨它们细微的语义差别；\u003c/li\u003e\n  \u003cli\u003e标志着向\u003cstrong\u003e\u003cmark\u003e机器学习驱动\u003c/mark\u003e\u003c/strong\u003e的信息检索的转变。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"122-bert-google-2019\"\u003e1.2.2 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eBERT\u003c/code\u003e (Google, 2019)\u003c/h3\u003e\n\n\u003cp\u003e基于 transformer 的\u003cstrong\u003e\u003cmark\u003e预训练（pretrain）语言模型\u003c/mark\u003e\u003c/strong\u003e BERT 的出现，彻底颠覆了传统的信息检索范式。\u003c/p\u003e\n\n\u003ch4 id=\"核心设计和优点\"\u003e核心设计和优点\u003c/h4\u003e\n\n\u003col\u003e\n  \u003cli\u003etransformer 的核心是 self-attention，\n    \u003cul\u003e\n      \u003cli\u003eself-attention 能\u003cstrong\u003e\u003cmark\u003e量化给定单词与句子中其他单词的关联性程度\u003c/mark\u003e\u003c/strong\u003e，\u003c/li\u003e\n      \u003cli\u003e换句话说就是：能在上下文中分辨单词的含义；\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eBERT 是双向（前向+后向）transformer，\n    \u003cul\u003e\n      \u003cli\u003e可以理解为在预训练时，每个句子正向读一遍，反向再读一遍；\u003c/li\u003e\n      \u003cli\u003e能更好地捕获句子的上下文语义（contextual semantics）；\u003c/li\u003e\n      \u003cli\u003e最终输出是一个 \u003cstrong\u003e\u003cmark\u003edense vector\u003c/mark\u003e\u003c/strong\u003e，本质上是对语义的压缩；\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e基于 dense vector 描述，用最近邻算法就能对给定的 query 进行检索，强大且语义准确。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch4 id=\"局限性领域外out-of-domain信息检索效果差\"\u003e局限性：领域外（Out-of-Domain）信息检索效果差\u003c/h4\u003e\n\n\u003cp\u003eBERT 严重依赖\u003cstrong\u003e\u003cmark\u003e预训练数据集\u003c/mark\u003e\u003c/strong\u003e的领域知识（domain-specific knowledge），\n预训练过程使 BERT 偏向于预训练数据的特征，\n因此在领域外（Out-Of-Domain），例如没有见过的文本片段，表现就不行了。\u003c/p\u003e\n\n\u003cp\u003e解决方式之一是\u003cstrong\u003e\u003cmark\u003e\u003ccode\u003efine-tune\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e（精调/微调），但成本相对较高，\n因为准备高质量数据集的成本是很高的。\u003c/p\u003e\n\n\u003cp\u003e另一方面，尽管传统 sparse embedding 在词汇不匹配问题时虽然也存在挑战，\n但在领域外信息检索中，它们的表现却优于 BERT。\n这是因为在这类算法中，未识别的术语不是靠“学习”，而是单纯靠“匹配”。\u003c/p\u003e\n\n\u003ch2 id=\"13-学习型组合前两种的优点\"\u003e1.3 学习型：组合前两种的优点\u003c/h2\u003e\n\n\u003ch3 id=\"131-原理传统-sparse-vector-与上下文化信息的融合\"\u003e1.3.1 原理：传统 sparse vector 与上下文化信息的融合\u003c/h3\u003e\n\n\u003col\u003e\n  \u003cli\u003e先通过 BERT 等深度学习模型生成 dense embedding；\u003c/li\u003e\n  \u003cli\u003e再引入额外的步骤对以上 dense embedding 进行稀疏化，得到一个 sparse embedding；\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e代表算法：BGE-M3。\u003c/p\u003e\n\n\u003ch3 id=\"132-与传统-sparse-embedding-的区别\"\u003e1.3.2 与传统 sparse embedding 的区别\u003c/h3\u003e\n\n\u003cp\u003e根据以上描述，乍一看，这种 learned sparse embedding 与传统 sparse embedding 好像没太大区别，\n但实际上二者有着本质不同，这种 embedding，\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e引入了 Token Importance Estimation；\u003c/li\u003e\n  \u003cli\u003e既保留了关键词搜索能力，又利用上下文信息，丰富了 embedding 的稀疏表示；\u003c/li\u003e\n  \u003cli\u003e能够辨别相邻或相关的 token 的重要性，即使这些 token 在文本中没有明确出现。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"133-优点\"\u003e1.3.3 优点\u003c/h3\u003e\n\n\u003cul\u003e\n  \u003cli\u003e将稀疏表示与学习上下文结合，同时具备精确匹配和语义理解两大能力，在领域外场景有很强的泛化能力；\u003c/li\u003e\n  \u003cli\u003e与 dense embedding 相比更简洁，只保留了最核心的文本信息；\u003c/li\u003e\n  \u003cli\u003e固有的稀疏性使向量相似性搜索所需的计算资源极少；\u003c/li\u003e\n  \u003cli\u003e术语匹配特性还增强了可解释性，能够更精确地洞察底层的检索过程，提高了系统的透明度。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch1 id=\"2-信息检索三种-embedding-的对比\"\u003e2 信息检索：三种 embedding 的对比\u003c/h1\u003e\n\n\u003cp\u003e简单来说，\nvector embedding，或称向量表示，是一个单词或句子在\u003cstrong\u003e\u003cmark\u003e高维向量空间\u003c/mark\u003e\u003c/strong\u003e中的\u003cstrong\u003e\u003cmark\u003e数值表示\u003c/mark\u003e\u003c/strong\u003e。\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e高维空间：一个维度能代表一个特征或属性，高维意味着分辨率高，能区分细微的语义差异；\u003c/li\u003e\n  \u003cli\u003e数值表示：一个 embedding 一般就是一个\u003cstrong\u003e\u003cmark\u003e浮点数数组\u003c/mark\u003e\u003c/strong\u003e，所以方便计算。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e对应上一节介绍的三个主要发展阶段，常见的有三种 embedding 类型：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003etraditional sparse embedding\u003c/li\u003e\n  \u003cli\u003edense embedding\u003c/li\u003e\n  \u003cli\u003elearned sparse embedding\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch2 id=\"21-sparse-embedding-lexical-matching\"\u003e2.1 Sparse embedding (lexical matching)\u003c/h2\u003e\n\n\u003cul\u003e\n  \u003cli\u003e映射成一个高维（维度一般就是 vocabulary 空间大小）向量\u003c/li\u003e\n  \u003cli\u003e向量的大部分元素都是 0，非零值表明 token 在特定文档中的相对重要性，只为那些输入文本中出现过的 token 计算权重\u003c/li\u003e\n  \u003cli\u003e典型模型：BM25（对 TF-IDF 的改进）\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e非常适合\u003cstrong\u003e\u003cmark\u003e关键词匹配\u003c/mark\u003e\u003c/strong\u003e任务（keyword-matching tasks）。\u003c/p\u003e\n\n\u003ch2 id=\"22-dense-embedding-eg-bert-based\"\u003e2.2 Dense embedding (e.g. BERT-based)\u003c/h2\u003e\n\n\u003cul\u003e\n  \u003cli\u003e映射到一个（相对低维）向量，所有维度都非零\u003c/li\u003e\n  \u003cli\u003e相比 sparse embedding 维度要低很多，例如基于 BERT 默认 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e1x768\u003c/code\u003e 维度；\u003c/li\u003e\n  \u003cli\u003e典型模型：BGE-v1.5\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e所有维度都非零，包含语义理解，信息非常丰富，因此适用于\n\u003cstrong\u003e\u003cmark\u003e语义搜索\u003c/mark\u003e\u003c/strong\u003e任务（semantic search tasks）。\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003eMulti-vector retrieval\u003c/p\u003e\n\n  \u003cul\u003e\n    \u003cli\u003e用多个向量表示一段文本，可以看做是对 dense retrieval 的一种扩展\u003c/li\u003e\n    \u003cli\u003e模型：ColBERT\u003c/li\u003e\n  \u003c/ul\u003e\n\u003c/blockquote\u003e\n\n\u003ch2 id=\"23-learned-sparse-embedding\"\u003e2.3 Learned sparse embedding\u003c/h2\u003e\n\n\u003cp\u003e结合了传统 sparse embedding 的精确度和 dense embedding 的语义丰富性，\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e可以通过深度学习模型“学习”相关 token 的重要性，即使是一些并未出现过的 token，\u003c/li\u003e\n  \u003cli\u003e生成的“学习型”稀疏表示，能有效捕捉 query 和 doc 中的关键词。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch1 id=\"3-embedding--retrieval-工作原理详解\"\u003e3 Embedding \u0026amp; retrieval 工作原理详解\u003c/h1\u003e\n\n\u003cp\u003e这里主要介绍 BGE-M3 模型的原理。\u003cstrong\u003e\u003cmark\u003eBGE-M3 建立在 BERT 之上\u003c/mark\u003e\u003c/strong\u003e，因此需要先回顾 BERT 的基本原理。\u003c/p\u003e\n\n\u003ch2 id=\"31-bert-是如何工作的\"\u003e3.1 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eBERT\u003c/code\u003e 是如何工作的\u003c/h2\u003e\n\n\u003ch3 id=\"311-理论基础\"\u003e3.1.1 理论基础\u003c/h3\u003e\n\n\u003cul\u003e\n  \u003cli\u003eBERT 论文：\u003ca href=\"/blog/bert-paper-zh/\"\u003e\u003cmark\u003eBERT：预训练深度双向 Transformers 做语言理解\u003c/mark\u003e（Google，2019）\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003eBERT 基于 transformer，后者的核心是 self-attention\n    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"/blog/transformers-from-scratch-zh/\"\u003eTransformer 是如何工作的：600 行 Python 代码实现 self-attention 和两类 Transformer（2019）\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"/blog/visual-intro-to-transformers-zh/\"\u003e什么是 GPT？Transformer 工作原理的动画展示（2024）\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"312-bert-dense-embedding-工作流\"\u003e3.1.2 BERT dense embedding 工作流\u003c/h3\u003e\n\n\u003cp\u003e以输入 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003e\u0026#34;Milvus is a vector database built for scalable similarity search\u0026#34;\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e 为例，工作过程 [2]：\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/rag-basis-bge/bert-dense-embedding.png\" width=\"90%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig. BERT dense embedding.\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eTokenization\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e\n    \u003col\u003e\n      \u003cli\u003e将输入文本转成 token 序列\u003c/li\u003e\n      \u003cli\u003eBERT 还会插入两个特殊的 token：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003e[CLS]\u003c/code\u003e token 表示开始，\u003ccode class=\"language-plaintext highlighter-rouge\"\u003e[SEP]\u003c/code\u003e token 表示一个句子的结束。\u003c/li\u003e\n    \u003c/ol\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eEmbedding\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e：使用 embedding matrix 将每个 token 转换为一个向量，详见 BERT 论文；\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eEncoding\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e：这些向量通过多层 encoder，每层由 self-attention 和 feed-forward 神经网络组成\n    \u003col\u003e\n      \u003cli\u003e会根据所有其他 token 提供的上下文细化每个 token 的表示。\u003c/li\u003e\n    \u003c/ol\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eOutput\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e：输出一系列最终的 \u003cstrong\u003e\u003cmark\u003eembedding vectors\u003c/mark\u003e\u003c/strong\u003e。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e最终生成的 dense embedding 能够捕捉单个单词的含义及其在句子中的相互关系。\u003c/p\u003e\n\n\u003cp\u003e理解 BERT 是如何生成 dense embedding 之后，接下来看看基于 BERT dense embedding 的信息检索是如何工作的。\u003c/p\u003e\n\n\u003ch2 id=\"32-基于-bert-dense-embedding-的文档检索是如何工作的\"\u003e3.2 基于 BERT dense embedding 的文档检索是如何工作的\u003c/h2\u003e\n\n\u003cp\u003e有了 dense embedding 之后，针对给定文本输入检索文档就很简单了，只需要再加一个最近邻之类的算法就行。\u003c/p\u003e\n\n\u003cp\u003e下面是两个句子的相似度判断，原理跟文档检索是一样的：\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/rag-basis-bge/bert-embedding-similarity.svg\" width=\"100%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig. Similarity score based on BERT embedding. \u003ca href=\"https://docs.kolena.com/metrics/bertscore/\"\u003eImage source\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e下面看个具体的 embedding \u0026amp; retrieval 模型：BGE-M3。\u003c/p\u003e\n\n\u003ch2 id=\"33-bge-m3bert-based-learned-sparse-embedding是如何工作的\"\u003e3.3 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eBGE-M3\u003c/code\u003e（BERT-based learned sparse embedding）是如何工作的？\u003c/h2\u003e\n\n\u003cp\u003eBGE 是一系列 embedding 模型，扩展了 BERT 的能力。\u003ca href=\"https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/BGE_M3\"\u003eBGE-M3\u003c/a\u003e\n是目前最新的一个，3 个 M 是强调的多个 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003emulti-\u003c/code\u003e 能力：\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eMulti-Functionality\u003c/li\u003e\n  \u003cli\u003eMulti-Linguisticity\u003c/li\u003e\n  \u003cli\u003eMulti-Granularity\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"331-设计--特点\"\u003e3.3.1 设计 \u0026amp; 特点\u003c/h3\u003e\n\n\u003cp\u003eBGE-M3 通过更精细的方法来捕捉每个 token 的重要性，\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eToken importance estimation\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e：BERT 在分类/相似性比较时仅关注第一个 token（\u003ccode class=\"language-plaintext highlighter-rouge\"\u003e[CLS]\u003c/code\u003e）， BGE-M3 则扩大到关注序列中的每个 token \u003ccode\u003eH\u003csub\u003ei\u003c/sub\u003e\u003c/code\u003e；\u003c/li\u003e\n  \u003cli\u003e线性变换：在 encoder 的输出层上又增加一个线性层，计算每个 token 的 importance weights \u003ccode\u003eW\u003csub\u003elex\u003c/sub\u003e\u003c/code\u003e；\u003c/li\u003e\n  \u003cli\u003e激活函数：\n    \u003cul\u003e\n      \u003cli\u003e\u003ccode\u003eW\u003csub\u003elex\u003c/sub\u003e\u003c/code\u003e 和 \u003ccode\u003eH\u003csub\u003ei\u003c/sub\u003e\u003c/code\u003e 的乘积经过 Rectified Linear Unit (ReLU) 激活函数，得到每个 token 的术语权重 \u003ccode\u003eW\u003csub\u003et\u003c/sub\u003e\u003c/code\u003e。\u003c/li\u003e\n      \u003cli\u003eReLU 的结果是非负的，有助于 embedding 的稀疏性。\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e\u003ccode\u003elearned sparse embedding\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e：以上输出的是一个 sparse embedding，其中每个 token 都有一个相关的 weights，表明在整个输入文本上下文中的重要性。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e下面看个例子。\u003c/p\u003e\n\n\u003ch3 id=\"332-bge-m3-生成-learned-sparse-embedding-的过程\"\u003e3.3.2 BGE-M3 生成 learned sparse embedding 的过程\u003c/h3\u003e\n\n\u003cp\u003e还是前面例子提到的输入，\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e先走 BERT dense embedding 的流程，\u003c/li\u003e\n  \u003cli\u003e最后加一个 linear 层，得到 learned sparse embedding。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/rag-basis-bge/bgem3-embedding-output.webp\" width=\"75%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig. BGE-M3 \u003cmark\u003elearned sparse embedding\u003c/mark\u003e.\n\u003ca href=\"https://medium.com/@zilliz_learn/exploring-bge-m3-and-splade-two-machine-learning-models-for-generating-sparse-embeddings-0772de2c52a7\"\u003eImage source\u003c/a\u003e\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003eIn M3-Embedding, the \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e[CLS]\u003c/code\u003e embedding is used for dense retrieval, while\n embeddings from other tokens are used for sparse retrieval and multi-vector\n retrieval [3].\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch1 id=\"4-bge-m3-实战\"\u003e4 BGE-M3 实战\u003c/h1\u003e\n\n\u003ch2 id=\"41-相似度判断检索\"\u003e4.1 相似度判断（检索）\u003c/h2\u003e\n\n\u003cdiv class=\"language-shell highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nv\"\u003e$ \u003c/span\u003epip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003eFlagEmbedding peft sentencepiece\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e来自官方的代码，稍作修改：\u003c/p\u003e\n\n\u003cdiv class=\"language-python highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eFlagEmbedding\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eBGEM3FlagModel\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eBGEM3FlagModel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#39;/root/bge-m3\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003euse_fp16\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003equeries\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;What is BGE M3?\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n           \u003cspan class=\"s\"\u003e\u0026#34;Defination of BM25\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003cspan class=\"n\"\u003edocs\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;BGE M3 is an embedding model supporting dense retrieval, lexical matching and multi-vector interaction.\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"s\"\u003e\u0026#34;BM25 is a bag-of-words retrieval function that ranks a set of documents based on the query terms appearing in each document\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003equery_embeddings\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eencode\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003equeries\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ebatch_size\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e12\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emax_length\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e8192\u003c/span\u003e\u003cspan class=\"p\"\u003e,)[\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#39;dense_vecs\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003cspan class=\"n\"\u003edocs_embeddings\u003c/span\u003e  \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eencode\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edocs\u003c/span\u003e\u003cspan class=\"p\"\u003e)[\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#39;dense_vecs\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003cspan class=\"n\"\u003esimilarity\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003equery_embeddings\u003c/span\u003e \u003cspan class=\"o\"\u003e@\u003c/span\u003e \u003cspan class=\"n\"\u003edocs_embeddings\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eT\u003c/span\u003e\n\u003cspan class=\"k\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esimilarity\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e这个例子是两个问题，分别去匹配两个答案，看彼此之间的相似度（四种组合），运行结果：\u003c/p\u003e\n\n\u003cdiv class=\"language-shell highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"o\"\u003e[[\u003c/span\u003e0.626  0.348 \u003cspan class=\"o\"\u003e]\u003c/span\u003e\n \u003cspan class=\"o\"\u003e[\u003c/span\u003e0.3499 0.678 \u003cspan class=\"o\"\u003e]]\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cul\u003e\n  \u003cli\u003e问题 1 和答案 1 相似度是 0.6265\u003c/li\u003e\n  \u003cli\u003e问题 2 和答案 2 相似度是 0.678\u003c/li\u003e\n  \u003cli\u003e问题 1 和答案 2，以及问题 2 和答案 1，相似度只有 0.3x\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e符合预期。\u003c/p\u003e\n\n\u003ch2 id=\"42-精调fine-tune\"\u003e4.2 精调（fine-tune）\u003c/h2\u003e\n\n\u003cp\u003e精调的目的是让正样本和负样本的分数差变大。\u003c/p\u003e\n\n\u003ch3 id=\"421-官方文档\"\u003e4.2.1 官方文档\u003c/h3\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003ca href=\"https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune\"\u003efine-tune the dense embedding\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/unified_finetune\"\u003efine-tune all embedding function of m3 (dense, sparse and colbert)\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch3 id=\"422-训练数据格式及要求\"\u003e4.2.2 训练数据格式及要求\u003c/h3\u003e\n\n\u003col\u003e\n  \u003cli\u003e文件为 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003ejsonl\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e 格式，每行一个 sample；\n    \u003cul\u003e\n      \u003cli\u003e例子：\u003ca href=\"https://github.com/FlagOpen/FlagEmbedding/blob/master/examples/unified_finetune/toy_train_data/toy_train_data1.jsonl\"\u003etoy_train_data/toy_train_data1.jsonl\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e每个 sample 的格式：\u003cstrong\u003e\u003cmark\u003e\u003ccode\u003e{\u0026#34;query\u0026#34;: str, \u0026#34;pos\u0026#34;: List[str], \u0026#34;neg\u0026#34;:List[str]}\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e\n    \u003cul\u003e\n      \u003cli\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003equery\u003c/code\u003e：用户问题；\u003c/li\u003e\n      \u003cli\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003epos\u003c/code\u003e：正样本列表，简单说就是期望给到用户的回答；不能为空，也就是说必需得有正样本；\u003c/li\u003e\n      \u003cli\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eneg\u003c/code\u003e：负样本列表，是避免给到用户的回答。\n        \u003cul\u003e\n          \u003cli\u003e空要写成 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003e\u0026#34;neg\u0026#34;: [\u0026#34;\u0026#34;]\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e，写 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003e\u0026#34;neg\u0026#34;: []\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e 会报错。\u003c/li\u003e\n          \u003cli\u003e另外为空时试过删掉 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e\u0026#34;neg\u0026#34;: []\u003c/code\u003e 也不行，必须得留着这个字段。\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e注意：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e不是标准 json 格式\u003c/mark\u003e\u003c/strong\u003e，所以 python 直接导出一个 json 文件作为训练数据集是不行的。\u003c/li\u003e\n  \u003cli\u003esample 不能分行，一个 sample 一行。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch3 id=\"423-精调命令及参数配置\"\u003e4.2.3 精调命令及参数配置\u003c/h3\u003e\n\n\u003cp\u003e从 huggingface 或国内的 modelscope 下载 BGE-M3 模型，\u003c/p\u003e\n\n\u003cdiv class=\"language-shell highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nv\"\u003e$ \u003c/span\u003egit lfs \u003cspan class=\"nb\"\u003einstall\u003c/span\u003e\n\u003cspan class=\"nv\"\u003e$ \u003c/span\u003egit clone https://www.modelscope.cn/Xorbits/bge-m3.git\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e精调命令：\u003c/p\u003e\n\n\u003cdiv class=\"language-shell highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nv\"\u003e$ \u003c/span\u003e\u003cspan class=\"nb\"\u003ecat \u003c/span\u003esft.sh\n\u003cspan class=\"c\"\u003e#!/bin/bash\u003c/span\u003e\n\n\u003cspan class=\"nv\"\u003enum_gpus\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e1\n\u003cspan class=\"nv\"\u003eoutput_dir\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e/root/bge-sft-output\n\u003cspan class=\"nv\"\u003emodel_path\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e/root/bge-m3\n\u003cspan class=\"nv\"\u003etrain_data\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e/data/share/bge-dataset\n\u003cspan class=\"nv\"\u003ebatch_size\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e2\n\u003cspan class=\"nv\"\u003equery_max_len\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e128    \u003cspan class=\"c\"\u003e# max 8192\u003c/span\u003e\n\u003cspan class=\"nv\"\u003epassage_max_len\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e1024 \u003cspan class=\"c\"\u003e# max 8192\u003c/span\u003e\n\ntorchrun \u003cspan class=\"nt\"\u003e--nproc_per_node\u003c/span\u003e \u003cspan class=\"nv\"\u003e$num_gpus\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e-m\u003c/span\u003e FlagEmbedding.BGE_M3.run \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e--output_dir\u003c/span\u003e \u003cspan class=\"nv\"\u003e$output_dir\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e--model_name_or_path\u003c/span\u003e \u003cspan class=\"nv\"\u003e$model_path\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e--train_data\u003c/span\u003e \u003cspan class=\"nv\"\u003e$train_data\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e--learning_rate\u003c/span\u003e 1e-5 \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e--fp16\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e--num_train_epochs\u003c/span\u003e 5 \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e--per_device_train_batch_size\u003c/span\u003e \u003cspan class=\"nv\"\u003e$batch_size\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e--dataloader_drop_last\u003c/span\u003e True \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e--normlized\u003c/span\u003e True \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e--temperature\u003c/span\u003e 0.02 \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e--query_max_len\u003c/span\u003e \u003cspan class=\"nv\"\u003e$query_max_len\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e--passage_max_len\u003c/span\u003e \u003cspan class=\"nv\"\u003e$passage_max_len\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e--train_group_size\u003c/span\u003e 2 \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e--negatives_cross_device\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e--logging_steps\u003c/span\u003e 10 \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e--same_task_within_batch\u003c/span\u003e True \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e--save_steps\u003c/span\u003e 10000 \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e--unified_finetuning\u003c/span\u003e True \u003cspan class=\"se\"\u003e\\\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e--use_self_distill\u003c/span\u003e True\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e几个参数要特别注意下：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\n    \u003cp\u003equery \u0026amp; doc 最大长度\u003c/p\u003e\n\n    \u003cul\u003e\n      \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e\u003ccode\u003equery_max_len\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e：支持的最长 query，最大 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e8192\u003c/code\u003e；\u003c/li\u003e\n      \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e\u003ccode\u003epassage_max_len\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e：支持的最长文档（一条 pos 或 neg 记录）长度，最大 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e8192\u003c/code\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n\n    \u003cp\u003eBGE-M3 会分别针对 query 和 doc 初始化两个 tokenizer，以上两个参数其实对应\n \u003cstrong\u003e\u003cmark\u003etokenizer 的 max_length\u003c/mark\u003e\u003c/strong\u003e，而 tokenizer 最大支持 8192（见模型目录 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003etokenizer_config.json\u003c/code\u003e）。\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e\u003ccode\u003ebatch_size\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e：并行度，直接决定了显存占用大小和精调快慢；\n    \u003cul\u003e\n      \u003cli\u003eBGE-M3 跑起来之后显存占用是恒定的，所以可以多试几个 batch size 配置，把显存用到最大；\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e\u003ccode\u003esave_steps\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e：多少个 step 保存一次 checkpoint，默认值 500 太小，每个 checkpoint \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e~7GB\u003c/code\u003e，多了之后可能会打爆磁盘导致任务失败。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e精调快慢取决于 GPU 算力、显存和参数配置，精调开始之后也会打印出预估的完成时间，还是比较准的。\u003c/p\u003e\n\n\u003ch3 id=\"424-测试精调之后的效果\"\u003e4.2.4 测试精调之后的效果\u003c/h3\u003e\n\n\u003cp\u003e还是用 4.1 的代码，稍微改一下，不要把 queries 和 docs 作为列表，而是针对每个 query 和 pos/neg 计算相似度得分。\n然后针对测试集跑一下，看相似性分数是否有提升。\u003c/p\u003e\n\n\u003cp\u003e数据集质量可以的话，精调之后区分度肯定有提升。\u003c/p\u003e\n\n\u003ch2 id=\"43-cpu-运行速度优化将模型转-onnx-格式\"\u003e4.3 CPU 运行速度优化：将模型转 onnx 格式\u003c/h2\u003e\n\n\u003cp\u003e如果是在 CPU 上跑模型（不用 GPU），\n根据之前实际的 BERT 工程经验，转成 onnx 之后能快几倍，尤其是在 Intel CPU 上\n（Intel 公司做了很多优化合并到社区库了）。\u003c/p\u003e\n\n\u003cp\u003e但 BGE-M3 官方没有转 onnx 文档，根据\u003ca href=\"https://huggingface.co/aapot/bge-m3-onnx/tree/main\"\u003e第三方的库\u003c/a\u003e能成功（稍微改点代码，从本地加载模型），效果待验证。\u003c/p\u003e\n\n\u003ch1 id=\"5-rerank-增强对-bge-m3-的检索结果进行重排序\"\u003e5 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ererank\u003c/code\u003e 增强：对 BGE-M3 的检索结果进行重排序\u003c/h1\u003e\n\n\u003ch2 id=\"51-rerankreranker-是什么\"\u003e5.1 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ererank/reranker\u003c/code\u003e 是什么？\u003c/h2\u003e\n\n\u003cp\u003ererank 的意思是“重新排序” —— 对 embedding model 检索得到的多个结果（对应多个分数），\n重新计算它们的相似性分数，给出一个排名。这是一个\u003cstrong\u003e\u003cmark\u003e可选模块\u003c/mark\u003e\u003c/strong\u003e，\n用于对检索结果进行增强，把相似度最高的结果返回给用户。\u003c/p\u003e\n\n\u003ch3 id=\"511-另一种相似度模型\"\u003e5.1.1 另一种相似度模型\u003c/h3\u003e\n\n\u003cp\u003ereranker 也是\u003cstrong\u003e\u003cmark\u003e一类\u003c/mark\u003e\u003c/strong\u003e计算相似度的模型，例如\u003ca href=\"https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/llm_reranker\"\u003e这个列表\u003c/a\u003e\n里的都是 rerank/reranker 模型，\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003ebge-reranker-v2-m3：与 bge-m3 配套的 reranker\u003c/li\u003e\n  \u003cli\u003ebge-reranker-v2-gemma：与 google gemma-2b 配套的 reranker\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e但它们的原理与 BGE-M3 这种 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eembedding model\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e 有差异。\u003c/p\u003e\n\n\u003ch3 id=\"512-与-bge-m3-等模型的差异cross-encoder-vs-bi-encoder\"\u003e5.1.2 与 BGE-M3 等模型的差异：\u003ccode class=\"language-plaintext highlighter-rouge\"\u003ecross-encoder vs. bi-encoder\u003c/code\u003e\u003c/h3\u003e\n\n\u003cp\u003e以两个句子的相似度检测为例，\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/rag-basis-bge/cross-encoder-vs-bi-encoder.webp\" width=\"50%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig. bi-encoder embedding model vs. cross-encoder model. \u003ca href=\"https://medium.com/@bhawana.prs/cross-encoders-and-bi-encoders-23373414f6fd\"\u003eImage source\u003c/a\u003e\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eBGE-M3 属于左边那种，所谓的 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003ebi-encoder embedding model\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e，\n简单说就是两个句子分别输入模型，得到各自的 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003eembedding\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e，\n然后根据 embedding vector 计算相似度；\u003c/li\u003e\n  \u003cli\u003ereranker 属于右边那种，所谓的 \u003cstrong\u003e\u003cmark\u003e\u003ccode\u003ecross-encoder model\u003c/code\u003e\u003c/mark\u003e\u003c/strong\u003e，直接得到结果；\n如果对 BERT 的工作原理比较熟悉（见 BERT paper），就会明白这其实就是 BERT 判别两个句子\n（next sentense prediction, NSP）任务的延伸。\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2 id=\"52-embedding-和-reranker-工作流\"\u003e5.2 embedding 和 reranker 工作流\u003c/h2\u003e\n\n\u003col\u003e\n  \u003cli\u003e用户输入 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003equery\u003c/code\u003e 和 doc 列表 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003edoc1/doc2/doc3/...\u003c/code\u003e，\u003c/li\u003e\n  \u003cli\u003eBGE-M3 计算相似分，返回 topN，例如 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e[{doc1, score1}, {doc2, score2}, {doc3, score3}]\u003c/code\u003e，其中 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003escore1 \u0026gt;= score2 \u0026gt;= score3\u003c/code\u003e，\u003c/li\u003e\n  \u003cli\u003ereranker 接受 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003equery\u003c/code\u003e 和 BGE-M3 的结果，\u003cstrong\u003e\u003cmark\u003e用自己的模型\u003c/mark\u003e\u003c/strong\u003e重新计算 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003equery\u003c/code\u003e 和 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003edoc1/doc2/doc3\u003c/code\u003e 的相似度分数。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch2 id=\"53-bge-m3-得到相似分之后为什么要通过-reranker-再计算一遍\"\u003e5.3 BGE-M3 得到相似分之后，为什么要通过 reranker 再计算一遍？\u003c/h2\u003e\n\n\u003cp\u003e这里可能有个疑问：step 2 不是已经检索出最相关的 N 个 doc 了吗？\n为什么又要进入 step3，\u003cstrong\u003e\u003cmark\u003e用另外一个完全不同的模型（reranker）再计算一种相似分\u003c/mark\u003e\u003c/strong\u003e呢？\u003c/p\u003e\n\n\u003cp\u003e简单来说，embdding 和 rerank 都是 NLP 中理解给定的两个句子（或文本片段）的关系的编码技术。\n再参考刚才的图，\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/rag-basis-bge/cross-encoder-vs-bi-encoder.webp\" width=\"50%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig. bi-encoder embedding model vs. cross-encoder model. \u003ca href=\"https://medium.com/@bhawana.prs/cross-encoders-and-bi-encoders-23373414f6fd\"\u003eImage source\u003c/a\u003e\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003ebi-encoder\n    \u003cul\u003e\n      \u003cli\u003e分别对两个句子进行编码，得到两个独立的 embedding，再计算相似度。\u003c/li\u003e\n      \u003cli\u003e速度快，准确性相对低。\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003ecross-encoder\u003c/p\u003e\n\n    \u003cul\u003e\n      \u003cli\u003e同时对两个句子编码，输出一个相似度分数；也可以换句话说，\u003cstrong\u003e\u003cmark\u003e把两个句子合成一个句子编码\u003c/mark\u003e\u003c/strong\u003e，所以\u003cstrong\u003e\u003cmark\u003e两个句子是彼此依赖的\u003c/mark\u003e\u003c/strong\u003e；\u003c/li\u003e\n      \u003cli\u003e\u003cstrong\u003e\u003cmark\u003e速度慢，准确性高\u003c/mark\u003e\u003c/strong\u003e。\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e总结起来：embedding model 计算的相似度是粗粒度的，只能算\u003cstrong\u003e\u003cmark\u003e粗排\u003c/mark\u003e\u003c/strong\u003e；\nreranker 对 embedding model 得到的若干结果再进行\u003cstrong\u003e\u003cmark\u003e细排\u003c/mark\u003e\u003c/strong\u003e；\n要体会和理解这种差异，还是要看基础 paper \u003ca href=\"/blog/bert-paper-zh/\"\u003e\u003cmark\u003eBERT：预训练深度双向 Transformers 做语言理解\u003c/mark\u003e（Google，2019）\u003c/a\u003e。\u003c/p\u003e\n\n\u003ch1 id=\"6-总结\"\u003e6 总结\u003c/h1\u003e\n\n\u003cp\u003e本文整理了一些 BGE-M3 相关的 RAG 知识。前两篇参考资料非常好，本文很多内容都来自它们，感谢作者。\u003c/p\u003e\n\n\u003ch1 id=\"参考资料\"\u003e参考资料\u003c/h1\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003ca href=\"https://zilliz.com/learn/enhancing-information-retrieval-learned-sparse-embeddings\"\u003eEnhancing Information Retrieval with Sparse Embeddings\u003c/a\u003e, zilliz.com/learn, 2024\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://medium.com/@zilliz_learn/exploring-bge-m3-and-splade-two-machine-learning-models-for-generating-sparse-embeddings-0772de2c52a7\"\u003eExploring BGE-M3 and Splade: Two Machine Learning Models for Generating Sparse Embeddings\u003c/a\u003e, medium.com/@zilliz_learn, 2024\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://arxiv.org/html/2402.03216v4\"\u003eBGE-M3 paper\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://medium.com/@bhawana.prs/cross-encoders-and-bi-encoders-23373414f6fd\"\u003eCross encoders and bi-encoders\u003c/a\u003e, medium.com, 2024\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003chr/\u003e\n\n\u003cp\u003e\u003ca href=\"https://notbyai.fyi\"\u003e\u003cimg src=\"/assets/img/Written-By-Human-Not-By-AI-Badge-white.svg\" alt=\"Written by Human, Not by AI\"/\u003e\u003c/a\u003e\n\u003ca href=\"https://notbyai.fyi\"\u003e\u003cimg src=\"/assets/img/Written-By-Human-Not-By-AI-Badge-black.svg\" alt=\"Written by Human, Not by AI\"/\u003e\u003c/a\u003e\u003c/p\u003e\n\n\n  \u003c!-- POST NAVIGATION --\u003e\n  \u003cdiv class=\"postNav clearfix\"\u003e\n     \n      \u003ca class=\"prev\" href=\"/blog/linux-clock-source-tsc-zh/\"\u003e\u003cspan\u003e« Linux 时钟源之 TSC：软硬件原理、使用场景、已知问题（2024）\u003c/span\u003e\n      \n    \u003c/a\u003e\n      \n      \n      \u003ca class=\"next\" href=\"/blog/gpu-advanced-notes-4-zh/\"\u003e\u003cspan\u003eGPU 进阶笔记（四）：NVIDIA GH200 芯片、服务器及集群组网（2024） »\u003c/span\u003e\n       \n      \u003c/a\u003e\n     \n  \u003c/div\u003e\n\u003c/div\u003e",
  "Date": "2024-08-04T00:00:00Z",
  "Author": "Arthur Chiao"
}