{
  "Source": "arthurchiao.art",
  "Title": "迈入 Cilium+BGP 的云原生网络时代",
  "Link": "https://arthurchiao.art/blog/trip-stepping-into-cloud-native-networking-era-zh/",
  "Content": "\u003cdiv class=\"post\"\u003e\n  \n  \u003ch1 class=\"postTitle\"\u003e迈入 Cilium+BGP 的云原生网络时代\u003c/h1\u003e\n  \u003cp class=\"meta\"\u003ePublished at 2020-11-04 | Last Update 2020-11-04\u003c/p\u003e\n  \n  \u003cblockquote\u003e\n  \u003cp\u003eThis post also provides an \u003ca href=\"/blog/trip-stepping-into-cloud-native-networking-era/\"\u003eEnglish version\u003c/a\u003e.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003e本文是我们的前一篇博客\n\u003ca href=\"/blog/trip-first-step-towards-cloud-native-networking/\"\u003e\u003cstrong\u003e\u003cem\u003eTrip.com: First Step towards Cloud Native Networking\u003c/em\u003e\u003c/strong\u003e\u003c/a\u003e\n的后续，介绍自上一篇博客以来我们在基于 Cilium 的云原生网络和云原生安全方面的一些\n探索和实践。\u003c/p\u003e\n\n\u003chr/\u003e\n\n\u003cul id=\"markdown-toc\"\u003e\n  \u003cli\u003e\u003ca href=\"#1-网络演进简要回顾\" id=\"markdown-toc-1-网络演进简要回顾\"\u003e1 网络演进：简要回顾\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#2-云原生网络实践\" id=\"markdown-toc-2-云原生网络实践\"\u003e2 云原生网络实践\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#21-bgp-建连模型\" id=\"markdown-toc-21-bgp-建连模型\"\u003e2.1 BGP 建连模型\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#22-典型流量转发路径从-pod-访问-service\" id=\"markdown-toc-22-典型流量转发路径从-pod-访问-service\"\u003e2.2 典型流量转发路径：从 Pod 访问 Service\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#23-集群边界-l4l7-入口解决方案\" id=\"markdown-toc-23-集群边界-l4l7-入口解决方案\"\u003e2.3 集群边界 L4/L7 入口解决方案\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#3-云原生安全尝试\" id=\"markdown-toc-3-云原生安全尝试\"\u003e3 云原生安全尝试\u003c/a\u003e    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"#31-cilium-安全策略\" id=\"markdown-toc-31-cilium-安全策略\"\u003e3.1 Cilium 安全策略\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#32-落地挑战\" id=\"markdown-toc-32-落地挑战\"\u003e3.2 落地挑战\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#多集群问题\" id=\"markdown-toc-多集群问题\"\u003e多集群问题\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#混合基础设施\" id=\"markdown-toc-混合基础设施\"\u003e混合基础设施\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"#33-整体方案设计\" id=\"markdown-toc-33-整体方案设计\"\u003e3.3 整体方案设计\u003c/a\u003e        \u003cul\u003e\n          \u003cli\u003e\u003ca href=\"#331-用-clustermesh-做-cilium-集群互连\" id=\"markdown-toc-331-用-clustermesh-做-cilium-集群互连\"\u003e3.3.1 用 ClusterMesh 做 Cilium 集群互连\u003c/a\u003e\u003c/li\u003e\n          \u003cli\u003e\u003ca href=\"#332-扩展-clustermesh感知-mesh-外实例\" id=\"markdown-toc-332-扩展-clustermesh感知-mesh-外实例\"\u003e3.3.2 扩展 ClusterMesh，感知 mesh 外实例\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#4-总结\" id=\"markdown-toc-4-总结\"\u003e4 总结\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"#参考文献\" id=\"markdown-toc-参考文献\"\u003e参考文献\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003chr/\u003e\n\n\u003ch1 id=\"1-网络演进简要回顾\"\u003e1 网络演进：简要回顾\u003c/h1\u003e\n\n\u003cp\u003e从 2013 到 2018 年，我们经历了“物理机 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e-\u0026gt;\u003c/code\u003e 虚拟机 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e-\u0026gt;\u003c/code\u003e 容器”的基础设施演进，但网络技\n术栈基本都是沿用 Neutron+OVS —— 即使对我们（前期）的 Kubernetes 集群也是\n如此。但业务开始往 Kubernetes 迁移之后，这套 Neutron+OVS 的网络方案越来越捉襟见肘，\n尤其是在部署密度更高、规模更大的容器面前，这种大二层网络模型的软件和硬件瓶颈暴露无遗 [1]。\u003c/p\u003e\n\n\u003cp\u003e为了解决这些问题，更重要地，为了满足云原生业务的各种需求（例如，支持Kubernetes\n的 Service 模型），我们调研了很多较新的网络方案，综合评估之后，选择了 Cilium+BGP\n的组合 [3]。\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/trip-first-step-towards-cloud-native-networking/network-evolution-2.png\" width=\"60%\" height=\"60%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig 1-1. Networking solutions over the past years [2]\u003c/p\u003e\n\n\u003cp\u003eCilium+BGP 方案 2019 年底正式在我们生产环境落地，我们打通了 Cilium 网络和现有网\n络，因此能灰度将容器从 Neutron 迁移到 Cilium。\u003c/p\u003e\n\n\u003ch1 id=\"2-云原生网络实践\"\u003e2 云原生网络实践\u003c/h1\u003e\n\n\u003cp\u003e作为 Cilium 的早期用户，我们对 Cilium 的实现和部署做了一些修改或定制化，以使\n这套方案能平滑地落地到我们现有的基础设施之中，例如 [2]，\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\n    \u003cp\u003e用 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003edocker-compsoe + salt\u003c/code\u003e 来部署，而不是采用默认的 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003edaemonset+configmap\u003c/code\u003e 方式。\u003c/p\u003e\n\n    \u003cp\u003e这样每台 node 上的 cilium-agent 都有独立配置，我们能完全控制发布灰度，将\n 变更风险降到最低。\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e用 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eBIRD\u003c/code\u003e 作为 BGP agent，而不是采用默认的 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ekube-router\u003c/code\u003e。\u003c/p\u003e\n\n    \u003cp\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003ekube-router\u003c/code\u003e 开箱即用，但缺少对 ECMP、BFD 等高级功能的支持，不符合我们生产环境的要求。\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e为了保证某些业务的平滑迁移，我们开发了 StatefulSet/AdvancedStatefulSet 固定 IP 的支持（需要 sticky 调度配合）。\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e定制化了监控和告警。\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e其他一些自定义配置。\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e我们之前的一篇文章 [2] 对此有较详细的介绍，有兴趣可以移步。\n下面讨论几个之前介绍较少或者没有覆盖到的主题。\u003c/p\u003e\n\n\u003ch2 id=\"21-bgp-建连模型\"\u003e2.1 BGP 建连模型\u003c/h2\u003e\n\n\u003cp\u003eCilium+BIRD 方案中，以宿主机为界，网络可以大致分为两部分，如图 2-1 所示，\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/trip-first-step-towards-cloud-native-networking/new-solution-topo.png\" width=\"70%\" height=\"70%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig 2-1. High level topology of the Cilium+BGP solution [2]\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003cstrong\u003e宿主机内部网络\u003c/strong\u003e：由 Cilium（及内核协议栈）负责，职责包括，\n    \u003cul\u003e\n      \u003cli\u003e为容器创建和删除虚拟网络。\u003c/li\u003e\n      \u003cli\u003e为容器生成、编译和加载 eBPF。\u003c/li\u003e\n      \u003cli\u003e处理同宿主机内容器之间的网络通信。\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e跨宿主机网络\u003c/strong\u003e：由 BGP（及内核路由模块）负责，职责包括，\n    \u003cul\u003e\n      \u003cli\u003e与数据中心网络交换路由（PodCIDRs）。\u003c/li\u003e\n      \u003cli\u003e对出宿主机的流量进行路由。\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e对于跨宿主机部分，需要确定要采用哪种 BGP peering 模型，这个模型解决的问题包括\n：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003eBGP agent 的职责，是作为一个全功能路由控制服务，还是仅用作 BGP speaker？\u003c/li\u003e\n  \u003cli\u003e宿主机和数据中心的哪些设备建立 BGP 邻居？\u003c/li\u003e\n  \u003cli\u003e使用哪种 BGP 协议，iBGP 还是 eBGP？\u003c/li\u003e\n  \u003cli\u003e如何划分自治域（AS），使用哪种 ASN（自治域系统编号）方案？\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e取决于具体的网络需求，这套 BGP 方案可能很复杂。基于我们数据中心网络能提供的能力\n及实际的需求，我们采用的是一种相对比较简单的模型，\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e每台 node 运行 BIRD，仅作为 BGP speaker，\n    \u003col\u003e\n      \u003cli\u003eNode 在上线时会自动分配一个 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e/25\u003c/code\u003e 或 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e/24\u003c/code\u003e 的 PodCIDR。\u003c/li\u003e\n      \u003cli\u003eBIRD 和数据中心网络中的两个邻居建立 BGP 连接。\u003c/li\u003e\n      \u003cli\u003e\u003cstrong\u003eBIRD 将 PodCIDR 通告给邻居\u003c/strong\u003e，但 \u003cstrong\u003e不从邻居接受任何路由\u003c/strong\u003e。\u003c/li\u003e\n    \u003c/ol\u003e\n  \u003c/li\u003e\n  \u003cli\u003e数据中心网络只从 node 接受 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e/25\u003c/code\u003e 或 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e/24\u003c/code\u003e 路由宣告，但不向 node 宣告任何路由。\u003c/li\u003e\n  \u003cli\u003e整张网络是一张三层纯路由网络（pure L3 routing network）。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e这种模型的简单之处在于，\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e数据中心网络从各 node 学习到 PodCIDR 路由，了解整张网络的拓扑，因此 Pod 流量在数据中心可路由。\u003c/li\u003e\n  \u003cli\u003eNode 不从数据中心学习任何路由，所有出宿主机的流量直接走宿主机默认路由（到数据\n中心网络），因此宿主机内部的路由表不随 node 规模膨胀，没有路由条目数量导致的性能瓶颈。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/trip-stepping-into-cloud-native-networking-era/bgp-peering.png\" width=\"40%\" height=\"40%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig 2-2. BGP peering model in 3-tier network topology\u003c/p\u003e\n\n\u003cp\u003e在路由协议方面，\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e老数据中心基于“接入-汇聚-核心”三级网络架构，如图 2-2 所示,\n    \u003cul\u003e\n      \u003cli\u003e节点和核心交换机建立 BGP 连接。\u003c/li\u003e\n      \u003cli\u003e使用 iBGP 协议交换路由。\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e新数据中心基于 Spine-Leaf 架构，\n    \u003cul\u003e\n      \u003cli\u003e节点和直连的 Leaf 交换机（置顶交换机）建立 BGP 连接。\u003c/li\u003e\n      \u003cli\u003e使用 eBGP 协议交换路由。\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e我们已经将这方面的实践整理成文档，见\n\u003ca href=\"https://docs.cilium.io/en/v1.8/gettingstarted/bird/\"\u003eUsing BIRD to run BGP\u003c/a\u003e [3]。\u003c/p\u003e\n\n\u003ch2 id=\"22-典型流量转发路径从-pod-访问-service\"\u003e2.2 典型流量转发路径：从 Pod 访问 Service\u003c/h2\u003e\n\n\u003cp\u003e来看一下在这套方案中，典型的流量转发路径。\u003c/p\u003e\n\n\u003cp\u003e假设从一个 Pod 内访问某个 Service，这个 Service 的后端位于另一台 Node，如下图所示，\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/trip-stepping-into-cloud-native-networking-era/pod-to-pod-path.png\" width=\"100%\" height=\"100%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig 2-3. Traffic path: accessing Service from a Pod [4] \u003c/p\u003e\n\n\u003cp\u003e主要步骤：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e在 Node1 上的 Pod1 里面访问某个 Service (\u003ccode class=\"language-plaintext highlighter-rouge\"\u003ecurl \u0026lt;ServiceIP\u0026gt;:\u0026lt;port\u0026gt;\u003c/code\u003e)。\u003c/li\u003e\n  \u003cli\u003eeBPF \u003cstrong\u003e处理 Service 抽象，做客户端负载均衡\u003c/strong\u003e：选择某个后端，然将包的目的 IP 地址从 ServiceIP 换成后端 PodIP（即执行 DNAT）。\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e内核路由决策\u003c/strong\u003e：查询系统路由表，根据包的目的 IP 地址确定下一跳；对于这个例\n子匹配到的是默认路由，应该通过宿主机网卡（或 bond）发送出去。\u003c/li\u003e\n  \u003cli\u003e包到达宿主机网卡（bond），通过默认路由发送到宿主机的默认网关（配置在数据中心\n网络设备上）。\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003e数据中心网络对包进行路由转发\u003c/strong\u003e。由于此前数据中心网络已经从各 Node 学习到了\n它们的 PodCIDR 路由，因此能根据目的 IP 地址判断应该将包送到哪个 Node。\u003c/li\u003e\n  \u003cli\u003e包达到 Node 2 的网卡（bond）：一段 eBPF 代码负责提取包头，根据 IP 信息找到\n另一段和目的 Pod 一一对应的 eBPF 代码，然后将包交给它。\u003c/li\u003e\n  \u003cli\u003e后一段 eBPF 代码对包执行 \u003cstrong\u003e入向策略检查\u003c/strong\u003e，如果允许通过，就将包交给 Pod4。\u003c/li\u003e\n  \u003cli\u003e包到达 Pod4 的虚拟网卡，然后被收起。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e我们有一篇专门的文章详细介绍整个过程，见 [4]。\u003c/p\u003e\n\n\u003ch2 id=\"23-集群边界-l4l7-入口解决方案\"\u003e2.3 集群边界 L4/L7 入口解决方案\u003c/h2\u003e\n\n\u003cp\u003e在 Kubernetes 的设计中，\u003cstrong\u003eServiceIP 只能在集群内访问\u003c/strong\u003e，如果要\u003cstrong\u003e从集群外访问\nService 怎么办？\u003c/strong\u003e例如，从 baremetal 集群、OpenStack 集群，或者其他 Kubernetes\n集群访问？这属于集群边界问题。\u003c/p\u003e\n\n\u003cp\u003eK8s 为这些场景提供了两种模型：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003cstrong\u003eL7 模型\u003c/strong\u003e：称为 Ingress，支持以 7 层的方式从集群外访问 Service，例如通过 HTTP API 访问。\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003eL4 模型\u003c/strong\u003e: 包括 externalIPs Service、LoadBalancer Service，支持以 4 层的方\n式访问 Service，例如通过 VIP+Port。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e但是，\u003cstrong\u003eK8s 只提供了模型，没提供实现\u003c/strong\u003e，具体的实现是留给各厂商的。例如，假如你使\n用的是 AWS，它提供的 ALB 和 ELB 就分别对应上面的 L7 和 L4 模型。在私有云，就需要\n我们自己解决。\u003c/p\u003e\n\n\u003cp\u003e我们基于 Cilium+BGP+ECMP 设计了一套四层入口方案。本质上这是一套四层负载均衡器（\nL4LB），它提供一组 VIP，可以将这些 VIP 配置到 externalIPs 类型或 LoadBalancer 类\n型的 Service，然后就可以从集群外访问了。\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/k8s-l4lb/l4lb-topo.png\" width=\"85%\" height=\"85%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig 2-4. L4LB solution with Cilium+BGP+ECMP [5]\u003c/p\u003e\n\n\u003cp\u003e基于这套四层入口方案部署 istio ingress-gateway，就解决了七层入口问题。从集群外访\n问时，典型的数据转发路由如下：\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/k8s-l4lb/l4lb-traffic-path.png\" width=\"85%\" height=\"85%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig 2-5. Traffic path when accesing Service from outside the Kubernetes cluster [5]\u003c/p\u003e\n\n\u003cp\u003e我们之前有篇博客详细介绍这个主题，见 [5]。\u003c/p\u003e\n\n\u003ch1 id=\"3-云原生安全尝试\"\u003e3 云原生安全尝试\u003c/h1\u003e\n\n\u003cp\u003eCilium 提供的两大核心能力：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e基于 eBPF 的灵活、动态、高性能网络。\u003c/li\u003e\n  \u003cli\u003eL3-L7 安全策略：CiliumNetworkPolicy 是对 K8s 的 NetworkPolicy 的扩展。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e在落地了网络功能后，针对安全需求，我们在尝试落地基于 Cilium 的安全。\u003c/p\u003e\n\n\u003ch2 id=\"31-cilium-安全策略\"\u003e3.1 Cilium 安全策略\u003c/h2\u003e\n\n\u003cp\u003e首先来看一个简单的例子，看看 CiliumNetworkPolicy (CNP) 长什么样 [6]：\u003c/p\u003e\n\n\u003cdiv class=\"language-yaml highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"na\"\u003eapiVersion\u003c/span\u003e\u003cspan class=\"pi\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"s\"\u003ecilium.io/v2\u0026#34;\u003c/span\u003e\n\u003cspan class=\"na\"\u003ekind\u003c/span\u003e\u003cspan class=\"pi\"\u003e:\u003c/span\u003e \u003cspan class=\"s\"\u003eCiliumNetworkPolicy\u003c/span\u003e\n\u003cspan class=\"na\"\u003emetadata\u003c/span\u003e\u003cspan class=\"pi\"\u003e:\u003c/span\u003e\n  \u003cspan class=\"na\"\u003ename\u003c/span\u003e\u003cspan class=\"pi\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"s\"\u003eclustermesh-ingress-l4-policy\u0026#34;\u003c/span\u003e\n  \u003cspan class=\"na\"\u003edescription\u003c/span\u003e\u003cspan class=\"pi\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"s\"\u003edemo:\u003c/span\u003e\u003cspan class=\"nv\"\u003e \u003c/span\u003e\u003cspan class=\"s\"\u003eallow\u003c/span\u003e\u003cspan class=\"nv\"\u003e \u003c/span\u003e\u003cspan class=\"s\"\u003eonly\u003c/span\u003e\u003cspan class=\"nv\"\u003e \u003c/span\u003e\u003cspan class=\"s\"\u003eemployee\u003c/span\u003e\u003cspan class=\"nv\"\u003e \u003c/span\u003e\u003cspan class=\"s\"\u003eto\u003c/span\u003e\u003cspan class=\"nv\"\u003e \u003c/span\u003e\u003cspan class=\"s\"\u003eaccess\u003c/span\u003e\u003cspan class=\"nv\"\u003e \u003c/span\u003e\u003cspan class=\"s\"\u003eprotected-db\u0026#34;\u003c/span\u003e\n\u003cspan class=\"na\"\u003espec\u003c/span\u003e\u003cspan class=\"pi\"\u003e:\u003c/span\u003e\n  \u003cspan class=\"na\"\u003eendpointSelector\u003c/span\u003e\u003cspan class=\"pi\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"na\"\u003ematchLabels\u003c/span\u003e\u003cspan class=\"pi\"\u003e:\u003c/span\u003e\n      \u003cspan class=\"na\"\u003eapp\u003c/span\u003e\u003cspan class=\"pi\"\u003e:\u003c/span\u003e \u003cspan class=\"s\"\u003eprotected-db\u003c/span\u003e\n  \u003cspan class=\"na\"\u003eingress\u003c/span\u003e\u003cspan class=\"pi\"\u003e:\u003c/span\u003e\n  \u003cspan class=\"pi\"\u003e-\u003c/span\u003e \u003cspan class=\"na\"\u003etoPorts\u003c/span\u003e\u003cspan class=\"pi\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"pi\"\u003e-\u003c/span\u003e \u003cspan class=\"na\"\u003eports\u003c/span\u003e\u003cspan class=\"pi\"\u003e:\u003c/span\u003e\n      \u003cspan class=\"pi\"\u003e-\u003c/span\u003e \u003cspan class=\"na\"\u003eport\u003c/span\u003e\u003cspan class=\"pi\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"s\"\u003e6379\u0026#34;\u003c/span\u003e\n        \u003cspan class=\"na\"\u003eprotocol\u003c/span\u003e\u003cspan class=\"pi\"\u003e:\u003c/span\u003e \u003cspan class=\"s\"\u003eTCP\u003c/span\u003e\n    \u003cspan class=\"na\"\u003efromEndpoints\u003c/span\u003e\u003cspan class=\"pi\"\u003e:\u003c/span\u003e\n      \u003cspan class=\"pi\"\u003e-\u003c/span\u003e \u003cspan class=\"na\"\u003ematchLabels\u003c/span\u003e\u003cspan class=\"pi\"\u003e:\u003c/span\u003e\n          \u003cspan class=\"na\"\u003eapp\u003c/span\u003e\u003cspan class=\"pi\"\u003e:\u003c/span\u003e \u003cspan class=\"s\"\u003eemployee\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e上面的 yaml：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e创建一个 CNP，可以指定 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ename\u003c/code\u003e 和 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003edescription\u003c/code\u003e 等描述字段。\u003c/li\u003e\n  \u003cli\u003e对带 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eapp=protected-db\u003c/code\u003e 标签（labels）的 endpoints（pods）执行这个 CNP。\u003c/li\u003e\n  \u003cli\u003e在执行 CNP 的时候，只对入向（\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eingress\u003c/code\u003e）流量做控制，并且限制如下流量来源：\n    \u003cul\u003e\n      \u003cli\u003e协议是 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eTCP\u003c/code\u003e，并且端口是 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e6379\u003c/code\u003e.\u003c/li\u003e\n      \u003cli\u003e流量来自带 \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eapp:employee\u003c/code\u003e labels 的 endpoints（pods）。\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e可以看到，CNP 非常灵活，使用起来也很方便。但真实世界要远比想象中复杂，要真正落地\nCilium 安全策略，还存在很多挑战。\u003c/p\u003e\n\n\u003ch2 id=\"32-落地挑战\"\u003e3.2 落地挑战\u003c/h2\u003e\n\n\u003cp\u003e下面举两个例子，相信这些问题在很多公司都需要面对，并不是我们独有的。\u003c/p\u003e\n\n\u003ch3 id=\"多集群问题\"\u003e多集群问题\u003c/h3\u003e\n\n\u003cp\u003e如果你所有的应用都运行在 Cilium 集群中，并且客户端和服务端都收敛到一个集群（大部\n分公有云厂商都推荐一个 region 只部署一套 K8s 集群，所有访问都收敛到这套集群），那落\n地起来会简单很多。\u003c/p\u003e\n\n\u003cp\u003e但大部分有基础设施演进的公司恐怕都不满足这个假设，实际的情况很可能是：业务分散在多\n个集群。\u003c/p\u003e\n\n\u003ch3 id=\"混合基础设施\"\u003e混合基础设施\u003c/h3\u003e\n\n\u003cp\u003e多集群还不是最大的问题，因为业界多少还有一些多集群解决方案。\u003c/p\u003e\n\n\u003cp\u003e更严重的一个问题是：业务不仅分散在不同集群，而且在不同平台。例如对我们来说，现在\n有：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003eBare metal 集群\u003c/li\u003e\n  \u003cli\u003eOpenStack 集群\u003c/li\u003e\n  \u003cli\u003e基于 Neutron+OVS 的 Kubernetes 集群\u003c/li\u003e\n  \u003cli\u003e基于 Cilium+BGP 的 Kubernetes 集群\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e虽然我们计划将所有容器从 Neutron 网络迁移到 Cilium 网络，但另外两种，bare metal\n和 OpenStack 集群，还是会长期存在的，虽然规模可能会逐渐减小。\u003c/p\u003e\n\n\u003ch2 id=\"33-整体方案设计\"\u003e3.3 整体方案设计\u003c/h2\u003e\n\n\u003cp\u003e我们目前的一个整体方案：\u003cstrong\u003e在服务端容器做入向安全策略，客户端可以来自任何平台、任何集群\u003c/strong\u003e：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e这将范围框定到了\u003cstrong\u003e已经在 Cilium 网络的服务端容器\u003c/strong\u003e，是一个不错的起点。\u003c/li\u003e\n  \u003cli\u003e传统网络里的服务端容器，会逐渐迁移到 Cilium 网络。\u003c/li\u003e\n  \u003cli\u003eBM 和 VM 的\u003cstrong\u003e服务端实例\u003c/strong\u003e，第一阶段先不考虑安全控制。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e那接下来的问题就是：服务端如何具备\u003cstrong\u003e对所有类型、所有集群的客户端进行限制的能力\u003c/strong\u003e？\n我们的解决方案是：\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e首先，用 Cilium 提供 ClusterMesh 将已有 Cilium 集群连接起来；\u003c/li\u003e\n  \u003cli\u003e然后，“扩展” ClusterMesh，让它能感知到 mesh 之外的 endpoints，即 BM、BM 和\nNeutron Pods。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e下面分别解释这两点。\u003c/p\u003e\n\n\u003ch3 id=\"331-用-clustermesh-做-cilium-集群互连\"\u003e3.3.1 用 ClusterMesh 做 Cilium 集群互连\u003c/h3\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/trip-stepping-into-cloud-native-networking-era/clustermesh.png\" width=\"100%\" height=\"100%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig 3-1. Vanilla Cilium ClusterMesh [6]\u003c/p\u003e\n\n\u003cp\u003eClusterMesh [7] 是 Cilium 自带的一个多集群解决方案。如果所有应用都在 Cilium 集群\n里，那这种方式可以解决跨集群的安全策略问题，即，application 实例可以分布在不同的集群。\u003c/p\u003e\n\n\u003cp\u003e这样说来，使用 ClusterMesh 似乎是理所当然的，但其实它并不是我们当初的第一选择。\n因为多集群还有其他方案，本质上做的事情就是如何在多个集群之间同步元数据，并且做到\n集群变动的实时感知。\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e出于多个内部需求，当时有考虑自己做这样一套元数据同步方案，它能解决包括 Cilium 在内的多个需求。\u003c/li\u003e\n  \u003cli\u003e并未看到业界大规模使用 ClusterMesh 的案例，所以对它的可用性还存疑。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e但后来综合对比了几种选项之后，觉得 ClusterMesh 还是值得尝试的。\u003c/p\u003e\n\n\u003cp\u003e关于 ClusterMesh 的实地（功能）测试，可以参考我们之前的一篇博客 [6]。\u003c/p\u003e\n\n\u003ch3 id=\"332-扩展-clustermesh感知-mesh-外实例\"\u003e3.3.2 扩展 ClusterMesh，感知 mesh 外实例\u003c/h3\u003e\n\n\u003cp\u003e这里的外部实例（external endpoints）包括 Neutron Pod、VM、BM。\u003c/p\u003e\n\n\u003cp\u003e基于对 Cilium 的理解，我们判断只要\u003cstrong\u003e将外部实例信息以 Cilium 能感知的方式（格式）同\n步到 Cilium 集群\u003c/strong\u003e，那在入向（inbound），Cilium 对这些实例的控制能力，与对原生\nCilium 实例的控制能力并无区别。换句话说，我们“骗一下” Cilium，让它认为这些实例都是 Cilium\nendpoints/pods。\u003c/p\u003e\n\n\u003cp\u003e为此我们开发了一个组件，使得 OpenStack 平台、Bare metal 平台和Neutron-powered\nKubernetes 平台能将它们的实例创建/销毁/更新信息同步更新到 Cilium 集群，如下图所示：\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\u003cimg src=\"/assets/img/trip-stepping-into-cloud-native-networking-era/trip-security-solution.png\" width=\"100%\" height=\"100%\"/\u003e\u003c/p\u003e\n\u003cp align=\"center\"\u003eFig 3-2. Proposed security solution over hybrid infrastructures\u003c/p\u003e\n\n\u003cp\u003e结合 3.3.1 \u0026amp; 3.3.2，在这套“扩展之后的” ClusterMesh 中，\u003cstrong\u003e每个 Cilium agent 都对\n全局实例（container/vm/bm）有着完整的、一致的视图\u003c/strong\u003e，因此能在 Cilium Pod 的入向\n对各种类型的客户端做安全控制。目前计划支持的是 L3-L4 安全策略，未来考虑支持 L7。\u003c/p\u003e\n\n\u003cp\u003e这套方案已经通过了功能验证，正在进行正式开发和测试，计划年底开始灰度上线。\u003c/p\u003e\n\n\u003ch1 id=\"4-总结\"\u003e4 总结\u003c/h1\u003e\n\n\u003cp\u003e本文总结了我们自上一篇博客以来，在基于 Cilium 的云原生网络和云原生安全方面的一些\n探索和实践。更多技术细节，可参考下面一些链接。\u003c/p\u003e\n\n\u003ch1 id=\"参考文献\"\u003e参考文献\u003c/h1\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003ca href=\"/blog/ctrip-network-arch-evolution/\"\u003eCtrip Network Architecture Evolution in the Cloud Computing Era\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"/blog/trip-first-step-towards-cloud-native-networking/\"\u003eTrip.com: First Step towards Cloud Native Networking\u003c/a\u003e.\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://docs.cilium.io/en/v1.8/gettingstarted/bird/\"\u003eCilium Doc: Using BIRD to run BGP\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"/blog/cilium-life-of-a-packet-pod-to-service/\"\u003eLife of a Packet in Cilium: Discovering the Pod-to-Service Traffic Path and BPF Processing Logics\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"/blog/k8s-l4lb/\"\u003eL4LB for Kubernetes: Theory and Practice with Cilium+BGP+ECMP\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"/blog/cilium-clustermesh/\"\u003eCilium ClusterMesh: A Hands-on Guide\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://docs.cilium.io/en/stable/gettingstarted/clustermesh/\"\u003eCilium Doc: clustermesh\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\n\n  \u003c!-- POST NAVIGATION --\u003e\n  \u003cdiv class=\"postNav clearfix\"\u003e\n     \n      \u003ca class=\"prev\" href=\"/blog/lartc-qdisc-zh/\"\u003e\u003cspan\u003e« [译] 《Linux 高级路由与流量控制手册（2012）》第九章：用 tc qdisc 管理 Linux 网络带宽\u003c/span\u003e\n      \n    \u003c/a\u003e\n      \n      \n      \u003ca class=\"next\" href=\"/blog/trip-stepping-into-cloud-native-networking-era/\"\u003e\u003cspan\u003eTrip.com: Stepping into Cloud Native Networking Era with Cilium+BGP »\u003c/span\u003e\n       \n      \u003c/a\u003e\n     \n  \u003c/div\u003e\n\u003c/div\u003e",
  "Date": "2020-11-04T00:00:00Z",
  "Author": "Arthur Chiao"
}