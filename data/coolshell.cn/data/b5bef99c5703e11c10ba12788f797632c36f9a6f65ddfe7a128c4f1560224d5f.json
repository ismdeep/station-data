{
  "Source": "coolshell.cn",
  "Title": "与程序员相关的CPU缓存知识",
  "Link": "https://coolshell.cn/articles/20793.html",
  "Content": "\u003cdiv class=\"entry-content\"\u003e\n\u003cp\u003e\u003cscript async=\"\" src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3415450859608158\" crossorigin=\"anonymous\" type=\"82c86912d27abfab2ac926c8-text/javascript\"\u003e\u003c/script\u003e\u003cimg decoding=\"async\" class=\"alignright size-medium wp-image-20817\" src=\"https://coolshell.cn/wp-content/uploads/2020/03/cpu_512x512-300x300.png\" alt=\"\" width=\"300\" height=\"300\" srcset=\"https://coolshell.cn/wp-content/uploads/2020/03/cpu_512x512-300x300.png 300w, https://coolshell.cn/wp-content/uploads/2020/03/cpu_512x512-150x150.png 150w, https://coolshell.cn/wp-content/uploads/2020/03/cpu_512x512-200x200.png 200w, https://coolshell.cn/wp-content/uploads/2020/03/cpu_512x512-270x270.png 270w, https://coolshell.cn/wp-content/uploads/2020/03/cpu_512x512.png 512w\" sizes=\"(max-width: 300px) 100vw, 300px\"/\u003e好久没有写一些微观方面的文章了，今天写一篇关于CPU Cache相关的文章，这篇文章比较长，主要分成这么几个部分：基础知识、缓存的命中、缓存的一致性、相关的代码示例和延伸阅读。其中会讲述一些多核 CPU 的系统架构以及其原理，包括对程序性能上的影响，以及在进行并发编程的时候需要注意到的一些问题。这篇文章我会尽量地写简单和通俗易懂一些，主要是讲清楚相关的原理和问题，而对于一些细节和延伸阅读我会在文章最后会给出相关的资源。\u003c/p\u003e\n\u003cp\u003e因为无论你写什么样的代码都会交给CPU来执行，所以，如果你想写出性能比较高的代码，这篇文章中提到的技术还是值得认真学习的。另外，千万别觉得这些东西没用，这些东西非常有用，十多年前就是这些知识在性能调优上帮了我的很多大忙，从而跟很多人拉开了差距……\u003c/p\u003e\n\u003cdiv id=\"ez-toc-container\" class=\"ez-toc-v2_0_48 counter-hierarchy ez-toc-counter ez-toc-grey ez-toc-container-direction\"\u003e\n\u003cdiv class=\"ez-toc-title-container\"\u003e\n\u003cp class=\"ez-toc-title\"\u003e目录\u003c/p\u003e\n\u003cspan class=\"ez-toc-title-toggle\"\u003e\u003c/span\u003e\u003c/div\u003e\n\u003cnav\u003e\u003cul class=\"ez-toc-list ez-toc-list-level-1 \"\u003e\u003cli class=\"ez-toc-page-1 ez-toc-heading-level-4\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-1\" href=\"#%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86\" title=\"基础知识\"\u003e基础知识\u003c/a\u003e\u003c/li\u003e\u003cli class=\"ez-toc-page-1 ez-toc-heading-level-4\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-2\" href=\"#%E7%BC%93%E5%AD%98%E7%9A%84%E5%91%BD%E4%B8%AD\" title=\"缓存的命中\"\u003e缓存的命中\u003c/a\u003e\u003c/li\u003e\u003cli class=\"ez-toc-page-1 ez-toc-heading-level-4\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-3\" href=\"#%E7%BC%93%E5%AD%98%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7\" title=\"缓存的一致性\"\u003e缓存的一致性\u003c/a\u003e\u003c/li\u003e\u003cli class=\"ez-toc-page-1 ez-toc-heading-level-4\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-4\" href=\"#%E7%A8%8B%E5%BA%8F%E6%80%A7%E8%83%BD\" title=\"程序性能\"\u003e程序性能\u003c/a\u003e\u003cul class=\"ez-toc-list-level-5\"\u003e\u003cli class=\"ez-toc-heading-level-5\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-5\" href=\"#%E7%A4%BA%E4%BE%8B%E4%B8%80\" title=\"示例一\"\u003e示例一\u003c/a\u003e\u003c/li\u003e\u003cli class=\"ez-toc-page-1 ez-toc-heading-level-5\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-6\" href=\"#%E7%A4%BA%E4%BE%8B%E4%BA%8C\" title=\"示例二\"\u003e示例二\u003c/a\u003e\u003c/li\u003e\u003cli class=\"ez-toc-page-1 ez-toc-heading-level-5\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-7\" href=\"#%E7%A4%BA%E4%BE%8B%E4%B8%89\" title=\"示例三\"\u003e示例三\u003c/a\u003e\u003c/li\u003e\u003cli class=\"ez-toc-page-1 ez-toc-heading-level-5\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-8\" href=\"#%E7%A4%BA%E4%BE%8B%E5%9B%9B\" title=\"示例四\"\u003e示例四\u003c/a\u003e\u003c/li\u003e\u003cli class=\"ez-toc-page-1 ez-toc-heading-level-5\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-9\" href=\"#%E7%A4%BA%E4%BE%8B%E4%BA%94\" title=\"示例五\"\u003e示例五\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003cli class=\"ez-toc-page-1 ez-toc-heading-level-4\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-10\" href=\"#%E5%BB%B6%E4%BC%B8%E9%98%85%E8%AF%BB\" title=\"延伸阅读\"\u003e延伸阅读\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/nav\u003e\u003c/div\u003e\n\u003ch4\u003e\u003cspan class=\"ez-toc-section\" id=\"%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86\"\u003e\u003c/span\u003e基础知识\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e首先，我们都知道现在的CPU多核技术，都会有几级缓存，老的CPU会有两级内存（L1和L2），新的CPU会有三级内存（L1，L2，L3 ），如下图所示：\u003c/p\u003e\n\u003cp\u003e\u003cimg decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-20794\" src=\"https://coolshell.cn/wp-content/uploads/2020/02/cache.architecture.png\" alt=\"\" width=\"729\" height=\"371\" srcset=\"https://coolshell.cn/wp-content/uploads/2020/02/cache.architecture.png 729w, https://coolshell.cn/wp-content/uploads/2020/02/cache.architecture-300x153.png 300w, https://coolshell.cn/wp-content/uploads/2020/02/cache.architecture-531x270.png 531w\" sizes=\"(max-width: 729px) 100vw, 729px\"/\u003e\u003cspan id=\"more-20793\"\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e其中：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eL1缓存分成两种，一种是指令缓存，一种是数据缓存。L2缓存和L3缓存不分指令和数据。\u003c/li\u003e\n\u003cli\u003eL1和L2缓存在每一个CPU核中，L3则是所有CPU核心共享的内存。\u003c/li\u003e\n\u003cli\u003eL1、L2、L3的越离CPU近就越小，速度也越快，越离CPU远，速度也越慢。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e再往后面就是内存，内存的后面就是硬盘。我们来看一些他们的速度：\u003c/p\u003e\n\u003cul class=\"\"\u003e\n\u003cli\u003eL1 的存取速度：\u003cstrong class=\"hd jp\"\u003e4 个CPU时钟周期\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eL2 的存取速度： \u003cstrong class=\"hd jp\"\u003e11 个CPU时钟周期\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eL3 的存取速度：\u003cstrong class=\"hd jp\"\u003e39 个CPU时钟周期\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eRAM内存的存取速度\u003cstrong class=\"hd jp\"\u003e：107 个CPU时钟周期\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e我们可以看到，L1的速度是RAM的27倍，但是L1/L2的大小基本上也就是KB级别的，L3会是MB级别的。例如：\u003ca href=\"https://en.wikichip.org/wiki/intel/core_i7/i7-8700k\" target=\"_blank\" rel=\"noopener noreferrer\"\u003eIntel Core i7-8700K\u003c/a\u003e ，是一个6核的CPU，每核上的L1是64KB（数据和指令各32KB），L2 是 256K，L3有2MB（我的苹果电脑是\u003ca href=\"https://en.wikichip.org/wiki/intel/core_i9/i9-8950hk\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e Intel Core i9-8950HK\u003c/a\u003e，和Core i7-8700K的Cache大小一样）。\u003c/p\u003e\n\u003cp\u003e我们的数据就从内存向上，先到L3，再到L2，再到L1，最后到寄存器进行CPU计算。为什么会设计成三层？这里有下面几个方面的考虑：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e一个方面是物理速度，如果要更大的容量就需要更多的晶体管，除了芯片的体积会变大，更重要的是大量的晶体管会导致速度下降，因为访问速度和要访问的晶体管所在的位置成反比，也就是当信号路径变长时，通信速度会变慢。这部分是物理问题。\u003c/li\u003e\n\u003cli\u003e另外一个问题是，多核技术中，数据的状态需要在多个CPU中进行同步，并且，我们可以看到，cache和RAM的速度差距太大，所以，多级不同尺寸的缓存有利于提高整体的性能。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e这个世界永远是平衡的，一面变得有多光鲜，另一面也会变得有多黑暗。建立这么多级的缓存，一定就会引入其它的问题，这里有两个比较重要的问题，\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e一个是比较简单的缓存的命中率的问题。\u003c/li\u003e\n\u003cli\u003e另一个是比较复杂的缓存更新的一致性问题。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e尤其是第二个问题，在多核技术下，这就很像分布式的系统了，要对多个地方进行更新。\u003c/p\u003e\n\u003ch4\u003e\u003cspan class=\"ez-toc-section\" id=\"%E7%BC%93%E5%AD%98%E7%9A%84%E5%91%BD%E4%B8%AD\"\u003e\u003c/span\u003e缓存的命中\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e在说明这两个问题之前。我们需要要解一个术语 Cache Line。缓存基本上来说就是把后面的数据加载到离自己近的地方，对于CPU来说，它是不会一个字节一个字节的加载的，因为这非常没有效率，一般来说都是要一块一块的加载的，对于这样的一块一块的数据单位，术语叫“Cache Line”，一般来说，一个主流的CPU的Cache Line 是 64 Bytes（也有的CPU用32Bytes和128Bytes），64Bytes也就是16个32位的整型，这就是CPU从内存中捞数据上来的最小数据单位。\u003c/p\u003e\n\u003cp\u003e比如：Cache Line是最小单位（64Bytes），所以先把Cache分布多个Cache Line，比如：L1有32KB，那么，32KB/64B = 512 个 Cache Line。\u003c/p\u003e\n\u003cp\u003e一方面，缓存需要把内存里的数据放到放进来，英文叫 CPU Associativity。Cache的数据放置的策略决定了内存中的数据块会拷贝到CPU Cache中的哪个位置上，因为Cache的大小远远小于内存，所以，需要有一种地址关联的算法，能够让内存中的数据可以被映射到Cache中来。这个有点像内存地址从逻辑地址向物理地址映射的方法，但不完全一样。\u003c/p\u003e\n\u003cp\u003e基本上来说，我们会有如下的一些方法。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e一种方法是，任何一个内存地址的数据可以被缓存在任何一个Cache Line里，这种方法是最灵活的，但是，如果我们要知道一个内存是否存在于Cache中，我们就需要进行O(n)复杂度的Cache遍历，这是很没有效率的。\u003c/li\u003e\n\u003cli\u003e另一种方法，为了降低缓存搜索算法，我们需要使用像Hash Table这样的数据结构，最简单的hash table就是做“求模运算”，比如：我们的L1 Cache有512个Cache Line，那么，公式：\u003ccode\u003e（内存地址 mod 512）* 64\u003c/code\u003e 就可以直接找到所在的Cache地址的偏移了。但是，这样的方式需要我们的程序对内存地址的访问要非常地平均，不然冲突就会非常严重。这成了一种非常理想的情况了。\u003c/li\u003e\n\u003cli\u003e为了避免上述的两种方案的问题，于是就要容忍一定的hash冲突，也就出现了 N-Way 关联。也就是把连续的N个Cache Line绑成一组，然后，先把找到相关的组，然后再在这个组内找到相关的Cache Line。这叫 Set Associativity。如下图所示。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-20806\" src=\"https://coolshell.cn/wp-content/uploads/2020/02/cache-associative-fill-both.png\" alt=\"\" width=\"546\" height=\"271\" srcset=\"https://coolshell.cn/wp-content/uploads/2020/02/cache-associative-fill-both.png 546w, https://coolshell.cn/wp-content/uploads/2020/02/cache-associative-fill-both-300x149.png 300w, https://coolshell.cn/wp-content/uploads/2020/02/cache-associative-fill-both-544x270.png 544w\" sizes=\"(max-width: 546px) 100vw, 546px\"/\u003e\u003c/p\u003e\n\u003cp\u003e对于 N-Way 组关联，可能有点不好理解，这里个例子，并多说一些细节（不然后面的代码你会不能理解），Intel 大多数处理器的L1 Cache都是32KB，8-Way 组相联，Cache Line 是64 Bytes。这意味着，\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e32KB的可以分成，32KB / 64 = 512 条 Cache Line。\u003c/li\u003e\n\u003cli\u003e因为有8 Way，于是会每一Way 有 512 / 8 = 64 条 Cache Line。\u003c/li\u003e\n\u003cli\u003e于是每一路就有 64 x 64 = 4096 Byts 的内存。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e为了方便索引内存地址，\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eTag\u003c/strong\u003e：每条 Cache Line 前都会有一个独立分配的 24 bits来存的 tag，其就是内存地址的前24bits\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eIndex\u003c/strong\u003e：内存地址后续的6个bits则是在这一Way的是Cache Line 索引，2^6 = 64 刚好可以索引64条Cache Line\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOffset\u003c/strong\u003e：再往后的6bits用于表示在Cache Line 里的偏移量\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e如下图所示：（图片来自《\u003ca href=\"https://manybutfinite.com/post/intel-cpu-caches/\" target=\"_blank\" rel=\"noopener noreferrer\"\u003eCache: a place for concealment and safekeeping\u003c/a\u003e》）\u003c/p\u003e\n\u003cp\u003e当拿到一个内存地址的时候，先拿出中间的 6bits 来，找到是哪组。\u003c/p\u003e\n\u003cp style=\"text-align: center;\"\u003e\u003cimg decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-20809\" src=\"https://coolshell.cn/wp-content/uploads/2020/03/L1CacheExample.png\" alt=\"\" width=\"687\" height=\"461\" srcset=\"https://coolshell.cn/wp-content/uploads/2020/03/L1CacheExample.png 687w, https://coolshell.cn/wp-content/uploads/2020/03/L1CacheExample-300x201.png 300w, https://coolshell.cn/wp-content/uploads/2020/03/L1CacheExample-402x270.png 402w\" sizes=\"(max-width: 687px) 100vw, 687px\"/\u003e\u003c/p\u003e\n\u003cp\u003e然后，在这一个8组的cache line中，再进行O(n) n=8 的遍历，主是要匹配前24bits的tag。如果匹配中了，就算命中，如果没有匹配到，那就是cache miss，如果是读操作，就需要进向后面的缓存进行访问了。L2/L3同样是这样的算法。而淘汰算法有两种，一种是随机一种是LRU。现在一般都是以LRU的算法（通过增加一个访问计数器来实现）\u003c/p\u003e\n\u003cp\u003e\u003cimg decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-20840\" src=\"https://coolshell.cn/wp-content/uploads/2020/03/selectingCacheLine.png\" alt=\"\" width=\"681\" height=\"283\" srcset=\"https://coolshell.cn/wp-content/uploads/2020/03/selectingCacheLine.png 681w, https://coolshell.cn/wp-content/uploads/2020/03/selectingCacheLine-300x125.png 300w, https://coolshell.cn/wp-content/uploads/2020/03/selectingCacheLine-604x251.png 604w\" sizes=\"(max-width: 681px) 100vw, 681px\"/\u003e\u003c/p\u003e\n\u003cp\u003e这也意味着：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eL1 Cache 可映射 36bits 的内存地址，一共 2^36 = 64GB的内存\u003c/li\u003e\n\u003cli\u003e当CPU要访问一个内存的时候，通过这个内存中间的6bits 定位是哪个set，通过前 24bits 定位相应的Cache Line。\u003c/li\u003e\n\u003cli\u003e就像一个hash Table的数据结构一样，先是O(1)的索引，然后进入冲突搜索。\u003c/li\u003e\n\u003cli\u003e因为中间的 6bits 决定了一个同一个set，所以，对于一段连续的内存来说，每隔4096的内存会被放在同一个组内，导致缓存冲突。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e此外，当有数据没有命中缓存的时候，CPU就会以最小为Cache Line的单元向内存更新数据。当然，CPU并不一定只是更新64Bytes，因为访问主存实在是太慢了，所以，一般都会多更新一些。好的CPU会有一些预测的技术，如果找到一种pattern的话，就会预先加载更多的内存，包括指令也可以预加载。这叫 Prefetching 技术 （参看，Wikipedia 的 \u003ca href=\"https://en.wikipedia.org/wiki/Cache_prefetching\" target=\"_blank\" rel=\"noopener noreferrer\"\u003eCache Prefetching\u003c/a\u003e 和 \u003ca href=\"http://compas.cs.stonybrook.edu/~nhonarmand/courses/sp16/cse502/slides/13-prefetch.pdf\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e纽约州立大学的 Memory Prefetching\u003c/a\u003e）。比如，你在for-loop访问一个连续的数组，你的步长是一个固定的数，内存就可以做到prefetching。（注：指令也是以预加载的方式执行，参看本站的《\u003ca href=\"https://coolshell.cn/articles/7886.html\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e代码执行的效率\u003c/a\u003e》中的第三个示例）\u003c/p\u003e\n\u003cp\u003e了解这些细节，会有利于我们知道在什么情况下有可以导致缓存的失效。\u003c/p\u003e\n\u003ch4\u003e\u003cspan class=\"ez-toc-section\" id=\"%E7%BC%93%E5%AD%98%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7\"\u003e\u003c/span\u003e缓存的一致性\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e对于主流的CPU来说，缓存的写操作基本上是两种策略（参看本站《\u003ca href=\"https://coolshell.cn/articles/17416.html\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e缓存更新的套路\u003c/a\u003e》），\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e一种是Write Back，写操作只要在cache上，然后再flush到内存上。\u003c/li\u003e\n\u003cli\u003e一种是Write Through，写操作同时写到cache和内存上。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e为了提高写的性能，一般来说，主流的CPU（如：Intel Core i7/i9）采用的是Write Back的策略，因为直接写内存实在是太慢了。\u003c/p\u003e\n\u003cp\u003e好了，现在问题来了，如果有一个数据 x 在 CPU 第0核的缓存上被更新了，那么其它CPU核上对于这个数据 x 的值也要被更新，这就是缓存一致性的问题。（当然，对于我们上层的程序我们不用关心CPU多个核的缓存是怎么同步的，这对上层的代码来说都是透明的）\u003c/p\u003e\n\u003cp\u003e一般来说，在CPU硬件上，会有两种方法来解决这个问题。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eDirectory 协议\u003c/strong\u003e。这种方法的典型实现是要设计一个集中式控制器，它是主存储器控制器的一部分。其中有一个目录存储在主存储器中，其中包含有关各种本地缓存内容的全局状态信息。当单个CPU Cache 发出读写请求时，这个集中式控制器会检查并发出必要的命令，以在主存和CPU Cache之间或在CPU Cache自身之间进行数据同步和传输。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSnoopy 协议\u003c/strong\u003e。这种协议更像是一种数据通知的总线型的技术。CPU Cache通过这个协议可以识别其它Cache上的数据状态。如果有数据共享的话，可以通过广播机制将共享数据的状态通知给其它CPU Cache。这个协议要求每个CPU Cache 都可以\u003cstrong class=\"hu je\"\u003e\u003cem class=\"io\"\u003e“\u003c/em\u003e窥探\u003cem class=\"io\"\u003e”\u003c/em\u003e\u003c/strong\u003e数据事件的通知并做出相应的反应。如下图所示，有一个Snoopy Bus的总线。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cimg decoding=\"async\" loading=\"lazy\" class=\"aligncenter wp-image-20797\" style=\"font-weight: 400;\" src=\"https://coolshell.cn/wp-content/uploads/2020/02/The-cache-coherence-problem-Initially-processors-0-and-1-both-read-location-x.png\" alt=\"\" width=\"400\" height=\"217\" srcset=\"https://coolshell.cn/wp-content/uploads/2020/02/The-cache-coherence-problem-Initially-processors-0-and-1-both-read-location-x.png 850w, https://coolshell.cn/wp-content/uploads/2020/02/The-cache-coherence-problem-Initially-processors-0-and-1-both-read-location-x-300x163.png 300w, https://coolshell.cn/wp-content/uploads/2020/02/The-cache-coherence-problem-Initially-processors-0-and-1-both-read-location-x-768x417.png 768w, https://coolshell.cn/wp-content/uploads/2020/02/The-cache-coherence-problem-Initially-processors-0-and-1-both-read-location-x-498x270.png 498w\" sizes=\"(max-width: 400px) 100vw, 400px\"/\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e因为Directory协议是一个中心式的，会有性能瓶颈，而且会增加整体设计的复杂度。而Snoopy协议更像是微服务+消息通讯，所以，现在基本都是使用Snoopy的总线的设计。\u003c/p\u003e\n\u003cp\u003e这里，我想多写一些细节，因为这种微观的东西，让人不自然地就会跟分布式系统关联起来，在分布式系统中我们一般用Paxos/Raft这样的分布式一致性的算法。而在CPU的微观世界里，则不必使用这样的算法，原因是因为CPU的多个核的硬件不必考虑网络会断会延迟的问题。所以，CPU的多核心缓存间的同步的核心就是要管理好数据的状态就好了。\u003c/p\u003e\n\u003cp\u003e这里介绍几个状态协议，先从最简单的开始，MESI协议，这个协议跟那个著名的足球运动员梅西没什么关系，其主要表示缓存数据有四个状态：Modified（已修改）, Exclusive（独占的）,Shared（共享的），Invalid（无效的）。\u003c/p\u003e\n\u003cp\u003e这些状态的状态机如下所示（有点复杂，你可以先不看，这个图就是想告诉你状态控制有多复杂）：\u003c/p\u003e\n\u003cp\u003e\u003cimg decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-full wp-image-20804\" src=\"https://coolshell.cn/wp-content/uploads/2020/02/MESI.png\" alt=\"\" width=\"420\" height=\"406\" srcset=\"https://coolshell.cn/wp-content/uploads/2020/02/MESI.png 420w, https://coolshell.cn/wp-content/uploads/2020/02/MESI-300x290.png 300w, https://coolshell.cn/wp-content/uploads/2020/02/MESI-279x270.png 279w\" sizes=\"(max-width: 420px) 100vw, 420px\"/\u003e\u003c/p\u003e\n\u003cp\u003e下面是个示例（如果你想看一下动画演示的话，这里有一个网页（\u003ca href=\"https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESIHelp.htm\" target=\"_blank\" rel=\"noopener noreferrer\"\u003eMESI Interactive Animations\u003c/a\u003e），你可以进行交互操作，这个动画演示中使用的Write Through算法）：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e当前操作\u003c/th\u003e\n\u003cth\u003eCPU0\u003c/th\u003e\n\u003cth\u003eCPU1\u003c/th\u003e\n\u003cth\u003eMemory\u003c/th\u003e\n\u003cth\u003e说明\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e1) CPU0 read(x)\u003c/td\u003e\n\u003ctd\u003e x=1 (E)\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003ex=1\u003c/td\u003e\n\u003ctd\u003e只有一个CPU有 x 变量，\u003cbr/\u003e\n所以，状态是 Exclusive\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2) CPU1 read(x)\u003c/td\u003e\n\u003ctd\u003e x=1 (S)\u003c/td\u003e\n\u003ctd\u003ex=1(S)\u003c/td\u003e\n\u003ctd\u003ex=1\u003c/td\u003e\n\u003ctd\u003e有两个CPU都读取 x 变量，\u003cbr/\u003e\n所以状态变成 Shared\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e3) CPU0 write(x,9)\u003c/td\u003e\n\u003ctd\u003e x=\u003cspan style=\"color: #ff0000;\"\u003e9\u003c/span\u003e (M)\u003c/td\u003e\n\u003ctd\u003ex=1(I)\u003c/td\u003e\n\u003ctd\u003ex=1\u003c/td\u003e\n\u003ctd\u003e变量改变，在CPU0中状态\u003cbr/\u003e\n变成 Modified，在CPU1中\u003cbr/\u003e\n状态变成 Invalid\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e4) 变量 x 写回内存\u003c/td\u003e\n\u003ctd\u003e x=9 (M)\u003c/td\u003e\n\u003ctd\u003eX=1(I)\u003c/td\u003e\n\u003ctd\u003ex=9\u003c/td\u003e\n\u003ctd\u003e目前的状态不变\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e5) CPU1  read(x)\u003c/td\u003e\n\u003ctd\u003e x=9 (S)\u003c/td\u003e\n\u003ctd\u003ex=9(S)\u003c/td\u003e\n\u003ctd\u003ex=9\u003c/td\u003e\n\u003ctd\u003e变量同步到所有的Cache中，\u003cbr/\u003e\n状态回到Shared\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e \u003c/p\u003e\n\u003cp\u003eMESI 这种协议在数据更新后，会标记其它共享的CPU缓存的数据拷贝为Invalid状态，然后当其它CPU再次read的时候，就会出现 cache miss 的问题，此时再从内存中更新数据。从内存中更新数据意味着20倍速度的降低。我们能不能直接从我隔壁的CPU缓存中更新？是的，这就可以增加很多速度了，但是状态控制也就变麻烦了。还需要多来一个状态：Owner(宿主)，用于标记，我是更新数据的源。于是，出现了 \u003ca href=\"https://en.wikipedia.org/wiki/MOESI_protocol\" target=\"_blank\" rel=\"noopener noreferrer\"\u003eMOESI 协议\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eMOESI协议的状态机和演示示例我就不贴了（有兴趣可以上\u003ca href=\"https://inst.eecs.berkeley.edu/~cs61c/su18/disc/11/Disc11Sol.pdf\" target=\"_blank\" rel=\"noopener\"\u003eBerkeley上看看相关的课件\u003c/a\u003e），\u003cstrong\u003e我们只需要理解MOESI协议允许 CPU Cache 间同步数据，于是也降低了对内存的操作\u003c/strong\u003e，性能是非常大的提升，但是控制逻辑也非常复杂。\u003c/p\u003e\n\u003cp\u003e顺便说一下，与 MOESI 协议类似的一个协议是 \u003ca href=\"https://en.wikipedia.org/wiki/MESIF_protocol\" target=\"_blank\" rel=\"noopener noreferrer\"\u003eMESIF\u003c/a\u003e，其中的 F 是 Forward，同样是把更新过的数据转发给别的 CPU Cache 但是，MOESI 中的 Owner 状态 和MESIF 中的 Forward 状态有一个非常大的不一样—— \u003cstrong\u003eOwner状态下的数据是dirty的，还没有写回内存，Forward状态下的数据是clean的，可以丢弃而不用另行通知\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e需要说明的是，AMD用MOESI，Intel用MESIF。所以，F 状态主要是针对 CPU L3 Cache 设计的（前面我们说过，L3是所有CPU核心共享的）。（相关的比较可以参看\u003ca href=\"https://stackoverflow.com/a/49989985\" target=\"_blank\" rel=\"noopener noreferrer\"\u003eStackOverlow上这个问题的答案\u003c/a\u003e）\u003c/p\u003e\n\u003ch4\u003e\u003cspan class=\"ez-toc-section\" id=\"%E7%A8%8B%E5%BA%8F%E6%80%A7%E8%83%BD\"\u003e\u003c/span\u003e程序性能\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e了解了我们上面的这些东西后，我们来看一下对于程序的影响。\u003c/p\u003e\n\u003ch5\u003e\u003cspan class=\"ez-toc-section\" id=\"%E7%A4%BA%E4%BE%8B%E4%B8%80\"\u003e\u003c/span\u003e示例一\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h5\u003e\n\u003cp\u003e首先，假设我们有一个64M长的数组，设想一下下面的两个循环：\u003c/p\u003e\n\u003cpre class=\"EnlighterJSRAW\" data-enlighter-language=\"cpp\"\u003econst int LEN = 64*1024*1024;\nint *arr = new int[LEN];\n\nfor (int i = 0; i \u0026lt; LEN; i += 2) arr[i] *= i;\n\nfor (int i = 0; i \u0026lt; LEN; i += 8) arr[i] *= i;\u003c/pre\u003e\n\u003cp\u003e按我们的想法来看，第二个循环要比第一个循环少4倍的计算量，其应该也是要快4倍的。但实际跑下来并不是，\u003cstrong\u003e在我的机器上，第一个循环需要127毫秒，第二个循环则需要121毫秒，相差无几\u003c/strong\u003e。这里最主要的原因就是 Cache Line，因为CPU会以一个Cache Line 64Bytes最小时单位加载，也就是16个32bits的整型，所以，无论你步长是2还是8，都差不多。而后面的乘法其实是不耗CPU时间的。\u003c/p\u003e\n\u003ch5\u003e\u003cspan class=\"ez-toc-section\" id=\"%E7%A4%BA%E4%BE%8B%E4%BA%8C\"\u003e\u003c/span\u003e示例二\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h5\u003e\n\u003cp\u003e我们再来看一个与缓存命中率有关的代码，我们以一定的步长\u003ccode\u003eincrement\u003c/code\u003e 来访问一个连续的数组。\u003c/p\u003e\n\u003cpre class=\"EnlighterJSRAW\" data-enlighter-language=\"cpp\"\u003efor (int i = 0; i \u0026lt; 10000000; i++) {\n    for (int j = 0; j \u0026lt; size; j += increment) {\n        memory[j] += j;\n    }\n}\u003c/pre\u003e\n\u003cp\u003e我们测试一下，在下表中， 表头是步长，也就是每次跳多少个整数，而纵向是这个数组可以跳几次（你可以理解为要几条Cache Line），于是表中的任何一项代表了这个数组有多少，而且步长是多少。比如：横轴是 512，纵轴是4，意思是，这个数组有 \u003ccode\u003e4*512 = 2048\u003c/code\u003e 个长度，访问时按512步长访问，也就是访问其中的这几项：\u003ccode\u003e[0, 512, 1024, 1536]\u003c/code\u003e 这四项。\u003c/p\u003e\n\u003cp\u003e表中同的项是，是循环1000万次的时间，单位是“微秒”（除以1000后是毫秒）\u003c/p\u003e\n\u003cpre\u003e| count |   1    |   16  |  512  | 1024  |\n------------------------------------------\n|     1 |  17539 | 16726 | 15143 | 14477 |\n|     2 |  15420 | 14648 | 13552 | 13343 |\n|     3 |  14716 | 14463 | 15086 | 17509 |\n|     4 |  18976 | 18829 | 18961 | 21645 |\n|     5 |  23693 | 23436 | 74349 | 29796 |\n|     6 |  23264 | 23707 | 27005 | 44103 |\n|     7 |  28574 | 28979 | 33169 | 58759 |\n|     8 |  33155 | 34405 | 39339 | 65182 |\n|     9 |  37088 | 37788 | 49863 |\u003cspan style=\"color: #cc0000;\"\u003e\u003cstrong\u003e156745\u003c/strong\u003e\u003c/span\u003e |\n|    10 |  41543 | 42103 | 58533 |\u003cspan style=\"color: #cc0000;\"\u003e\u003cstrong\u003e215278\u003c/strong\u003e\u003c/span\u003e |\n|    11 |  47638 | 50329 | 66620 |\u003cspan style=\"color: #cc0000;\"\u003e\u003cstrong\u003e335603\u003c/strong\u003e\u003c/span\u003e |\n|    12 |  49759 | 51228 | 75087 |\u003cspan style=\"color: #cc0000;\"\u003e\u003cstrong\u003e305075\u003c/strong\u003e\u003c/span\u003e |\n|    13 |  53938 | 53924 | 77790 |\u003cspan style=\"color: #cc0000;\"\u003e\u003cstrong\u003e366879\u003c/strong\u003e\u003c/span\u003e |\n|    14 |  58422 | 59565 | 90501 |\u003cspan style=\"color: #cc0000;\"\u003e\u003cstrong\u003e466368\u003c/strong\u003e\u003c/span\u003e |\n|    15 |  62161 | 64129 | 90814 |\u003cspan style=\"color: #cc0000;\"\u003e\u003cstrong\u003e525780\u003c/strong\u003e\u003c/span\u003e |\n|    16 |  67061 | 66663 | 98734 |\u003cspan style=\"color: #cc0000;\"\u003e\u003cstrong\u003e440558\u003c/strong\u003e\u003c/span\u003e |\n|    17 |  71132 | 69753 |\u003cspan style=\"color: #cc0000;\"\u003e\u003cstrong\u003e171203\u003c/strong\u003e\u003c/span\u003e |\u003cspan style=\"color: #cc0000;\"\u003e\u003cstrong\u003e506631\u003c/strong\u003e\u003c/span\u003e |\n|    18 |  74102 | 73130 |\u003cspan style=\"color: #cc0000;\"\u003e\u003cstrong\u003e293947\u003c/strong\u003e\u003c/span\u003e |\u003cspan style=\"color: #cc0000;\"\u003e\u003cstrong\u003e550920\u003c/strong\u003e\u003c/span\u003e |\n\u003c/pre\u003e\n\u003cp\u003e我们可以看到，从 \u003ccode\u003e[9，1024]\u003c/code\u003e 以后，时间显著上升。包括 \u003ccode\u003e[17，512]\u003c/code\u003e 和 \u003ccode\u003e[18,512]\u003c/code\u003e 也显著上升。这是因为，我机器的 L1 Cache 是 32KB, 8 Way 的，前面说过，8 Way的有64组，每组8个Cache Line，当for-loop步长超过1024个整型，也就是正好 4096 Bytes时，也就是导致内存地址的变化是变化在高位的24bits上，而低位的12bits变化不大，尤其是中间6bits没有变化，导致全部命中同一组set，导致大量的cache 冲突，导致性能下降，时间上升。而 [16, 512]也是一样的，其中的几步开始导致L1 Cache开始冲突失效。\u003c/p\u003e\n\u003ch5\u003e\u003cspan class=\"ez-toc-section\" id=\"%E7%A4%BA%E4%BE%8B%E4%B8%89\"\u003e\u003c/span\u003e示例三\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h5\u003e\n\u003cp\u003e接下来，我们再来看个示例。下面是一个二维数组的两种遍历方式，一个逐行遍历，一个是逐列遍历，这两种方式在理论上来说，寻址和计算量都是一样的，执行时间应该也是一样的。\u003c/p\u003e\n\u003cpre class=\"EnlighterJSRAW\" data-enlighter-language=\"cpp\"\u003econst int row = 1024;\nconst int col = 512\nint matrix[row][col];\n\n//逐行遍历\nint sum_row=0;\nfor(int _r=0; _r\u0026lt;row; _r++) {\n    for(int _c=0; _c\u0026lt;col; _c++){\n        sum_row += matrix[_r][_c];\n    }\n}\n\n//逐列遍历\nint sum_col=0;\nfor(int _c=0; _c\u0026lt;col; _c++) {\n    for(int _r=0; _r\u0026lt;row; _r++){\n        sum_col += matrix[_r][_c];\n    }\n}\u003c/pre\u003e\n\u003cp\u003e然而，并不是，在我的机器上，得到下面的结果。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e逐行遍历：0.081ms\u003c/li\u003e\n\u003cli\u003e逐列遍历：1.069ms\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e执行时间有十几倍的差距。其中的原因，就是逐列遍历对于CPU Cache 的运作方式并不友好，所以，付出巨大的代价。\u003c/p\u003e\n\u003ch5\u003e\u003cspan class=\"ez-toc-section\" id=\"%E7%A4%BA%E4%BE%8B%E5%9B%9B\"\u003e\u003c/span\u003e示例四\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h5\u003e\n\u003cp\u003e接下来，我们来看一下多核下的性能问题，参看如下的代码。两个线程在操作一个数组的两个不同的元素（无需加锁），线程循环1000万次，做加法操作。在下面的代码中，我高亮了一行，就是\u003ccode\u003ep2\u003c/code\u003e指针，要么是\u003ccode\u003ep[1]\u003c/code\u003e，或是 \u003ccode\u003ep[30]\u003c/code\u003e，理论上来说，无论访问哪两个数组元素，都应该是一样的执行时间。\u003c/p\u003e\n\u003cpre class=\"EnlighterJSRAW\" data-enlighter-language=\"cpp\" data-enlighter-highlight=\"9\"\u003evoid fn (int* data) {\n    for(int i = 0; i \u0026lt; 10*1024*1024; ++i)\n        *data += rand();\n}\n\nint p[32];\n\nint *p1 = \u0026amp;p[0];\nint *p2 = \u0026amp;p[1]; // int *p2 = \u0026amp;p[30];\n\nthread t1(fn, p1);\nthread t2(fn, p2);\u003c/pre\u003e\n\u003cp\u003e然而，并不是，在我的机器上执行下来的结果是：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e对于 \u003ccode\u003ep[0]\u003c/code\u003e 和 \u003ccode\u003ep[1]\u003c/code\u003e ：560ms\u003c/li\u003e\n\u003cli\u003e对于 \u003ccode\u003ep[0]\u003c/code\u003e 和 \u003ccode\u003ep[30]\u003c/code\u003e：104ms\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e这是因为 \u003ccode\u003ep[0]\u003c/code\u003e 和 \u003ccode\u003ep[1]\u003c/code\u003e 在同一条 Cache Line 上，而 \u003ccode\u003ep[0]\u003c/code\u003e 和 \u003ccode\u003ep[30]\u003c/code\u003e 则不可能在同一条Cache Line 上 ，CPU的缓存最小的更新单位是Cache Line，所以，\u003cstrong\u003e这导致虽然两个线程在写不同的数据，但是因为这两个数据在同一条Cache Line上，就会导致缓存需要不断进在两个CPU的L1/L2中进行同步，从而导致了5倍的时间差异\u003c/strong\u003e。\u003c/p\u003e\n\u003ch5\u003e\u003cspan class=\"ez-toc-section\" id=\"%E7%A4%BA%E4%BE%8B%E4%BA%94\"\u003e\u003c/span\u003e示例五\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h5\u003e\n\u003cp\u003e接下来，我们再来看一下另外一段代码：我们想统计一下一个数组中的奇数个数，但是这个数组太大了，我们希望可以用多线程来完成这个统计。下面的代码中，\u003cstrong\u003e我们为每一个线程传入一个 id ，然后通过这个 id 来完成对应数组段的统计任务。这样可以加快整个处理速度\u003c/strong\u003e。\u003c/p\u003e\n\u003cpre class=\"EnlighterJSRAW\" data-enlighter-language=\"cpp\"\u003eint total_size = 16 * 1024 * 1024; //数组长度\nint* test_data = new test_data[total_size]; //数组\nint nthread = 6; //线程数（因为我的机器是6核的）\nint result[nthread]; //收集结果的数组\n\nvoid thread_func (int id) {\n    result[id] = 0;\n    int chunk_size = total_size / nthread + 1;\n    int start = id * chunk_size;\n    int end = min(start + chunk_size, total_size);\n\n    for ( int i = start; i \u0026lt; end; ++i ) {\n        if (test_data[i] % 2 != 0 ) ++result[id];\n    }\n}\u003c/pre\u003e\n\u003cp\u003e然而，在执行过程中，\u003cstrong\u003e你会发现，6个线程居然跑不过1个线程\u003c/strong\u003e。因为根据上面的例子你知道 \u003ccode\u003eresult[]\u003c/code\u003e 这个数组中的数据在一个Cache Line中，所以，所有的线程都会对这个 Cache Line 进行写操作，导致所有的线程都在不断地重新同步 \u003ccode\u003eresult[]\u003c/code\u003e 所在的 Cache Line，所以，导致 6 个线程还跑不过一个线程的结果。这叫 \u003cstrong\u003eFalse Sharing\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e优化也很简单，使用一个线程内的变量。\u003c/p\u003e\n\u003cpre class=\"EnlighterJSRAW\" data-enlighter-language=\"cpp\"\u003evoid thread_func (int id) {\n    result[id] = 0;\n    int chunk_size = total_size / nthread + 1;\n    int start = id * chunk_size;\n    int end = min(start + chunk_size, total_size);\n\n    int c = 0; //使用临时变量，没有cache line的同步了\n    for ( int i = start; i \u0026lt; end; ++i ) {\n        if (test_data[i] % 2 != 0 ) ++c;\n    }\n    result[id] = c;\n}\u003c/pre\u003e\n\u003cp\u003e我们把两个程序分别在 1 到 32 个线程上跑一下，得出的结果画一张图如下所示（横轴是线程数，纵轴是完成统的时间，单位是微秒）：\u003c/p\u003e\n\u003cp\u003e\u003cimg decoding=\"async\" loading=\"lazy\" class=\"aligncenter size-large wp-image-20813\" src=\"https://coolshell.cn/wp-content/uploads/2020/03/false.sharing-1024x643.png\" alt=\"\" width=\"640\" height=\"402\" srcset=\"https://coolshell.cn/wp-content/uploads/2020/03/false.sharing-1024x643.png 1024w, https://coolshell.cn/wp-content/uploads/2020/03/false.sharing-300x188.png 300w, https://coolshell.cn/wp-content/uploads/2020/03/false.sharing-768x482.png 768w, https://coolshell.cn/wp-content/uploads/2020/03/false.sharing-430x270.png 430w, https://coolshell.cn/wp-content/uploads/2020/03/false.sharing.png 1320w\" sizes=\"(max-width: 640px) 100vw, 640px\"/\u003e\u003c/p\u003e\n\u003cp\u003e上图中，我们可以看到，灰色的曲线就是第一种方法，橙色的就是第二种（用局部变量的）方法。当只有一个线程的时候，两个方法相当，基本没有什么差别，但是在线程数增加的时候的时候，你会发现，第二种方法的性能提高的非常快。直到到达6个线程的时候，开始变得稳定（前面说过，我的CPU是6核的）。而第一种方法无论加多少线程也没有办法超过第二种方法。因为第一种方法不是CPU Cache 友好的。也就是说，第二种方法，\u003cstrong\u003e只要我的CPU核数足够多，就可以做到线性的性能扩展，让每一个CPU核都跑起来，而第一种则不能\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e篇幅问题，示例就写到这里，相关的代码参看\u003ca href=\"https://github.com/haoel/cpu-cache\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e我的Github相关仓库\u003c/a\u003e。\u003c/p\u003e\n\u003ch4\u003e\u003cspan class=\"ez-toc-section\" id=\"%E5%BB%B6%E4%BC%B8%E9%98%85%E8%AF%BB\"\u003e\u003c/span\u003e延伸阅读\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eWikipedia : \u003ca href=\"https://en.wikipedia.org/wiki/CPU_cache\" target=\"_blank\" rel=\"noopener noreferrer\"\u003eCPU Cache \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e经典文章：\u003ca href=\"http://igoro.com/archive/gallery-of-processor-cache-effects/\" target=\"_blank\" rel=\"noopener noreferrer\"\u003eGallery of Processor Cache Effects\u003c/a\u003e （这篇文章中的测试已经有点过时了，但是这篇文章中所说的那些东西还是非常适用的）\u003c/li\u003e\n\u003cli\u003eEffective C++作者 Scott Meyers 的演讲 CPU Caches and Why You Care （\u003ca href=\"https://www.youtube.com/watch?v=WDIkqP4JbkE\" target=\"_blank\" rel=\"noopener noreferrer\"\u003eYoutube\u003c/a\u003e，\u003ca href=\"https://www.aristeia.com/TalkNotes/codedive-CPUCachesHandouts.pdf\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ePPT\u003c/a\u003e）\u003c/li\u003e\n\u003cli\u003e美国私立大学Swarthmore的教材 \u003ca href=\"https://www.cs.swarthmore.edu/~kwebb/cs31/f18/memhierarchy/caching.html\" target=\"_blank\" rel=\"noopener noreferrer\"\u003eCache Architecture and Design\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e经典文章：\u003ca href=\"https://people.freebsd.org/~lstewart/articles/cpumemory.pdf\" target=\"_blank\" rel=\"noopener noreferrer\"\u003eWhat Every Programmer Should Know About Memory\u003c/a\u003e （这篇文章非常经典，但是开篇太晦涩了，居然告诉你晶体管内的构造，第三章和第六章是重点）\u003c/li\u003e\n\u003cli\u003eNonblocking Algorithms and Scalable Multicore Programming （\u003ca href=\"https://queue.acm.org/detail.cfm?id=2492433\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e英文版\u003c/a\u003e，\u003ca href=\"https://www.oschina.net/translate/nonblocking-algorithms-and-scalable-multicore-programming\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e中文版\u003c/a\u003e）\u003c/li\u003e\n\u003cli\u003eGithub上的一个代码库 \u003ca href=\"https://github.com/Kobzol/hardware-effects\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ehardware-effects\u003c/a\u003e 里面有受CPU影响的程序的演示\u003c/li\u003e\n\u003cli\u003eOptimizing for instruction caches （\u003ca href=\"https://www.eetimes.com/optimizing-for-instruction-caches-part-1/\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ePart 1\u003c/a\u003e，\u003ca href=\"https://www.eetimes.com/optimizing-for-instruction-caches-part-2/\" target=\"_blank\" rel=\"noopener noreferrer\"\u003ePart 2\u003c/a\u003e， \u003ca href=\"https://www.eetimes.com/optimizing-for-instruction-caches-part-3/\"\u003ePart 3\u003c/a\u003e）\u003c/li\u003e\n\u003cli\u003e经典数据：\u003ca href=\"https://gist.github.com/jboner/2841832\" target=\"_blank\" rel=\"noopener noreferrer\"\u003eLatency Numbers Every Programmer Should Know\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e关于Java的可以看一下这篇\u003ca href=\"https://dzone.com/articles/optimizing-memory-access-with-cpu-cache\" target=\"_blank\" rel=\"noopener noreferrer\"\u003eOptimizing Memory Access With CPU Cache\u003c/a\u003e 或是 \u003ca href=\"https://www.stardog.com/blog/writing-cache-friendly-code/\" target=\"_blank\" rel=\"noopener noreferrer\"\u003eWriting cache-friendly code\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e总之，这个CPU Cache的调优技术不是什么新鲜的东西，只要Google就能找到有很多很多文章……\u003c/p\u003e\n\u003cp\u003e（全文完）\u003c/p\u003e\n\u003cdiv style=\"margin-top: 15px; font-size: 16px;color: #cc0000;\"\u003e\n\u003cp align=\"center\"\u003e\u003cstrong\u003e（转载本站文章请注明作者和出处 \u003ca href=\"https://coolshell.cn/\"\u003e酷 壳 – CoolShell\u003c/a\u003e ，请勿用于任何商业用途）\u003c/strong\u003e\u003c/p\u003e\n\u003c/div\u003e\n\u003cdiv class=\"wp_rp_wrap  wp_rp_vertical_m\" id=\"wp_rp_first\"\u003e\u003cdiv class=\"wp_rp_content\"\u003e\u003ch3 class=\"related_post_title\"\u003e相关文章\u003c/h3\u003e\u003cul class=\"related_post wp_rp\"\u003e\u003cli\u003e\u003ca href=\"https://coolshell.cn/articles/10249.html\" class=\"wp_rp_thumbnail\"\u003e\u003cimg src=\"https://coolshell.cn/wp-content/uploads/2013/07/image6-150x150.png\" alt=\"7个示例科普CPU Cache\" width=\"150\" height=\"150\"/\u003e\u003c/a\u003e\u003ca href=\"https://coolshell.cn/articles/10249.html\" class=\"wp_rp_title\"\u003e7个示例科普CPU Cache\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://coolshell.cn/articles/17416.html\" class=\"wp_rp_thumbnail\"\u003e\u003cimg src=\"https://coolshell.cn/wp-content/uploads/2016/07/cache-150x150.png\" alt=\"缓存更新的套路\" width=\"150\" height=\"150\"/\u003e\u003c/a\u003e\u003ca href=\"https://coolshell.cn/articles/17416.html\" class=\"wp_rp_title\"\u003e缓存更新的套路\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://coolshell.cn/articles/2039.html\" class=\"wp_rp_thumbnail\"\u003e\u003cimg src=\"https://coolshell.cn/wp-content/plugins/wordpress-23-related-posts-plugin/static/thumbs/10.jpg\" alt=\"CPU的性价比\" width=\"150\" height=\"150\"/\u003e\u003c/a\u003e\u003ca href=\"https://coolshell.cn/articles/2039.html\" class=\"wp_rp_title\"\u003eCPU的性价比\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://coolshell.cn/articles/22367.html\" class=\"wp_rp_thumbnail\"\u003e\u003cimg src=\"https://coolshell.cn/wp-content/uploads/2023/02/nostr-aplicacion-descentralizada-1140x570-1-150x150.png\" alt=\"聊聊 nostr 和 审查\" width=\"150\" height=\"150\"/\u003e\u003c/a\u003e\u003ca href=\"https://coolshell.cn/articles/22367.html\" class=\"wp_rp_title\"\u003e聊聊 nostr 和 审查\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://coolshell.cn/articles/1183.html\" class=\"wp_rp_thumbnail\"\u003e\u003cimg src=\"https://coolshell.cn/wp-content/plugins/wordpress-23-related-posts-plugin/static/thumbs/25.jpg\" alt=\"15个Web在线WYSIWYG编辑器\" width=\"150\" height=\"150\"/\u003e\u003c/a\u003e\u003ca href=\"https://coolshell.cn/articles/1183.html\" class=\"wp_rp_title\"\u003e15个Web在线WYSIWYG编辑器\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://coolshell.cn/articles/19840.html\" class=\"wp_rp_thumbnail\"\u003e\u003cimg src=\"https://coolshell.cn/wp-content/uploads/2019/10/HTTP-770x513-300x200-1-150x150.jpg\" alt=\"HTTP的前世今生\" width=\"150\" height=\"150\"/\u003e\u003c/a\u003e\u003ca href=\"https://coolshell.cn/articles/19840.html\" class=\"wp_rp_title\"\u003eHTTP的前世今生\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003c/div\u003e\n\u003cdiv id=\"post-ratings-20793\" class=\"post-ratings\" itemscope=\"\" itemtype=\"https://schema.org/Article\" data-nonce=\"49e91ac5c9\"\u003e\u003cimg id=\"rating_20793_1\" src=\"https://coolshell.cn/wp-content/plugins/wp-postratings/images/stars_crystal/rating_on.gif\" alt=\"好烂啊\" title=\"好烂啊\" onmouseover=\"if (!window.__cfRLUnblockHandlers) return false; current_rating(20793, 1, \u0026#39;好烂啊\u0026#39;);\" onmouseout=\"if (!window.__cfRLUnblockHandlers) return false; ratings_off(4.5, 5, 0);\" onclick=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" onkeypress=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" style=\"cursor: pointer; border: 0px;\" data-cf-modified-82c86912d27abfab2ac926c8-=\"\"/\u003e\u003cimg id=\"rating_20793_2\" src=\"https://coolshell.cn/wp-content/plugins/wp-postratings/images/stars_crystal/rating_on.gif\" alt=\"有点差\" title=\"有点差\" onmouseover=\"if (!window.__cfRLUnblockHandlers) return false; current_rating(20793, 2, \u0026#39;有点差\u0026#39;);\" onmouseout=\"if (!window.__cfRLUnblockHandlers) return false; ratings_off(4.5, 5, 0);\" onclick=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" onkeypress=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" style=\"cursor: pointer; border: 0px;\" data-cf-modified-82c86912d27abfab2ac926c8-=\"\"/\u003e\u003cimg id=\"rating_20793_3\" src=\"https://coolshell.cn/wp-content/plugins/wp-postratings/images/stars_crystal/rating_on.gif\" alt=\"凑合看看\" title=\"凑合看看\" onmouseover=\"if (!window.__cfRLUnblockHandlers) return false; current_rating(20793, 3, \u0026#39;凑合看看\u0026#39;);\" onmouseout=\"if (!window.__cfRLUnblockHandlers) return false; ratings_off(4.5, 5, 0);\" onclick=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" onkeypress=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" style=\"cursor: pointer; border: 0px;\" data-cf-modified-82c86912d27abfab2ac926c8-=\"\"/\u003e\u003cimg id=\"rating_20793_4\" src=\"https://coolshell.cn/wp-content/plugins/wp-postratings/images/stars_crystal/rating_on.gif\" alt=\"还不错\" title=\"还不错\" onmouseover=\"if (!window.__cfRLUnblockHandlers) return false; current_rating(20793, 4, \u0026#39;还不错\u0026#39;);\" onmouseout=\"if (!window.__cfRLUnblockHandlers) return false; ratings_off(4.5, 5, 0);\" onclick=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" onkeypress=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" style=\"cursor: pointer; border: 0px;\" data-cf-modified-82c86912d27abfab2ac926c8-=\"\"/\u003e\u003cimg id=\"rating_20793_5\" src=\"https://coolshell.cn/wp-content/plugins/wp-postratings/images/stars_crystal/rating_half.gif\" alt=\"很精彩\" title=\"很精彩\" onmouseover=\"if (!window.__cfRLUnblockHandlers) return false; current_rating(20793, 5, \u0026#39;很精彩\u0026#39;);\" onmouseout=\"if (!window.__cfRLUnblockHandlers) return false; ratings_off(4.5, 5, 0);\" onclick=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" onkeypress=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" style=\"cursor: pointer; border: 0px;\" data-cf-modified-82c86912d27abfab2ac926c8-=\"\"/\u003e (\u003cstrong\u003e149\u003c/strong\u003e 人打了分，平均分： \u003cstrong\u003e4.54\u003c/strong\u003e )\u003cbr/\u003e\u003cspan class=\"post-ratings-text\" id=\"ratings_20793_text\"\u003e\u003c/span\u003e\u003cmeta itemprop=\"name\" content=\"与程序员相关的CPU缓存知识\"/\u003e\u003cmeta itemprop=\"headline\" content=\"与程序员相关的CPU缓存知识\"/\u003e\u003cmeta itemprop=\"description\" content=\"好久没有写一些微观方面的文章了，今天写一篇关于CPU Cache相关的文章，这篇文章比较长，主要分成这么几个部分：基础知识、缓存的命中、缓存的一致性、相关的代码示例和延伸阅读。其中会讲述一些多核 CPU 的系统架构以及其原理，包括对程序性能上的影响，以及在进行并发编程的时候需要注意到的一些问题。这篇文章我会尽量地写简单和通俗易懂一些，主要是讲清楚相关的原理和问题，而对于一些细节和延伸阅读我会在文章...\"/\u003e\u003cmeta itemprop=\"datePublished\" content=\"2020-03-01T19:43:41+08:00\"/\u003e\u003cmeta itemprop=\"dateModified\" content=\"2020-12-22T13:02:17+08:00\"/\u003e\u003cmeta itemprop=\"url\" content=\"https://coolshell.cn/articles/20793.html\"/\u003e\u003cmeta itemprop=\"author\" content=\"陈皓\"/\u003e\u003cmeta itemprop=\"mainEntityOfPage\" content=\"https://coolshell.cn/articles/20793.html\"/\u003e\u003cdiv style=\"display: none;\" itemprop=\"publisher\" itemscope=\"\" itemtype=\"https://schema.org/Organization\"\u003e\u003cmeta itemprop=\"name\" content=\"酷 壳 - CoolShell\"/\u003e\u003cmeta itemprop=\"url\" content=\"https://coolshell.cn\"/\u003e\u003cdiv itemprop=\"logo\" itemscope=\"\" itemtype=\"https://schema.org/ImageObject\"\u003e\u003cmeta itemprop=\"url\" content=\"\"/\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv style=\"display: none;\" itemprop=\"aggregateRating\" itemscope=\"\" itemtype=\"https://schema.org/AggregateRating\"\u003e\u003cmeta itemprop=\"bestRating\" content=\"5\"/\u003e\u003cmeta itemprop=\"worstRating\" content=\"1\"/\u003e\u003cmeta itemprop=\"ratingValue\" content=\"4.54\"/\u003e\u003cmeta itemprop=\"ratingCount\" content=\"149\"/\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv id=\"post-ratings-20793-loading\" class=\"post-ratings-loading\"\u003e\u003cimg src=\"https://coolshell.cn/wp-content/plugins/wp-postratings/images/loading.gif\" width=\"16\" height=\"16\" class=\"post-ratings-image\"/\u003eLoading...\u003c/div\u003e\n\u003c/div\u003e",
  "Date": "2020-03-01T19:43:41+08:00",
  "Author": "陈皓"
}