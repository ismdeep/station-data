{
  "Source": "coolshell.cn",
  "Title": "7个示例科普CPU Cache",
  "Link": "https://coolshell.cn/articles/10249.html",
  "Content": "\u003cdiv class=\"entry-content\"\u003e\n\u003cp\u003e\u003cscript async=\"\" src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3415450859608158\" crossorigin=\"anonymous\" type=\"37e99e6d60d35d2fdc1a43d3-text/javascript\"\u003e\u003c/script\u003e\u003cstrong\u003e（感谢网友 \u003c/strong\u003e\u003ca href=\"http://weibo.com/fullofbull\" target=\"_blank\"\u003e\u003cstrong\u003e@我的上铺叫路遥\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e 翻译投稿）\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eCPU cache一直是理解计算机体系架构的重要知识点，也是并发编程设计中的技术难点，而且相关参考资料如同过江之鲫，浩瀚繁星，阅之如临深渊，味同嚼蜡，三言两语难以入门。正好网上有人推荐了微软大牛Igor Ostrovsky一篇博文\u003cstrong\u003e《漫游处理器缓存效应》\u003c/strong\u003e，文章不仅仅用7个最简单的源码示例就将CPU cache的原理娓娓道来，还附加图表量化分析做数学上的佐证，个人感觉这种案例教学的切入方式绝对是俺的菜，故而忍不住贸然译之，以飨列位看官。\u003c/p\u003e\n\u003cp\u003e原文地址：\u003ca href=\"http://igoro.com/archive/gallery-of-processor-cache-effects/\"\u003eGallery of Processor Cache Effects\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e大多数读者都知道cache是一种快速小型的内存，用以存储最近访问内存位置。这种描述合理而准确，但是更多地了解一些处理器缓存工作中的“烦人”细节对于理解程序运行性能有很大帮助。\u003c/p\u003e\n\u003cp\u003e在这篇博客中，我将运用代码示例来详解cache工作的方方面面，以及对现实世界中程序运行产生的影响。\u003c/p\u003e\n\u003cp\u003e下面的例子都是用C#写的，但语言的选择同程序运行状况以及得出的结论几乎没什么影响。\u003c/p\u003e\n\u003cdiv id=\"ez-toc-container\" class=\"ez-toc-v2_0_48 counter-hierarchy ez-toc-counter ez-toc-grey ez-toc-container-direction\"\u003e\n\u003cdiv class=\"ez-toc-title-container\"\u003e\n\u003cp class=\"ez-toc-title\"\u003e目录\u003c/p\u003e\n\u003cspan class=\"ez-toc-title-toggle\"\u003e\u003c/span\u003e\u003c/div\u003e\n\u003cnav\u003e\u003cul class=\"ez-toc-list ez-toc-list-level-1 \"\u003e\u003cli class=\"ez-toc-page-1 ez-toc-heading-level-4\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-1\" href=\"#%E7%A4%BA%E4%BE%8B1%EF%BC%9A%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E5%92%8C%E8%BF%90%E8%A1%8C\" title=\"示例1：内存访问和运行\"\u003e示例1：内存访问和运行\u003c/a\u003e\u003c/li\u003e\u003cli class=\"ez-toc-page-1 ez-toc-heading-level-4\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-2\" href=\"#%E7%A4%BA%E4%BE%8B2%EF%BC%9A%E7%BC%93%E5%AD%98%E8%A1%8C%E7%9A%84%E5%BD%B1%E5%93%8D\" title=\"示例2：缓存行的影响\"\u003e示例2：缓存行的影响\u003c/a\u003e\u003c/li\u003e\u003cli class=\"ez-toc-page-1 ez-toc-heading-level-4\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-3\" href=\"#%E7%A4%BA%E4%BE%8B3%EF%BC%9AL1%E5%92%8CL2%E7%BC%93%E5%AD%98%E5%A4%A7%E5%B0%8F\" title=\"示例3：L1和L2缓存大小\"\u003e示例3：L1和L2缓存大小\u003c/a\u003e\u003c/li\u003e\u003cli class=\"ez-toc-page-1 ez-toc-heading-level-4\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-4\" href=\"#%E7%A4%BA%E4%BE%8B4%EF%BC%9A%E6%8C%87%E4%BB%A4%E7%BA%A7%E5%88%AB%E5%B9%B6%E5%8F%91\" title=\"示例4：指令级别并发\"\u003e示例4：指令级别并发\u003c/a\u003e\u003c/li\u003e\u003cli class=\"ez-toc-page-1 ez-toc-heading-level-4\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-5\" href=\"#%E7%A4%BA%E4%BE%8B5%EF%BC%9A%E7%BC%93%E5%AD%98%E5%85%B3%E8%81%94%E6%80%A7\" title=\"示例5：缓存关联性\"\u003e示例5：缓存关联性\u003c/a\u003e\u003c/li\u003e\u003cli class=\"ez-toc-page-1 ez-toc-heading-level-4\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-6\" href=\"#%E7%A4%BA%E4%BE%8B6%EF%BC%9A%E7%BC%93%E5%AD%98%E8%A1%8C%E7%9A%84%E4%BC%AA%E5%85%B1%E4%BA%ABfalse-sharing\" title=\"示例6：缓存行的伪共享(false-sharing)\"\u003e示例6：缓存行的伪共享(false-sharing)\u003c/a\u003e\u003c/li\u003e\u003cli class=\"ez-toc-page-1 ez-toc-heading-level-4\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-7\" href=\"#%E7%A4%BA%E4%BE%8B7%EF%BC%9A%E7%A1%AC%E4%BB%B6%E5%A4%8D%E6%9D%82%E6%80%A7\" title=\"示例7：硬件复杂性\"\u003e示例7：硬件复杂性\u003c/a\u003e\u003c/li\u003e\u003cli class=\"ez-toc-page-1 ez-toc-heading-level-4\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-8\" href=\"#%E5%85%B3%E4%BA%8E%E7%AC%AC7%E4%B8%AA%E4%BE%8B%E5%AD%90%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9B%9E%E5%B8%96\" title=\"关于第7个例子的一个回帖\"\u003e关于第7个例子的一个回帖\u003c/a\u003e\u003c/li\u003e\u003cli class=\"ez-toc-page-1 ez-toc-heading-level-4\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-9\" href=\"#PS%E4%B8%AA%E4%BA%BA%E6%84%9F%E6%82%9F%E2%80%94%E2%80%94%E5%B1%80%E9%83%A8%E6%80%A7%E5%8E%9F%E7%90%86%E5%92%8C%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E5%8F%91\" title=\"P.S.个人感悟——局部性原理和流水线并发\"\u003eP.S.个人感悟——局部性原理和流水线并发\u003c/a\u003e\u003c/li\u003e\u003cli class=\"ez-toc-page-1 ez-toc-heading-level-4\"\u003e\u003ca class=\"ez-toc-link ez-toc-heading-10\" href=\"#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99\" title=\"参考资料\"\u003e参考资料\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/nav\u003e\u003c/div\u003e\n\u003ch4\u003e\u003cspan class=\"ez-toc-section\" id=\"%E7%A4%BA%E4%BE%8B1%EF%BC%9A%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E5%92%8C%E8%BF%90%E8%A1%8C\"\u003e\u003c/span\u003e示例1：内存访问和运行\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e你认为相较于循环1，循环2会运行多快？\u003c/p\u003e\n\u003cpre data-enlighter-language=\"c\" class=\"EnlighterJSRAW\"\u003eint[] arr = new int[64 * 1024 * 1024];\n\n// Loop 1\nfor (int i = 0; i \u0026lt; arr.Length; i++) arr[i] *= 3;\n\n// Loop 2\nfor (int i = 0; i \u0026lt; arr.Length; i += 16) arr[i] *= 3;\u003c/pre\u003e\n\u003cp\u003e\u003cspan id=\"more-10249\"\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e第一个循环将数组的每个值乘3，第二个循环将每16个值乘3，第二个循环只做了第一个约6%的工作，但在现代机器上，两者几乎运行相同时间：在我机器上分别是80毫秒和78毫秒。\u003c/p\u003e\n\u003cp\u003e两个循环花费相同时间的原因跟内存有关。\u003cstrong\u003e循环执行时间长短由数组的内存访问次数决定的，而非整型数的乘法运算次数。\u003c/strong\u003e经过下面对第二个示例的解释，你会发现硬件对这两个循环的主存访问次数是相同的。\u003c/p\u003e\n\u003ch4\u003e\u003cspan class=\"ez-toc-section\" id=\"%E7%A4%BA%E4%BE%8B2%EF%BC%9A%E7%BC%93%E5%AD%98%E8%A1%8C%E7%9A%84%E5%BD%B1%E5%93%8D\"\u003e\u003c/span\u003e示例2：缓存行的影响\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e让我们进一步探索这个例子。我们将尝试不同的循环步长，而不仅仅是1和16。\u003c/p\u003e\n\u003cp\u003e\u003ccode data-enlighter-language=\"c\" class=\"EnlighterJSRAW\"\u003efor (int i = 0; i \u0026lt; arr.Length; i += K) arr[i] *= 3;\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e下图为该循环在不同步长(K)下的运行时间：\u003c/p\u003e\n\u003cp\u003e\u003cimg decoding=\"async\" class=\"aligncenter\" alt=\"running times of this loop for different step values (K)\" src=\"http://igoro.com/wordpress/wp-content/uploads/2010/01/image6.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e注意当步长在1到16范围内，循环运行时间几乎不变。但从16开始，每次步长加倍，运行时间减半。\u003c/p\u003e\n\u003cp\u003e背后的原因是今天的CPU不再是按字节访问内存，而是以64字节为单位的块(chunk)拿取，称为一个缓存行(cache line)。当你读一个特定的内存地址，整个缓存行将从主存换入缓存，并且访问同一个缓存行内的其它值的开销是很小的。\u003c/p\u003e\n\u003cp\u003e由于16个整型数占用64字节（一个缓存行），for循环步长在1到16之间必定接触到相同数目的缓存行：即数组中所有的缓存行。当步长为32，我们只有大约每两个缓存行接触一次，当步长为64，只有每四个接触一次。\u003c/p\u003e\n\u003cp\u003e理解缓存行对某些类型的程序优化而言可能很重要。比如，数据字节对齐可能决定一次操作接触1个还是2个缓存行。那上面的例子来说，很显然操作不对齐的数据将损失一半性能。\u003c/p\u003e\n\u003ch4\u003e\u003cspan class=\"ez-toc-section\" id=\"%E7%A4%BA%E4%BE%8B3%EF%BC%9AL1%E5%92%8CL2%E7%BC%93%E5%AD%98%E5%A4%A7%E5%B0%8F\"\u003e\u003c/span\u003e示例3：L1和L2缓存大小\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e今天的计算机具有两级或三级缓存，通常叫做L1、L2以及可能的L3（译者注：如果你不明白什么叫二级缓存，可以参考\u003ca href=\"https://coolshell.cn/articles/3236.html\" target=\"_blank\"\u003e这篇精悍的博文\u003c/a\u003elol）。如果你想知道不同缓存的大小，你可以使用系统内部工具\u003ca href=\"http://technet.microsoft.com/en-us/sysinternals/cc835722.aspx\" target=\"_blank\"\u003eCoreInfo\u003c/a\u003e，或者Windows API调用\u003ca href=\"http://msdn.microsoft.com/en-us/library/ms683194(VS.85).aspx\" target=\"_blank\"\u003eGetLogicalProcessorInfo\u003c/a\u003e。两者都将告诉你缓存行以及缓存本身的大小。\u003c/p\u003e\n\u003cp\u003e在我的机器上，CoreInfo现实我有一个32KB的L1数据缓存，一个32KB的L1指令缓存，还有一个4MB大小L2数据缓存。L1缓存是处理器独享的，L2缓存是成对处理器共享的。\u003c/p\u003e\n\u003cp\u003eLogical Processor to Cache Map:\u003cbr/\u003e\n*— Data Cache 0, Level 1, 32 KB, Assoc 8, LineSize 64\u003cbr/\u003e\n*— Instruction Cache 0, Level 1, 32 KB, Assoc 8, LineSize 64\u003cbr/\u003e\n-*– Data Cache 1, Level 1, 32 KB, Assoc 8, LineSize 64\u003cbr/\u003e\n-*– Instruction Cache 1, Level 1, 32 KB, Assoc 8, LineSize 64\u003cbr/\u003e\n**– Unified Cache 0, Level 2, 4 MB, Assoc 16, LineSize 64\u003cbr/\u003e\n–*- Data Cache 2, Level 1, 32 KB, Assoc 8, LineSize 64\u003cbr/\u003e\n–*- Instruction Cache 2, Level 1, 32 KB, Assoc 8, LineSize 64\u003cbr/\u003e\n—* Data Cache 3, Level 1, 32 KB, Assoc 8, LineSize 64\u003cbr/\u003e\n—* Instruction Cache 3, Level 1, 32 KB, Assoc 8, LineSize 64\u003cbr/\u003e\n–** Unified Cache 1, Level 2, 4 MB, Assoc 16, LineSize 64\u003c/p\u003e\n\u003cp\u003e（译者注：作者平台是四核机，所以L1编号为0~3，数据/指令各一个，L2只有数据缓存，两个处理器共享一个，编号0~1。关联性字段在后面例子说明。）\u003c/p\u003e\n\u003cp\u003e让我们通过一个实验来验证这些数字。遍历一个整型数组，每16个值自增1——一种节约地方式改变每个缓存行。当遍历到最后一个值，就重头开始。我们将使用不同的数组大小，可以看到当数组溢出一级缓存大小，程序运行的性能将急剧滑落。\u003c/p\u003e\n\u003cpre data-enlighter-language=\"c\" class=\"EnlighterJSRAW\"\u003eint steps = 64 * 1024 * 1024;\n// Arbitrary number of steps\nint lengthMod = arr.Length - 1;\nfor (int i = 0; i \u0026lt; steps; i++)\n{\n    arr[(i * 16) \u0026amp; lengthMod]++; // (x \u0026amp; lengthMod) is equal to (x % arr.Length)\n}\u003c/pre\u003e\n\u003cp\u003e下图是运行时间图表：\u003cbr/\u003e\n\u003cimg decoding=\"async\" class=\"aligncenter\" alt=\"cache size\" src=\"http://igoro.com/wordpress/wp-content/uploads/2010/02/image.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e你可以看到在32KB和4MB之后性能明显滑落——正好是我机器上L1和L2缓存大小。\u003c/p\u003e\n\u003ch4\u003e\u003cspan class=\"ez-toc-section\" id=\"%E7%A4%BA%E4%BE%8B4%EF%BC%9A%E6%8C%87%E4%BB%A4%E7%BA%A7%E5%88%AB%E5%B9%B6%E5%8F%91\"\u003e\u003c/span\u003e示例4：指令级别并发\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e现在让我们看一看不同的东西。下面两个循环中你以为哪个较快？\u003c/p\u003e\n\u003cpre data-enlighter-language=\"c\" class=\"EnlighterJSRAW\"\u003eint steps = 256 * 1024 * 1024;\nint[] a = new int[2];\n\n// Loop 1\nfor (int i=0; i\u0026lt;steps; i++) { a[0]++; a[0]++; }\n\n// Loop 2\nfor (int i=0; i\u0026lt;steps; i++) { a[0]++; a[1]++; }\u003c/pre\u003e\n\u003cp\u003e结果是第二个循环约比第一个快一倍，至少在我测试的机器上。为什么呢？这跟两个循环体内的操作指令依赖性有关。\u003c/p\u003e\n\u003cp\u003e第一个循环体内，操作做是相互依赖的（译者注：下一次依赖于前一次）：\u003cbr/\u003e\n\u003cimg decoding=\"async\" class=\"aligncenter\" alt=\"same value dependency\" src=\"http://igoro.com/wordpress/wp-content/uploads/2010/01/image.png\"/\u003e\u003cbr/\u003e\n但第二个例子中，依赖性就不同了：\u003cbr/\u003e\n\u003cimg decoding=\"async\" class=\"aligncenter\" alt=\"different values dependency\" src=\"http://igoro.com/wordpress/wp-content/uploads/2010/02/image2.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e现代处理器中对不同部分指令拥有一点并发性（译者注：跟流水线有关，比如Pentium处理器就有U/V两条流水线，后面说明）。这使得CPU在同一时刻访问L1两处内存位置，或者执行两次简单算术操作。在第一个循环中，处理器无法发掘这种指令级别的并发性，但第二个循环中就可以。\u003c/p\u003e\n\u003cp\u003e[原文更新]：许多人在reddit上询问有关编译器优化的问题，像{ a[0]++; a[0]++; }能否优化为{ a[0]+=2; }。实际上，C#编译器和CLR JIT没有做优化——在数组访问方面。我用release模式编译了所有测试（使用优化选项），但我查询了JIT汇编语言证实优化并未影响结果。\u003c/p\u003e\n\u003ch4\u003e\u003cspan class=\"ez-toc-section\" id=\"%E7%A4%BA%E4%BE%8B5%EF%BC%9A%E7%BC%93%E5%AD%98%E5%85%B3%E8%81%94%E6%80%A7\"\u003e\u003c/span\u003e示例5：缓存关联性\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e缓存设计的一个关键决定是确保每个主存块(chunk)能够存储在任何一个缓存槽里，或者只是其中一些（译者注：此处一个槽位就是一个缓存行）。\u003c/p\u003e\n\u003cp\u003e有三种方式将缓存槽映射到主存块中：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e直接映射(Direct mapped cache)\u003c/strong\u003e\u003cbr/\u003e\n每个内存块只能映射到一个特定的缓存槽。一个简单的方案是通过块索引chunk_index映射到对应的槽位(chunk_index % cache_slots)。被映射到同一内存槽上的两个内存块是不能同时换入缓存的。（译者注：chunk_index可以通过物理地址/缓存行字节计算得到）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eN路组关联(N-way set associative cache)\u003c/strong\u003e\u003cbr/\u003e\n每个内存块能够被映射到N路特定缓存槽中的任意一路。比如一个16路缓存，每个内存块能够被映射到16路不同的缓存槽。一般地，具有一定相同低bit位地址的内存块将共享16路缓存槽。（译者注：相同低位地址表明相距一定单元大小的连续内存）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e完全关联(Fully associative cache)\u003c/strong\u003e\u003cbr/\u003e\n每个内存块能够被映射到任意一个缓存槽。操作效果上相当于一个散列表。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e直接映射缓存会引发冲突——当多个值竞争同一个缓存槽，它们将相互驱逐对方，导致命中率暴跌。另一方面，完全关联缓存过于复杂，并且硬件实现上昂贵。N路组关联是处理器缓存的典型方案，它在电路实现简化和高命中率之间取得了良好的折中。\u003c/p\u003e\n\u003cp\u003e\u003cimg decoding=\"async\" class=\"aligncenter\" alt=\"完全关联与多路关联的cache映射\" src=\"http://my.csdn.net/uploads/201204/18/1334757273_8141.png\"/\u003e\u003cbr/\u003e\n（此图由译者给出，直接映射和完全关联可以看做N路组关联的两个极端，从图中可知当N=1时，即直接映射；当N取最大值时，即完全关联。读者可以自行想象直接映射图例，具体表述见参考资料。）\u003c/p\u003e\n\u003cp\u003e举个例子，4MB大小的L2缓存在我机器上是16路关联。所有64字节内存块将分割为不同组，映射到同一组的内存块将竞争L2缓存里的16路槽位。\u003c/p\u003e\n\u003cp\u003eL2缓存有65,536个缓存行（译者注：4MB/64），每个组需要16路缓存行，我们将获得4096个集。这样一来，块属于哪个组取决于块索引的低12位bit(2^12=4096)。\u003cstrong\u003e因此缓存行对应的物理地址凡是以262,144字节(4096*64)的倍数区分的，将竞争同一个缓存槽。我机器上最多维持16个这样的缓存槽。\u003c/strong\u003e（译者注：请结合上图中的2路关联延伸理解，一个块索引对应64字节，chunk0对应组0中的任意一路槽位，chunk1对应组1中的任意一路槽位，以此类推chunk4095对应组4095中的任意一路槽位，chunk0和chunk4096地址的低12bit是相同的，所以chunk4096、chunk8192将同chunk0竞争组0中的槽位，它们之间的地址相差262,144字节的倍数，而最多可以进行16次竞争，否则就要驱逐一个chunk）。\u003c/p\u003e\n\u003cp\u003e为了使得缓存关联效果更加明了，我需要重复地访问同一组中的16个以上的元素，通过如下方法证明：\u003c/p\u003e\n\u003cpre data-enlighter-language=\"c\" class=\"EnlighterJSRAW\"\u003epublic static long UpdateEveryKthByte(byte[] arr, int K)\n{\n    Stopwatch sw = Stopwatch.StartNew();\n    const int rep = 1024*1024; // Number of iterations – arbitrary\n    int p = 0;\n    for (int i = 0; i \u0026lt; rep; i++)\n    {\n        arr[p]++;\n        p += K;\n        if (p \u0026gt;= arr.Length) p = 0;\n    }\n    sw.Stop();\n    return sw.ElapsedMilliseconds;\n}\u003c/pre\u003e\n\u003cp\u003e该方法每次在数组中迭代K个值，当到达末尾时从头开始。循环在运行足够长（2^20次）之后停止。\u003c/p\u003e\n\u003cp\u003e我使用不同的数组大小（每次增加1MB）和不同的步长传入UpdateEveryKthByte()。以下是绘制的图表，蓝色代表运行较长时间，白色代表较短时间：\u003cbr/\u003e\n\u003cimg decoding=\"async\" class=\"aligncenter\" alt=\"timing\" src=\"http://igoro.com/wordpress/wp-content/uploads/2010/02/image_thumb1_opt.png\"/\u003e\u003cbr/\u003e\n蓝色区域（较长时间）表明当我们重复数组迭代时，更新的值无法同时放在缓存中。浅蓝色区域对应80毫秒，白色区域对应10毫秒。\u003c/p\u003e\n\u003cp\u003e让我们来解释一下图表中蓝色部分：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e1.为何有垂直线？\u003c/strong\u003e垂直线表明步长值过多接触到同一组中内存位置（大于16次）。在这些次数里，我的机器无法同时将接触过的值放到16路关联缓存中。\u003c/p\u003e\n\u003cp\u003e一些糟糕的步长值为2的幂：256和512。举个例子，考虑512步长遍历8MB数组，存在32个元素以相距262,144字节空间分布，所有32个元素都会在循环遍历中更新到，因为512能够整除262,144（译者注：此处一个步长代表一个字节）。\u003c/p\u003e\n\u003cp\u003e由于32大于16，这32个元素将一直竞争缓存里的16路槽位。\u003c/p\u003e\n\u003cp\u003e（译者注：为何512步长的垂直线比256步长颜色更深？在同样足够多的步数下，512比256访问到存在竞争的块索引次数多一倍。比如跨越262,144字节边界512需要512步，而256需要1024步。那么当步数为2^20时，512访问了2048次存在竞争的块而256只有1024次。最差情况下步长为262,144的倍数，因为每次循环都会引发一个缓存行驱逐。）\u003c/p\u003e\n\u003cp\u003e有些不是2的幂的步长运行时间长仅仅是运气不好，最终访问到的是同一组中不成比例的许多元素，这些步长值同样显示为蓝线。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e2.为何垂直线在4MB数组长度的地方停止？\u003c/strong\u003e因为对于小于等于4MB的数组，16路关联缓存相当于完全关联缓存。\u003c/p\u003e\n\u003cp\u003e一个16路关联缓存最多能够维护16个以262,144字节分隔的缓存行，4MB内组17或更多的缓存行都没有对齐在262,144字节边界上，因为16*262,144=4,194,304。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e3.为何左上角出现蓝色三角？\u003c/strong\u003e在三角区域内，我们无法在缓存中同时存放所有必要的数据，不是出于关联性，而仅仅是因为L2缓存大小所限。\u003c/p\u003e\n\u003cp\u003e举个例子，考虑步长128遍历16MB数组，数组中每128字节更新一次，这意味着我们一次接触两个64字节内存块。为了存储16MB数组中每两个缓存行，我们需要8MB大小缓存。但我的机器中只有4MB缓存（译者注：这意味着必然存在冲突从而延时）。\u003c/p\u003e\n\u003cp\u003e即使我机器中4MB缓存是全关联，仍无法同时存放8MB数据。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e4.为何三角最左边部分是褪色的？\u003c/strong\u003e注意左边0~64字节部分——正好一个缓存行！就像上面示例1和2所说，额外访问相同缓存行的数据几乎没有开销。比如说，步长为16字节，它需要4步到达下一个缓存行，也就是说4次内存访问只有1次开销。\u003c/p\u003e\n\u003cp\u003e在相同循环次数下的所有测试用例中，采取省力步长的运行时间来得短。\u003c/p\u003e\n\u003cp\u003e将图表延伸后的模型：\u003cbr/\u003e\n\u003cimg decoding=\"async\" class=\"aligncenter\" alt=\"timing2\" src=\"http://igoro.com/wordpress/wp-content/uploads/2010/02/assoc_big_thumb1_opt.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e缓存关联性理解起来有趣而且确能被证实，但对于本文探讨的其它问题比起来，它肯定不会是你编程时所首先需要考虑的问题。\u003c/p\u003e\n\u003ch4\u003e\u003cspan class=\"ez-toc-section\" id=\"%E7%A4%BA%E4%BE%8B6%EF%BC%9A%E7%BC%93%E5%AD%98%E8%A1%8C%E7%9A%84%E4%BC%AA%E5%85%B1%E4%BA%ABfalse-sharing\"\u003e\u003c/span\u003e示例6：缓存行的伪共享(false-sharing)\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e在多核机器上，缓存遇到了另一个问题——一致性。不同的处理器拥有完全或部分分离的缓存。在我的机器上，L1缓存是分离的（这很普遍），而我有两对处理器，每一对共享一个L2缓存。这随着具体情况而不同，如果一个现代多核机器上拥有多级缓存，那么快速小型的缓存将被处理器独占。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e当一个处理器改变了属于它自己缓存中的一个值，其它处理器就再也无法使用它自己原来的值，因为其对应的内存位置将被刷新(invalidate)到所有缓存。而且由于缓存操作是以缓存行而不是字节为粒度，所有缓存中整个缓存行将被刷新！\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e为证明这个问题，考虑如下例子：\u003c/p\u003e\n\u003cpre data-enlighter-language=\"c\" class=\"EnlighterJSRAW\"\u003eprivate static int[] s_counter = new int[1024];\nprivate void UpdateCounter(int position)\n{\n    for (int j = 0; j \u0026lt; 100000000; j++)\n    {\n        s_counter[position] = s_counter[position] + 3;\n    }\n}\u003c/pre\u003e\n\u003cp\u003e在我的四核机上，如果我通过四个线程传入参数0,1,2,3并调用UpdateCounter，所有线程将花费4.3秒。\u003c/p\u003e\n\u003cp\u003e另一方面，如果我传入16,32,48,64，整个操作进花费0.28秒！\u003c/p\u003e\n\u003cp\u003e为何会这样？第一个例子中的四个值很可能在同一个缓存行里，每次一个处理器增加计数，这四个计数所在的缓存行将被刷新，而其它处理器在下一次访问它们各自的计数（译者注：注意数组是private属性，每个线程独占）将失去命中(miss)一个缓存。这种多线程行为有效地禁止了缓存功能，削弱了程序性能。\u003c/p\u003e\n\u003ch4\u003e\u003cspan class=\"ez-toc-section\" id=\"%E7%A4%BA%E4%BE%8B7%EF%BC%9A%E7%A1%AC%E4%BB%B6%E5%A4%8D%E6%9D%82%E6%80%A7\"\u003e\u003c/span\u003e示例7：硬件复杂性\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e即使你懂得了缓存的工作基础，有时候硬件行为仍会使你惊讶。不用处理器在工作时有不同的优化、探试和微妙的细节。\u003c/p\u003e\n\u003cp\u003e有些处理器上，L1缓存能够并发处理两路访问，如果访问是来自不同的存储体，而对同一存储体的访问只能串行处理。而且处理器聪明的优化策略也会使你感到惊讶，比如在伪共享的例子中，以前在一些没有微调的机器上运行表现并不良好，但我家里的机器能够对最简单的例子进行优化来减少缓存刷新。\u003c/p\u003e\n\u003cp\u003e下面是一个“硬件怪事”的奇怪例子：\u003c/p\u003e\n\u003cpre data-enlighter-language=\"c\" class=\"EnlighterJSRAW\"\u003eprivate static int A, B, C, D, E, F, G;\nprivate static void Weirdness()\n{\n    for (int i = 0; i \u0026lt; 200000000; i++)\n    {\n        // do something...\n    }\n}\u003c/pre\u003e\n\u003cp\u003e当我在循环体内进行三种不同操作，我得到如下运行时间：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e           操作\u003c/strong\u003e                    \u003cstrong\u003e时间\u003c/strong\u003e\u003cbr/\u003e\nA++; B++; C++; D++;     719 ms\u003cbr/\u003e\nA++; C++; E++; G++;     448 ms\u003cbr/\u003e\nA++; C++;                      518 ms\u003c/p\u003e\n\u003cp\u003e增加A,B,C,D字段比增加A,C,E,G字段花费更长时间，更奇怪的是，增加A,C两个字段比增加A,C,E,G执行更久！\u003c/p\u003e\n\u003cp\u003e我无法肯定这些数字背后的原因，但我怀疑这跟存储体有关，如果有人能够解释这些数字，我将洗耳恭听。\u003c/p\u003e\n\u003cp\u003e这个例子的教训是，你很难完全预测硬件的行为。你可以预测很多事情，但最终，衡量及验证你的假设非常重要。\u003c/p\u003e\n\u003ch4\u003e\u003cspan class=\"ez-toc-section\" id=\"%E5%85%B3%E4%BA%8E%E7%AC%AC7%E4%B8%AA%E4%BE%8B%E5%AD%90%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9B%9E%E5%B8%96\"\u003e\u003c/span\u003e关于第7个例子的一个回帖\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003eGoz：我询问Intel的工程师最后的例子，得到以下答复：\u003c/p\u003e\n\u003cp\u003e“很显然这涉及到执行单元里指令是怎样终止的，机器处理存储-命中-加载的速度，以及如何快速且优雅地处理试探性执行的循环展开（比如是否由于内部冲突而多次循环）。但这意味着你需要非常细致的流水线跟踪器和模拟器才能弄明白。在纸上预测流水线里的乱序指令是无比困难的工作，就算是设计芯片的人也一样。对于门外汉来说，没门，抱歉！”\u003c/p\u003e\n\u003ch4\u003e\u003cspan class=\"ez-toc-section\" id=\"PS%E4%B8%AA%E4%BA%BA%E6%84%9F%E6%82%9F%E2%80%94%E2%80%94%E5%B1%80%E9%83%A8%E6%80%A7%E5%8E%9F%E7%90%86%E5%92%8C%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E5%8F%91\"\u003e\u003c/span\u003eP.S.个人感悟——局部性原理和流水线并发\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e程序的运行存在\u003cstrong\u003e时间和空间上的局部性\u003c/strong\u003e，前者是指只要内存中的值被换入缓存，今后一段时间内会被多次引用，后者是指该内存附近的值也被换入缓存。如果在编程中特别注意运用局部性原理，就会获得性能上的回报。\u003c/p\u003e\n\u003cp\u003e比如\u003cstrong\u003eC语言中应该尽量减少静态变量的引用，\u003c/strong\u003e这是因为静态变量存储在全局数据段，在一个被反复调用的函数体内，引用该变量需要对缓存多次换入换出，而如果是分配在堆栈上的局部变量，函数每次调用CPU只要从缓存中就能找到它了，因为堆栈的重复利用率高。\u003c/p\u003e\n\u003cp\u003e再比如\u003cstrong\u003e循环体内的代码要尽量精简，\u003c/strong\u003e因为代码是放在指令缓存里的，而指令缓存都是一级缓存，只有几K字节大小，如果对某段代码需要多次读取，而这段代码又跨越一个L1缓存大小，那么缓存优势将荡然无存。\u003c/p\u003e\n\u003cp\u003e关于\u003cstrong\u003eCPU的流水线(pipeline)并发性\u003c/strong\u003e简单说说，Intel Pentium处理器有两条流水线U和V，每条流水线可各自独立地读写缓存，所以可以在一个时钟周期内同时执行两条指令。但这两条流水线不是对等的，U流水线可以处理所有指令集，V流水线只能处理简单指令。\u003c/p\u003e\n\u003cp\u003eCPU指令通常被分为四类，第一类是常用的简单指令，像mov, nop, push, pop, add, sub, and, or, xor, inc, dec, cmp, lea，可以在任意一条流水线执行，只要相互之间不存在依赖性，完全可以做到指令并发。\u003c/p\u003e\n\u003cp\u003e第二类指令需要同别的流水线配合，像一些进位和移位操作，这类指令如果在U流水线中，那么别的指令可以在V流水线并发运行，如果在V流水线中，那么U流水线是暂停的。\u003c/p\u003e\n\u003cp\u003e第三类指令是一些跳转指令，如cmp,call以及条件分支，它们同第二类相反，当工作在V流水线时才能通U流水线协作，否则只能独占CPU。\u003c/p\u003e\n\u003cp\u003e第四类指令是其它复杂的指令，一般不常用，因为它们都只能独占CPU。\u003c/p\u003e\n\u003cp\u003e如果是汇编级别编程，\u003cstrong\u003e要达到指令级别并发，必须要注重指令之间的配对。\u003c/strong\u003e尽量使用第一类指令，避免第四类，还要在顺序上减少上下文依赖。\u003c/p\u003e\n\u003ch4\u003e\u003cspan class=\"ez-toc-section\" id=\"%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99\"\u003e\u003c/span\u003e参考资料\u003cspan class=\"ez-toc-section-end\"\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003ewiki上的CPU cache解析（\u003ca href=\"https://zh.wikipedia.org/zh-cn/CPU%E7%BC%93%E5%AD%98\" target=\"_blank\"\u003e中文版\u003c/a\u003e）（\u003ca href=\"https://en.wikipedia.org/wiki/CPU_cache\" target=\"_blank\"\u003e英文版\u003c/a\u003e）。\u003c/p\u003e\n\u003cp\u003e上海交通大学师生制作的一个关于\u003ca href=\"http://yoursunny.com/study/EI209/?topic=cache\" target=\"_blank\"\u003ecache映射功能、命中率计算\u003c/a\u003e的教学演示程序，模拟了不同关联模式下cache的映射和命中几率，形象直观。\u003c/p\u003e\n\u003cp\u003e网易数据库大牛\u003ca href=\"http://weibo.com/u/2216172320\" target=\"_blank\"\u003e@何_登成\u003c/a\u003e自制PPT\u003ca href=\"http://vdisk.weibo.com/s/dBzv2sibdUB8\" target=\"_blank\"\u003e《CPU Cache and Memory Ordering》\u003c/a\u003e，信息量超大！\u003c/p\u003e\n\u003cp\u003e南京大学计算机教学\u003ca href=\"http://cs.nju.edu.cn/swang/CompArchOrg_12F/slides/lecture09.pdf\" target=\"_blank\"\u003e公开PPT\u003c/a\u003e，温馨提示，地址域名里面改变字段”lecture”后面的数字编号可切换课程;-)\u003c/p\u003e\n\u003cp\u003e（全文完）\u003c/p\u003e\n\u003cdiv style=\"margin-top: 15px; font-size: 16px;color: #cc0000;\"\u003e\n\u003cp align=\"center\"\u003e\u003cstrong\u003e（转载本站文章请注明作者和出处 \u003ca href=\"https://coolshell.cn/\"\u003e酷 壳 – CoolShell\u003c/a\u003e ，请勿用于任何商业用途）\u003c/strong\u003e\u003c/p\u003e\n\u003c/div\u003e\n\u003cdiv class=\"wp_rp_wrap  wp_rp_vertical_m\" id=\"wp_rp_first\"\u003e\u003cdiv class=\"wp_rp_content\"\u003e\u003ch3 class=\"related_post_title\"\u003e相关文章\u003c/h3\u003e\u003cul class=\"related_post wp_rp\"\u003e\u003cli\u003e\u003ca href=\"https://coolshell.cn/articles/20793.html\" class=\"wp_rp_thumbnail\"\u003e\u003cimg src=\"https://coolshell.cn/wp-content/uploads/2020/03/cpu_512x512-150x150.png\" alt=\"与程序员相关的CPU缓存知识\" width=\"150\" height=\"150\"/\u003e\u003c/a\u003e\u003ca href=\"https://coolshell.cn/articles/20793.html\" class=\"wp_rp_title\"\u003e与程序员相关的CPU缓存知识\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://coolshell.cn/articles/17416.html\" class=\"wp_rp_thumbnail\"\u003e\u003cimg src=\"https://coolshell.cn/wp-content/uploads/2016/07/cache-150x150.png\" alt=\"缓存更新的套路\" width=\"150\" height=\"150\"/\u003e\u003c/a\u003e\u003ca href=\"https://coolshell.cn/articles/17416.html\" class=\"wp_rp_title\"\u003e缓存更新的套路\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://coolshell.cn/articles/9703.html\" class=\"wp_rp_thumbnail\"\u003e\u003cimg src=\"https://coolshell.cn/wp-content/uploads/2013/05/图1-3-150x150.jpg\" alt=\"无锁HashMap的原理与实现\" width=\"150\" height=\"150\"/\u003e\u003c/a\u003e\u003ca href=\"https://coolshell.cn/articles/9703.html\" class=\"wp_rp_title\"\u003e无锁HashMap的原理与实现\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://coolshell.cn/articles/9606.html\" class=\"wp_rp_thumbnail\"\u003e\u003cimg src=\"https://coolshell.cn/wp-content/uploads/2013/05/race_condition-150x150.jpg\" alt=\"疫苗：Java HashMap的死循环\" width=\"150\" height=\"150\"/\u003e\u003c/a\u003e\u003ca href=\"https://coolshell.cn/articles/9606.html\" class=\"wp_rp_title\"\u003e疫苗：Java HashMap的死循环\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://coolshell.cn/articles/2039.html\" class=\"wp_rp_thumbnail\"\u003e\u003cimg src=\"https://coolshell.cn/wp-content/plugins/wordpress-23-related-posts-plugin/static/thumbs/10.jpg\" alt=\"CPU的性价比\" width=\"150\" height=\"150\"/\u003e\u003c/a\u003e\u003ca href=\"https://coolshell.cn/articles/2039.html\" class=\"wp_rp_title\"\u003eCPU的性价比\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://coolshell.cn/articles/11432.html\" class=\"wp_rp_thumbnail\"\u003e\u003cimg src=\"https://coolshell.cn/wp-content/uploads/2014/04/code_review-150x150.jpg\" alt=\"从Code Review 谈如何做技术\" width=\"150\" height=\"150\"/\u003e\u003c/a\u003e\u003ca href=\"https://coolshell.cn/articles/11432.html\" class=\"wp_rp_title\"\u003e从Code Review 谈如何做技术\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003c/div\u003e\n\u003cdiv id=\"post-ratings-10249\" class=\"post-ratings\" itemscope=\"\" itemtype=\"https://schema.org/Article\" data-nonce=\"9a296af3a0\"\u003e\u003cimg id=\"rating_10249_1\" src=\"https://coolshell.cn/wp-content/plugins/wp-postratings/images/stars_crystal/rating_on.gif\" alt=\"好烂啊\" title=\"好烂啊\" onmouseover=\"if (!window.__cfRLUnblockHandlers) return false; current_rating(10249, 1, \u0026#39;好烂啊\u0026#39;);\" onmouseout=\"if (!window.__cfRLUnblockHandlers) return false; ratings_off(4, 0, 0);\" onclick=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" onkeypress=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" style=\"cursor: pointer; border: 0px;\" data-cf-modified-37e99e6d60d35d2fdc1a43d3-=\"\"/\u003e\u003cimg id=\"rating_10249_2\" src=\"https://coolshell.cn/wp-content/plugins/wp-postratings/images/stars_crystal/rating_on.gif\" alt=\"有点差\" title=\"有点差\" onmouseover=\"if (!window.__cfRLUnblockHandlers) return false; current_rating(10249, 2, \u0026#39;有点差\u0026#39;);\" onmouseout=\"if (!window.__cfRLUnblockHandlers) return false; ratings_off(4, 0, 0);\" onclick=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" onkeypress=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" style=\"cursor: pointer; border: 0px;\" data-cf-modified-37e99e6d60d35d2fdc1a43d3-=\"\"/\u003e\u003cimg id=\"rating_10249_3\" src=\"https://coolshell.cn/wp-content/plugins/wp-postratings/images/stars_crystal/rating_on.gif\" alt=\"凑合看看\" title=\"凑合看看\" onmouseover=\"if (!window.__cfRLUnblockHandlers) return false; current_rating(10249, 3, \u0026#39;凑合看看\u0026#39;);\" onmouseout=\"if (!window.__cfRLUnblockHandlers) return false; ratings_off(4, 0, 0);\" onclick=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" onkeypress=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" style=\"cursor: pointer; border: 0px;\" data-cf-modified-37e99e6d60d35d2fdc1a43d3-=\"\"/\u003e\u003cimg id=\"rating_10249_4\" src=\"https://coolshell.cn/wp-content/plugins/wp-postratings/images/stars_crystal/rating_on.gif\" alt=\"还不错\" title=\"还不错\" onmouseover=\"if (!window.__cfRLUnblockHandlers) return false; current_rating(10249, 4, \u0026#39;还不错\u0026#39;);\" onmouseout=\"if (!window.__cfRLUnblockHandlers) return false; ratings_off(4, 0, 0);\" onclick=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" onkeypress=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" style=\"cursor: pointer; border: 0px;\" data-cf-modified-37e99e6d60d35d2fdc1a43d3-=\"\"/\u003e\u003cimg id=\"rating_10249_5\" src=\"https://coolshell.cn/wp-content/plugins/wp-postratings/images/stars_crystal/rating_off.gif\" alt=\"很精彩\" title=\"很精彩\" onmouseover=\"if (!window.__cfRLUnblockHandlers) return false; current_rating(10249, 5, \u0026#39;很精彩\u0026#39;);\" onmouseout=\"if (!window.__cfRLUnblockHandlers) return false; ratings_off(4, 0, 0);\" onclick=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" onkeypress=\"if (!window.__cfRLUnblockHandlers) return false; rate_post();\" style=\"cursor: pointer; border: 0px;\" data-cf-modified-37e99e6d60d35d2fdc1a43d3-=\"\"/\u003e (\u003cstrong\u003e55\u003c/strong\u003e 人打了分，平均分： \u003cstrong\u003e4.00\u003c/strong\u003e )\u003cbr/\u003e\u003cspan class=\"post-ratings-text\" id=\"ratings_10249_text\"\u003e\u003c/span\u003e\u003cmeta itemprop=\"name\" content=\"7个示例科普CPU Cache\"/\u003e\u003cmeta itemprop=\"headline\" content=\"7个示例科普CPU Cache\"/\u003e\u003cmeta itemprop=\"description\" content=\"（感谢网友 @我的上铺叫路遥 翻译投稿）\n\nCPU cache一直是理解计算机体系架构的重要知识点，也是并发编程设计中的技术难点，而且相关参考资料如同过江之鲫，浩瀚繁星，阅之如临深渊，味同嚼蜡，三言两语难以入门。正好网上有人推荐了微软大牛Igor Ostrovsky一篇博文《漫游处理器缓存效应》，文章不仅仅用7个最简单的源码示例就将CPU cache的原理娓娓道来，还附加图表量化分析做数学上的...\"/\u003e\u003cmeta itemprop=\"datePublished\" content=\"2013-07-30T09:05:38+08:00\"/\u003e\u003cmeta itemprop=\"dateModified\" content=\"2013-07-30T09:49:49+08:00\"/\u003e\u003cmeta itemprop=\"url\" content=\"https://coolshell.cn/articles/10249.html\"/\u003e\u003cmeta itemprop=\"author\" content=\"Leo\"/\u003e\u003cmeta itemprop=\"mainEntityOfPage\" content=\"https://coolshell.cn/articles/10249.html\"/\u003e\u003cdiv style=\"display: none;\" itemprop=\"publisher\" itemscope=\"\" itemtype=\"https://schema.org/Organization\"\u003e\u003cmeta itemprop=\"name\" content=\"酷 壳 - CoolShell\"/\u003e\u003cmeta itemprop=\"url\" content=\"https://coolshell.cn\"/\u003e\u003cdiv itemprop=\"logo\" itemscope=\"\" itemtype=\"https://schema.org/ImageObject\"\u003e\u003cmeta itemprop=\"url\" content=\"\"/\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv style=\"display: none;\" itemprop=\"aggregateRating\" itemscope=\"\" itemtype=\"https://schema.org/AggregateRating\"\u003e\u003cmeta itemprop=\"bestRating\" content=\"5\"/\u003e\u003cmeta itemprop=\"worstRating\" content=\"1\"/\u003e\u003cmeta itemprop=\"ratingValue\" content=\"4\"/\u003e\u003cmeta itemprop=\"ratingCount\" content=\"55\"/\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv id=\"post-ratings-10249-loading\" class=\"post-ratings-loading\"\u003e\u003cimg src=\"https://coolshell.cn/wp-content/plugins/wp-postratings/images/loading.gif\" width=\"16\" height=\"16\" class=\"post-ratings-image\"/\u003eLoading...\u003c/div\u003e\n\u003c/div\u003e",
  "Date": "2013-07-30T09:05:38+08:00",
  "Author": "Leo"
}