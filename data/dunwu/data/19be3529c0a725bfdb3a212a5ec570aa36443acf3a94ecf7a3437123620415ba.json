{
  "Source": "dunwu",
  "Title": "Hive 入门",
  "Link": "https://dunwu.github.io/blog/pages/e1b37c/",
  "Content": "\u003cdiv class=\"post-body\" itemprop=\"articleBody\"\u003e\u003ch1 id=\"Hive-入门\"\u003e\u003ca href=\"#Hive-入门\" class=\"headerlink\" title=\"Hive 入门\"\u003e\u003c/a\u003eHive 入门\u003c/h1\u003e\u003ch2 id=\"简介\"\u003e\u003ca href=\"#简介\" class=\"headerlink\" title=\"简介\"\u003e\u003c/a\u003e简介\u003c/h2\u003e\u003cp\u003eHive 是一个构建在 Hadoop 之上的数据仓库，它可以将结构化的数据文件映射成表，并提供类 SQL 查询功能，用于查询的 SQL 语句会被转化为 MapReduce 作业，然后提交到 Hadoop 上运行。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e特点\u003c/strong\u003e：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e简单、容易上手 (提供了类似 sql 的查询语言 hql)，使得精通 sql 但是不了解 Java 编程的人也能很好地进行大数据分析；\u003c/li\u003e\n\u003cli\u003e灵活性高，可以自定义用户函数 (UDF) 和存储格式；\u003c/li\u003e\n\u003cli\u003e为超大的数据集设计的计算和存储能力，集群扩展容易;\u003c/li\u003e\n\u003cli\u003e统一的元数据管理，可与 presto／impala／sparksql 等共享数据；\u003c/li\u003e\n\u003cli\u003e执行延迟高，不适合做数据的实时处理，但适合做海量数据的离线处理。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"Hive-的体系架构\"\u003e\u003ca href=\"#Hive-的体系架构\" class=\"headerlink\" title=\"Hive 的体系架构\"\u003e\u003c/a\u003eHive 的体系架构\u003c/h2\u003e\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/dunwu/images/master/snap/20200224193019.png\" alt=\"img\"/\u003e\u003c/p\u003e\n\u003ch3 id=\"command-line-shell-thrift-jdbc\"\u003e\u003ca href=\"#command-line-shell-thrift-jdbc\" class=\"headerlink\" title=\"command-line shell \u0026amp; thrift/jdbc\"\u003e\u003c/a\u003ecommand-line shell \u0026amp; thrift/jdbc\u003c/h3\u003e\u003cp\u003e可以用 command-line shell 和 thrift／jdbc 两种方式来操作数据：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ecommand-line shell\u003c/strong\u003e：通过 hive 命令行的的方式来操作数据；\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ethrift／jdbc\u003c/strong\u003e：通过 thrift 协议按照标准的 JDBC 的方式操作数据。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"Metastore\"\u003e\u003ca href=\"#Metastore\" class=\"headerlink\" title=\"Metastore\"\u003e\u003c/a\u003eMetastore\u003c/h3\u003e\u003cp\u003e在 Hive 中，表名、表结构、字段名、字段类型、表的分隔符等统一被称为元数据。所有的元数据默认存储在 Hive 内置的 derby 数据库中，但由于 derby 只能有一个实例，也就是说不能有多个命令行客户端同时访问，所以在实际生产环境中，通常使用 MySQL 代替 derby。\u003c/p\u003e\n\u003cp\u003eHive 进行的是统一的元数据管理，就是说你在 Hive 上创建了一张表，然后在 presto／impala／sparksql 中都是可以直接使用的，它们会从 Metastore 中获取统一的元数据信息，同样的你在 presto／impala／sparksql 中创建一张表，在 Hive 中也可以直接使用。\u003c/p\u003e\n\u003ch3 id=\"HQL-的执行流程\"\u003e\u003ca href=\"#HQL-的执行流程\" class=\"headerlink\" title=\"HQL 的执行流程\"\u003e\u003c/a\u003eHQL 的执行流程\u003c/h3\u003e\u003cp\u003eHive 在执行一条 HQL 的时候，会经过以下步骤：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e语法解析：Antlr 定义 SQL 的语法规则，完成 SQL 词法，语法解析，将 SQL 转化为抽象 语法树 AST Tree；\u003c/li\u003e\n\u003cli\u003e语义解析：遍历 AST Tree，抽象出查询的基本组成单元 QueryBlock；\u003c/li\u003e\n\u003cli\u003e生成逻辑执行计划：遍历 QueryBlock，翻译为执行操作树 OperatorTree；\u003c/li\u003e\n\u003cli\u003e优化逻辑执行计划：逻辑层优化器进行 OperatorTree 变换，合并不必要的 ReduceSinkOperator，减少 shuffle 数据量；\u003c/li\u003e\n\u003cli\u003e生成物理执行计划：遍历 OperatorTree，翻译为 MapReduce 任务；\u003c/li\u003e\n\u003cli\u003e优化物理执行计划：物理层优化器进行 MapReduce 任务的变换，生成最终的执行计划。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cblockquote\u003e\n\u003cp\u003e关于 Hive SQL 的详细执行流程可以参考美团技术团队的文章：\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html\"\u003eHive SQL 的编译过程\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"数据类型\"\u003e\u003ca href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"\u003e\u003c/a\u003e数据类型\u003c/h2\u003e\u003ch3 id=\"基本数据类型\"\u003e\u003ca href=\"#基本数据类型\" class=\"headerlink\" title=\"基本数据类型\"\u003e\u003c/a\u003e基本数据类型\u003c/h3\u003e\u003cp\u003eHive 表中的列支持以下基本数据类型：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e大类\u003c/th\u003e\n\u003cth\u003e类型\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eIntegers（整型）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eTINYINT—1 字节的有符号整数 \u003cbr/\u003eSMALLINT—2 字节的有符号整数\u003cbr/\u003e INT—4 字节的有符号整数\u003cbr/\u003e BIGINT—8 字节的有符号整数\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eBoolean（布尔型）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eBOOLEAN—TRUE/FALSE\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eFloating point numbers（浮点型）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eFLOAT— 单精度浮点型 \u003cbr/\u003eDOUBLE—双精度浮点型\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eFixed point numbers（定点数）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eDECIMAL—用户自定义精度定点数，比如 DECIMAL(7,2)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eString types（字符串）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eSTRING—指定字符集的字符序列\u003cbr/\u003e VARCHAR—具有最大长度限制的字符序列 \u003cbr/\u003eCHAR—固定长度的字符序列\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eDate and time types（日期时间类型）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eTIMESTAMP — 时间戳 \u003cbr/\u003eTIMESTAMP WITH LOCAL TIME ZONE — 时间戳，纳秒精度\u003cbr/\u003e DATE—日期类型\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eBinary types（二进制类型）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eBINARY—字节序列\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cblockquote\u003e\n\u003cp\u003eTIMESTAMP 和 TIMESTAMP WITH LOCAL TIME ZONE 的区别如下：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eTIMESTAMP WITH LOCAL TIME ZONE\u003c/strong\u003e：用户提交时间给数据库时，会被转换成数据库所在的时区来保存。查询时则按照查询客户端的不同，转换为查询客户端所在时区的时间。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTIMESTAMP\u003c/strong\u003e ：提交什么时间就保存什么时间，查询时也不做任何转换。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"隐式转换\"\u003e\u003ca href=\"#隐式转换\" class=\"headerlink\" title=\"隐式转换\"\u003e\u003c/a\u003e隐式转换\u003c/h3\u003e\u003cp\u003eHive 中基本数据类型遵循以下的层次结构，按照这个层次结构，子类型到祖先类型允许隐式转换。例如 INT 类型的数据允许隐式转换为 BIGINT 类型。额外注意的是：按照类型层次结构允许将 STRING 类型隐式转换为 DOUBLE 类型。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/dunwu/images/master/snap/20200224193613.png\" alt=\"img\"/\u003e\u003c/p\u003e\n\u003ch3 id=\"复杂类型\"\u003e\u003ca href=\"#复杂类型\" class=\"headerlink\" title=\"复杂类型\"\u003e\u003c/a\u003e复杂类型\u003c/h3\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e类型\u003c/th\u003e\n\u003cth\u003e描述\u003c/th\u003e\n\u003cth\u003e示例\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eSTRUCT\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e类似于对象，是字段的集合，字段的类型可以不同，可以使用 \u003ccode\u003e名称.字段名\u003c/code\u003e 方式进行访问\u003c/td\u003e\n\u003ctd\u003eSTRUCT (‘xiaoming’, 12 , ‘2018-12-12’)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eMAP\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e键值对的集合，可以使用 \u003ccode\u003e名称[key]\u003c/code\u003e 的方式访问对应的值\u003c/td\u003e\n\u003ctd\u003emap(‘a’, 1, ‘b’, 2)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eARRAY\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e数组是一组具有相同类型和名称的变量的集合，可以使用 \u003ccode\u003e名称[index]\u003c/code\u003e 访问对应的值\u003c/td\u003e\n\u003ctd\u003eARRAY(‘a’, ‘b’, ‘c’, ‘d’)\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3 id=\"示例\"\u003e\u003ca href=\"#示例\" class=\"headerlink\" title=\"示例\"\u003e\u003c/a\u003e示例\u003c/h3\u003e\u003cp\u003e如下给出一个基本数据类型和复杂数据类型的使用示例：\u003c/p\u003e\n\u003cfigure class=\"highlight sql\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e4\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e5\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e6\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e7\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"keyword\"\u003eCREATE\u003c/span\u003e \u003cspan class=\"keyword\"\u003eTABLE\u003c/span\u003e students(\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  name      STRING,   \u003cspan class=\"comment\"\u003e-- 姓名\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  age       \u003cspan class=\"type\"\u003eINT\u003c/span\u003e,      \u003cspan class=\"comment\"\u003e-- 年龄\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  subject   \u003cspan class=\"keyword\"\u003eARRAY\u003c/span\u003e\u003cspan class=\"operator\"\u003e\u0026lt;\u003c/span\u003eSTRING\u003cspan class=\"operator\"\u003e\u0026gt;\u003c/span\u003e,   \u003cspan class=\"comment\"\u003e--学科\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  score     MAP\u003cspan class=\"operator\"\u003e\u0026lt;\u003c/span\u003eSTRING,\u003cspan class=\"type\"\u003eFLOAT\u003c/span\u003e\u003cspan class=\"operator\"\u003e\u0026gt;\u003c/span\u003e,  \u003cspan class=\"comment\"\u003e--各个学科考试成绩\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  address   STRUCT\u003cspan class=\"operator\"\u003e\u0026lt;\u003c/span\u003ehouseNumber:\u003cspan class=\"type\"\u003eint\u003c/span\u003e, street:STRING, city:STRING, province：STRING\u003cspan class=\"operator\"\u003e\u0026gt;\u003c/span\u003e  \u003cspan class=\"comment\"\u003e--家庭居住地址\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e) \u003cspan class=\"type\"\u003eROW\u003c/span\u003e FORMAT DELIMITED FIELDS TERMINATED \u003cspan class=\"keyword\"\u003eBY\u003c/span\u003e \u0026#34;\\t\u0026#34;;\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\u003ch2 id=\"内容格式\"\u003e\u003ca href=\"#内容格式\" class=\"headerlink\" title=\"内容格式\"\u003e\u003c/a\u003e内容格式\u003c/h2\u003e\u003cp\u003e当数据存储在文本文件中，必须按照一定格式区别行和列，如使用逗号作为分隔符的 CSV 文件 (Comma-Separated Values) 或者使用制表符作为分隔值的 TSV 文件 (Tab-Separated Values)。但此时也存在一个缺点，就是正常的文件内容中也可能出现逗号或者制表符。\u003c/p\u003e\n\u003cp\u003e所以 Hive 默认使用了几个平时很少出现的字符，这些字符一般不会作为内容出现在文件中。Hive 默认的行和列分隔符如下表所示。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e分隔符\u003c/th\u003e\n\u003cth\u003e描述\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e\\n\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e对于文本文件来说，每行是一条记录，所以可以使用换行符来分割记录\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e^A (Ctrl+A)\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e分割字段 (列)，在 CREATE TABLE 语句中也可以使用八进制编码 \u003ccode\u003e\\001\u003c/code\u003e 来表示\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e^B\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e用于分割 ARRAY 或者 STRUCT 中的元素，或者用于 MAP 中键值对之间的分割，\u003cbr/\u003e在 CREATE TABLE 语句中也可以使用八进制编码 \u003ccode\u003e\\002\u003c/code\u003e 表示\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e^C\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e用于 MAP 中键和值之间的分割，在 CREATE TABLE 语句中也可以使用八进制编码 \u003ccode\u003e\\003\u003c/code\u003e 表示\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e使用示例如下：\u003c/p\u003e\n\u003cfigure class=\"highlight sql\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e4\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e5\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e6\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"keyword\"\u003eCREATE\u003c/span\u003e \u003cspan class=\"keyword\"\u003eTABLE\u003c/span\u003e page_view(viewTime \u003cspan class=\"type\"\u003eINT\u003c/span\u003e, userid \u003cspan class=\"type\"\u003eBIGINT\u003c/span\u003e)\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e \u003cspan class=\"type\"\u003eROW\u003c/span\u003e FORMAT DELIMITED\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   FIELDS TERMINATED \u003cspan class=\"keyword\"\u003eBY\u003c/span\u003e \u003cspan class=\"string\"\u003e\u0026#39;\\001\u0026#39;\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   COLLECTION ITEMS TERMINATED \u003cspan class=\"keyword\"\u003eBY\u003c/span\u003e \u003cspan class=\"string\"\u003e\u0026#39;\\002\u0026#39;\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   MAP KEYS TERMINATED \u003cspan class=\"keyword\"\u003eBY\u003c/span\u003e \u003cspan class=\"string\"\u003e\u0026#39;\\003\u0026#39;\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e STORED \u003cspan class=\"keyword\"\u003eAS\u003c/span\u003e SEQUENCEFILE;\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\u003ch2 id=\"存储格式\"\u003e\u003ca href=\"#存储格式\" class=\"headerlink\" title=\"存储格式\"\u003e\u003c/a\u003e存储格式\u003c/h2\u003e\u003ch3 id=\"支持的存储格式\"\u003e\u003ca href=\"#支持的存储格式\" class=\"headerlink\" title=\"支持的存储格式\"\u003e\u003c/a\u003e支持的存储格式\u003c/h3\u003e\u003cp\u003eHive 会在 HDFS 为每个数据库上创建一个目录，数据库中的表是该目录的子目录，表中的数据会以文件的形式存储在对应的表目录下。Hive 支持以下几种文件存储格式：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e格式\u003c/th\u003e\n\u003cth\u003e说明\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eTextFile\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e存储为纯文本文件。 这是 Hive 默认的文件存储格式。这种存储方式数据不做压缩，磁盘开销大，数据解析开销大。\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eSequenceFile\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eSequenceFile 是 Hadoop API 提供的一种二进制文件，它将数据以\u0026lt;key,value\u0026gt;的形式序列化到文件中。这种二进制文件内部使用 Hadoop 的标准的 Writable 接口实现序列化和反序列化。它与 Hadoop API 中的 MapFile 是互相兼容的。Hive 中的 SequenceFile 继承自 Hadoop API 的 SequenceFile，不过它的 key 为空，使用 value 存放实际的值，这样是为了避免 MR 在运行 map 阶段进行额外的排序操作。\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eRCFile\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eRCFile 文件格式是 FaceBook 开源的一种 Hive 的文件存储格式，首先将表分为几个行组，对每个行组内的数据按列存储，每一列的数据都是分开存储。\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eORC Files\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eORC 是在一定程度上扩展了 RCFile，是对 RCFile 的优化。\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eAvro Files\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eAvro 是一个数据序列化系统，设计用于支持大批量数据交换的应用。它的主要特点有：支持二进制序列化方式，可以便捷，快速地处理大量数据；动态语言友好，Avro 提供的机制使动态语言可以方便地处理 Avro 数据。\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eParquet\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eParquet 是基于 Dremel 的数据模型和算法实现的，面向分析型业务的列式存储格式。它通过按列进行高效压缩和特殊的编码技术，从而在降低存储空间的同时提高了 IO 效率。\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cblockquote\u003e\n\u003cp\u003e以上压缩格式中 ORC 和 Parquet 的综合性能突出，使用较为广泛，推荐使用这两种格式。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"指定存储格式\"\u003e\u003ca href=\"#指定存储格式\" class=\"headerlink\" title=\"指定存储格式\"\u003e\u003c/a\u003e指定存储格式\u003c/h3\u003e\u003cp\u003e通常在创建表的时候使用 \u003ccode\u003eSTORED AS\u003c/code\u003e 参数指定：\u003c/p\u003e\n\u003cfigure class=\"highlight sql\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e4\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e5\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e6\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"keyword\"\u003eCREATE\u003c/span\u003e \u003cspan class=\"keyword\"\u003eTABLE\u003c/span\u003e page_view(viewTime \u003cspan class=\"type\"\u003eINT\u003c/span\u003e, userid \u003cspan class=\"type\"\u003eBIGINT\u003c/span\u003e)\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e \u003cspan class=\"type\"\u003eROW\u003c/span\u003e FORMAT DELIMITED\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   FIELDS TERMINATED \u003cspan class=\"keyword\"\u003eBY\u003c/span\u003e \u003cspan class=\"string\"\u003e\u0026#39;\\001\u0026#39;\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   COLLECTION ITEMS TERMINATED \u003cspan class=\"keyword\"\u003eBY\u003c/span\u003e \u003cspan class=\"string\"\u003e\u0026#39;\\002\u0026#39;\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   MAP KEYS TERMINATED \u003cspan class=\"keyword\"\u003eBY\u003c/span\u003e \u003cspan class=\"string\"\u003e\u0026#39;\\003\u0026#39;\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e STORED \u003cspan class=\"keyword\"\u003eAS\u003c/span\u003e SEQUENCEFILE;\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\u003cp\u003e各个存储文件类型指定方式如下：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSTORED AS TEXTFILE\u003c/li\u003e\n\u003cli\u003eSTORED AS SEQUENCEFILE\u003c/li\u003e\n\u003cli\u003eSTORED AS ORC\u003c/li\u003e\n\u003cli\u003eSTORED AS PARQUET\u003c/li\u003e\n\u003cli\u003eSTORED AS AVRO\u003c/li\u003e\n\u003cli\u003eSTORED AS RCFILE\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"内部表和外部表\"\u003e\u003ca href=\"#内部表和外部表\" class=\"headerlink\" title=\"内部表和外部表\"\u003e\u003c/a\u003e内部表和外部表\u003c/h2\u003e\u003cp\u003e内部表又叫做管理表 (Managed/Internal Table)，创建表时不做任何指定，默认创建的就是内部表。想要创建外部表 (External Table)，则需要使用 External 进行修饰。 内部表和外部表主要区别如下：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003e内部表\u003c/th\u003e\n\u003cth\u003e外部表\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e数据存储位置\u003c/td\u003e\n\u003ctd\u003e内部表数据存储的位置由 hive.metastore.warehouse.dir 参数指定，默认情况下表的数据存储在 HDFS 的 \u003ccode\u003e/user/hive/warehouse/数据库名.db/表名/\u003c/code\u003e 目录下\u003c/td\u003e\n\u003ctd\u003e外部表数据的存储位置创建表时由 \u003ccode\u003eLocation\u003c/code\u003e 参数指定；\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e导入数据\u003c/td\u003e\n\u003ctd\u003e在导入数据到内部表，内部表将数据移动到自己的数据仓库目录下，数据的生命周期由 Hive 来进行管理\u003c/td\u003e\n\u003ctd\u003e外部表不会将数据移动到自己的数据仓库目录下，只是在元数据中存储了数据的位置\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e删除表\u003c/td\u003e\n\u003ctd\u003e删除元数据（metadata）和文件\u003c/td\u003e\n\u003ctd\u003e只删除元数据（metadata）\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch2 id=\"参考资料\"\u003e\u003ca href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"\u003e\u003c/a\u003e参考资料\u003c/h2\u003e\u003cul\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://cwiki.apache.org/confluence/display/Hive/GettingStarted\"\u003eHive Getting Started\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html\"\u003eHive SQL 的编译过程\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL\"\u003eLanguageManual DDL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types\"\u003eLanguageManual Types\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://cwiki.apache.org/confluence/display/Hive/Managed+vs.+External+Tables\"\u003eManaged vs. External Tables\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n    \u003c/div\u003e",
  "Date": "2020-02-24T13:14:47Z",
  "Author": "钝悟 ◾ Dunwu"
}