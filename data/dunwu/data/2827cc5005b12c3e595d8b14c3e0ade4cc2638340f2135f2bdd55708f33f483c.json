{
  "Source": "dunwu",
  "Title": "Hive 分区表和分桶表",
  "Link": "https://dunwu.github.io/blog/pages/18eb58/",
  "Content": "\u003cdiv class=\"post-body\" itemprop=\"articleBody\"\u003e\u003ch1 id=\"Hive-分区表和分桶表\"\u003e\u003ca href=\"#Hive-分区表和分桶表\" class=\"headerlink\" title=\"Hive 分区表和分桶表\"\u003e\u003c/a\u003eHive 分区表和分桶表\u003c/h1\u003e\u003ch2 id=\"分区表\"\u003e\u003ca href=\"#分区表\" class=\"headerlink\" title=\"分区表\"\u003e\u003c/a\u003e分区表\u003c/h2\u003e\u003ch3 id=\"概念\"\u003e\u003ca href=\"#概念\" class=\"headerlink\" title=\"概念\"\u003e\u003c/a\u003e概念\u003c/h3\u003e\u003cp\u003eHive 中的表对应为 HDFS 上的指定目录，在查询数据时候，默认会对全表进行扫描，这样时间和性能的消耗都非常大。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e分区为 HDFS 上表目录的子目录\u003c/strong\u003e，数据按照分区存储在子目录中。如果查询的 \u003ccode\u003ewhere\u003c/code\u003e 子句中包含分区条件，则直接从该分区去查找，而不是扫描整个表目录，合理的分区设计可以极大提高查询速度和性能。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e这里说明一下分区表并非 Hive 独有的概念，实际上这个概念非常常见。比如在我们常用的 Oracle 数据库中，当表中的数据量不断增大，查询数据的速度就会下降，这时也可以对表进行分区。表进行分区后，逻辑上表仍然是一张完整的表，只是将表中的数据存放到多个表空间（物理文件上），这样查询数据时，就不必要每次都扫描整张表，从而提升查询性能。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"使用场景\"\u003e\u003ca href=\"#使用场景\" class=\"headerlink\" title=\"使用场景\"\u003e\u003c/a\u003e使用场景\u003c/h3\u003e\u003cp\u003e通常，在管理大规模数据集的时候都需要进行分区，比如将日志文件按天进行分区，从而保证数据细粒度的划分，使得查询性能得到提升。\u003c/p\u003e\n\u003ch3 id=\"创建分区表\"\u003e\u003ca href=\"#创建分区表\" class=\"headerlink\" title=\"创建分区表\"\u003e\u003c/a\u003e创建分区表\u003c/h3\u003e\u003cp\u003e在 Hive 中可以使用 \u003ccode\u003ePARTITIONED BY\u003c/code\u003e 子句创建分区表。表可以包含一个或多个分区列，程序会为分区列中的每个不同值组合创建单独的数据目录。下面的我们创建一张雇员表作为测试：\u003c/p\u003e\n\u003cfigure class=\"highlight sql\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e4\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e5\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e6\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e7\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e8\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e9\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e10\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e11\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e12\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"keyword\"\u003eCREATE\u003c/span\u003e \u003cspan class=\"keyword\"\u003eEXTERNAL\u003c/span\u003e \u003cspan class=\"keyword\"\u003eTABLE\u003c/span\u003e emp_partition(\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   empno \u003cspan class=\"type\"\u003eINT\u003c/span\u003e,\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   ename STRING,\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   job STRING,\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   mgr \u003cspan class=\"type\"\u003eINT\u003c/span\u003e,\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   hiredate \u003cspan class=\"type\"\u003eTIMESTAMP\u003c/span\u003e,\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   sal \u003cspan class=\"type\"\u003eDECIMAL\u003c/span\u003e(\u003cspan class=\"number\"\u003e7\u003c/span\u003e,\u003cspan class=\"number\"\u003e2\u003c/span\u003e),\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   comm \u003cspan class=\"type\"\u003eDECIMAL\u003c/span\u003e(\u003cspan class=\"number\"\u003e7\u003c/span\u003e,\u003cspan class=\"number\"\u003e2\u003c/span\u003e)\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   )\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   PARTITIONED \u003cspan class=\"keyword\"\u003eBY\u003c/span\u003e (deptno \u003cspan class=\"type\"\u003eINT\u003c/span\u003e)   \u003cspan class=\"comment\"\u003e-- 按照部门编号进行分区\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   \u003cspan class=\"type\"\u003eROW\u003c/span\u003e FORMAT DELIMITED FIELDS TERMINATED \u003cspan class=\"keyword\"\u003eBY\u003c/span\u003e \u0026#34;\\t\u0026#34;\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   LOCATION \u003cspan class=\"string\"\u003e\u0026#39;/hive/emp_partition\u0026#39;\u003c/span\u003e;\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\u003ch3 id=\"加载数据到分区表\"\u003e\u003ca href=\"#加载数据到分区表\" class=\"headerlink\" title=\"加载数据到分区表\"\u003e\u003c/a\u003e加载数据到分区表\u003c/h3\u003e\u003cp\u003e加载数据到分区表时候必须要指定数据所处的分区：\u003c/p\u003e\n\u003cfigure class=\"highlight shell\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e4\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"meta prompt_\"\u003e# \u003c/span\u003e\u003cspan class=\"language-bash\"\u003e加载部门编号为20的数据到表中\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003eLOAD DATA LOCAL INPATH \u0026#34;/usr/file/emp20.txt\u0026#34; OVERWRITE INTO TABLE emp_partition PARTITION (deptno=20)\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"meta prompt_\"\u003e# \u003c/span\u003e\u003cspan class=\"language-bash\"\u003e加载部门编号为30的数据到表中\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003eLOAD DATA LOCAL INPATH \u0026#34;/usr/file/emp30.txt\u0026#34; OVERWRITE INTO TABLE emp_partition PARTITION (deptno=30)\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\u003ch3 id=\"查看分区目录\"\u003e\u003ca href=\"#查看分区目录\" class=\"headerlink\" title=\"查看分区目录\"\u003e\u003c/a\u003e查看分区目录\u003c/h3\u003e\u003cp\u003e这时候我们直接查看表目录，可以看到表目录下存在两个子目录，分别是 \u003ccode\u003edeptno=20\u003c/code\u003e 和 \u003ccode\u003edeptno=30\u003c/code\u003e,这就是分区目录，分区目录下才是我们加载的数据文件。\u003c/p\u003e\n\u003cfigure class=\"highlight shell\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"meta prompt_\"\u003e# \u003c/span\u003e\u003cspan class=\"language-bash\"\u003ehadoop fs -\u003cspan class=\"built_in\"\u003els\u003c/span\u003e  hdfs://hadoop001:8020/hive/emp_partition/\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\u003cp\u003e这时候当你的查询语句的 \u003ccode\u003ewhere\u003c/code\u003e 包含 \u003ccode\u003edeptno=20\u003c/code\u003e，则就去对应的分区目录下进行查找，而不用扫描全表。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://github.com/heibaiying/BigData-Notes/raw/master/pictures/hive-hadoop-partitation.png\" alt=\"img\"/\u003e\u003c/p\u003e\n\u003ch2 id=\"分桶表\"\u003e\u003ca href=\"#分桶表\" class=\"headerlink\" title=\"分桶表\"\u003e\u003c/a\u003e分桶表\u003c/h2\u003e\u003ch3 id=\"简介\"\u003e\u003ca href=\"#简介\" class=\"headerlink\" title=\"简介\"\u003e\u003c/a\u003e简介\u003c/h3\u003e\u003cp\u003e分区提供了一个隔离数据和优化查询的可行方案，但是并非所有的数据集都可以形成合理的分区，分区的数量也不是越多越好，过多的分区条件可能会导致很多分区上没有数据。同时 Hive 会限制动态分区可以创建的最大分区数，用来避免过多分区文件对文件系统产生负担。鉴于以上原因，Hive 还提供了一种更加细粒度的数据拆分方案：分桶表 (bucket Table)。\u003c/p\u003e\n\u003cp\u003e分桶表会将指定列的值进行哈希散列，并对 bucket（桶数量）取余，然后存储到对应的 bucket（桶）中。\u003c/p\u003e\n\u003ch3 id=\"理解分桶表\"\u003e\u003ca href=\"#理解分桶表\" class=\"headerlink\" title=\"理解分桶表\"\u003e\u003c/a\u003e理解分桶表\u003c/h3\u003e\u003cp\u003e单从概念上理解分桶表可能会比较晦涩，其实和分区一样，分桶这个概念同样不是 Hive 独有的，对于 Java 开发人员而言，这可能是一个每天都会用到的概念，因为 Hive 中的分桶概念和 Java 数据结构中的 HashMap 的分桶概念是一致的。\u003c/p\u003e\n\u003cp\u003e当调用 HashMap 的 put() 方法存储数据时，程序会先对 key 值调用 hashCode() 方法计算出 hashcode，然后对数组长度取模计算出 index，最后将数据存储在数组 index 位置的链表上，链表达到一定阈值后会转换为红黑树 (JDK1.8+)。下图为 HashMap 的数据结构图：\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/dunwu/images/master/snap/20200224194352.png\" alt=\"img\"/\u003e\u003c/p\u003e\n\u003cp\u003e图片引用自：\u003ca target=\"_blank\" rel=\"noopener\" href=\"http://www.itcuties.com/java/hashmap-hashtable/\"\u003eHashMap vs. Hashtable\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"创建分桶表\"\u003e\u003ca href=\"#创建分桶表\" class=\"headerlink\" title=\"创建分桶表\"\u003e\u003c/a\u003e创建分桶表\u003c/h3\u003e\u003cp\u003e在 Hive 中，我们可以通过 \u003ccode\u003eCLUSTERED BY\u003c/code\u003e 指定分桶列，并通过 \u003ccode\u003eSORTED BY\u003c/code\u003e 指定桶中数据的排序参考列。下面为分桶表建表语句示例：\u003c/p\u003e\n\u003cfigure class=\"highlight sql\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e4\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e5\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e6\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e7\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e8\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e9\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e10\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e11\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e12\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"keyword\"\u003eCREATE\u003c/span\u003e \u003cspan class=\"keyword\"\u003eEXTERNAL\u003c/span\u003e \u003cspan class=\"keyword\"\u003eTABLE\u003c/span\u003e emp_bucket(\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  empno \u003cspan class=\"type\"\u003eINT\u003c/span\u003e,\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  ename STRING,\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  job STRING,\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  mgr \u003cspan class=\"type\"\u003eINT\u003c/span\u003e,\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  hiredate \u003cspan class=\"type\"\u003eTIMESTAMP\u003c/span\u003e,\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  sal \u003cspan class=\"type\"\u003eDECIMAL\u003c/span\u003e(\u003cspan class=\"number\"\u003e7\u003c/span\u003e,\u003cspan class=\"number\"\u003e2\u003c/span\u003e),\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  comm \u003cspan class=\"type\"\u003eDECIMAL\u003c/span\u003e(\u003cspan class=\"number\"\u003e7\u003c/span\u003e,\u003cspan class=\"number\"\u003e2\u003c/span\u003e),\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  deptno \u003cspan class=\"type\"\u003eINT\u003c/span\u003e)\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  CLUSTERED \u003cspan class=\"keyword\"\u003eBY\u003c/span\u003e(empno) SORTED \u003cspan class=\"keyword\"\u003eBY\u003c/span\u003e(empno \u003cspan class=\"keyword\"\u003eASC\u003c/span\u003e) \u003cspan class=\"keyword\"\u003eINTO\u003c/span\u003e \u003cspan class=\"number\"\u003e4\u003c/span\u003e BUCKETS  \u003cspan class=\"comment\"\u003e--按照员工编号散列到四个 bucket 中\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  \u003cspan class=\"type\"\u003eROW\u003c/span\u003e FORMAT DELIMITED FIELDS TERMINATED \u003cspan class=\"keyword\"\u003eBY\u003c/span\u003e \u0026#34;\\t\u0026#34;\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  LOCATION \u003cspan class=\"string\"\u003e\u0026#39;/hive/emp_bucket\u0026#39;\u003c/span\u003e;\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\u003ch3 id=\"加载数据到分桶表\"\u003e\u003ca href=\"#加载数据到分桶表\" class=\"headerlink\" title=\"加载数据到分桶表\"\u003e\u003c/a\u003e加载数据到分桶表\u003c/h3\u003e\u003cp\u003e这里直接使用 \u003ccode\u003eLoad\u003c/code\u003e 语句向分桶表加载数据，数据时可以加载成功的，但是数据并不会分桶。\u003c/p\u003e\n\u003cp\u003e这是由于分桶的实质是对指定字段做了 hash 散列然后存放到对应文件中，这意味着向分桶表中插入数据是必然要通过 MapReduce，且 Reducer 的数量必须等于分桶的数量。由于以上原因，分桶表的数据通常只能使用 CTAS(CREATE TABLE AS SELECT) 方式插入，因为 CTAS 操作会触发 MapReduce。加载数据步骤如下：\u003c/p\u003e\n\u003ch4 id=\"设置强制分桶\"\u003e\u003ca href=\"#设置强制分桶\" class=\"headerlink\" title=\"设置强制分桶\"\u003e\u003c/a\u003e设置强制分桶\u003c/h4\u003e\u003cfigure class=\"highlight sql\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"keyword\"\u003eset\u003c/span\u003e hive.enforce.bucketing \u003cspan class=\"operator\"\u003e=\u003c/span\u003e \u003cspan class=\"literal\"\u003etrue\u003c/span\u003e; \u003cspan class=\"comment\"\u003e--Hive 2.x 不需要这一步\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\u003cp\u003e在 Hive 0.x and 1.x 版本，必须使用设置 \u003ccode\u003ehive.enforce.bucketing = true\u003c/code\u003e，表示强制分桶，允许程序根据表结构自动选择正确数量的 Reducer 和 cluster by column 来进行分桶。\u003c/p\u003e\n\u003ch4 id=\"CTAS-导入数据\"\u003e\u003ca href=\"#CTAS-导入数据\" class=\"headerlink\" title=\"CTAS 导入数据\"\u003e\u003c/a\u003eCTAS 导入数据\u003c/h4\u003e\u003cfigure class=\"highlight sql\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"keyword\"\u003eINSERT\u003c/span\u003e \u003cspan class=\"keyword\"\u003eINTO\u003c/span\u003e \u003cspan class=\"keyword\"\u003eTABLE\u003c/span\u003e emp_bucket \u003cspan class=\"keyword\"\u003eSELECT\u003c/span\u003e \u003cspan class=\"operator\"\u003e*\u003c/span\u003e  \u003cspan class=\"keyword\"\u003eFROM\u003c/span\u003e emp;  \u003cspan class=\"comment\"\u003e--这里的 emp 表就是一张普通的雇员表\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\u003cp\u003e可以从执行日志看到 CTAS 触发 MapReduce 操作，且 Reducer 数量和建表时候指定 bucket 数量一致：\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://github.com/heibaiying/BigData-Notes/raw/master/pictures/hive-hadoop-mapreducer.png\" alt=\"img\"/\u003e\u003c/p\u003e\n\u003ch3 id=\"查看分桶文件\"\u003e\u003ca href=\"#查看分桶文件\" class=\"headerlink\" title=\"查看分桶文件\"\u003e\u003c/a\u003e查看分桶文件\u003c/h3\u003e\u003cp\u003ebucket(桶) 本质上就是表目录下的具体文件：\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://github.com/heibaiying/BigData-Notes/raw/master/pictures/hive-hadoop-bucket.png\" alt=\"img\"/\u003e\u003c/p\u003e\n\u003ch2 id=\"分区表和分桶表结合使用\"\u003e\u003ca href=\"#分区表和分桶表结合使用\" class=\"headerlink\" title=\"分区表和分桶表结合使用\"\u003e\u003c/a\u003e分区表和分桶表结合使用\u003c/h2\u003e\u003cp\u003e分区表和分桶表的本质都是将数据按照不同粒度进行拆分，从而使得在查询时候不必扫描全表，只需要扫描对应的分区或分桶，从而提升查询效率。两者可以结合起来使用，从而保证表数据在不同粒度上都能得到合理的拆分。下面是 Hive 官方给出的示例：\u003c/p\u003e\n\u003cfigure class=\"highlight sql\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e4\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e5\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e6\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e7\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e8\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e9\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e10\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e11\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e12\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e13\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"keyword\"\u003eCREATE\u003c/span\u003e \u003cspan class=\"keyword\"\u003eTABLE\u003c/span\u003e page_view_bucketed(\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\tviewTime \u003cspan class=\"type\"\u003eINT\u003c/span\u003e,\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    userid \u003cspan class=\"type\"\u003eBIGINT\u003c/span\u003e,\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    page_url STRING,\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    referrer_url STRING,\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    ip STRING )\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e PARTITIONED \u003cspan class=\"keyword\"\u003eBY\u003c/span\u003e(dt STRING)\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e CLUSTERED \u003cspan class=\"keyword\"\u003eBY\u003c/span\u003e(userid) SORTED \u003cspan class=\"keyword\"\u003eBY\u003c/span\u003e(viewTime) \u003cspan class=\"keyword\"\u003eINTO\u003c/span\u003e \u003cspan class=\"number\"\u003e32\u003c/span\u003e BUCKETS\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e \u003cspan class=\"type\"\u003eROW\u003c/span\u003e FORMAT DELIMITED\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   FIELDS TERMINATED \u003cspan class=\"keyword\"\u003eBY\u003c/span\u003e \u003cspan class=\"string\"\u003e\u0026#39;\\001\u0026#39;\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   COLLECTION ITEMS TERMINATED \u003cspan class=\"keyword\"\u003eBY\u003c/span\u003e \u003cspan class=\"string\"\u003e\u0026#39;\\002\u0026#39;\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e   MAP KEYS TERMINATED \u003cspan class=\"keyword\"\u003eBY\u003c/span\u003e \u003cspan class=\"string\"\u003e\u0026#39;\\003\u0026#39;\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e STORED \u003cspan class=\"keyword\"\u003eAS\u003c/span\u003e SEQUENCEFILE;\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\u003cp\u003e此时导入数据时需要指定分区：\u003c/p\u003e\n\u003cfigure class=\"highlight shell\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003eINSERT OVERWRITE page_view_bucketed\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003ePARTITION (dt=\u0026#39;2009-02-25\u0026#39;)\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003eSELECT * FROM page_view WHERE dt=\u0026#39;2009-02-25\u0026#39;;\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\u003ch2 id=\"参考资料\"\u003e\u003ca href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"\u003e\u003c/a\u003e参考资料\u003c/h2\u003e\u003cul\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL+BucketedTables\"\u003eLanguageManual DDL BucketedTables\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n    \u003c/div\u003e",
  "Date": "2020-02-24T13:14:47Z",
  "Author": "钝悟 ◾ Dunwu"
}