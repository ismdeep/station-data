{
  "Source": "dunwu",
  "Title": "Elasticsearch 快速入门",
  "Link": "https://dunwu.github.io/blog/pages/98c3a5/",
  "Content": "\u003cdiv class=\"post-body\" itemprop=\"articleBody\"\u003e\u003ch1 id=\"Elasticsearch-快速入门\"\u003e\u003ca href=\"#Elasticsearch-快速入门\" class=\"headerlink\" title=\"Elasticsearch 快速入门\"\u003e\u003c/a\u003eElasticsearch 快速入门\u003c/h1\u003e\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/elastic/elasticsearch\"\u003eElasticsearch\u003c/a\u003e 是一个分布式、RESTful 风格的搜索和数据分析引擎\u003c/strong\u003e，能够解决不断涌现出的各种用例。 作为 Elastic Stack 的核心，它集中存储您的数据，帮助您发现意料之中以及意料之外的情况。\u003c/p\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/elastic/elasticsearch\"\u003eElasticsearch\u003c/a\u003e 基于搜索库 \u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/apache/lucene-solr\"\u003eLucene\u003c/a\u003e 开发。ElasticSearch 隐藏了 Lucene 的复杂性，提供了简单易用的 REST API / Java API 接口（另外还有其他语言的 API 接口）。\u003c/p\u003e\n\u003cp\u003e_以下简称 ES_。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"Elasticsearch-简介\"\u003e\u003ca href=\"#Elasticsearch-简介\" class=\"headerlink\" title=\"Elasticsearch 简介\"\u003e\u003c/a\u003eElasticsearch 简介\u003c/h2\u003e\u003ch3 id=\"什么是-Elasticsearch\"\u003e\u003ca href=\"#什么是-Elasticsearch\" class=\"headerlink\" title=\"什么是 Elasticsearch\"\u003e\u003c/a\u003e什么是 Elasticsearch\u003c/h3\u003e\u003cp\u003e\u003cstrong\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/elastic/elasticsearch\"\u003eElasticsearch\u003c/a\u003e 是一个分布式、RESTful 风格的搜索和数据分析引擎\u003c/strong\u003e，能够解决不断涌现出的各种用例。 作为 Elastic Stack 的核心，它集中存储您的数据，帮助您发现意料之中以及意料之外的情况。\u003c/p\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/elastic/elasticsearch\"\u003eElasticsearch\u003c/a\u003e \u003cstrong\u003e基于搜索库 \u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/apache/lucene-solr\"\u003eLucene\u003c/a\u003e 开发\u003c/strong\u003e。ElasticSearch 隐藏了 Lucene 的复杂性，提供了简单易用的 REST API / Java API 接口（另外还有其他语言的 API 接口）。\u003c/p\u003e\n\u003cp\u003eElasticSearch 可以视为一个文档存储，它\u003cstrong\u003e将复杂数据结构序列化为 JSON 存储\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eElasticSearch 是近乎于实时的全文搜素\u003c/strong\u003e，这是指：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e从写入数据到数据可以被搜索，存在较小的延迟（大概是 1s）\u003c/li\u003e\n\u003cli\u003e基于 ES 执行搜索和分析可以达到秒级\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"核心概念\"\u003e\u003ca href=\"#核心概念\" class=\"headerlink\" title=\"核心概念\"\u003e\u003c/a\u003e核心概念\u003c/h3\u003e\u003cfigure class=\"highlight xl\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"function\"\u003e\u003cspan class=\"title\"\u003eindex\u003c/span\u003e -\u0026gt;\u003c/span\u003e \u003cspan class=\"function\"\u003e\u003cspan class=\"title\"\u003etype\u003c/span\u003e -\u0026gt;\u003c/span\u003e \u003cspan class=\"function\"\u003e\u003cspan class=\"title\"\u003emapping\u003c/span\u003e -\u0026gt;\u003c/span\u003e \u003cspan class=\"function\"\u003e\u003cspan class=\"title\"\u003edocument\u003c/span\u003e -\u0026gt;\u003c/span\u003e field\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\u003ch4 id=\"Cluster\"\u003e\u003ca href=\"#Cluster\" class=\"headerlink\" title=\"Cluster\"\u003e\u003c/a\u003eCluster\u003c/h4\u003e\u003cp\u003e集群包含多个节点，每个节点属于哪个集群都是通过一个配置来决定的，对于中小型应用来说，刚开始一个集群就一个节点很正常。\u003c/p\u003e\n\u003ch4 id=\"Node\"\u003e\u003ca href=\"#Node\" class=\"headerlink\" title=\"Node\"\u003e\u003c/a\u003eNode\u003c/h4\u003e\u003cp\u003eNode 是集群中的一个节点，节点也有一个名称，默认是随机分配的。默认节点会去加入一个名称为 \u003ccode\u003eelasticsearch\u003c/code\u003e 的集群。如果直接启动一堆节点，那么它们会自动组成一个 elasticsearch 集群，当然一个节点也可以组成 elasticsearch 集群。\u003c/p\u003e\n\u003ch4 id=\"Index\"\u003e\u003ca href=\"#Index\" class=\"headerlink\" title=\"Index\"\u003e\u003c/a\u003eIndex\u003c/h4\u003e\u003cp\u003e\u003cstrong\u003e可以认为是文档（document）的优化集合。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eES 会为所有字段建立索引，经过处理后写入一个反向索引（Inverted Index）。查找数据的时候，直接查找该索引。\u003c/p\u003e\n\u003cp\u003e所以，ES 数据管理的顶层单位就叫做 Index（索引）。它是单个数据库的同义词。每个 Index （即数据库）的名字必须是小写。\u003c/p\u003e\n\u003ch4 id=\"Type\"\u003e\u003ca href=\"#Type\" class=\"headerlink\" title=\"Type\"\u003e\u003c/a\u003eType\u003c/h4\u003e\u003cp\u003e每个索引里可以有一个或者多个类型（type）。\u003ccode\u003e类型（type）\u003c/code\u003e 是 index 的一个逻辑分类。\u003c/p\u003e\n\u003cp\u003e不同的 Type 应该有相似的结构（schema），举例来说，\u003ccode\u003eid\u003c/code\u003e字段不能在这个组是字符串，在另一个组是数值。这是与关系型数据库的表的\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://www.elastic.co/guide/en/elasticsearch/guide/current/mapping.html\"\u003e一个区别\u003c/a\u003e。性质完全不同的数据（比如\u003ccode\u003eproducts\u003c/code\u003e和\u003ccode\u003elogs\u003c/code\u003e）应该存成两个 Index，而不是一个 Index 里面的两个 Type（虽然可以做到）。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e注意：根据\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://www.elastic.co/blog/index-type-parent-child-join-now-future-in-elasticsearch\"\u003e规划\u003c/a\u003e，Elastic 6.x 版只允许每个 Index 包含一个 Type，7.x 版将会彻底移除 Type。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch4 id=\"Document\"\u003e\u003ca href=\"#Document\" class=\"headerlink\" title=\"Document\"\u003e\u003c/a\u003eDocument\u003c/h4\u003e\u003cp\u003eIndex 里面单条的记录称为 Document（文档）。许多条 Document 构成了一个 Index。\u003c/p\u003e\n\u003cp\u003e每个 \u003cstrong\u003e\u003ccode\u003e文档（document）\u003c/code\u003e\u003c/strong\u003e 都是字段（field）的集合。\u003c/p\u003e\n\u003cp\u003eDocument 使用 JSON 格式表示，下面是一个例子。\u003c/p\u003e\n\u003cfigure class=\"highlight javascript\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e4\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e5\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e{\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"string\"\u003e\u0026#34;user\u0026#34;\u003c/span\u003e: \u003cspan class=\"string\"\u003e\u0026#34;张三\u0026#34;\u003c/span\u003e,\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"string\"\u003e\u0026#34;title\u0026#34;\u003c/span\u003e: \u003cspan class=\"string\"\u003e\u0026#34;工程师\u0026#34;\u003c/span\u003e,\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"string\"\u003e\u0026#34;desc\u0026#34;\u003c/span\u003e: \u003cspan class=\"string\"\u003e\u0026#34;数据库管理\u0026#34;\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e}\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\u003cp\u003e同一个 Index 里面的 Document，不要求有相同的结构（scheme），但是最好保持相同，这样有利于提高搜索效率。\u003c/p\u003e\n\u003ch4 id=\"Field\"\u003e\u003ca href=\"#Field\" class=\"headerlink\" title=\"Field\"\u003e\u003c/a\u003eField\u003c/h4\u003e\u003cp\u003e\u003cstrong\u003e\u003ccode\u003e字段（field）\u003c/code\u003e\u003c/strong\u003e 是包含数据的键值对。\u003c/p\u003e\n\u003cp\u003e默认情况下，Elasticsearch 对每个字段中的所有数据建立索引，并且每个索引字段都具有专用的优化数据结构。\u003c/p\u003e\n\u003ch4 id=\"Shard\"\u003e\u003ca href=\"#Shard\" class=\"headerlink\" title=\"Shard\"\u003e\u003c/a\u003eShard\u003c/h4\u003e\u003cp\u003e当单台机器不足以存储大量数据时，Elasticsearch 可以将一个索引中的数据切分为多个 \u003cstrong\u003e\u003ccode\u003e分片（shard）\u003c/code\u003e\u003c/strong\u003e 。 \u003cstrong\u003e\u003ccode\u003e分片（shard）\u003c/code\u003e\u003c/strong\u003e 分布在多台服务器上存储。有了 shard 就可以横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能。每个 shard 都是一个 lucene index。\u003c/p\u003e\n\u003ch4 id=\"Replica\"\u003e\u003ca href=\"#Replica\" class=\"headerlink\" title=\"Replica\"\u003e\u003c/a\u003eReplica\u003c/h4\u003e\u003cp\u003e任何一个服务器随时可能故障或宕机，此时 shard 可能就会丢失，因此可以为每个 shard 创建多个 **\u003ccode\u003e副本（replica）\u003c/code\u003e**。replica 可以在 shard 故障时提供备用服务，保证数据不丢失，多个 replica 还可以提升搜索操作的吞吐量和性能。primary shard（建立索引时一次设置，不能修改，默认 5 个），replica shard（随时修改数量，默认 1 个），默认每个索引 10 个 shard，5 个 primary shard，5 个 replica shard，最小的高可用配置，是 2 台服务器。\u003c/p\u003e\n\u003ch4 id=\"ES-核心概念-vs-DB-核心概念\"\u003e\u003ca href=\"#ES-核心概念-vs-DB-核心概念\" class=\"headerlink\" title=\"ES 核心概念 vs. DB 核心概念\"\u003e\u003c/a\u003eES 核心概念 vs. DB 核心概念\u003c/h4\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eES\u003c/th\u003e\n\u003cth\u003eDB\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003eindex\u003c/td\u003e\n\u003ctd\u003e数据库\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003etype\u003c/td\u003e\n\u003ctd\u003e数据表\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003edocuemnt\u003c/td\u003e\n\u003ctd\u003e一行数据\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch2 id=\"ElasticSearch-基本原理\"\u003e\u003ca href=\"#ElasticSearch-基本原理\" class=\"headerlink\" title=\"ElasticSearch 基本原理\"\u003e\u003c/a\u003eElasticSearch 基本原理\u003c/h2\u003e\u003ch3 id=\"ES-写数据过程\"\u003e\u003ca href=\"#ES-写数据过程\" class=\"headerlink\" title=\"ES 写数据过程\"\u003e\u003c/a\u003eES 写数据过程\u003c/h3\u003e\u003cul\u003e\n\u003cli\u003e客户端选择一个 node 发送请求过去，这个 node 就是 \u003ccode\u003ecoordinating node\u003c/code\u003e（协调节点）。\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecoordinating node\u003c/code\u003e 对 document 进行\u003cstrong\u003e路由\u003c/strong\u003e，将请求转发给对应的 node（有 primary shard）。\u003c/li\u003e\n\u003cli\u003e实际的 node 上的 \u003ccode\u003eprimary shard\u003c/code\u003e 处理请求，然后将数据同步到 \u003ccode\u003ereplica node\u003c/code\u003e。\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecoordinating node\u003c/code\u003e 如果发现 \u003ccode\u003eprimary node\u003c/code\u003e 和所有 \u003ccode\u003ereplica node\u003c/code\u003e 都搞定之后，就返回响应结果给客户端。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/dunwu/images/master/snap/20210712104055.png\" alt=\"img\"/\u003e\u003c/p\u003e\n\u003ch3 id=\"ES-读数据过程\"\u003e\u003ca href=\"#ES-读数据过程\" class=\"headerlink\" title=\"ES 读数据过程\"\u003e\u003c/a\u003eES 读数据过程\u003c/h3\u003e\u003cp\u003e可以通过 \u003ccode\u003edoc id\u003c/code\u003e 来查询，会根据 \u003ccode\u003edoc id\u003c/code\u003e 进行 hash，判断出来当时把 \u003ccode\u003edoc id\u003c/code\u003e 分配到了哪个 shard 上面去，从那个 shard 去查询。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e客户端发送请求到\u003cstrong\u003e任意\u003c/strong\u003e一个 node，成为 \u003ccode\u003ecoordinate node\u003c/code\u003e。\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecoordinate node\u003c/code\u003e 对 \u003ccode\u003edoc id\u003c/code\u003e 进行哈希路由，将请求转发到对应的 node，此时会使用 \u003ccode\u003eround-robin\u003c/code\u003e \u003cstrong\u003e轮询算法\u003c/strong\u003e，在 \u003ccode\u003eprimary shard\u003c/code\u003e 以及其所有 replica 中随机选择一个，让读请求负载均衡。\u003c/li\u003e\n\u003cli\u003e接收请求的 node 返回 document 给 \u003ccode\u003ecoordinate node\u003c/code\u003e。\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecoordinate node\u003c/code\u003e 返回 document 给客户端。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"es-搜索数据过程\"\u003e\u003ca href=\"#es-搜索数据过程\" class=\"headerlink\" title=\"es 搜索数据过程\"\u003e\u003c/a\u003ees 搜索数据过程\u003c/h3\u003e\u003cp\u003ees 最强大的是做全文检索，就是比如你有三条数据：\u003c/p\u003e\n\u003cfigure class=\"highlight mipsasm\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"keyword\"\u003ejava真好玩儿啊\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"keyword\"\u003e\u003c/span\u003e\u003cspan class=\"keyword\"\u003ejava好难学啊\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"keyword\"\u003e\u003c/span\u003e\u003cspan class=\"keyword\"\u003ej2ee特别牛\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\u003cp\u003e你根据 \u003ccode\u003ejava\u003c/code\u003e 关键词来搜索，将包含 \u003ccode\u003ejava\u003c/code\u003e 的 \u003ccode\u003edocument\u003c/code\u003e 给搜索出来。es 就会给你返回：java 真好玩儿啊，java 好难学啊。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e客户端发送请求到一个 \u003ccode\u003ecoordinate node\u003c/code\u003e 。\u003c/li\u003e\n\u003cli\u003e协调节点将搜索请求转发到\u003cstrong\u003e所有\u003c/strong\u003e的 shard 对应的 \u003ccode\u003eprimary shard\u003c/code\u003e 或 \u003ccode\u003ereplica shard\u003c/code\u003e ，都可以。\u003c/li\u003e\n\u003cli\u003equery phase：每个 shard 将自己的搜索结果（其实就是一些 \u003ccode\u003edoc id\u003c/code\u003e ）返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果。\u003c/li\u003e\n\u003cli\u003efetch phase：接着由协调节点根据 \u003ccode\u003edoc id\u003c/code\u003e 去各个节点上\u003cstrong\u003e拉取实际\u003c/strong\u003e的 \u003ccode\u003edocument\u003c/code\u003e 数据，最终返回给客户端。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003e写请求是写入 primary shard，然后同步给所有的 replica shard；读请求可以从 primary shard 或 replica shard 读取，采用的是随机轮询算法。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"写数据底层原理\"\u003e\u003ca href=\"#写数据底层原理\" class=\"headerlink\" title=\"写数据底层原理\"\u003e\u003c/a\u003e写数据底层原理\u003c/h3\u003e\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/images/es-write-detail.png\"\u003e\u003cimg src=\"https://github.com/doocs/advanced-java/raw/master/docs/high-concurrency/images/es-write-detail.png\" alt=\"es-write-detail\"/\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e先写入内存 buffer，在 buffer 里的时候数据是搜索不到的；同时将数据写入 translog 日志文件。\u003c/p\u003e\n\u003cp\u003e如果 buffer 快满了，或者到一定时间，就会将内存 buffer 数据 \u003ccode\u003erefresh\u003c/code\u003e 到一个新的 \u003ccode\u003esegment file\u003c/code\u003e 中，但是此时数据不是直接进入 \u003ccode\u003esegment file\u003c/code\u003e 磁盘文件，而是先进入 \u003ccode\u003eos cache\u003c/code\u003e 。这个过程就是 \u003ccode\u003erefresh\u003c/code\u003e。\u003c/p\u003e\n\u003cp\u003e每隔 1 秒钟，es 将 buffer 中的数据写入一个\u003cstrong\u003e新的\u003c/strong\u003e \u003ccode\u003esegment file\u003c/code\u003e，每秒钟会产生一个\u003cstrong\u003e新的磁盘文件\u003c/strong\u003e \u003ccode\u003esegment file\u003c/code\u003e，这个 \u003ccode\u003esegment file\u003c/code\u003e 中就存储最近 1 秒内 buffer 中写入的数据。\u003c/p\u003e\n\u003cp\u003e但是如果 buffer 里面此时没有数据，那当然不会执行 refresh 操作，如果 buffer 里面有数据，默认 1 秒钟执行一次 refresh 操作，刷入一个新的 segment file 中。\u003c/p\u003e\n\u003cp\u003e操作系统里面，磁盘文件其实都有一个东西，叫做 \u003ccode\u003eos cache\u003c/code\u003e，即操作系统缓存，就是说数据写入磁盘文件之前，会先进入 \u003ccode\u003eos cache\u003c/code\u003e，先进入操作系统级别的一个内存缓存中去。只要 \u003ccode\u003ebuffer\u003c/code\u003e 中的数据被 refresh 操作刷入 \u003ccode\u003eos cache\u003c/code\u003e中，这个数据就可以被搜索到了。\u003c/p\u003e\n\u003cp\u003e为什么叫 es 是\u003cstrong\u003e准实时\u003c/strong\u003e的？ \u003ccode\u003eNRT\u003c/code\u003e，全称 \u003ccode\u003enear real-time\u003c/code\u003e。默认是每隔 1 秒 refresh 一次的，所以 es 是准实时的，因为写入的数据 1 秒之后才能被看到。可以通过 es 的 \u003ccode\u003erestful api\u003c/code\u003e 或者 \u003ccode\u003ejava api\u003c/code\u003e，\u003cstrong\u003e手动\u003c/strong\u003e执行一次 refresh 操作，就是手动将 buffer 中的数据刷入 \u003ccode\u003eos cache\u003c/code\u003e中，让数据立马就可以被搜索到。只要数据被输入 \u003ccode\u003eos cache\u003c/code\u003e 中，buffer 就会被清空了，因为不需要保留 buffer 了，数据在 translog 里面已经持久化到磁盘去一份了。\u003c/p\u003e\n\u003cp\u003e重复上面的步骤，新的数据不断进入 buffer 和 translog，不断将 \u003ccode\u003ebuffer\u003c/code\u003e 数据写入一个又一个新的 \u003ccode\u003esegment file\u003c/code\u003e 中去，每次 \u003ccode\u003erefresh\u003c/code\u003e 完 buffer 清空，translog 保留。随着这个过程推进，translog 会变得越来越大。当 translog 达到一定长度的时候，就会触发 \u003ccode\u003ecommit\u003c/code\u003e 操作。\u003c/p\u003e\n\u003cp\u003ecommit 操作发生第一步，就是将 buffer 中现有数据 \u003ccode\u003erefresh\u003c/code\u003e 到 \u003ccode\u003eos cache\u003c/code\u003e 中去，清空 buffer。然后，将一个 \u003ccode\u003ecommit point\u003c/code\u003e 写入磁盘文件，里面标识着这个 \u003ccode\u003ecommit point\u003c/code\u003e 对应的所有 \u003ccode\u003esegment file\u003c/code\u003e，同时强行将 \u003ccode\u003eos cache\u003c/code\u003e 中目前所有的数据都 \u003ccode\u003efsync\u003c/code\u003e 到磁盘文件中去。最后\u003cstrong\u003e清空\u003c/strong\u003e 现有 translog 日志文件，重启一个 translog，此时 commit 操作完成。\u003c/p\u003e\n\u003cp\u003e这个 commit 操作叫做 \u003ccode\u003eflush\u003c/code\u003e。默认 30 分钟自动执行一次 \u003ccode\u003eflush\u003c/code\u003e，但如果 translog 过大，也会触发 \u003ccode\u003eflush\u003c/code\u003e。flush 操作就对应着 commit 的全过程，我们可以通过 es api，手动执行 flush 操作，手动将 os cache 中的数据 fsync 强刷到磁盘上去。\u003c/p\u003e\n\u003cp\u003etranslog 日志文件的作用是什么？你执行 commit 操作之前，数据要么是停留在 buffer 中，要么是停留在 os cache 中，无论是 buffer 还是 os cache 都是内存，一旦这台机器死了，内存中的数据就全丢了。所以需要将数据对应的操作写入一个专门的日志文件 \u003ccode\u003etranslog\u003c/code\u003e 中，一旦此时机器宕机，再次重启的时候，es 会自动读取 translog 日志文件中的数据，恢复到内存 buffer 和 os cache 中去。\u003c/p\u003e\n\u003cp\u003etranslog 其实也是先写入 os cache 的，默认每隔 5 秒刷一次到磁盘中去，所以默认情况下，可能有 5 秒的数据会仅仅停留在 buffer 或者 translog 文件的 os cache 中，如果此时机器挂了，会\u003cstrong\u003e丢失\u003c/strong\u003e 5 秒钟的数据。但是这样性能比较好，最多丢 5 秒的数据。也可以将 translog 设置成每次写操作必须是直接 \u003ccode\u003efsync\u003c/code\u003e 到磁盘，但是性能会差很多。\u003c/p\u003e\n\u003cp\u003e实际上你在这里，如果面试官没有问你 es 丢数据的问题，你可以在这里给面试官炫一把，你说，其实 es 第一是准实时的，数据写入 1 秒后可以搜索到；可能会丢失数据的。有 5 秒的数据，停留在 buffer、translog os cache、segment file os cache 中，而不在磁盘上，此时如果宕机，会导致 5 秒的\u003cstrong\u003e数据丢失\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e总结一下\u003c/strong\u003e，数据先写入内存 buffer，然后每隔 1s，将数据 refresh 到 os cache，到了 os cache 数据就能被搜索到（所以我们才说 es 从写入到能被搜索到，中间有 1s 的延迟）。每隔 5s，将数据写入 translog 文件（这样如果机器宕机，内存数据全没，最多会有 5s 的数据丢失），translog 大到一定程度，或者默认每隔 30mins，会触发 commit 操作，将缓冲区的数据都 flush 到 segment file 磁盘文件中。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e数据写入 segment file 之后，同时就建立好了倒排索引。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"删除-更新数据底层原理\"\u003e\u003ca href=\"#删除-更新数据底层原理\" class=\"headerlink\" title=\"删除/更新数据底层原理\"\u003e\u003c/a\u003e删除/更新数据底层原理\u003c/h3\u003e\u003cp\u003e如果是删除操作，commit 的时候会生成一个 \u003ccode\u003e.del\u003c/code\u003e 文件，里面将某个 doc 标识为 \u003ccode\u003edeleted\u003c/code\u003e 状态，那么搜索的时候根据 \u003ccode\u003e.del\u003c/code\u003e 文件就知道这个 doc 是否被删除了。\u003c/p\u003e\n\u003cp\u003e如果是更新操作，就是将原来的 doc 标识为 \u003ccode\u003edeleted\u003c/code\u003e 状态，然后新写入一条数据。\u003c/p\u003e\n\u003cp\u003ebuffer 每 refresh 一次，就会产生一个 \u003ccode\u003esegment file\u003c/code\u003e，所以默认情况下是 1 秒钟一个 \u003ccode\u003esegment file\u003c/code\u003e，这样下来 \u003ccode\u003esegment file\u003c/code\u003e 会越来越多，此时会定期执行 merge。每次 merge 的时候，会将多个 \u003ccode\u003esegment file\u003c/code\u003e 合并成一个，同时这里会将标识为 \u003ccode\u003edeleted\u003c/code\u003e 的 doc 给\u003cstrong\u003e物理删除掉\u003c/strong\u003e，然后将新的 \u003ccode\u003esegment file\u003c/code\u003e 写入磁盘，这里会写一个 \u003ccode\u003ecommit point\u003c/code\u003e，标识所有新的 \u003ccode\u003esegment file\u003c/code\u003e，然后打开 \u003ccode\u003esegment file\u003c/code\u003e 供搜索使用，同时删除旧的 \u003ccode\u003esegment file\u003c/code\u003e。\u003c/p\u003e\n\u003ch3 id=\"底层-lucene\"\u003e\u003ca href=\"#底层-lucene\" class=\"headerlink\" title=\"底层 lucene\"\u003e\u003c/a\u003e底层 lucene\u003c/h3\u003e\u003cp\u003e简单来说，lucene 就是一个 jar 包，里面包含了封装好的各种建立倒排索引的算法代码。我们用 Java 开发的时候，引入 lucene jar，然后基于 lucene 的 api 去开发就可以了。\u003c/p\u003e\n\u003cp\u003e通过 lucene，我们可以将已有的数据建立索引，lucene 会在本地磁盘上面，给我们组织索引的数据结构。\u003c/p\u003e\n\u003ch3 id=\"倒排索引\"\u003e\u003ca href=\"#倒排索引\" class=\"headerlink\" title=\"倒排索引\"\u003e\u003c/a\u003e倒排索引\u003c/h3\u003e\u003cp\u003e在搜索引擎中，每个文档都有一个对应的文档 ID，文档内容被表示为一系列关键词的集合。例如，文档 1 经过分词，提取了 20 个关键词，每个关键词都会记录它在文档中出现的次数和出现位置。\u003c/p\u003e\n\u003cp\u003e那么，倒排索引就是\u003cstrong\u003e关键词到文档\u003c/strong\u003e ID 的映射，每个关键词都对应着一系列的文件，这些文件中都出现了关键词。\u003c/p\u003e\n\u003cp\u003e举个栗子。\u003c/p\u003e\n\u003cp\u003e有以下文档：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eDocId\u003c/th\u003e\n\u003cth\u003eDoc\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e谷歌地图之父跳槽 Facebook\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2\u003c/td\u003e\n\u003ctd\u003e谷歌地图之父加盟 Facebook\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e3\u003c/td\u003e\n\u003ctd\u003e谷歌地图创始人拉斯离开谷歌加盟 Facebook\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e4\u003c/td\u003e\n\u003ctd\u003e谷歌地图之父跳槽 Facebook 与 Wave 项目取消有关\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e5\u003c/td\u003e\n\u003ctd\u003e谷歌地图之父拉斯加盟社交网站 Facebook\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e对文档进行分词之后，得到以下\u003cstrong\u003e倒排索引\u003c/strong\u003e。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eWordId\u003c/th\u003e\n\u003cth\u003eWord\u003c/th\u003e\n\u003cth\u003eDocIds\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e谷歌\u003c/td\u003e\n\u003ctd\u003e1,2,3,4,5\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2\u003c/td\u003e\n\u003ctd\u003e地图\u003c/td\u003e\n\u003ctd\u003e1,2,3,4,5\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e3\u003c/td\u003e\n\u003ctd\u003e之父\u003c/td\u003e\n\u003ctd\u003e1,2,4,5\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e4\u003c/td\u003e\n\u003ctd\u003e跳槽\u003c/td\u003e\n\u003ctd\u003e1,4\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e5\u003c/td\u003e\n\u003ctd\u003eFacebook\u003c/td\u003e\n\u003ctd\u003e1,2,3,4,5\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e6\u003c/td\u003e\n\u003ctd\u003e加盟\u003c/td\u003e\n\u003ctd\u003e2,3,5\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e7\u003c/td\u003e\n\u003ctd\u003e创始人\u003c/td\u003e\n\u003ctd\u003e3\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e8\u003c/td\u003e\n\u003ctd\u003e拉斯\u003c/td\u003e\n\u003ctd\u003e3,5\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e9\u003c/td\u003e\n\u003ctd\u003e离开\u003c/td\u003e\n\u003ctd\u003e3\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e10\u003c/td\u003e\n\u003ctd\u003e与\u003c/td\u003e\n\u003ctd\u003e4\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e..\u003c/td\u003e\n\u003ctd\u003e..\u003c/td\u003e\n\u003ctd\u003e..\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e另外，实用的倒排索引还可以记录更多的信息，比如文档频率信息，表示在文档集合中有多少个文档包含某个单词。\u003c/p\u003e\n\u003cp\u003e那么，有了倒排索引，搜索引擎可以很方便地响应用户的查询。比如用户输入查询 \u003ccode\u003eFacebook\u003c/code\u003e，搜索系统查找倒排索引，从中读出包含这个单词的文档，这些文档就是提供给用户的搜索结果。\u003c/p\u003e\n\u003cp\u003e要注意倒排索引的两个重要细节：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e倒排索引中的所有词项对应一个或多个文档；\u003c/li\u003e\n\u003cli\u003e倒排索引中的词项\u003cstrong\u003e根据字典顺序升序排列\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003e上面只是一个简单的栗子，并没有严格按照字典顺序升序排列。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"参考资料\"\u003e\u003ca href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"\u003e\u003c/a\u003e参考资料\u003c/h2\u003e\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e官方\u003c/strong\u003e\u003cul\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://www.elastic.co/cn/products/elasticsearch\"\u003eElasticsearch 官网\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/elastic/elasticsearch\"\u003eElasticsearch Github\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html\"\u003eElasticsearch 官方文档\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e文章\u003c/strong\u003e\u003cul\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/rpm.html#rpm\"\u003eInstall Elasticsearch with RPM\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://www.ruanyifeng.com/blog/2017/08/elasticsearch.html\"\u003ehttps://www.ruanyifeng.com/blog/2017/08/elasticsearch.html\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/es-introduction.md\"\u003ees-introduction\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/es-write-query-search.md\"\u003ees-write-query-search\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n    \u003c/div\u003e",
  "Date": "2020-06-15T23:10:44Z",
  "Author": "钝悟 ◾ Dunwu"
}