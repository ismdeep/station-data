{
  "Source": "dunwu",
  "Title": "《机器学习 40 讲》笔记",
  "Link": "https://dunwu.github.io/blog/pages/c3ab9e/",
  "Content": "\u003cdiv class=\"post-body\" itemprop=\"articleBody\"\u003e\u003ch1 id=\"《机器学习-40-讲》笔记\"\u003e\u003ca href=\"#《机器学习-40-讲》笔记\" class=\"headerlink\" title=\"《机器学习 40 讲》笔记\"\u003e\u003c/a\u003e《机器学习 40 讲》笔记\u003c/h1\u003e\u003ch2 id=\"开篇词-打通修炼机器学习的任督二脉\"\u003e\u003ca href=\"#开篇词-打通修炼机器学习的任督二脉\" class=\"headerlink\" title=\"开篇词 | 打通修炼机器学习的任督二脉\"\u003e\u003c/a\u003e开篇词 | 打通修炼机器学习的任督二脉\u003c/h2\u003e\u003cp\u003e“机器学习”分为 3 个模块\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e机器学习概观\u003c/strong\u003e：介绍机器学习中超脱于具体模型和方法之上的一些共性问题\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e统计学习（频率学派）\u003c/strong\u003e：利用不同的模型去拟合数据背后的规律；用拟合出的规律去推断和预测未知的结果\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e符号学习（贝叶斯学派）\u003c/strong\u003e：即概率图模型，它计算的是变量间的相关关系，每个遍历的先验分布和大量复杂的积分技巧。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"01-丨频率视角下的机器学习\"\u003e\u003ca href=\"#01-丨频率视角下的机器学习\" class=\"headerlink\" title=\"01 丨频率视角下的机器学习\"\u003e\u003c/a\u003e01 丨频率视角下的机器学习\u003c/h2\u003e\u003cp\u003e频率学派认为概率是随机事件发生频率的极限值；\u003c/p\u003e\n\u003cp\u003e频率学派执行参数估计时，视参数为确定取值，视数据为随机变量；\u003c/p\u003e\n\u003cp\u003e频率学派主要使用最大似然估计法，让数据在给定参数下的似然概率最大化；\u003c/p\u003e\n\u003cp\u003e频率学派对应机器学习中的统计学习，以经验风险最小化作为模型选择的准则。\u003c/p\u003e\n\u003ch2 id=\"02-贝叶斯视角下的机器学习\"\u003e\u003ca href=\"#02-贝叶斯视角下的机器学习\" class=\"headerlink\" title=\"02 | 贝叶斯视角下的机器学习\"\u003e\u003c/a\u003e02 | 贝叶斯视角下的机器学习\u003c/h2\u003e\u003cp\u003e贝叶斯学派认为概率是事件的可信程度或主体对事件的信任程度；\u003c/p\u003e\n\u003cp\u003e贝叶斯学派执行参数估计时，视参数为随机变量，视数据为确定取值；\u003c/p\u003e\n\u003cp\u003e贝叶斯学派主要使用最大后验概率法，让参数在先验信息和给定数据下的后验概率最大化；\u003c/p\u003e\n\u003cp\u003e贝叶斯学派对应机器学习中的概率图模型，可以在模型预测和选择中提供更加完整的信息。\u003c/p\u003e\n\u003ch2 id=\"03-丨学什么与怎么学\"\u003e\u003ca href=\"#03-丨学什么与怎么学\" class=\"headerlink\" title=\"03 丨学什么与怎么学\"\u003e\u003c/a\u003e03 丨学什么与怎么学\u003c/h2\u003e\u003cp\u003e什么样的问题才能通过机器学习来解决呢？\u003c/p\u003e\n\u003cp\u003e首先，问题不能是完全随机的，需要具备一定的模式；\u003c/p\u003e\n\u003cp\u003e其次，问题本身不能通过纯计算的方法解决；\u003c/p\u003e\n\u003cp\u003e再次，有大量的数据可供使用。\u003c/p\u003e\n\u003cp\u003e机器学习的任务，就是使用数据计算出与目标函数最接近的假设，或者说拟合出最精确的模型 。\u003c/p\u003e\n\u003cp\u003e输入特征类型\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e具体特征（concrete feature）\u003c/li\u003e\n\u003cli\u003e原始特征（raw feature）\u003c/li\u003e\n\u003cli\u003e抽象特征（abstract feature）\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e机器学习方法类型\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e分类算法（classification）\u003c/li\u003e\n\u003cli\u003e回归算法（regression）\u003c/li\u003e\n\u003cli\u003e标注算法（tagging）\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e如果训练数据中的每组输入都有其对应的输出结果，这类学习任务就是\u003cstrong\u003e监督学习（supervised learning）\u003c/strong\u003e，对没有输出的数据进行学习则是\u003cstrong\u003e无监督学习（unsupervised learning）\u003c/strong\u003e。监督学习具有更好的预测精度，无监督学习则可以发现数据中隐含的结构特性，起到的也是分类的作用，只不过没有给每个类别赋予标签而已。无监督学习可以用于对数据进行聚类或者密度估计，也可以完成异常检测这类监督学习中的预处理操作。直观地看，监督学习适用于预测任务，无监督学习适用于描述任务。\u003c/p\u003e\n\u003ch2 id=\"04-丨计算学习理论\"\u003e\u003ca href=\"#04-丨计算学习理论\" class=\"headerlink\" title=\"04 丨计算学习理论\"\u003e\u003c/a\u003e04 丨计算学习理论\u003c/h2\u003e\n    \u003c/div\u003e",
  "Date": "2023-02-09T13:08:48Z",
  "Author": "钝悟 ◾ Dunwu"
}