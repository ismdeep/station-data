{
  "Source": "go.dev",
  "Title": "More powerful Go execution traces",
  "Link": "https://go.dev/blog/execution-traces-2024",
  "Content": "\u003cdiv class=\"Article\" data-slug=\"/blog/execution-traces-2024\"\u003e\n    \n    \u003ch1 class=\"small\"\u003e\u003ca href=\"/blog/\"\u003eThe Go Blog\u003c/a\u003e\u003c/h1\u003e\n    \n\n    \u003ch1\u003eMore powerful Go execution traces\u003c/h1\u003e\n      \n      \u003cp class=\"author\"\u003e\n      Michael Knyszek\u003cbr/\u003e\n      14 March 2024\n      \u003c/p\u003e\n      \n      \u003cp\u003eThe \u003ca href=\"/pkg/runtime/trace\"\u003eruntime/trace\u003c/a\u003e package contains a powerful tool for understanding and\ntroubleshooting Go programs.\nThe functionality within allows one to produce a trace of each goroutine’s execution over some\ntime period.\nWith the \u003ca href=\"/pkg/cmd/trace\"\u003e\u003ccode\u003ego tool trace\u003c/code\u003e command\u003c/a\u003e (or the excellent open source\n\u003ca href=\"https://gotraceui.dev/\" rel=\"noreferrer\" target=\"_blank\"\u003egotraceui tool\u003c/a\u003e), one may then visualize and explore the data within these\ntraces.\u003c/p\u003e\n\u003cp\u003eThe magic of a trace is that it can easily reveal things about a program that are hard to see in\nother ways.\nFor example, a concurrency bottleneck where lots of goroutines block on the same channel might be\nquite difficult to see in a CPU profile, because there’s no execution to sample.\nBut in an execution trace, the \u003cem\u003elack\u003c/em\u003e of execution will show up with amazing clarity, and the stack\ntraces of blocked goroutines will quickly point at the culprit.\u003c/p\u003e\n\u003cdiv class=\"image\"\u003e\n  \u003cimg src=\"execution-traces-2024/gotooltrace.png\" alt=\"\"/\u003e\n\u003c/div\u003e\n\u003cp\u003eGo developers are even able to instrument their own programs with \u003ca href=\"/pkg/runtime/trace#Task\"\u003etasks\u003c/a\u003e,\n\u003ca href=\"/pkg/runtime/trace#WithRegion\"\u003eregions\u003c/a\u003e, and \u003ca href=\"/pkg/runtime/trace#Log\"\u003elogs\u003c/a\u003e that\nthey can use to correlate their higher-level concerns with lower-level execution details.\u003c/p\u003e\n\u003ch2 id=\"issues\"\u003eIssues\u003c/h2\u003e\n\u003cp\u003eUnfortunately, the wealth of information in execution traces can often be out of reach.\nFour big issues with traces have historically gotten in the way.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTraces had high overheads.\u003c/li\u003e\n\u003cli\u003eTraces didn’t scale well, and could become too big to analyze.\u003c/li\u003e\n\u003cli\u003eIt was often unclear when to start tracing to capture a specific bad behavior.\u003c/li\u003e\n\u003cli\u003eOnly the most adventurous gophers could programmatically analyze traces, given the lack of a\npublic package for parsing and interpreting execution traces.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf you’ve used traces in the last few years, you’ve likely been frustrated by one or more of these\nproblems.\nBut we’re excited to share that over the last two Go releases we’ve made big progress in all four\nof these areas.\u003c/p\u003e\n\u003ch2 id=\"low-overhead-tracing\"\u003eLow-overhead tracing\u003c/h2\u003e\n\u003cp\u003ePrior to Go 1.21, the run-time overhead of tracing was somewhere between 10–20% CPU for many\napplications, which limits tracing to situational usage, rather than continuous usage like CPU\nprofiling.\nIt turned out that much of the cost of tracing came down to tracebacks.\nMany events produced by the runtime have stack traces attached, which are invaluable to actually\nidentifying what goroutines were doing at key moments in their execution.\u003c/p\u003e\n\u003cp\u003eThanks to work by Felix Geisendörfer and Nick Ripley on optimizing the efficiency of tracebacks,\nthe run-time CPU overhead of execution traces has been cut dramatically, down to 1–2% for many\napplications.\nYou can read more about the work done here in \u003ca href=\"https://blog.felixge.de/reducing-gos-execution-tracer-overhead-with-frame-pointer-unwinding/\" rel=\"noreferrer\" target=\"_blank\"\u003eFelix’s great blog\npost\u003c/a\u003e\non the topic.\u003c/p\u003e\n\u003ch2 id=\"scalable-traces\"\u003eScalable traces\u003c/h2\u003e\n\u003cp\u003eThe trace format and its events were designed around relatively efficient emission, but required\ntooling to parse and keep around the state of the entirety of a trace.\nA few hundred MiB trace could require several GiB of RAM to analyze!\u003c/p\u003e\n\u003cp\u003eThis issue is unfortunately fundamental to how traces are generated.\nTo keep run-time overheads low, all events are written to the equivalent of thread-local buffers.\nBut this means events appear out of their true order, and the burden is placed on the trace\ntooling to figure out what really happened.\u003c/p\u003e\n\u003cp\u003eThe key insight to making traces scale while keeping overheads low was to occasionally split the\ntrace being generated.\nEach split point would behave a bit like simultaneously disabling and reenabling tracing in one\ngo.\nAll the trace data so far would represent a complete and self-contained trace, while the new trace\ndata would seamlessly pick up from where it left off.\u003c/p\u003e\n\u003cp\u003eAs you might imagine, fixing this required \u003ca href=\"/issue/60773\"\u003erethinking and rewriting a lot of the foundation of\nthe trace implementation\u003c/a\u003e in the runtime.\nWe’re happy to say that the work landed in Go 1.22 and is now generally available.\n\u003ca href=\"/doc/go1.22#runtime/trace\"\u003eA lot of nice improvements\u003c/a\u003e came with the rewrite, including some\nimprovements to the \u003ca href=\"/doc/go1.22#trace\"\u003e\u003ccode\u003ego tool trace\u003c/code\u003e command\u003c/a\u003e as well.\nThe gritty details are all in the \u003ca href=\"https://github.com/golang/proposal/blob/master/design/60773-execution-tracer-overhaul.md\" rel=\"noreferrer\" target=\"_blank\"\u003edesign\ndocument\u003c/a\u003e,\nif you’re curious.\u003c/p\u003e\n\u003cp\u003e(Note: \u003ccode\u003ego tool trace\u003c/code\u003e still loads the full trace into memory, but \u003ca href=\"/issue/65315\"\u003eremoving this\nlimitation\u003c/a\u003e for traces produced by Go 1.22+ programs is now feasible.)\u003c/p\u003e\n\u003ch2 id=\"flight-recording\"\u003eFlight recording\u003c/h2\u003e\n\u003cp\u003eSuppose you work on a web service and an RPC took a very long time.\nYou couldn’t start tracing at the point you knew the RPC was already taking a while, because the\nroot cause of the slow request already happened and wasn’t recorded.\u003c/p\u003e\n\u003cp\u003eThere’s a technique that can help with this called flight recording, which you may already be\nfamiliar with from other programming environments.\nThe insight with flight recording is to have tracing on continuously and always keep the most\nrecent trace data around, just in case.\nThen, once something interesting happens, the program can just write out whatever it has!\u003c/p\u003e\n\u003cp\u003eBefore traces could be split, this was pretty much a non-starter.\nBut because continuous tracing is now viable thanks to low overheads, and the fact that the runtime\ncan now split traces any time it needs, it turns out it was straightforward to implement flight\nrecording.\u003c/p\u003e\n\u003cp\u003eAs a result, we’re happy to announce a flight recorder experiment, available in the\n\u003ca href=\"/pkg/golang.org/x/exp/trace#FlightRecorder\"\u003egolang.org/x/exp/trace package\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003ePlease try it out!\nBelow is an example that sets up flight recording to capture a long HTTP request to get you started.\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003e    \u003cspan class=\"comment\"\u003e// Set up the flight recorder.\u003c/span\u003e\n    fr := trace.NewFlightRecorder()\n    fr.Start()\n\n    \u003cspan class=\"comment\"\u003e// Set up and run an HTTP server.\u003c/span\u003e\n    var once sync.Once\n    http.HandleFunc(\u0026#34;/my-endpoint\u0026#34;, func(w http.ResponseWriter, r *http.Request) {\n        start := time.Now()\n\n        \u003cspan class=\"comment\"\u003e// Do the work...\u003c/span\u003e\n        doWork(w, r)\n\n        \u003cspan class=\"comment\"\u003e// We saw a long request. Take a snapshot!\u003c/span\u003e\n        if time.Since(start) \u0026gt; 300*time.Millisecond {\n            \u003cspan class=\"comment\"\u003e// Do it only once for simplicity, but you can take more than one.\u003c/span\u003e\n            once.Do(func() {\n                \u003cspan class=\"comment\"\u003e// Grab the snapshot.\u003c/span\u003e\n                var b bytes.Buffer\n                _, err = fr.WriteTo(\u0026amp;b)\n                if err != nil {\n                    log.Print(err)\n                    return\n                }\n                \u003cspan class=\"comment\"\u003e// Write it to a file.\u003c/span\u003e\n                if err := os.WriteFile(\u0026#34;trace.out\u0026#34;, b.Bytes(), 0o755); err != nil {\n                    log.Print(err)\n                    return\n                }\n            })\n        }\n    })\n    log.Fatal(http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil))\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eIf you have any feedback, positive or negative, please share it to the \u003ca href=\"/issue/63185\"\u003eproposal\nissue\u003c/a\u003e!\u003c/p\u003e\n\u003ch2 id=\"trace-reader-api\"\u003eTrace reader API\u003c/h2\u003e\n\u003cp\u003eAlong with the trace implementation rewrite came an effort to clean up the other trace internals,\nlike \u003ccode\u003ego tool trace\u003c/code\u003e.\nThis spawned an attempt to create a trace reader API that was good enough to share and that could\nmake traces more accessible.\u003c/p\u003e\n\u003cp\u003eJust like the flight recorder, we’re happy to announce that we also have an experimental trace reader\nAPI that we’d like to share.\nIt’s available in the \u003ca href=\"/pkg/golang.org/x/exp/trace#Reader\"\u003esame package as the flight recorder,\ngolang.org/x/exp/trace\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eWe think it’s good enough to start building things on top of, so please try it out!\nBelow is an example that measures the proportion of goroutine block events that blocked to wait on\nthe network.\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003e    \u003cspan class=\"comment\"\u003e// Start reading from STDIN.\u003c/span\u003e\n    r, err := trace.NewReader(os.Stdin)\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    var blocked int\n    var blockedOnNetwork int\n    for {\n        \u003cspan class=\"comment\"\u003e// Read the event.\u003c/span\u003e\n        ev, err := r.ReadEvent()\n        if err == io.EOF {\n            break\n        } else if err != nil {\n            log.Fatal(err)\n        }\n\n        \u003cspan class=\"comment\"\u003e// Process it.\u003c/span\u003e\n        if ev.Kind() == trace.EventStateTransition {\n            st := ev.StateTransition()\n            if st.Resource.Kind == trace.ResourceGoroutine {\n                from, to := st.Goroutine()\n\n                \u003cspan class=\"comment\"\u003e// Look for goroutines blocking, and count them.\u003c/span\u003e\n                if from.Executing() \u0026amp;\u0026amp; to == trace.GoWaiting {\n                    blocked++\n                    if strings.Contains(st.Reason, \u0026#34;network\u0026#34;) {\n                        blockedOnNetwork++\n                    }\n                }\n            }\n        }\n    }\n    \u003cspan class=\"comment\"\u003e// Print what we found.\u003c/span\u003e\n    p := 100 * float64(blockedOnNetwork) / float64(blocked)\n    fmt.Printf(\u0026#34;%2.3f%% instances of goroutines blocking were to block on the network\\n\u0026#34;, p)\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eAnd just like the flight recorder, there’s a \u003ca href=\"/issue/62627\"\u003eproposal issue\u003c/a\u003e that would\nbe a great place to leave feedback!\u003c/p\u003e\n\u003cp\u003eWe’d like to quickly call out Dominik Honnef as someone who tried it out early, provided great\nfeedback, and has contributed support for older trace versions to the API.\u003c/p\u003e\n\u003ch2 id=\"thank-you\"\u003eThank you!\u003c/h2\u003e\n\u003cp\u003eThis work was completed, in no small part, thanks to the help of the those in the \u003ca href=\"/issue/57175\"\u003ediagnostics\nworking group\u003c/a\u003e, started over a year ago as a collaboration between stakeholders from\nacross the Go community, and open to the public.\u003c/p\u003e\n\u003cp\u003eWe’d like to take a moment to thank those community members who have attended the diagnostic\nmeetings regularly over the last year: Felix Geisendörfer, Nick Ripley, Rhys Hiltner, Dominik\nHonnef, Bryan Boreham, thepudds.\u003c/p\u003e\n\u003cp\u003eThe discussions, feedback, and work you all put in have been instrumental to getting us to where we\nare today.\nThank you!\u003c/p\u003e\n\n    \u003c/div\u003e",
  "Date": "2024-03-14T00:00:00Z",
  "Author": "Michael Knyszek"
}