{
  "Source": "go.dev",
  "Title": "Profile-guided optimization in Go 1.21",
  "Link": "https://go.dev/blog/pgo",
  "Content": "\u003cdiv class=\"Article\" data-slug=\"/blog/pgo\"\u003e\n    \n    \u003ch1 class=\"small\"\u003e\u003ca href=\"/blog/\"\u003eThe Go Blog\u003c/a\u003e\u003c/h1\u003e\n    \n\n    \u003ch1\u003eProfile-guided optimization in Go 1.21\u003c/h1\u003e\n      \n      \u003cp class=\"author\"\u003e\n      Michael Pratt\u003cbr/\u003e\n      5 September 2023\n      \u003c/p\u003e\n      \n      \u003cp\u003eEarlier in 2023, Go 1.20 \u003ca href=\"/blog/pgo-preview\"\u003eshipped a preview of profile-guided optimization (PGO)\u003c/a\u003e for users to test.\nAfter addressing known limitations in the preview, and with additional refinements thanks to community feedback and contributions, PGO support in Go 1.21 is ready for general production use!\nSee the \u003ca href=\"/doc/pgo\"\u003eprofile-guided optimization user guide\u003c/a\u003e for complete documentation.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"#example\"\u003eBelow\u003c/a\u003e we will run through an example of using PGO to improve the performance of an application.\nBefore we get to that, what exactly is “profile-guided optimization”?\u003c/p\u003e\n\u003cp\u003eWhen you build a Go binary, the Go compiler performs optimizations to try to generate the best performing binary it can.\nFor example, constant propagation can evaluate constant expressions at compile time, avoiding runtime evaluation cost.\nEscape analysis avoids heap allocations for locally-scoped objects, avoiding GC overheads.\nInlining copies the body of simple functions into callers, often enabling further optimization in the caller (such as additional constant propagation or better escape analysis).\nDevirtualization converts indirect calls on interface values whose type can be determined statically into direct calls to the concrete method (which often enables inlining of the call).\u003c/p\u003e\n\u003cp\u003eGo improves optimizations from release to release, but doing so is no easy task.\nSome optimizations are tunable, but the compiler can’t just “turn it up to 11” on every optimization because overly aggressive optimizations can actually hurt performance or cause excessive build times.\nOther optimizations require the compiler to make a judgment call about what the “common” and “uncommon” paths in a function are.\nThe compiler must make a best guess based on static heuristics because it can’t know which cases will be common at run time.\u003c/p\u003e\n\u003cp\u003eOr can it?\u003c/p\u003e\n\u003cp\u003eWith no definitive information about how the code is used in a production environment, the compiler can operate only on the source code of packages.\nBut we do have a tool to evaluate production behavior: \u003ca href=\"/doc/diagnostics#profiling\"\u003eprofiling\u003c/a\u003e.\nIf we provide a profile to the compiler, it can make more informed decisions: more aggressively optimizing the most frequently used functions, or more accurately selecting common cases.\u003c/p\u003e\n\u003cp\u003eUsing profiles of application behavior for compiler optimization is known as \u003cem\u003eProfile-Guided Optimization (PGO)\u003c/em\u003e (also known as Feedback-Directed Optimization (FDO)).\u003c/p\u003e\n\u003ch2 id=\"example\"\u003eExample\u003c/h2\u003e\n\u003cp\u003eLet’s build a service that converts Markdown to HTML: users upload Markdown source to \u003ccode\u003e/render\u003c/code\u003e, which returns the HTML conversion.\nWe can use \u003ca href=\"https://pkg.go.dev/gitlab.com/golang-commonmark/markdown\" rel=\"noreferrer\" target=\"_blank\"\u003e\u003ccode\u003egitlab.com/golang-commonmark/markdown\u003c/code\u003e\u003c/a\u003e to implement this easily.\u003c/p\u003e\n\u003ch3 id=\"set-up\"\u003eSet up\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e$ go mod init example.com/markdown\n$ go get gitlab.com/golang-commonmark/markdown@bf3e522c626a\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn \u003ccode\u003emain.go\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epackage main\n\nimport (\n    \u0026#34;bytes\u0026#34;\n    \u0026#34;io\u0026#34;\n    \u0026#34;log\u0026#34;\n    \u0026#34;net/http\u0026#34;\n    _ \u0026#34;net/http/pprof\u0026#34;\n\n    \u0026#34;gitlab.com/golang-commonmark/markdown\u0026#34;\n)\n\nfunc render(w http.ResponseWriter, r *http.Request) {\n    if r.Method != \u0026#34;POST\u0026#34; {\n        http.Error(w, \u0026#34;Only POST allowed\u0026#34;, http.StatusMethodNotAllowed)\n        return\n    }\n\n    src, err := io.ReadAll(r.Body)\n    if err != nil {\n        log.Printf(\u0026#34;error reading body: %v\u0026#34;, err)\n        http.Error(w, \u0026#34;Internal Server Error\u0026#34;, http.StatusInternalServerError)\n        return\n    }\n\n    md := markdown.New(\n        markdown.XHTMLOutput(true),\n        markdown.Typographer(true),\n        markdown.Linkify(true),\n        markdown.Tables(true),\n    )\n\n    var buf bytes.Buffer\n    if err := md.Render(\u0026amp;buf, src); err != nil {\n        log.Printf(\u0026#34;error converting markdown: %v\u0026#34;, err)\n        http.Error(w, \u0026#34;Malformed markdown\u0026#34;, http.StatusBadRequest)\n        return\n    }\n\n    if _, err := io.Copy(w, \u0026amp;buf); err != nil {\n        log.Printf(\u0026#34;error writing response: %v\u0026#34;, err)\n        http.Error(w, \u0026#34;Internal Server Error\u0026#34;, http.StatusInternalServerError)\n        return\n    }\n}\n\nfunc main() {\n    http.HandleFunc(\u0026#34;/render\u0026#34;, render)\n    log.Printf(\u0026#34;Serving on port 8080...\u0026#34;)\n    log.Fatal(http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil))\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eBuild and run the server:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go build -o markdown.nopgo.exe\n$ ./markdown.nopgo.exe\n2023/08/23 03:55:51 Serving on port 8080...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eLet’s try sending some Markdown from another terminal.\nWe can use the \u003ccode\u003eREADME.md\u003c/code\u003e from the Go project as a sample document:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ curl -o README.md -L \u0026#34;https://raw.githubusercontent.com/golang/go/c16c2c49e2fa98ae551fc6335215fadd62d33542/README.md\u0026#34;\n$ curl --data-binary @README.md http://localhost:8080/render\n\u0026lt;h1\u0026gt;The Go Programming Language\u0026lt;/h1\u0026gt;\n\u0026lt;p\u0026gt;Go is an open source programming language that makes it easy to build simple,\nreliable, and efficient software.\u0026lt;/p\u0026gt;\n...\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"profiling\"\u003eProfiling\u003c/h3\u003e\n\u003cp\u003eNow that we have a working service, let’s collect a profile and rebuild with PGO to see if we get better performance.\u003c/p\u003e\n\u003cp\u003eIn \u003ccode\u003emain.go\u003c/code\u003e, we imported \u003ca href=\"https://pkg.go.dev/net/http/pprof\" rel=\"noreferrer\" target=\"_blank\"\u003enet/http/pprof\u003c/a\u003e which automatically adds a \u003ccode\u003e/debug/pprof/profile\u003c/code\u003e endpoint to the server for fetching a CPU profile.\u003c/p\u003e\n\u003cp\u003eNormally you want to collect a profile from your production environment so that the compiler gets a representative view of behavior in production.\nSince this example doesn’t have a “production” environment, I have created a \u003ca href=\"https://github.com/prattmic/markdown-pgo/blob/main/load/main.go\" rel=\"noreferrer\" target=\"_blank\"\u003esimple program\u003c/a\u003e to generate load while we collect a profile.\nFetch and start the load generator (make sure the server is still running!):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go run github.com/prattmic/markdown-pgo/load@latest\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhile that is running, download a profile from the server:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ curl -o cpu.pprof \u0026#34;http://localhost:8080/debug/pprof/profile?seconds=30\u0026#34;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce this completes, kill the load generator and the server.\u003c/p\u003e\n\u003ch3 id=\"using-the-profile\"\u003eUsing the profile\u003c/h3\u003e\n\u003cp\u003eThe Go toolchain will automatically enable PGO when it finds a profile named \u003ccode\u003edefault.pgo\u003c/code\u003e in the main package directory.\nAlternatively, the \u003ccode\u003e-pgo\u003c/code\u003e flag to \u003ccode\u003ego build\u003c/code\u003e takes a path to a profile to use for PGO.\u003c/p\u003e\n\u003cp\u003eWe recommend committing \u003ccode\u003edefault.pgo\u003c/code\u003e files to your repository.\nStoring profiles alongside your source code ensures that users automatically have access to the profile simply by fetching the repository (either via the version control system, or via \u003ccode\u003ego get\u003c/code\u003e) and that builds remain reproducible.\u003c/p\u003e\n\u003cp\u003eLet’s build:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ mv cpu.pprof default.pgo\n$ go build -o markdown.withpgo.exe\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe can check that PGO was enabled in the build with \u003ccode\u003ego version\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go version -m markdown.withpgo.exe\n./markdown.withpgo.exe: go1.21.0\n...\n        build   -pgo=/tmp/pgo121/default.pgo\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"evaluation\"\u003eEvaluation\u003c/h3\u003e\n\u003cp\u003eWe will use a Go benchmark \u003ca href=\"https://github.com/prattmic/markdown-pgo/blob/main/load/bench_test.go\" rel=\"noreferrer\" target=\"_blank\"\u003eversion of the load generator\u003c/a\u003e to evaluate the effect of PGO on performance.\u003c/p\u003e\n\u003cp\u003eFirst, we will benchmark the server without PGO.\nStart that server:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ ./markdown.nopgo.exe\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhile that is running, run several benchmark iterations:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go get github.com/prattmic/markdown-pgo@latest\n$ go test github.com/prattmic/markdown-pgo/load -bench=. -count=40 -source $(pwd)/README.md \u0026gt; nopgo.txt\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce that completes, kill the original server and start the version with PGO:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ ./markdown.withpgo.exe\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhile that is running, run several benchmark iterations:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go test github.com/prattmic/markdown-pgo/load -bench=. -count=40 -source $(pwd)/README.md \u0026gt; withpgo.txt\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce that completes, let’s compare the results:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go install golang.org/x/perf/cmd/benchstat@latest\n$ benchstat nopgo.txt withpgo.txt\ngoos: linux\ngoarch: amd64\npkg: github.com/prattmic/markdown-pgo/load\ncpu: Intel(R) Xeon(R) W-2135 CPU @ 3.70GHz\n        │  nopgo.txt  │            withpgo.txt             │\n        │   sec/op    │   sec/op     vs base               │\nLoad-12   374.5µ ± 1%   360.2µ ± 0%  -3.83% (p=0.000 n=40)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe new version is around 3.8% faster!\nIn Go 1.21, workloads typically get between 2% and 7% CPU usage improvements from enabling PGO.\nProfiles contain a wealth of information about application behavior and Go 1.21 just begins to crack the surface by using this information for a limited set of optimizations.\nFuture releases will continue improving performance as more parts of the compiler take advantage of PGO.\u003c/p\u003e\n\u003ch2 id=\"next-steps\"\u003eNext steps\u003c/h2\u003e\n\u003cp\u003eIn this example, after collecting a profile, we rebuilt our server using the exact same source code used in the original build.\nIn a real-world scenario, there is always ongoing development.\nSo we may collect a profile from production, which is running last week’s code, and use it to build with today’s source code.\nThat is perfectly fine!\nPGO in Go can handle minor changes to source code without issue.\nOf course, over time source code will drift more and more, so it is still important to update the profile occasionally.\u003c/p\u003e\n\u003cp\u003eFor much more information on using PGO, best practices and caveats to be aware of, please see the \u003ca href=\"/doc/pgo\"\u003eprofile-guided optimization user guide\u003c/a\u003e.\nIf you are curious about what is going on under the hood, keep reading!\u003c/p\u003e\n\u003ch2 id=\"under-the-hood\"\u003eUnder the hood\u003c/h2\u003e\n\u003cp\u003eTo get a better understanding of what made this application faster, let’s take a look under the hood to see how performance has changed.\nWe are going to take a look at two different PGO-driven optimizations.\u003c/p\u003e\n\u003ch3 id=\"inlining\"\u003eInlining\u003c/h3\u003e\n\u003cp\u003eTo observe inlining improvements, let’s analyze this markdown application both with and without PGO.\u003c/p\u003e\n\u003cp\u003eI will compare this using a technique called differential profiling, where we collect two profiles (one with PGO and one without) and compare them.\nFor differential profiling, it’s important that both profiles represent the same amount of \u003cstrong\u003ework\u003c/strong\u003e, not the same amount of time, so I’ve adjusted the server to automatically collect profiles, and the load generator to send a fixed number of requests and then exit the server.\u003c/p\u003e\n\u003cp\u003eThe changes I have made to the server as well as the profiles collected can be found at \u003ca href=\"https://github.com/prattmic/markdown-pgo\" rel=\"noreferrer\" target=\"_blank\"\u003ehttps://github.com/prattmic/markdown-pgo\u003c/a\u003e.\nThe load generator was run with \u003ccode\u003e-count=300000 -quit\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eAs a quick consistency check, let’s take a look at the total CPU time required to handle all 300k requests:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go tool pprof -top cpu.nopgo.pprof | grep \u0026#34;Total samples\u0026#34;\nDuration: 116.92s, Total samples = 118.73s (101.55%)\n$ go tool pprof -top cpu.withpgo.pprof | grep \u0026#34;Total samples\u0026#34;\nDuration: 113.91s, Total samples = 115.03s (100.99%)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCPU time dropped from ~118s to ~115s, or about 3%.\nThis is in line with our benchmark results, which is a good sign that these profiles are representative.\u003c/p\u003e\n\u003cp\u003eNow we can open a differential profile to look for savings:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go tool pprof -diff_base cpu.nopgo.pprof cpu.withpgo.pprof\nFile: markdown.profile.withpgo.exe\nType: cpu\nTime: Aug 28, 2023 at 10:26pm (EDT)\nDuration: 230.82s, Total samples = 118.73s (51.44%)\nEntering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options)\n(pprof) top -cum\nShowing nodes accounting for -0.10s, 0.084% of 118.73s total\nDropped 268 nodes (cum \u0026lt;= 0.59s)\nShowing top 10 nodes out of 668\n      flat  flat%   sum%        cum   cum%\n    -0.03s 0.025% 0.025%     -2.56s  2.16%  gitlab.com/golang-commonmark/markdown.ruleLinkify\n     0.04s 0.034% 0.0084%     -2.19s  1.84%  net/http.(*conn).serve\n     0.02s 0.017% 0.025%     -1.82s  1.53%  gitlab.com/golang-commonmark/markdown.(*Markdown).Render\n     0.02s 0.017% 0.042%     -1.80s  1.52%  gitlab.com/golang-commonmark/markdown.(*Markdown).Parse\n    -0.03s 0.025% 0.017%     -1.71s  1.44%  runtime.mallocgc\n    -0.07s 0.059% 0.042%     -1.62s  1.36%  net/http.(*ServeMux).ServeHTTP\n     0.04s 0.034% 0.0084%     -1.58s  1.33%  net/http.serverHandler.ServeHTTP\n    -0.01s 0.0084% 0.017%     -1.57s  1.32%  main.render\n     0.01s 0.0084% 0.0084%     -1.56s  1.31%  net/http.HandlerFunc.ServeHTTP\n    -0.09s 0.076% 0.084%     -1.25s  1.05%  runtime.newobject\n(pprof) top\nShowing nodes accounting for -1.41s, 1.19% of 118.73s total\nDropped 268 nodes (cum \u0026lt;= 0.59s)\nShowing top 10 nodes out of 668\n      flat  flat%   sum%        cum   cum%\n    -0.46s  0.39%  0.39%     -0.91s  0.77%  runtime.scanobject\n    -0.40s  0.34%  0.72%     -0.40s  0.34%  runtime.nextFreeFast (inline)\n     0.36s   0.3%  0.42%      0.36s   0.3%  gitlab.com/golang-commonmark/markdown.performReplacements\n    -0.35s  0.29%  0.72%     -0.37s  0.31%  runtime.writeHeapBits.flush\n     0.32s  0.27%  0.45%      0.67s  0.56%  gitlab.com/golang-commonmark/markdown.ruleReplacements\n    -0.31s  0.26%  0.71%     -0.29s  0.24%  runtime.writeHeapBits.write\n    -0.30s  0.25%  0.96%     -0.37s  0.31%  runtime.deductAssistCredit\n     0.29s  0.24%  0.72%      0.10s 0.084%  gitlab.com/golang-commonmark/markdown.ruleText\n    -0.29s  0.24%  0.96%     -0.29s  0.24%  runtime.(*mspan).base (inline)\n    -0.27s  0.23%  1.19%     -0.42s  0.35%  bytes.(*Buffer).WriteRune\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhen specifying \u003ccode\u003epprof -diff_base\u003c/code\u003e, the values in displayed in pprof are the \u003cem\u003edifference\u003c/em\u003e between the two profiles.\nSo, for instance, \u003ccode\u003eruntime.scanobject\u003c/code\u003e used 0.46s less CPU time with PGO than without.\nOn the other hand, \u003ccode\u003egitlab.com/golang-commonmark/markdown.performReplacements\u003c/code\u003e used 0.36s more CPU time.\nIn a differential profile, we typically want to look at the absolute values (\u003ccode\u003eflat\u003c/code\u003e and \u003ccode\u003ecum\u003c/code\u003e columns), as the percentages aren’t meaningful.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003etop -cum\u003c/code\u003e shows the top differences by cumulative change.\nThat is, the difference in CPU of a function and all transitive callees from that function.\nThis will generally show the outermost frames in our program’s call graph, such as \u003ccode\u003emain\u003c/code\u003e or another goroutine entry point.\nHere we can see most savings are coming from the \u003ccode\u003eruleLinkify\u003c/code\u003e portion of handling HTTP requests.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003etop\u003c/code\u003e shows the top differences limited only to changes in the function itself.\nThis will generally show inner frames in our program’s call graph, where most of the actual work is happening.\nHere we can see that individual savings are coming mostly from \u003ccode\u003eruntime\u003c/code\u003e functions.\u003c/p\u003e\n\u003cp\u003eWhat are those? Let’s peek up the call stack to see where they come from:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e(pprof) peek scanobject$\nShowing nodes accounting for -3.72s, 3.13% of 118.73s total\n----------------------------------------------------------+-------------\n      flat  flat%   sum%        cum   cum%   calls calls% + context\n----------------------------------------------------------+-------------\n                                            -0.86s 94.51% |   runtime.gcDrain\n                                            -0.09s  9.89% |   runtime.gcDrainN\n                                             0.04s  4.40% |   runtime.markrootSpans\n    -0.46s  0.39%  0.39%     -0.91s  0.77%                | runtime.scanobject\n                                            -0.19s 20.88% |   runtime.greyobject\n                                            -0.13s 14.29% |   runtime.heapBits.nextFast (inline)\n                                            -0.08s  8.79% |   runtime.heapBits.next\n                                            -0.08s  8.79% |   runtime.spanOfUnchecked (inline)\n                                             0.04s  4.40% |   runtime.heapBitsForAddr\n                                            -0.01s  1.10% |   runtime.findObject\n----------------------------------------------------------+-------------\n(pprof) peek gcDrain$\nShowing nodes accounting for -3.72s, 3.13% of 118.73s total\n----------------------------------------------------------+-------------\n      flat  flat%   sum%        cum   cum%   calls calls% + context\n----------------------------------------------------------+-------------\n                                               -1s   100% |   runtime.gcBgMarkWorker.func2\n     0.15s  0.13%  0.13%        -1s  0.84%                | runtime.gcDrain\n                                            -0.86s 86.00% |   runtime.scanobject\n                                            -0.18s 18.00% |   runtime.(*gcWork).balance\n                                            -0.11s 11.00% |   runtime.(*gcWork).tryGet\n                                             0.09s  9.00% |   runtime.pollWork\n                                            -0.03s  3.00% |   runtime.(*gcWork).tryGetFast (inline)\n                                            -0.03s  3.00% |   runtime.markroot\n                                            -0.02s  2.00% |   runtime.wbBufFlush\n                                             0.01s  1.00% |   runtime/internal/atomic.(*Bool).Load (inline)\n                                            -0.01s  1.00% |   runtime.gcFlushBgCredit\n                                            -0.01s  1.00% |   runtime/internal/atomic.(*Int64).Add (inline)\n----------------------------------------------------------+-------------\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSo \u003ccode\u003eruntime.scanobject\u003c/code\u003e is ultimately coming from \u003ccode\u003eruntime.gcBgMarkWorker\u003c/code\u003e.\nThe \u003ca href=\"/doc/gc-guide#Identiying_costs\"\u003eGo GC Guide\u003c/a\u003e tells us that \u003ccode\u003eruntime.gcBgMarkWorker\u003c/code\u003e is part of the garbage collector, so \u003ccode\u003eruntime.scanobject\u003c/code\u003e savings must be GC savings.\nWhat about \u003ccode\u003enextFreeFast\u003c/code\u003e and other \u003ccode\u003eruntime\u003c/code\u003e functions?\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e(pprof) peek nextFreeFast$\nShowing nodes accounting for -3.72s, 3.13% of 118.73s total\n----------------------------------------------------------+-------------\n      flat  flat%   sum%        cum   cum%   calls calls% + context\n----------------------------------------------------------+-------------\n                                            -0.40s   100% |   runtime.mallocgc (inline)\n    -0.40s  0.34%  0.34%     -0.40s  0.34%                | runtime.nextFreeFast\n----------------------------------------------------------+-------------\n(pprof) peek writeHeapBits\nShowing nodes accounting for -3.72s, 3.13% of 118.73s total\n----------------------------------------------------------+-------------\n      flat  flat%   sum%        cum   cum%   calls calls% + context\n----------------------------------------------------------+-------------\n                                            -0.37s   100% |   runtime.heapBitsSetType\n                                                 0     0% |   runtime.(*mspan).initHeapBits\n    -0.35s  0.29%  0.29%     -0.37s  0.31%                | runtime.writeHeapBits.flush\n                                            -0.02s  5.41% |   runtime.arenaIndex (inline)\n----------------------------------------------------------+-------------\n                                            -0.29s   100% |   runtime.heapBitsSetType\n    -0.31s  0.26%  0.56%     -0.29s  0.24%                | runtime.writeHeapBits.write\n                                             0.02s  6.90% |   runtime.arenaIndex (inline)\n----------------------------------------------------------+-------------\n(pprof) peek heapBitsSetType$\nShowing nodes accounting for -3.72s, 3.13% of 118.73s total\n----------------------------------------------------------+-------------\n      flat  flat%   sum%        cum   cum%   calls calls% + context\n----------------------------------------------------------+-------------\n                                            -0.82s   100% |   runtime.mallocgc\n    -0.12s   0.1%   0.1%     -0.82s  0.69%                | runtime.heapBitsSetType\n                                            -0.37s 45.12% |   runtime.writeHeapBits.flush\n                                            -0.29s 35.37% |   runtime.writeHeapBits.write\n                                            -0.03s  3.66% |   runtime.readUintptr (inline)\n                                            -0.01s  1.22% |   runtime.writeHeapBitsForAddr (inline)\n----------------------------------------------------------+-------------\n(pprof) peek deductAssistCredit$\nShowing nodes accounting for -3.72s, 3.13% of 118.73s total\n----------------------------------------------------------+-------------\n      flat  flat%   sum%        cum   cum%   calls calls% + context\n----------------------------------------------------------+-------------\n                                            -0.37s   100% |   runtime.mallocgc\n    -0.30s  0.25%  0.25%     -0.37s  0.31%                | runtime.deductAssistCredit\n                                            -0.07s 18.92% |   runtime.gcAssistAlloc\n----------------------------------------------------------+-------------\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eLooks like \u003ccode\u003enextFreeFast\u003c/code\u003e and some of the others in the top 10 are ultimately coming from \u003ccode\u003eruntime.mallocgc\u003c/code\u003e, which the GC Guide tells us is the memory allocator.\u003c/p\u003e\n\u003cp\u003eReduced costs in the GC and allocator imply that we are allocating less overall.\nLet’s take a look at the heap profiles for insight:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go tool pprof -sample_index=alloc_objects -diff_base heap.nopgo.pprof heap.withpgo.pprof\nFile: markdown.profile.withpgo.exe\nType: alloc_objects\nTime: Aug 28, 2023 at 10:28pm (EDT)\nEntering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options)\n(pprof) top\nShowing nodes accounting for -12044903, 8.29% of 145309950 total\nDropped 60 nodes (cum \u0026lt;= 726549)\nShowing top 10 nodes out of 58\n      flat  flat%   sum%        cum   cum%\n  -4974135  3.42%  3.42%   -4974135  3.42%  gitlab.com/golang-commonmark/mdurl.Parse\n  -4249044  2.92%  6.35%   -4249044  2.92%  gitlab.com/golang-commonmark/mdurl.(*URL).String\n   -901135  0.62%  6.97%    -977596  0.67%  gitlab.com/golang-commonmark/puny.mapLabels\n   -653998  0.45%  7.42%    -482491  0.33%  gitlab.com/golang-commonmark/markdown.(*StateInline).PushPending\n   -557073  0.38%  7.80%    -557073  0.38%  gitlab.com/golang-commonmark/linkify.Links\n   -557073  0.38%  8.18%    -557073  0.38%  strings.genSplit\n   -436919   0.3%  8.48%    -232152  0.16%  gitlab.com/golang-commonmark/markdown.(*StateBlock).Lines\n   -408617  0.28%  8.77%    -408617  0.28%  net/textproto.readMIMEHeader\n    401432  0.28%  8.49%     499610  0.34%  bytes.(*Buffer).grow\n    291659   0.2%  8.29%     291659   0.2%  bytes.(*Buffer).String (inline)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003e-sample_index=alloc_objects\u003c/code\u003e option is showing us the count of allocations, regardless of size.\nThis is useful since we are investigating a decrease in CPU usage, which tends to correlate more with allocation count rather than size.\nThere are quite a few reductions here, but let’s focus on the biggest reduction, \u003ccode\u003emdurl.Parse\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eFor reference, let’s look at the total allocation counts for this function without PGO:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go tool pprof -sample_index=alloc_objects -top heap.nopgo.pprof | grep mdurl.Parse\n   4974135  3.42% 68.60%    4974135  3.42%  gitlab.com/golang-commonmark/mdurl.Parse\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe total count before was 4974135, meaning that \u003ccode\u003emdurl.Parse\u003c/code\u003e has eliminated 100% of allocations!\u003c/p\u003e\n\u003cp\u003eBack in the differential profile, let’s gather a bit more context:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e(pprof) peek mdurl.Parse\nShowing nodes accounting for -12257184, 8.44% of 145309950 total\n----------------------------------------------------------+-------------\n      flat  flat%   sum%        cum   cum%   calls calls% + context\n----------------------------------------------------------+-------------\n                                          -2956806 59.44% |   gitlab.com/golang-commonmark/markdown.normalizeLink\n                                          -2017329 40.56% |   gitlab.com/golang-commonmark/markdown.normalizeLinkText\n  -4974135  3.42%  3.42%   -4974135  3.42%                | gitlab.com/golang-commonmark/mdurl.Parse\n----------------------------------------------------------+-------------\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe calls to \u003ccode\u003emdurl.Parse\u003c/code\u003e are coming from \u003ccode\u003emarkdown.normalizeLink\u003c/code\u003e and \u003ccode\u003emarkdown.normalizeLinkText\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e(pprof) list mdurl.Parse\nTotal: 145309950\nROUTINE ======================== gitlab.com/golang-commonmark/mdurl.Parse in /usr/local/google/home/mpratt/go/pkg/mod/gitlab.com/golang-commonmark/mdurl@v0.0.0-20191124015652-932350d1cb84/parse\n.go\n  -4974135   -4974135 (flat, cum)  3.42% of Total\n         .          .     60:func Parse(rawurl string) (*URL, error) {\n         .          .     61:   n, err := findScheme(rawurl)\n         .          .     62:   if err != nil {\n         .          .     63:           return nil, err\n         .          .     64:   }\n         .          .     65:\n  -4974135   -4974135     66:   var url URL\n         .          .     67:   rest := rawurl\n         .          .     68:   hostless := false\n         .          .     69:   if n \u0026gt; 0 {\n         .          .     70:           url.RawScheme = rest[:n]\n         .          .     71:           url.Scheme, rest = strings.ToLower(rest[:n]), rest[n+1:]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFull source for these functions and callers can be found at:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://gitlab.com/golang-commonmark/mdurl/-/blob/bd573caec3d827ead19e40b1f141a3802d956710/parse.go#L60\" rel=\"noreferrer\" target=\"_blank\"\u003e\u003ccode\u003emdurl.Parse\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://gitlab.com/golang-commonmark/markdown/-/blob/fd7971701a0cab12e9347109a4c889f5c0a1a479/util.go#L53\" rel=\"noreferrer\" target=\"_blank\"\u003e\u003ccode\u003emarkdown.normalizeLink\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://gitlab.com/golang-commonmark/markdown/-/blob/fd7971701a0cab12e9347109a4c889f5c0a1a479/util.go#L68\" rel=\"noreferrer\" target=\"_blank\"\u003e\u003ccode\u003emarkdown.normalizeLinkText\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSo what happened here? In a non-PGO build, \u003ccode\u003emdurl.Parse\u003c/code\u003e is considered too large to be eligible for inlining.\nHowever, because our PGO profile indicated that the calls to this function were hot, the compiler did inline them.\nWe can see this from the “(inline)” annotation in the profiles:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go tool pprof -top cpu.nopgo.pprof | grep mdurl.Parse\n     0.36s   0.3% 63.76%      2.75s  2.32%  gitlab.com/golang-commonmark/mdurl.Parse\n$ go tool pprof -top cpu.withpgo.pprof | grep mdurl.Parse\n     0.55s  0.48% 58.12%      2.03s  1.76%  gitlab.com/golang-commonmark/mdurl.Parse (inline)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ccode\u003emdurl.Parse\u003c/code\u003e creates a \u003ccode\u003eURL\u003c/code\u003e as a local variable on line 66 (\u003ccode\u003evar url URL\u003c/code\u003e), and then returns a pointer to that variable on line 145 (\u003ccode\u003ereturn \u0026amp;url, nil\u003c/code\u003e).\nNormally this requires the variable to be allocated on the heap, as a reference to it lives beyond function return.\nHowever, once \u003ccode\u003emdurl.Parse\u003c/code\u003e is inlined into \u003ccode\u003emarkdown.normalizeLink\u003c/code\u003e, the compiler can observe that the variable does not escape \u003ccode\u003enormalizeLink\u003c/code\u003e, which allows the compiler to allocate it on the stack.\n\u003ccode\u003emarkdown.normalizeLinkText\u003c/code\u003e is similar to \u003ccode\u003emarkdown.normalizeLink\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eThe second largest reduction shown in the profile, from \u003ccode\u003emdurl.(*URL).String\u003c/code\u003e is a similar case of eliminating an escape after inlining.\u003c/p\u003e\n\u003cp\u003eIn these cases, we got improved performance through fewer heap allocations.\nPart of the power of PGO and compiler optimizations in general is that effects on allocations are not part of the compiler’s PGO implementation at all.\nThe only change that PGO made was to allow inlining of these hot function calls.\nAll of the effects to escape analysis and heap allocation were standard optimizations that apply to any build.\nImproved escape behavior is a great downstream effect of inlining, but it is not the only effect.\nMany optimizations can take advantage of inlining.\nFor example, constant propagation may be able to simplify the code in a function after inlining when some of the inputs are constants.\u003c/p\u003e\n\u003ch3 id=\"devirtualization\"\u003eDevirtualization\u003c/h3\u003e\n\u003cp\u003eIn addition to inling, which we saw in the example above, PGO can also drive conditional devirtualization of interface calls.\u003c/p\u003e\n\u003cp\u003eBefore getting to PGO-driven devirtualization, let’s step back and define “devirtualization” in general.\nSuppose you have code that looks like something like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ef, _ := os.Open(\u0026#34;foo.txt\u0026#34;)\nvar r io.Reader = f\nr.Read(b)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eHere we have a call to the \u003ccode\u003eio.Reader\u003c/code\u003e interface method \u003ccode\u003eRead\u003c/code\u003e.\nSince interfaces can have multiple implementations, the compiler generates an \u003cem\u003eindirect\u003c/em\u003e function call, meaning it looks up the correct method to call at run time from the type in the interface value.\nIndirect calls have a small additional runtime cost compared to direct calls, but more importantly they preclude some compiler optimizations.\nFor example, the compiler can’t perform escape analysis on an indirect call since it doesn’t know the concrete method implementation.\u003c/p\u003e\n\u003cp\u003eBut in the example above, we \u003cem\u003edo\u003c/em\u003e know the concrete method implementation.\nIt must be \u003ccode\u003eos.(*File).Read\u003c/code\u003e, since \u003ccode\u003e*os.File\u003c/code\u003e is the only type that could possibly be assigned to \u003ccode\u003er\u003c/code\u003e.\nIn this case, the compiler will perform \u003cem\u003edevirtualization\u003c/em\u003e, where it replaces the indirect call to \u003ccode\u003eio.Reader.Read\u003c/code\u003e with a direct call to \u003ccode\u003eos.(*File).Read\u003c/code\u003e, thus allowing other optimizations.\u003c/p\u003e\n\u003cp\u003e(You are probably thinking “that code is useless, why would anyone write it that way?” This is a good point, but note that code like above could be the result of inlining.\nSuppose \u003ccode\u003ef\u003c/code\u003e is passed into a function that takes an \u003ccode\u003eio.Reader\u003c/code\u003e argument.\nOnce the function is inlined, now the \u003ccode\u003eio.Reader\u003c/code\u003e becomes concrete.)\u003c/p\u003e\n\u003cp\u003ePGO-driven devirtualization extends this concept to situations where the concrete type is not statically known, but profiling can show that, for example, an \u003ccode\u003eio.Reader.Read\u003c/code\u003e call targets \u003ccode\u003eos.(*File).Read\u003c/code\u003e most of the time.\nIn this case, PGO can replace \u003ccode\u003er.Read(b)\u003c/code\u003e with something like:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eif f, ok := r.(*os.File); ok {\n    f.Read(b)\n} else {\n    r.Read(b)\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThat is, we add a runtime check for the concrete type that is most likely to appear, and if so use a concrete call, or otherwise fall back to the standard indirect call.\nThe advantage here is that the common path (using \u003ccode\u003e*os.File\u003c/code\u003e) can be inlined and have additional optimizations applied, but we still maintain a fallback path because a profile is not a guarantee that this will always be the case.\u003c/p\u003e\n\u003cp\u003eIn our analysis of the markdown server we didn’t see PGO-driven devirtualization, but we also only looked at the top impacted areas.\nPGO (and most compiler optimizations) generally yield their benefit in the aggregate of very small improvements in lots of different places, so there is likely more happening than just what we looked at.\u003c/p\u003e\n\u003cp\u003eInlining and devirtualization are the two PGO-driven optimizations available in Go 1.21, but as we’ve seen, these often unlock additional optimizations.\nIn addition, future versions of Go will continue to improve PGO with additional optimizations.\u003c/p\u003e\n\n    \u003c/div\u003e",
  "Date": "2023-09-05T00:00:00Z",
  "Author": "Michael Pratt"
}