{
  "Source": "go.dev",
  "Title": "Profiling Go Programs",
  "Link": "https://go.dev/blog/pprof",
  "Content": "\u003cdiv class=\"Article\" data-slug=\"/blog/pprof\"\u003e\n    \n    \u003ch1 class=\"small\"\u003e\u003ca href=\"/blog/\"\u003eThe Go Blog\u003c/a\u003e\u003c/h1\u003e\n    \n\n    \u003ch1\u003eProfiling Go Programs\u003c/h1\u003e\n      \n      \u003cp class=\"author\"\u003e\n      Russ Cox, July 2011; updated by Shenghou Ma, May 2013\u003cbr/\u003e\n      24 June 2011\n      \u003c/p\u003e\n      \n      \u003cp\u003eAt Scala Days 2011, Robert Hundt presented a paper titled\n\u003ca href=\"http://research.google.com/pubs/pub37122.html\" rel=\"noreferrer\" target=\"_blank\"\u003eLoop Recognition in C++/Java/Go/Scala.\u003c/a\u003e\nThe paper implemented a specific loop finding algorithm, such as you might use\nin a flow analysis pass of a compiler, in C++, Go, Java, Scala, and then used\nthose programs to draw conclusions about typical performance concerns in these\nlanguages.\nThe Go program presented in that paper runs quite slowly, making it\nan excellent opportunity to demonstrate how to use Go’s profiling tools to take\na slow program and make it faster.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eBy using Go’s profiling tools to identify and correct specific bottlenecks, we can make the Go loop finding program run an order of magnitude faster and use 6x less memory.\u003c/em\u003e\n(Update: Due to recent optimizations of \u003ccode\u003elibstdc++\u003c/code\u003e in \u003ccode\u003egcc\u003c/code\u003e, the memory reduction is now 3.7x.)\u003c/p\u003e\n\u003cp\u003eHundt’s paper does not specify which versions of the C++, Go, Java, and Scala\ntools he used.\nIn this blog post, we will be using the most recent weekly snapshot of the \u003ccode\u003e6g\u003c/code\u003e\nGo compiler and the version of \u003ccode\u003eg++\u003c/code\u003e that ships with the Ubuntu Natty\ndistribution.\n(We will not be using Java or Scala, because we are not skilled at writing efficient\nprograms in either of those languages, so the comparison would be unfair.\nSince C++ was the fastest language in the paper, the comparisons here with C++ should\nsuffice.)\n(Update: In this updated post, we will be using the most recent development snapshot\nof the Go compiler on amd64 and the most recent version of \u003ccode\u003eg++\u003c/code\u003e – 4.8.0, which was\nreleased in March 2013.)\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go version\ngo version devel +08d20469cc20 Tue Mar 26 08:27:18 2013 +0100 linux/amd64\n$ g++ --version\ng++ (GCC) 4.8.0\nCopyright (C) 2013 Free Software Foundation, Inc.\n...\n$\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe programs are run on a computer with a 3.4GHz Core i7-2600 CPU and 16 GB of\nRAM running Gentoo Linux’s 3.8.4-gentoo kernel.\nThe machine is running with CPU frequency scaling disabled via\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ sudo bash\n# for i in /sys/devices/system/cpu/cpu[0-7]\ndo\n    echo performance \u0026gt; $i/cpufreq/scaling_governor\ndone\n#\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe’ve taken \u003ca href=\"https://github.com/hundt98847/multi-language-bench\" rel=\"noreferrer\" target=\"_blank\"\u003eHundt’s benchmark programs\u003c/a\u003e\nin C++ and Go, combined each into a single source file, and removed all but one\nline of output.\nWe’ll time the program using Linux’s \u003ccode\u003etime\u003c/code\u003e utility with a format that shows user time,\nsystem time, real time, and maximum memory usage:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ cat xtime\n#!/bin/sh\n/usr/bin/time -f \u0026#39;%Uu %Ss %er %MkB %C\u0026#39; \u0026#34;$@\u0026#34;\n$\n\n$ make havlak1cc\ng++ -O3 -o havlak1cc havlak1.cc\n$ ./xtime ./havlak1cc\n# of loops: 76002 (total 3800100)\nloop-0, nest: 0, depth: 0\n17.70u 0.05s 17.80r 715472kB ./havlak1cc\n$\n\n$ make havlak1\ngo build havlak1.go\n$ ./xtime ./havlak1\n# of loops: 76000 (including 1 artificial root node)\n25.05u 0.11s 25.20r 1334032kB ./havlak1\n$\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe C++ program runs in 17.80 seconds and uses 700 MB of memory.\nThe Go program runs in 25.20 seconds and uses 1302 MB of memory.\n(These measurements are difficult to reconcile with the ones in the paper, but the\npoint of this post is to explore how to use \u003ccode\u003ego tool pprof\u003c/code\u003e, not to reproduce the\nresults from the paper.)\u003c/p\u003e\n\u003cp\u003eTo start tuning the Go program, we have to enable profiling.\nIf the code used the \u003ca href=\"/pkg/testing/\"\u003eGo testing package\u003c/a\u003e’s\nbenchmarking support, we could use gotest’s standard \u003ccode\u003e-cpuprofile\u003c/code\u003e and \u003ccode\u003e-memprofile\u003c/code\u003e\nflags.\nIn a standalone program like this one, we have to import \u003ccode\u003eruntime/pprof\u003c/code\u003e and add a few\nlines of code:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003evar cpuprofile = flag.String(\u0026#34;cpuprofile\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;write cpu profile to file\u0026#34;)\n\nfunc main() {\n    flag.Parse()\n    if *cpuprofile != \u0026#34;\u0026#34; {\n        f, err := os.Create(*cpuprofile)\n        if err != nil {\n            log.Fatal(err)\n        }\n        pprof.StartCPUProfile(f)\n        defer pprof.StopCPUProfile()\n    }\n    ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe new code defines a flag named \u003ccode\u003ecpuprofile\u003c/code\u003e, calls the\n\u003ca href=\"/pkg/flag/\"\u003eGo flag library\u003c/a\u003e to parse the command line flags,\nand then, if the \u003ccode\u003ecpuprofile\u003c/code\u003e flag has been set on the command line,\n\u003ca href=\"/pkg/runtime/pprof/#StartCPUProfile\"\u003estarts CPU profiling\u003c/a\u003e\nredirected to that file.\nThe profiler requires a final call to\n\u003ca href=\"/pkg/runtime/pprof/#StopCPUProfile\"\u003e\u003ccode\u003eStopCPUProfile\u003c/code\u003e\u003c/a\u003e to\nflush any pending writes to the file before the program exits; we use \u003ccode\u003edefer\u003c/code\u003e\nto make sure this happens as \u003ccode\u003emain\u003c/code\u003e returns.\u003c/p\u003e\n\u003cp\u003eAfter adding that code, we can run the program with the new \u003ccode\u003e-cpuprofile\u003c/code\u003e flag\nand then run \u003ccode\u003ego tool pprof\u003c/code\u003e to interpret the profile.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ make havlak1.prof\n./havlak1 -cpuprofile=havlak1.prof\n# of loops: 76000 (including 1 artificial root node)\n$ go tool pprof havlak1 havlak1.prof\nWelcome to pprof!  For help, type \u0026#39;help\u0026#39;.\n(pprof)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003ego tool pprof\u003c/code\u003e program is a slight variant of\n\u003ca href=\"https://github.com/gperftools/gperftools\" rel=\"noreferrer\" target=\"_blank\"\u003eGoogle’s \u003ccode\u003epprof\u003c/code\u003e C++ profiler\u003c/a\u003e.\nThe most important command is \u003ccode\u003etopN\u003c/code\u003e, which shows the top \u003ccode\u003eN\u003c/code\u003e samples in the profile:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e(pprof) top10\nTotal: 2525 samples\n     298  11.8%  11.8%      345  13.7% runtime.mapaccess1_fast64\n     268  10.6%  22.4%     2124  84.1% main.FindLoops\n     251   9.9%  32.4%      451  17.9% scanblock\n     178   7.0%  39.4%      351  13.9% hash_insert\n     131   5.2%  44.6%      158   6.3% sweepspan\n     119   4.7%  49.3%      350  13.9% main.DFS\n      96   3.8%  53.1%       98   3.9% flushptrbuf\n      95   3.8%  56.9%       95   3.8% runtime.aeshash64\n      95   3.8%  60.6%      101   4.0% runtime.settype_flush\n      88   3.5%  64.1%      988  39.1% runtime.mallocgc\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhen CPU profiling is enabled, the Go program stops about 100 times per second\nand records a sample consisting of the program counters on the currently executing\ngoroutine’s stack.\nThe profile has 2525 samples, so it was running for a bit over 25 seconds.\nIn the \u003ccode\u003ego tool pprof\u003c/code\u003e output, there is a row for each function that appeared in\na sample.\nThe first two columns show the number of samples in which the function was running\n(as opposed to waiting for a called function to return), as a raw count and as a\npercentage of total samples.\nThe \u003ccode\u003eruntime.mapaccess1_fast64\u003c/code\u003e function was running during 298 samples, or 11.8%.\nThe \u003ccode\u003etop10\u003c/code\u003e output is sorted by this sample count.\nThe third column shows the running total during the listing:\nthe first three rows account for 32.4% of the samples.\nThe fourth and fifth columns show the number of samples in which the function appeared\n(either running or waiting for a called function to return).\nThe \u003ccode\u003emain.FindLoops\u003c/code\u003e function was running in 10.6% of the samples, but it was on the\ncall stack (it or functions it called were running) in 84.1% of the samples.\u003c/p\u003e\n\u003cp\u003eTo sort by the fourth and fifth columns, use the \u003ccode\u003e-cum\u003c/code\u003e (for cumulative) flag:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e(pprof) top5 -cum\nTotal: 2525 samples\n       0   0.0%   0.0%     2144  84.9% gosched0\n       0   0.0%   0.0%     2144  84.9% main.main\n       0   0.0%   0.0%     2144  84.9% runtime.main\n       0   0.0%   0.0%     2124  84.1% main.FindHavlakLoops\n     268  10.6%  10.6%     2124  84.1% main.FindLoops\n(pprof) top5 -cum\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn fact the total for \u003ccode\u003emain.FindLoops\u003c/code\u003e and \u003ccode\u003emain.main\u003c/code\u003e should have been 100%, but\neach stack sample only includes the bottom 100 stack frames; during about a quarter\nof the samples, the recursive \u003ccode\u003emain.DFS\u003c/code\u003e function was more than 100 frames deeper\nthan \u003ccode\u003emain.main\u003c/code\u003e so the complete trace was truncated.\u003c/p\u003e\n\u003cp\u003eThe stack trace samples contain more interesting data about function call relationships\nthan the text listings can show.\nThe \u003ccode\u003eweb\u003c/code\u003e command writes a graph of the profile data in SVG format and opens it in a web\nbrowser.\n(There is also a \u003ccode\u003egv\u003c/code\u003e command that writes PostScript and opens it in Ghostview.\nFor either command, you need \u003ca href=\"http://www.graphviz.org/\" rel=\"noreferrer\" target=\"_blank\"\u003egraphviz\u003c/a\u003e installed.)\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e(pprof) web\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eA small fragment of\n\u003ca href=\"https://rawgit.com/rsc/benchgraffiti/master/havlak/havlak1.svg\" rel=\"noreferrer\" target=\"_blank\"\u003ethe full graph\u003c/a\u003e looks like:\u003c/p\u003e\n\u003cdiv class=\"image\"\u003e\n  \u003cimg src=\"pprof/havlak1a-75.png\" alt=\"\"/\u003e\n\u003c/div\u003e\n\u003cp\u003eEach box in the graph corresponds to a single function, and the boxes are sized\naccording to the number of samples in which the function was running.\nAn edge from box X to box Y indicates that X calls Y; the number along the edge is\nthe number of times that call appears in a sample.\nIf a call appears multiple times in a single sample, such as during recursive function\ncalls, each appearance counts toward the edge weight.\nThat explains the 21342 on the self-edge from \u003ccode\u003emain.DFS\u003c/code\u003e to itself.\u003c/p\u003e\n\u003cp\u003eJust at a glance, we can see that the program spends much of its time in hash\noperations, which correspond to use of Go’s \u003ccode\u003emap\u003c/code\u003e values.\nWe can tell \u003ccode\u003eweb\u003c/code\u003e to use only samples that include a specific function, such as\n\u003ccode\u003eruntime.mapaccess1_fast64\u003c/code\u003e, which clears some of the noise from the graph:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e(pprof) web mapaccess1\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"image\"\u003e\n  \u003cimg src=\"pprof/havlak1-hash_lookup-75.png\" alt=\"\"/\u003e\n\u003c/div\u003e\n\u003cp\u003eIf we squint, we can see that the calls to \u003ccode\u003eruntime.mapaccess1_fast64\u003c/code\u003e are being\nmade by \u003ccode\u003emain.FindLoops\u003c/code\u003e and \u003ccode\u003emain.DFS\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eNow that we have a rough idea of the big picture, it’s time to zoom in on a particular\nfunction.\nLet’s look at \u003ccode\u003emain.DFS\u003c/code\u003e first, just because it is a shorter function:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e(pprof) list DFS\nTotal: 2525 samples\nROUTINE ====================== main.DFS in /home/rsc/g/benchgraffiti/havlak/havlak1.go\n   119    697 Total samples (flat / cumulative)\n     3      3  240: func DFS(currentNode *BasicBlock, nodes []*UnionFindNode, number map[*BasicBlock]int, last []int, current int) int {\n     1      1  241:     nodes[current].Init(currentNode, current)\n     1     37  242:     number[currentNode] = current\n     .      .  243:\n     1      1  244:     lastid := current\n    89     89  245:     for _, target := range currentNode.OutEdges {\n     9    152  246:             if number[target] == unvisited {\n     7    354  247:                     lastid = DFS(target, nodes, number, last, lastid+1)\n     .      .  248:             }\n     .      .  249:     }\n     7     59  250:     last[number[currentNode]] = lastid\n     1      1  251:     return lastid\n(pprof)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe listing shows the source code for the \u003ccode\u003eDFS\u003c/code\u003e function (really, for every function\nmatching the regular expression \u003ccode\u003eDFS\u003c/code\u003e).\nThe first three columns are the number of samples taken while running that line, the\nnumber of samples taken while running that line or in code called from that line, and\nthe line number in the file.\nThe related command \u003ccode\u003edisasm\u003c/code\u003e shows a disassembly of the function instead of a source\nlisting; when there are enough samples this can help you see which instructions are\nexpensive.\nThe \u003ccode\u003eweblist\u003c/code\u003e command mixes the two modes: it shows\n\u003ca href=\"https://rawgit.com/rsc/benchgraffiti/master/havlak/havlak1.html\" rel=\"noreferrer\" target=\"_blank\"\u003ea source listing in which clicking a line shows the disassembly\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSince we already know that the time is going into map lookups implemented by the\nhash runtime functions, we care most about the second column.\nA large fraction of time is spent in recursive calls to \u003ccode\u003eDFS\u003c/code\u003e (line 247), as would be\nexpected from a recursive traversal.\nExcluding the recursion, it looks like the time is going into the accesses to the\n\u003ccode\u003enumber\u003c/code\u003e map on lines 242, 246, and 250.\nFor that particular lookup, a map is not the most efficient choice.\nJust as they would be in a compiler, the basic block structures have unique sequence\nnumbers assigned to them.\nInstead of using a \u003ccode\u003emap[*BasicBlock]int\u003c/code\u003e we can use a \u003ccode\u003e[]int\u003c/code\u003e, a slice indexed by the\nblock number.\nThere’s no reason to use a map when an array or slice will do.\u003c/p\u003e\n\u003cp\u003eChanging \u003ccode\u003enumber\u003c/code\u003e from a map to a slice requires editing seven lines in the program\nand cut its run time by nearly a factor of two:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ make havlak2\ngo build havlak2.go\n$ ./xtime ./havlak2\n# of loops: 76000 (including 1 artificial root node)\n16.55u 0.11s 16.69r 1321008kB ./havlak2\n$\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e(See the \u003ca href=\"https://github.com/rsc/benchgraffiti/commit/58ac27bcac3ffb553c29d0b3fb64745c91c95948\" rel=\"noreferrer\" target=\"_blank\"\u003ediff between \u003ccode\u003ehavlak1\u003c/code\u003e and \u003ccode\u003ehavlak2\u003c/code\u003e\u003c/a\u003e)\u003c/p\u003e\n\u003cp\u003eWe can run the profiler again to confirm that \u003ccode\u003emain.DFS\u003c/code\u003e is no longer a significant\npart of the run time:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ make havlak2.prof\n./havlak2 -cpuprofile=havlak2.prof\n# of loops: 76000 (including 1 artificial root node)\n$ go tool pprof havlak2 havlak2.prof\nWelcome to pprof!  For help, type \u0026#39;help\u0026#39;.\n(pprof)\n(pprof) top5\nTotal: 1652 samples\n     197  11.9%  11.9%      382  23.1% scanblock\n     189  11.4%  23.4%     1549  93.8% main.FindLoops\n     130   7.9%  31.2%      152   9.2% sweepspan\n     104   6.3%  37.5%      896  54.2% runtime.mallocgc\n      98   5.9%  43.5%      100   6.1% flushptrbuf\n(pprof)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe entry \u003ccode\u003emain.DFS\u003c/code\u003e no longer appears in the profile, and the rest of the program\nruntime has dropped too.\nNow the program is spending most of its time allocating memory and garbage collecting\n(\u003ccode\u003eruntime.mallocgc\u003c/code\u003e, which both allocates and runs periodic garbage collections,\naccounts for 54.2% of the time).\nTo find out why the garbage collector is running so much, we have to find out what is\nallocating memory.\nOne way is to add memory profiling to the program.\nWe’ll arrange that if the \u003ccode\u003e-memprofile\u003c/code\u003e flag is supplied, the program stops after one\niteration of the loop finding, writes a memory profile, and exits:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003evar memprofile = flag.String(\u0026#34;memprofile\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;write memory profile to this file\u0026#34;)\n...\n\n    FindHavlakLoops(cfgraph, lsgraph)\n    if *memprofile != \u0026#34;\u0026#34; {\n        f, err := os.Create(*memprofile)\n        if err != nil {\n            log.Fatal(err)\n        }\n        pprof.WriteHeapProfile(f)\n        f.Close()\n        return\n    }\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe invoke the program with \u003ccode\u003e-memprofile\u003c/code\u003e flag to write a profile:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ make havlak3.mprof\ngo build havlak3.go\n./havlak3 -memprofile=havlak3.mprof\n$\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e(See the \u003ca href=\"https://github.com/rsc/benchgraffiti/commit/b78dac106bea1eb3be6bb3ca5dba57c130268232\" rel=\"noreferrer\" target=\"_blank\"\u003ediff from havlak2\u003c/a\u003e)\u003c/p\u003e\n\u003cp\u003eWe use \u003ccode\u003ego tool pprof\u003c/code\u003e exactly the same way. Now the samples we are examining are\nmemory allocations, not clock ticks.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go tool pprof havlak3 havlak3.mprof\nAdjusting heap profiles for 1-in-524288 sampling rate\nWelcome to pprof!  For help, type \u0026#39;help\u0026#39;.\n(pprof) top5\nTotal: 82.4 MB\n    56.3  68.4%  68.4%     56.3  68.4% main.FindLoops\n    17.6  21.3%  89.7%     17.6  21.3% main.(*CFG).CreateNode\n     8.0   9.7%  99.4%     25.6  31.0% main.NewBasicBlockEdge\n     0.5   0.6% 100.0%      0.5   0.6% itab\n     0.0   0.0% 100.0%      0.5   0.6% fmt.init\n(pprof)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe command \u003ccode\u003ego tool pprof\u003c/code\u003e reports that \u003ccode\u003eFindLoops\u003c/code\u003e has allocated approximately\n56.3 of the 82.4 MB in use; \u003ccode\u003eCreateNode\u003c/code\u003e accounts for another 17.6 MB.\nTo reduce overhead, the memory profiler only records information for approximately\none block per half megabyte allocated (the “1-in-524288 sampling rate”), so these\nare approximations to the actual counts.\u003c/p\u003e\n\u003cp\u003eTo find the memory allocations, we can list those functions.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e(pprof) list FindLoops\nTotal: 82.4 MB\nROUTINE ====================== main.FindLoops in /home/rsc/g/benchgraffiti/havlak/havlak3.go\n  56.3   56.3 Total MB (flat / cumulative)\n...\n   1.9    1.9  268:     nonBackPreds := make([]map[int]bool, size)\n   5.8    5.8  269:     backPreds := make([][]int, size)\n     .      .  270:\n   1.9    1.9  271:     number := make([]int, size)\n   1.9    1.9  272:     header := make([]int, size, size)\n   1.9    1.9  273:     types := make([]int, size, size)\n   1.9    1.9  274:     last := make([]int, size, size)\n   1.9    1.9  275:     nodes := make([]*UnionFindNode, size, size)\n     .      .  276:\n     .      .  277:     for i := 0; i \u0026lt; size; i++ {\n   9.5    9.5  278:             nodes[i] = new(UnionFindNode)\n     .      .  279:     }\n...\n     .      .  286:     for i, bb := range cfgraph.Blocks {\n     .      .  287:             number[bb.Name] = unvisited\n  29.5   29.5  288:             nonBackPreds[i] = make(map[int]bool)\n     .      .  289:     }\n...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIt looks like the current bottleneck is the same as the last one: using maps where\nsimpler data structures suffice.\n\u003ccode\u003eFindLoops\u003c/code\u003e is allocating about 29.5 MB of maps.\u003c/p\u003e\n\u003cp\u003eAs an aside, if we run \u003ccode\u003ego tool pprof\u003c/code\u003e with the \u003ccode\u003e--inuse_objects\u003c/code\u003e flag, it will\nreport allocation counts instead of sizes:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go tool pprof --inuse_objects havlak3 havlak3.mprof\nAdjusting heap profiles for 1-in-524288 sampling rate\nWelcome to pprof!  For help, type \u0026#39;help\u0026#39;.\n(pprof) list FindLoops\nTotal: 1763108 objects\nROUTINE ====================== main.FindLoops in /home/rsc/g/benchgraffiti/havlak/havlak3.go\n720903 720903 Total objects (flat / cumulative)\n...\n     .      .  277:     for i := 0; i \u0026lt; size; i++ {\n311296 311296  278:             nodes[i] = new(UnionFindNode)\n     .      .  279:     }\n     .      .  280:\n     .      .  281:     // Step a:\n     .      .  282:     //   - initialize all nodes as unvisited.\n     .      .  283:     //   - depth-first traversal and numbering.\n     .      .  284:     //   - unreached BB\u0026#39;s are marked as dead.\n     .      .  285:     //\n     .      .  286:     for i, bb := range cfgraph.Blocks {\n     .      .  287:             number[bb.Name] = unvisited\n409600 409600  288:             nonBackPreds[i] = make(map[int]bool)\n     .      .  289:     }\n...\n(pprof)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSince the ~200,000 maps account for 29.5 MB, it looks like the initial map allocation\ntakes about 150 bytes.\nThat’s reasonable when a map is being used to hold key-value pairs, but not when a map\nis being used as a stand-in for a simple set, as it is here.\u003c/p\u003e\n\u003cp\u003eInstead of using a map, we can use a simple slice to list the elements.\nIn all but one of the cases where maps are being used, it is impossible for the algorithm\nto insert a duplicate element.\nIn the one remaining case, we can write a simple variant of the \u003ccode\u003eappend\u003c/code\u003e built-in function:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efunc appendUnique(a []int, x int) []int {\n    for _, y := range a {\n        if x == y {\n            return a\n        }\n    }\n    return append(a, x)\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn addition to writing that function, changing the Go program to use slices instead\nof maps requires changing just a few lines of code.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ make havlak4\ngo build havlak4.go\n$ ./xtime ./havlak4\n# of loops: 76000 (including 1 artificial root node)\n11.84u 0.08s 11.94r 810416kB ./havlak4\n$\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e(See the \u003ca href=\"https://github.com/rsc/benchgraffiti/commit/245d899f7b1a33b0c8148a4cd147cb3de5228c8a\" rel=\"noreferrer\" target=\"_blank\"\u003ediff from havlak3\u003c/a\u003e)\u003c/p\u003e\n\u003cp\u003eWe’re now at 2.11x faster than when we started. Let’s look at a CPU profile again.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ make havlak4.prof\n./havlak4 -cpuprofile=havlak4.prof\n# of loops: 76000 (including 1 artificial root node)\n$ go tool pprof havlak4 havlak4.prof\nWelcome to pprof!  For help, type \u0026#39;help\u0026#39;.\n(pprof) top10\nTotal: 1173 samples\n     205  17.5%  17.5%     1083  92.3% main.FindLoops\n     138  11.8%  29.2%      215  18.3% scanblock\n      88   7.5%  36.7%       96   8.2% sweepspan\n      76   6.5%  43.2%      597  50.9% runtime.mallocgc\n      75   6.4%  49.6%       78   6.6% runtime.settype_flush\n      74   6.3%  55.9%       75   6.4% flushptrbuf\n      64   5.5%  61.4%       64   5.5% runtime.memmove\n      63   5.4%  66.8%      524  44.7% runtime.growslice\n      51   4.3%  71.1%       51   4.3% main.DFS\n      50   4.3%  75.4%      146  12.4% runtime.MCache_Alloc\n(pprof)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow memory allocation and the consequent garbage collection (\u003ccode\u003eruntime.mallocgc\u003c/code\u003e)\naccounts for 50.9% of our run time.\nAnother way to look at why the system is garbage collecting is to look at the\nallocations that are causing the collections, the ones that spend most of the time\nin \u003ccode\u003emallocgc\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e(pprof) web mallocgc\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"image\"\u003e\n  \u003cimg src=\"pprof/havlak4a-mallocgc.png\" alt=\"\"/\u003e\n\u003c/div\u003e\n\u003cp\u003eIt’s hard to tell what’s going on in that graph, because there are many nodes with\nsmall sample numbers obscuring the big ones.\nWe can tell \u003ccode\u003ego tool pprof\u003c/code\u003e to ignore nodes that don’t account for at least 10% of\nthe samples:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go tool pprof --nodefraction=0.1 havlak4 havlak4.prof\nWelcome to pprof!  For help, type \u0026#39;help\u0026#39;.\n(pprof) web mallocgc\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"image\"\u003e\n  \u003cimg src=\"pprof/havlak4a-mallocgc-trim.png\" alt=\"\"/\u003e\n\u003c/div\u003e\n\u003cp\u003eWe can follow the thick arrows easily now, to see that \u003ccode\u003eFindLoops\u003c/code\u003e is triggering\nmost of the garbage collection.\nIf we list \u003ccode\u003eFindLoops\u003c/code\u003e we can see that much of it is right at the beginning:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e(pprof) list FindLoops\n...\n     .      .  270: func FindLoops(cfgraph *CFG, lsgraph *LSG) {\n     .      .  271:     if cfgraph.Start == nil {\n     .      .  272:             return\n     .      .  273:     }\n     .      .  274:\n     .      .  275:     size := cfgraph.NumNodes()\n     .      .  276:\n     .    145  277:     nonBackPreds := make([][]int, size)\n     .      9  278:     backPreds := make([][]int, size)\n     .      .  279:\n     .      1  280:     number := make([]int, size)\n     .     17  281:     header := make([]int, size, size)\n     .      .  282:     types := make([]int, size, size)\n     .      .  283:     last := make([]int, size, size)\n     .      .  284:     nodes := make([]*UnionFindNode, size, size)\n     .      .  285:\n     .      .  286:     for i := 0; i \u0026lt; size; i++ {\n     2     79  287:             nodes[i] = new(UnionFindNode)\n     .      .  288:     }\n...\n(pprof)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eEvery time \u003ccode\u003eFindLoops\u003c/code\u003e is called, it allocates some sizable bookkeeping structures.\nSince the benchmark calls \u003ccode\u003eFindLoops\u003c/code\u003e 50 times, these add up to a significant amount\nof garbage, so a significant amount of work for the garbage collector.\u003c/p\u003e\n\u003cp\u003eHaving a garbage-collected language doesn’t mean you can ignore memory allocation\nissues.\nIn this case, a simple solution is to introduce a cache so that each call to \u003ccode\u003eFindLoops\u003c/code\u003e\nreuses the previous call’s storage when possible.\n(In fact, in Hundt’s paper, he explains that the Java program needed just this change to\nget anything like reasonable performance, but he did not make the same change in the\nother garbage-collected implementations.)\u003c/p\u003e\n\u003cp\u003eWe’ll add a global \u003ccode\u003ecache\u003c/code\u003e structure:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003evar cache struct {\n    size int\n    nonBackPreds [][]int\n    backPreds [][]int\n    number []int\n    header []int\n    types []int\n    last []int\n    nodes []*UnionFindNode\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eand then have \u003ccode\u003eFindLoops\u003c/code\u003e consult it as a replacement for allocation:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eif cache.size \u0026lt; size {\n    cache.size = size\n    cache.nonBackPreds = make([][]int, size)\n    cache.backPreds = make([][]int, size)\n    cache.number = make([]int, size)\n    cache.header = make([]int, size)\n    cache.types = make([]int, size)\n    cache.last = make([]int, size)\n    cache.nodes = make([]*UnionFindNode, size)\n    for i := range cache.nodes {\n        cache.nodes[i] = new(UnionFindNode)\n    }\n}\n\nnonBackPreds := cache.nonBackPreds[:size]\nfor i := range nonBackPreds {\n    nonBackPreds[i] = nonBackPreds[i][:0]\n}\nbackPreds := cache.backPreds[:size]\nfor i := range nonBackPreds {\n    backPreds[i] = backPreds[i][:0]\n}\nnumber := cache.number[:size]\nheader := cache.header[:size]\ntypes := cache.types[:size]\nlast := cache.last[:size]\nnodes := cache.nodes[:size]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSuch a global variable is bad engineering practice, of course: it means that\nconcurrent calls to \u003ccode\u003eFindLoops\u003c/code\u003e are now unsafe.\nFor now, we are making the minimal possible changes in order to understand what\nis important for the performance of our program; this change is simple and mirrors\nthe code in the Java implementation.\nThe final version of the Go program will use a separate \u003ccode\u003eLoopFinder\u003c/code\u003e instance to\ntrack this memory, restoring the possibility of concurrent use.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ make havlak5\ngo build havlak5.go\n$ ./xtime ./havlak5\n# of loops: 76000 (including 1 artificial root node)\n8.03u 0.06s 8.11r 770352kB ./havlak5\n$\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e(See the \u003ca href=\"https://github.com/rsc/benchgraffiti/commit/2d41d6d16286b8146a3f697dd4074deac60d12a4\" rel=\"noreferrer\" target=\"_blank\"\u003ediff from havlak4\u003c/a\u003e)\u003c/p\u003e\n\u003cp\u003eThere’s more we can do to clean up the program and make it faster, but none of\nit requires profiling techniques that we haven’t already shown.\nThe work list used in the inner loop can be reused across iterations and across\ncalls to \u003ccode\u003eFindLoops\u003c/code\u003e, and it can be combined with the separate “node pool” generated\nduring that pass.\nSimilarly, the loop graph storage can be reused on each iteration instead of reallocated.\nIn addition to these performance changes, the\n\u003ca href=\"https://github.com/rsc/benchgraffiti/blob/master/havlak/havlak6.go\" rel=\"noreferrer\" target=\"_blank\"\u003efinal version\u003c/a\u003e\nis written using idiomatic Go style, using data structures and methods.\nThe stylistic changes have only a minor effect on the run time: the algorithm and\nconstraints are unchanged.\u003c/p\u003e\n\u003cp\u003eThe final version runs in 2.29 seconds and uses 351 MB of memory:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ make havlak6\ngo build havlak6.go\n$ ./xtime ./havlak6\n# of loops: 76000 (including 1 artificial root node)\n2.26u 0.02s 2.29r 360224kB ./havlak6\n$\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThat’s 11 times faster than the program we started with.\nEven if we disable reuse of the generated loop graph, so that the only cached memory\nis the loop finding bookkeeping, the program still runs 6.7x faster than the original\nand uses 1.5x less memory.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ ./xtime ./havlak6 -reuseloopgraph=false\n# of loops: 76000 (including 1 artificial root node)\n3.69u 0.06s 3.76r 797120kB ./havlak6 -reuseloopgraph=false\n$\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOf course, it’s no longer fair to compare this Go program to the original C++\nprogram, which used inefficient data structures like \u003ccode\u003eset\u003c/code\u003es where \u003ccode\u003evector\u003c/code\u003es would\nbe more appropriate.\nAs a sanity check, we translated the final Go program into\n\u003ca href=\"https://github.com/rsc/benchgraffiti/blob/master/havlak/havlak6.cc\" rel=\"noreferrer\" target=\"_blank\"\u003eequivalent C++ code\u003c/a\u003e.\nIts execution time is similar to the Go program’s:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ make havlak6cc\ng++ -O3 -o havlak6cc havlak6.cc\n$ ./xtime ./havlak6cc\n# of loops: 76000 (including 1 artificial root node)\n1.99u 0.19s 2.19r 387936kB ./havlak6cc\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe Go program runs almost as fast as the C++ program.\nAs the C++ program is using automatic deletes and allocation instead of an explicit\ncache, the C++ program a bit shorter and easier to write, but not dramatically so:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ wc havlak6.cc; wc havlak6.go\n 401 1220 9040 havlak6.cc\n 461 1441 9467 havlak6.go\n$\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e(See \u003ca href=\"https://github.com/rsc/benchgraffiti/blob/master/havlak/havlak6.cc\" rel=\"noreferrer\" target=\"_blank\"\u003ehavlak6.cc\u003c/a\u003e\nand \u003ca href=\"https://github.com/rsc/benchgraffiti/blob/master/havlak/havlak6.go\" rel=\"noreferrer\" target=\"_blank\"\u003ehavlak6.go\u003c/a\u003e)\u003c/p\u003e\n\u003cp\u003eBenchmarks are only as good as the programs they measure.\nWe used \u003ccode\u003ego tool pprof\u003c/code\u003e to study an inefficient Go program and then to improve its\nperformance by an order of magnitude and to reduce its memory usage by a factor of 3.7.\nA subsequent comparison with an equivalently optimized C++ program shows that Go can be\ncompetitive with C++ when programmers are careful about how much garbage is generated\nby inner loops.\u003c/p\u003e\n\u003cp\u003eThe program sources, Linux x86-64 binaries, and profiles used to write this post\nare available in the \u003ca href=\"https://github.com/rsc/benchgraffiti/\" rel=\"noreferrer\" target=\"_blank\"\u003ebenchgraffiti project on GitHub\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eAs mentioned above, \u003ca href=\"/cmd/go/#Test_packages\"\u003e\u003ccode\u003ego test\u003c/code\u003e\u003c/a\u003e includes\nthese profiling flags already: define a\n\u003ca href=\"/pkg/testing/\"\u003ebenchmark function\u003c/a\u003e and you’re all set.\nThere is also a standard HTTP interface to profiling data. In an HTTP server, adding\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport _ \u0026#34;net/http/pprof\u0026#34;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ewill install handlers for a few URLs under \u003ccode\u003e/debug/pprof/\u003c/code\u003e.\nThen you can run \u003ccode\u003ego tool pprof\u003c/code\u003e with a single argument—the URL to your server’s\nprofiling data and it will download and examine a live profile.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ego tool pprof http://localhost:6060/debug/pprof/profile   # 30-second CPU profile\ngo tool pprof http://localhost:6060/debug/pprof/heap      # heap profile\ngo tool pprof http://localhost:6060/debug/pprof/block     # goroutine blocking profile\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe goroutine blocking profile will be explained in a future post. Stay tuned.\u003c/p\u003e\n\n    \u003c/div\u003e",
  "Date": "2011-06-24T00:00:00Z",
  "Author": "Russ Cox, July 2011; updated by Shenghou Ma, May 2013"
}