{
  "Source": "go.dev",
  "Title": "Go Concurrency Patterns: Pipelines and cancellation",
  "Link": "https://go.dev/blog/pipelines",
  "Content": "\u003cdiv class=\"Article\" data-slug=\"/blog/pipelines\"\u003e\n    \n    \u003ch1 class=\"small\"\u003e\u003ca href=\"/blog/\"\u003eThe Go Blog\u003c/a\u003e\u003c/h1\u003e\n    \n\n    \u003ch1\u003eGo Concurrency Patterns: Pipelines and cancellation\u003c/h1\u003e\n      \n      \u003cp class=\"author\"\u003e\n      Sameer Ajmani\u003cbr/\u003e\n      13 March 2014\n      \u003c/p\u003e\n      \n      \u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eGo’s concurrency primitives make it easy to construct streaming data pipelines\nthat make efficient use of I/O and multiple CPUs.  This article presents\nexamples of such pipelines, highlights subtleties that arise when operations\nfail, and introduces techniques for dealing with failures cleanly.\u003c/p\u003e\n\u003ch2 id=\"what-is-a-pipeline\"\u003eWhat is a pipeline?\u003c/h2\u003e\n\u003cp\u003eThere’s no formal definition of a pipeline in Go; it’s just one of many kinds of\nconcurrent programs.  Informally, a pipeline is a series of \u003cem\u003estages\u003c/em\u003e connected\nby channels, where each stage is a group of goroutines running the same\nfunction.  In each stage, the goroutines\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ereceive values from \u003cem\u003eupstream\u003c/em\u003e via \u003cem\u003einbound\u003c/em\u003e channels\u003c/li\u003e\n\u003cli\u003eperform some function on that data, usually producing new values\u003c/li\u003e\n\u003cli\u003esend values \u003cem\u003edownstream\u003c/em\u003e via \u003cem\u003eoutbound\u003c/em\u003e channels\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEach stage has any number of inbound and outbound channels, except the\nfirst and last stages, which have only outbound or inbound channels,\nrespectively.  The first stage is sometimes called the \u003cem\u003esource\u003c/em\u003e or\n\u003cem\u003eproducer\u003c/em\u003e; the last stage, the \u003cem\u003esink\u003c/em\u003e or \u003cem\u003econsumer\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eWe’ll begin with a simple example pipeline to explain the ideas and techniques.\nLater, we’ll present a more realistic example.\u003c/p\u003e\n\u003ch2 id=\"squaring-numbers\"\u003eSquaring numbers\u003c/h2\u003e\n\u003cp\u003eConsider a pipeline with three stages.\u003c/p\u003e\n\u003cp\u003eThe first stage, \u003ccode\u003egen\u003c/code\u003e, is a function that converts a list of integers to a\nchannel that emits the integers in the list.  The \u003ccode\u003egen\u003c/code\u003e function starts a\ngoroutine that sends the integers on the channel and closes the channel when all\nthe values have been sent:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003efunc gen(nums ...int) \u0026lt;-chan int {\n    out := make(chan int)\n    go func() {\n        for _, n := range nums {\n            out \u0026lt;- n\n        }\n        close(out)\n    }()\n    return out\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThe second stage, \u003ccode\u003esq\u003c/code\u003e, receives integers from a channel and returns a\nchannel that emits the square of each received integer.  After the\ninbound channel is closed and this stage has sent all the values\ndownstream, it closes the outbound channel:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003efunc sq(in \u0026lt;-chan int) \u0026lt;-chan int {\n    out := make(chan int)\n    go func() {\n        for n := range in {\n            out \u0026lt;- n * n\n        }\n        close(out)\n    }()\n    return out\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThe \u003ccode\u003emain\u003c/code\u003e function sets up the pipeline and runs the final stage: it receives\nvalues from the second stage and prints each one, until the channel is closed:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003efunc main() {\n    \u003cspan class=\"comment\"\u003e// Set up the pipeline.\u003c/span\u003e\n    c := gen(2, 3)\n    out := sq(c)\n\n    \u003cspan class=\"comment\"\u003e// Consume the output.\u003c/span\u003e\n    fmt.Println(\u0026lt;-out) \u003cspan class=\"comment\"\u003e// 4\u003c/span\u003e\n    fmt.Println(\u0026lt;-out) \u003cspan class=\"comment\"\u003e// 9\u003c/span\u003e\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eSince \u003ccode\u003esq\u003c/code\u003e has the same type for its inbound and outbound channels, we\ncan compose it any number of times.  We can also rewrite \u003ccode\u003emain\u003c/code\u003e as a\nrange loop, like the other stages:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003efunc main() {\n    \u003cspan class=\"comment\"\u003e// Set up the pipeline and consume the output.\u003c/span\u003e\n    for n := range sq(sq(gen(2, 3))) {\n        fmt.Println(n) \u003cspan class=\"comment\"\u003e// 16 then 81\u003c/span\u003e\n    }\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003ch2 id=\"fan-out-fan-in\"\u003eFan-out, fan-in\u003c/h2\u003e\n\u003cp\u003eMultiple functions can read from the same channel until that channel is closed;\nthis is called \u003cem\u003efan-out\u003c/em\u003e. This provides a way to distribute work amongst a group\nof workers to parallelize CPU use and I/O.\u003c/p\u003e\n\u003cp\u003eA function can read from multiple inputs and proceed until all are closed by\nmultiplexing the input channels onto a single channel that’s closed when all the\ninputs are closed.  This is called \u003cem\u003efan-in\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eWe can change our pipeline to run two instances of \u003ccode\u003esq\u003c/code\u003e, each reading from the\nsame input channel.  We introduce a new function, \u003cem\u003emerge\u003c/em\u003e, to fan in the\nresults:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003efunc main() {\n    in := gen(2, 3)\n\n    \u003cspan class=\"comment\"\u003e// Distribute the sq work across two goroutines that both read from in.\u003c/span\u003e\n    c1 := sq(in)\n    c2 := sq(in)\n\n    \u003cspan class=\"comment\"\u003e// Consume the merged output from c1 and c2.\u003c/span\u003e\n    for n := range merge(c1, c2) {\n        fmt.Println(n) \u003cspan class=\"comment\"\u003e// 4 then 9, or 9 then 4\u003c/span\u003e\n    }\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThe \u003ccode\u003emerge\u003c/code\u003e function converts a list of channels to a single channel by starting\na goroutine for each inbound channel that copies the values to the sole outbound\nchannel.  Once all the \u003ccode\u003eoutput\u003c/code\u003e goroutines have been started, \u003ccode\u003emerge\u003c/code\u003e starts one\nmore goroutine to close the outbound channel after all sends on that channel are\ndone.\u003c/p\u003e\n\u003cp\u003eSends on a closed channel panic, so it’s important to ensure all sends\nare done before calling close.  The\n\u003ca href=\"/pkg/sync/#WaitGroup\"\u003e\u003ccode\u003esync.WaitGroup\u003c/code\u003e\u003c/a\u003e type\nprovides a simple way to arrange this synchronization:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003efunc merge(cs ...\u0026lt;-chan int) \u0026lt;-chan int {\n    \u003cspan class=\"highlight\"\u003evar wg sync.WaitGroup\u003c/span\u003e\n    out := make(chan int)\n\n    \u003cspan class=\"comment\"\u003e// Start an output goroutine for each input channel in cs.  output\u003c/span\u003e\n    \u003cspan class=\"comment\"\u003e// copies values from c to out until c is closed, then calls wg.Done.\u003c/span\u003e\n    output := func(c \u0026lt;-chan int) {\n        for n := range c {\n            out \u0026lt;- n\n        }\n        \u003cspan class=\"highlight\"\u003ewg.Done()\u003c/span\u003e\n    }\n    \u003cspan class=\"highlight\"\u003ewg.Add(len(cs))\u003c/span\u003e\n    for _, c := range cs {\n        go output(c)\n    }\n\n    \u003cspan class=\"comment\"\u003e// Start a goroutine to close out once all the output goroutines are\u003c/span\u003e\n    \u003cspan class=\"comment\"\u003e// done.  This must start after the wg.Add call.\u003c/span\u003e\n    go func() {\n        \u003cspan class=\"highlight\"\u003ewg.Wait()\u003c/span\u003e\n        close(out)\n    }()\n    return out\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003ch2 id=\"stopping-short\"\u003eStopping short\u003c/h2\u003e\n\u003cp\u003eThere is a pattern to our pipeline functions:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003estages close their outbound channels when all the send operations are done.\u003c/li\u003e\n\u003cli\u003estages keep receiving values from inbound channels until those channels are closed.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis pattern allows each receiving stage to be written as a \u003ccode\u003erange\u003c/code\u003e loop and\nensures that all goroutines exit once all values have been successfully sent\ndownstream.\u003c/p\u003e\n\u003cp\u003eBut in real pipelines, stages don’t always receive all the inbound\nvalues.  Sometimes this is by design: the receiver may only need a\nsubset of values to make progress.  More often, a stage exits early\nbecause an inbound value represents an error in an earlier stage. In\neither case the receiver should not have to wait for the remaining\nvalues to arrive, and we want earlier stages to stop producing values\nthat later stages don’t need.\u003c/p\u003e\n\u003cp\u003eIn our example pipeline, if a stage fails to consume all the inbound values, the\ngoroutines attempting to send those values will block indefinitely:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003e    \u003cspan class=\"comment\"\u003e// Consume the first value from the output.\u003c/span\u003e\n    out := merge(c1, c2)\n    fmt.Println(\u0026lt;-out) \u003cspan class=\"comment\"\u003e// 4 or 9\u003c/span\u003e\n    return\n    \u003cspan class=\"comment\"\u003e// Since we didn\u0026#39;t receive the second value from out,\u003c/span\u003e\n    \u003cspan class=\"comment\"\u003e// one of the output goroutines is hung attempting to send it.\u003c/span\u003e\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThis is a resource leak: goroutines consume memory and runtime resources, and\nheap references in goroutine stacks keep data from being garbage collected.\nGoroutines are not garbage collected; they must exit on their own.\u003c/p\u003e\n\u003cp\u003eWe need to arrange for the upstream stages of our pipeline to exit even when the\ndownstream stages fail to receive all the inbound values.  One way to do this is\nto change the outbound channels to have a buffer.  A buffer can hold a fixed\nnumber of values; send operations complete immediately if there’s room in the\nbuffer:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ec := make(chan int, 2) // buffer size 2\nc \u0026lt;- 1  // succeeds immediately\nc \u0026lt;- 2  // succeeds immediately\nc \u0026lt;- 3  // blocks until another goroutine does \u0026lt;-c and receives 1\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhen the number of values to be sent is known at channel creation time, a buffer\ncan simplify the code.  For example, we can rewrite \u003ccode\u003egen\u003c/code\u003e to copy the list of\nintegers into a buffered channel and avoid creating a new goroutine:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003efunc gen(nums ...int) \u0026lt;-chan int {\n    out := make(chan int, len(nums))\n    for _, n := range nums {\n        out \u0026lt;- n\n    }\n    close(out)\n    return out\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eReturning to the blocked goroutines in our pipeline, we might consider adding a\nbuffer to the outbound channel returned by \u003ccode\u003emerge\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003efunc merge(cs ...\u0026lt;-chan int) \u0026lt;-chan int {\n    var wg sync.WaitGroup\n    out := make(chan int, 1) \u003cspan class=\"comment\"\u003e// enough space for the unread inputs\u003c/span\u003e\n    \u003cspan class=\"comment\"\u003e// ... the rest is unchanged ...\u003c/span\u003e\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eWhile this fixes the blocked goroutine in this program, this is bad code.  The\nchoice of buffer size of 1 here depends on knowing the number of values \u003ccode\u003emerge\u003c/code\u003e\nwill receive and the number of values downstream stages will consume.  This is\nfragile: if we pass an additional value to \u003ccode\u003egen\u003c/code\u003e, or if the downstream stage\nreads any fewer values, we will again have blocked goroutines.\u003c/p\u003e\n\u003cp\u003eInstead, we need to provide a way for downstream stages to indicate to the\nsenders that they will stop accepting input.\u003c/p\u003e\n\u003ch2 id=\"explicit-cancellation\"\u003eExplicit cancellation\u003c/h2\u003e\n\u003cp\u003eWhen \u003ccode\u003emain\u003c/code\u003e decides to exit without receiving all the values from\n\u003ccode\u003eout\u003c/code\u003e, it must tell the goroutines in the upstream stages to abandon\nthe values they’re trying to send.  It does so by sending values on a\nchannel called \u003ccode\u003edone\u003c/code\u003e.  It sends two values since there are\npotentially two blocked senders:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003efunc main() {\n    in := gen(2, 3)\n\n    \u003cspan class=\"comment\"\u003e// Distribute the sq work across two goroutines that both read from in.\u003c/span\u003e\n    c1 := sq(in)\n    c2 := sq(in)\n\n    \u003cspan class=\"comment\"\u003e// Consume the first value from output.\u003c/span\u003e\n    \u003cspan class=\"highlight\"\u003edone := make(chan struct{}, 2)\u003c/span\u003e\n    out := merge(done, c1, c2)\n    fmt.Println(\u0026lt;-out) \u003cspan class=\"comment\"\u003e// 4 or 9\u003c/span\u003e\n\n    \u003cspan class=\"comment\"\u003e// Tell the remaining senders we\u0026#39;re leaving.\u003c/span\u003e\n    \u003cspan class=\"highlight\"\u003edone \u0026lt;- struct{}{}\u003c/span\u003e\n    \u003cspan class=\"highlight\"\u003edone \u0026lt;- struct{}{}\u003c/span\u003e\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThe sending goroutines replace their send operation with a \u003ccode\u003eselect\u003c/code\u003e statement\nthat proceeds either when the send on \u003ccode\u003eout\u003c/code\u003e happens or when they receive a value\nfrom \u003ccode\u003edone\u003c/code\u003e.  The value type of \u003ccode\u003edone\u003c/code\u003e is the empty struct because the value\ndoesn’t matter: it is the receive event that indicates the send on \u003ccode\u003eout\u003c/code\u003e should\nbe abandoned.  The \u003ccode\u003eoutput\u003c/code\u003e goroutines continue looping on their inbound\nchannel, \u003ccode\u003ec\u003c/code\u003e, so the upstream stages are not blocked. (We’ll discuss in a moment\nhow to allow this loop to return early.)\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003efunc merge(done \u0026lt;-chan struct{}, cs ...\u0026lt;-chan int) \u0026lt;-chan int {\n    var wg sync.WaitGroup\n    out := make(chan int)\n\n    \u003cspan class=\"comment\"\u003e// Start an output goroutine for each input channel in cs.  output\u003c/span\u003e\n    \u003cspan class=\"comment\"\u003e// copies values from c to out until c is closed or it receives a value\u003c/span\u003e\n    \u003cspan class=\"comment\"\u003e// from done, then output calls wg.Done.\u003c/span\u003e\n    output := func(c \u0026lt;-chan int) {\n        for n := range c {\n            select {\n            case out \u0026lt;- n:\n            \u003cspan class=\"highlight\"\u003ecase \u0026lt;-done:\u003c/span\u003e\n            }\n        }\n        wg.Done()\n    }\n    \u003cspan class=\"comment\"\u003e// ... the rest is unchanged ...\u003c/span\u003e\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThis approach has a problem: \u003cem\u003eeach\u003c/em\u003e downstream receiver needs to know the number\nof potentially blocked upstream senders and arrange to signal those senders on\nearly return.  Keeping track of these counts is tedious and error-prone.\u003c/p\u003e\n\u003cp\u003eWe need a way to tell an unknown and unbounded number of goroutines to\nstop sending their values downstream.  In Go, we can do this by\nclosing a channel, because\n\u003ca href=\"/ref/spec#Receive_operator\"\u003ea receive operation on a closed channel can always proceed immediately, yielding the element type’s zero value.\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThis means that \u003ccode\u003emain\u003c/code\u003e can unblock all the senders simply by closing\nthe \u003ccode\u003edone\u003c/code\u003e channel.  This close is effectively a broadcast signal to\nthe senders.  We extend \u003cem\u003eeach\u003c/em\u003e of our pipeline functions to accept\n\u003ccode\u003edone\u003c/code\u003e as a parameter and arrange for the close to happen via a\n\u003ccode\u003edefer\u003c/code\u003e statement, so that all return paths from \u003ccode\u003emain\u003c/code\u003e will signal\nthe pipeline stages to exit.\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003efunc main() {\n    \u003cspan class=\"comment\"\u003e// Set up a done channel that\u0026#39;s shared by the whole pipeline,\u003c/span\u003e\n    \u003cspan class=\"comment\"\u003e// and close that channel when this pipeline exits, as a signal\u003c/span\u003e\n    \u003cspan class=\"comment\"\u003e// for all the goroutines we started to exit.\u003c/span\u003e\n    \u003cspan class=\"highlight\"\u003edone := make(chan struct{})\u003c/span\u003e\n    \u003cspan class=\"highlight\"\u003edefer close(done)          \u003c/span\u003e\n\n    in := gen(done, 2, 3)\n\n    \u003cspan class=\"comment\"\u003e// Distribute the sq work across two goroutines that both read from in.\u003c/span\u003e\n    c1 := sq(done, in)\n    c2 := sq(done, in)\n\n    \u003cspan class=\"comment\"\u003e// Consume the first value from output.\u003c/span\u003e\n    out := merge(done, c1, c2)\n    fmt.Println(\u0026lt;-out) \u003cspan class=\"comment\"\u003e// 4 or 9\u003c/span\u003e\n\n    \u003cspan class=\"highlight-comment\"\u003e// done will be closed by the deferred call.\u003c/span\u003e\u003cspan class=\"comment\"\u003e      \u003c/span\u003e\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eEach of our pipeline stages is now free to return as soon as \u003ccode\u003edone\u003c/code\u003e is closed.\nThe \u003ccode\u003eoutput\u003c/code\u003e routine in \u003ccode\u003emerge\u003c/code\u003e can return without draining its inbound channel,\nsince it knows the upstream sender, \u003ccode\u003esq\u003c/code\u003e, will stop attempting to send when\n\u003ccode\u003edone\u003c/code\u003e is closed.  \u003ccode\u003eoutput\u003c/code\u003e ensures \u003ccode\u003ewg.Done\u003c/code\u003e is called on all return paths via\na \u003ccode\u003edefer\u003c/code\u003e statement:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003efunc merge(done \u0026lt;-chan struct{}, cs ...\u0026lt;-chan int) \u0026lt;-chan int {\n    var wg sync.WaitGroup\n    out := make(chan int)\n\n    \u003cspan class=\"comment\"\u003e// Start an output goroutine for each input channel in cs.  output\u003c/span\u003e\n    \u003cspan class=\"comment\"\u003e// copies values from c to out until c or done is closed, then calls\u003c/span\u003e\n    \u003cspan class=\"comment\"\u003e// wg.Done.\u003c/span\u003e\n    output := func(c \u0026lt;-chan int) {\n        \u003cspan class=\"highlight\"\u003edefer wg.Done()\u003c/span\u003e\n        for n := range c {\n            select {\n            case out \u0026lt;- n:\n            case \u0026lt;-done:\n                \u003cspan class=\"highlight\"\u003ereturn\u003c/span\u003e\n            }\n        }\n    }\n    \u003cspan class=\"comment\"\u003e// ... the rest is unchanged ...\u003c/span\u003e\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eSimilarly, \u003ccode\u003esq\u003c/code\u003e can return as soon as \u003ccode\u003edone\u003c/code\u003e is closed.  \u003ccode\u003esq\u003c/code\u003e ensures its \u003ccode\u003eout\u003c/code\u003e\nchannel is closed on all return paths via a \u003ccode\u003edefer\u003c/code\u003e statement:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003efunc sq(done \u0026lt;-chan struct{}, in \u0026lt;-chan int) \u0026lt;-chan int {\n    out := make(chan int)\n    go func() {\n        \u003cspan class=\"highlight\"\u003edefer close(out)\u003c/span\u003e\n        for n := range in {\n            select {\n            case out \u0026lt;- n * n:\n            case \u0026lt;-done:\n                \u003cspan class=\"highlight\"\u003ereturn\u003c/span\u003e\n            }\n        }\n    }()\n    return out\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eHere are the guidelines for pipeline construction:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003estages close their outbound channels when all the send operations are done.\u003c/li\u003e\n\u003cli\u003estages keep receiving values from inbound channels until those channels are closed or the senders are unblocked.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ePipelines unblock senders either by ensuring there’s enough buffer for all the\nvalues that are sent or by explicitly signalling senders when the receiver may\nabandon the channel.\u003c/p\u003e\n\u003ch2 id=\"digesting-a-tree\"\u003eDigesting a tree\u003c/h2\u003e\n\u003cp\u003eLet’s consider a more realistic pipeline.\u003c/p\u003e\n\u003cp\u003eMD5 is a message-digest algorithm that’s useful as a file checksum.  The command\nline utility \u003ccode\u003emd5sum\u003c/code\u003e prints digest values for a list of files.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e% md5sum *.go\nd47c2bbc28298ca9befdfbc5d3aa4e65  bounded.go\nee869afd31f83cbb2d10ee81b2b831dc  parallel.go\nb88175e65fdcbc01ac08aaf1fd9b5e96  serial.go\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOur example program is like \u003ccode\u003emd5sum\u003c/code\u003e but instead takes a single directory as an\nargument and prints the digest values for each regular file under that\ndirectory, sorted by path name.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e% go run serial.go .\nd47c2bbc28298ca9befdfbc5d3aa4e65  bounded.go\nee869afd31f83cbb2d10ee81b2b831dc  parallel.go\nb88175e65fdcbc01ac08aaf1fd9b5e96  serial.go\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe main function of our program invokes a helper function \u003ccode\u003eMD5All\u003c/code\u003e, which\nreturns a map from path name to digest value, then sorts and prints the results:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003efunc main() {\n    \u003cspan class=\"comment\"\u003e// Calculate the MD5 sum of all files under the specified directory,\u003c/span\u003e\n    \u003cspan class=\"comment\"\u003e// then print the results sorted by path name.\u003c/span\u003e\n    \u003cspan class=\"highlight\"\u003em, err := MD5All(os.Args[1])\u003c/span\u003e\n    if err != nil {\n        fmt.Println(err)\n        return\n    }\n    var paths []string\n    for path := range m {\n        paths = append(paths, path)\n    }\n    \u003cspan class=\"highlight\"\u003esort.Strings(paths)\u003c/span\u003e\n    for _, path := range paths {\n        fmt.Printf(\u0026#34;%x  %s\\n\u0026#34;, m[path], path)\n    }\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThe \u003ccode\u003eMD5All\u003c/code\u003e function is the focus of our discussion.  In\n\u003ca href=\"pipelines/serial.go\"\u003eserial.go\u003c/a\u003e, the implementation uses no concurrency and\nsimply reads and sums each file as it walks the tree.\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003e\u003cspan class=\"comment\"\u003e// MD5All reads all the files in the file tree rooted at root and returns a map\u003c/span\u003e\n\u003cspan class=\"comment\"\u003e// from file path to the MD5 sum of the file\u0026#39;s contents.  If the directory walk\u003c/span\u003e\n\u003cspan class=\"comment\"\u003e// fails or any read operation fails, MD5All returns an error.\u003c/span\u003e\nfunc MD5All(root string) (map[string][md5.Size]byte, error) {\n    m := make(map[string][md5.Size]byte)\n    \u003cspan class=\"highlight\"\u003eerr := filepath.Walk(root, func(path string, info os.FileInfo, err error) error {\u003c/span\u003e\n        if err != nil {\n            return err\n        }\n        if !info.Mode().IsRegular() {\n            return nil\n        }\n        \u003cspan class=\"highlight\"\u003edata, err := ioutil.ReadFile(path)\u003c/span\u003e\n        if err != nil {\n            return err\n        }\n        \u003cspan class=\"highlight\"\u003em[path] = md5.Sum(data)\u003c/span\u003e\n        return nil\n    })\n    if err != nil {\n        return nil, err\n    }\n    return m, nil\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003ch2 id=\"parallel-digestion\"\u003eParallel digestion\u003c/h2\u003e\n\u003cp\u003eIn \u003ca href=\"pipelines/parallel.go\"\u003eparallel.go\u003c/a\u003e, we split \u003ccode\u003eMD5All\u003c/code\u003e into a two-stage\npipeline.  The first stage, \u003ccode\u003esumFiles\u003c/code\u003e, walks the tree, digests each file in\na new goroutine, and sends the results on a channel with value type \u003ccode\u003eresult\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003etype result struct {\n    path string\n    sum  [md5.Size]byte\n    err  error\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003e\u003ccode\u003esumFiles\u003c/code\u003e returns two channels: one for the \u003ccode\u003eresults\u003c/code\u003e and another for the error\nreturned by \u003ccode\u003efilepath.Walk\u003c/code\u003e.  The walk function starts a new goroutine to\nprocess each regular file, then checks \u003ccode\u003edone\u003c/code\u003e.  If \u003ccode\u003edone\u003c/code\u003e is closed, the walk\nstops immediately:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003efunc sumFiles(done \u0026lt;-chan struct{}, root string) (\u0026lt;-chan result, \u0026lt;-chan error) {\n    \u003cspan class=\"comment\"\u003e// For each regular file, start a goroutine that sums the file and sends\u003c/span\u003e\n    \u003cspan class=\"comment\"\u003e// the result on c.  Send the result of the walk on errc.\u003c/span\u003e\n    c := make(chan result)\n    errc := make(chan error, 1)\n    \u003cspan class=\"highlight\"\u003ego func() {\u003c/span\u003e\n        var wg sync.WaitGroup\n        err := filepath.Walk(root, func(path string, info os.FileInfo, err error) error {\n            if err != nil {\n                return err\n            }\n            if !info.Mode().IsRegular() {\n                return nil\n            }\n            wg.Add(1)\n            \u003cspan class=\"highlight\"\u003ego func() {\u003c/span\u003e\n                data, err := ioutil.ReadFile(path)\n                select {\n                \u003cspan class=\"highlight\"\u003ecase c \u0026lt;- result{path, md5.Sum(data), err}:\u003c/span\u003e\n                \u003cspan class=\"highlight\"\u003ecase \u0026lt;-done:\u003c/span\u003e\n                }\n                wg.Done()\n            }()\n            \u003cspan class=\"comment\"\u003e// Abort the walk if done is closed.\u003c/span\u003e\n            select {\n            \u003cspan class=\"highlight\"\u003ecase \u0026lt;-done:\u003c/span\u003e\n                return errors.New(\u0026#34;walk canceled\u0026#34;)\n            default:\n                return nil\n            }\n        })\n        \u003cspan class=\"comment\"\u003e// Walk has returned, so all calls to wg.Add are done.  Start a\u003c/span\u003e\n        \u003cspan class=\"comment\"\u003e// goroutine to close c once all the sends are done.\u003c/span\u003e\n        \u003cspan class=\"highlight\"\u003ego func() {\u003c/span\u003e\n            wg.Wait()\n            \u003cspan class=\"highlight\"\u003eclose(c)\u003c/span\u003e\n        }()\n        \u003cspan class=\"comment\"\u003e// No select needed here, since errc is buffered.\u003c/span\u003e\n        \u003cspan class=\"highlight\"\u003eerrc \u0026lt;- err\u003c/span\u003e\n    }()\n    return c, errc\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003e\u003ccode\u003eMD5All\u003c/code\u003e receives the digest values from \u003ccode\u003ec\u003c/code\u003e.  \u003ccode\u003eMD5All\u003c/code\u003e returns early on error,\nclosing \u003ccode\u003edone\u003c/code\u003e via a \u003ccode\u003edefer\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003efunc MD5All(root string) (map[string][md5.Size]byte, error) {\n    \u003cspan class=\"comment\"\u003e// MD5All closes the done channel when it returns; it may do so before\u003c/span\u003e\n    \u003cspan class=\"comment\"\u003e// receiving all the values from c and errc.\u003c/span\u003e\n    \u003cspan class=\"highlight\"\u003edone := make(chan struct{})\u003c/span\u003e\n    \u003cspan class=\"highlight\"\u003edefer close(done)          \u003c/span\u003e\n\n    \u003cspan class=\"highlight\"\u003ec, errc := sumFiles(done, root)\u003c/span\u003e\n\n    m := make(map[string][md5.Size]byte)\n    for r := range c {\n        if r.err != nil {\n            return nil, r.err\n        }\n        m[r.path] = r.sum\n    }\n    if err := \u0026lt;-errc; err != nil {\n        return nil, err\n    }\n    return m, nil\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003ch2 id=\"bounded-parallelism\"\u003eBounded parallelism\u003c/h2\u003e\n\u003cp\u003eThe \u003ccode\u003eMD5All\u003c/code\u003e implementation in \u003ca href=\"pipelines/parallel.go\"\u003eparallel.go\u003c/a\u003e\nstarts a new goroutine for each file. In a directory with many large\nfiles, this may allocate more memory than is available on the machine.\u003c/p\u003e\n\u003cp\u003eWe can limit these allocations by bounding the number of files read in\nparallel.  In \u003ca href=\"pipelines/bounded.go\"\u003ebounded.go\u003c/a\u003e, we do this by\ncreating a fixed number of goroutines for reading files.  Our pipeline\nnow has three stages: walk the tree, read and digest the files, and\ncollect the digests.\u003c/p\u003e\n\u003cp\u003eThe first stage, \u003ccode\u003ewalkFiles\u003c/code\u003e, emits the paths of regular files in the tree:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003efunc walkFiles(done \u0026lt;-chan struct{}, root string) (\u0026lt;-chan string, \u0026lt;-chan error) {\n    paths := make(chan string)\n    errc := make(chan error, 1)\n    \u003cspan class=\"highlight\"\u003ego func() {\u003c/span\u003e\n        \u003cspan class=\"comment\"\u003e// Close the paths channel after Walk returns.\u003c/span\u003e\n        \u003cspan class=\"highlight\"\u003edefer close(paths)\u003c/span\u003e\n        \u003cspan class=\"comment\"\u003e// No select needed for this send, since errc is buffered.\u003c/span\u003e\n        \u003cspan class=\"highlight\"\u003eerrc \u0026lt;- filepath.Walk(root, func(path string, info os.FileInfo, err error) error {\u003c/span\u003e\n            if err != nil {\n                return err\n            }\n            if !info.Mode().IsRegular() {\n                return nil\n            }\n            select {\n            \u003cspan class=\"highlight\"\u003ecase paths \u0026lt;- path:\u003c/span\u003e\n            \u003cspan class=\"highlight\"\u003ecase \u0026lt;-done:\u003c/span\u003e\n                return errors.New(\u0026#34;walk canceled\u0026#34;)\n            }\n            return nil\n        })\n    }()\n    return paths, errc\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThe middle stage starts a fixed number of \u003ccode\u003edigester\u003c/code\u003e goroutines that receive\nfile names from \u003ccode\u003epaths\u003c/code\u003e and send \u003ccode\u003eresults\u003c/code\u003e on channel \u003ccode\u003ec\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003efunc digester(done \u0026lt;-chan struct{}, paths \u0026lt;-chan string, c chan\u0026lt;- result) {\n    \u003cspan class=\"highlight\"\u003efor path := range paths {\u003c/span\u003e\n        data, err := ioutil.ReadFile(path)\n        select {\n        case c \u0026lt;- result{path, md5.Sum(data), err}:\n        case \u0026lt;-done:\n            return\n        }\n    }\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eUnlike our previous examples, \u003ccode\u003edigester\u003c/code\u003e does not close its output channel, as\nmultiple goroutines are sending on a shared channel.  Instead, code in \u003ccode\u003eMD5All\u003c/code\u003e\narranges for the channel to be closed when all the \u003ccode\u003edigesters\u003c/code\u003e are done:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003e    \u003cspan class=\"comment\"\u003e// Start a fixed number of goroutines to read and digest files.\u003c/span\u003e\n    \u003cspan class=\"highlight\"\u003ec := make(chan result)\u003c/span\u003e\n    var wg sync.WaitGroup\n    const numDigesters = 20\n    wg.Add(numDigesters)\n    for i := 0; i \u0026lt; numDigesters; i++ {\n        go func() {\n            \u003cspan class=\"highlight\"\u003edigester(done, paths, c)\u003c/span\u003e\n            wg.Done()\n        }()\n    }\n    go func() {\n        wg.Wait()\n        \u003cspan class=\"highlight\"\u003eclose(c)\u003c/span\u003e\n    }()\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eWe could instead have each digester create and return its own output\nchannel, but then we would need additional goroutines to fan-in the\nresults.\u003c/p\u003e\n\u003cp\u003eThe final stage receives all the \u003ccode\u003eresults\u003c/code\u003e from \u003ccode\u003ec\u003c/code\u003e then checks the\nerror from \u003ccode\u003eerrc\u003c/code\u003e.  This check cannot happen any earlier, since before\nthis point, \u003ccode\u003ewalkFiles\u003c/code\u003e may block sending values downstream:\u003c/p\u003e\n\u003cdiv class=\"code\"\u003e\n\u003cpre\u003e    m := make(map[string][md5.Size]byte)\n    for r := range c {\n        if r.err != nil {\n            return nil, r.err\n        }\n        m[r.path] = r.sum\n    }\n    \u003cspan class=\"comment\"\u003e// Check whether the Walk failed.\u003c/span\u003e\n    \u003cspan class=\"highlight\"\u003eif err := \u0026lt;-errc; err != nil {\u003c/span\u003e\n        return nil, err\n    }\n    return m, nil\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eThis article has presented techniques for constructing streaming data pipelines\nin Go.  Dealing with failures in such pipelines is tricky, since each stage in\nthe pipeline may block attempting to send values downstream, and the downstream\nstages may no longer care about the incoming data.  We showed how closing a\nchannel can broadcast a “done” signal to all the goroutines started by a\npipeline and defined guidelines for constructing pipelines correctly.\u003c/p\u003e\n\u003cp\u003eFurther reading:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/talks/2012/concurrency.slide#1\"\u003eGo Concurrency Patterns\u003c/a\u003e\n(\u003ca href=\"https://www.youtube.com/watch?v=f6kdp27TYZs\" rel=\"noreferrer\" target=\"_blank\"\u003evideo\u003c/a\u003e) presents the basics\nof Go’s concurrency primitives and several ways to apply them.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/blog/advanced-go-concurrency-patterns\"\u003eAdvanced Go Concurrency Patterns\u003c/a\u003e\n(\u003ca href=\"http://www.youtube.com/watch?v=QDDwwePbDtw\" rel=\"noreferrer\" target=\"_blank\"\u003evideo\u003c/a\u003e) covers more complex\nuses of Go’s primitives,\nespecially \u003ccode\u003eselect\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eDouglas McIlroy’s paper \u003ca href=\"https://swtch.com/~rsc/thread/squint.pdf\" rel=\"noreferrer\" target=\"_blank\"\u003eSquinting at Power Series\u003c/a\u003e\nshows how Go-like concurrency provides elegant support for complex calculations.\u003c/li\u003e\n\u003c/ul\u003e\n\n    \u003c/div\u003e",
  "Date": "2014-03-13T00:00:00Z",
  "Author": "Sameer Ajmani"
}