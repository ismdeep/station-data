{
  "Source": "go.dev",
  "Title": "Profile-guided optimization preview",
  "Link": "https://go.dev/blog/pgo-preview",
  "Content": "\u003cdiv class=\"Article\" data-slug=\"/blog/pgo-preview\"\u003e\n    \n    \u003ch1 class=\"small\"\u003e\u003ca href=\"/blog/\"\u003eThe Go Blog\u003c/a\u003e\u003c/h1\u003e\n    \n\n    \u003ch1\u003eProfile-guided optimization preview\u003c/h1\u003e\n      \n      \u003cp class=\"author\"\u003e\n      Michael Pratt\u003cbr/\u003e\n      8 February 2023\n      \u003c/p\u003e\n      \n      \u003cp\u003eWhen you build a Go binary, the Go compiler performs optimizations to try to generate the best performing binary it can.\nFor example, constant propagation can evaluate constant expressions at compile time, avoiding runtime evaluation cost.\nEscape analysis avoids heap allocations for locally-scoped objects, avoiding GC overheads.\nInlining copies the body of simple functions into callers, often enabling further optimization in the caller (such as additional constant propagation or better escape analysis).\u003c/p\u003e\n\u003cp\u003eGo improves optimizations from release to release, but this is not always an easy task.\nSome optimizations are tunable, but the compiler can’t just “turn it up to 11” on every function because overly aggressive optimizations can actually hurt performance or cause excessive build times.\nOther optimizations require the compiler to make a judgment call about what the “common” and “uncommon” paths in a function are.\nThe compiler must make a best guess based on static heuristics because it can’t know which cases will be common at run time.\u003c/p\u003e\n\u003cp\u003eOr can it?\u003c/p\u003e\n\u003cp\u003eWith no definitive information about how the code is used in a production environment, the compiler can operate only on the source code of packages.\nBut we do have a tool to evaluate production behavior: \u003ca href=\"/doc/diagnostics#profiling\"\u003eprofiling\u003c/a\u003e.\nIf we provide a profile to the compiler, it can make more informed decisions: more aggressively optimizing the most frequently used functions, or more accurately selecting common cases.\u003c/p\u003e\n\u003cp\u003eUsing profiles of application behavior for compiler optimization is known as \u003cem\u003eProfile-Guided Optimization (PGO)\u003c/em\u003e (also known as Feedback-Directed Optimization (FDO)).\u003c/p\u003e\n\u003cp\u003eGo 1.20 includes initial support for PGO as a preview.\nSee the \u003ca href=\"/doc/pgo\"\u003eprofile-guided optimization user guide\u003c/a\u003e for complete documentation.\nThere are still some rough edges that may prevent production use, but we would love for you to try it out and \u003ca href=\"/issue/new\"\u003esend us any feedback or issues you encounter\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"example\"\u003eExample\u003c/h2\u003e\n\u003cp\u003eLet’s build a service that converts Markdown to HTML: users upload Markdown source to \u003ccode\u003e/render\u003c/code\u003e, which returns the HTML conversion.\nWe can use \u003ca href=\"https://pkg.go.dev/gitlab.com/golang-commonmark/markdown\" rel=\"noreferrer\" target=\"_blank\"\u003e\u003ccode\u003egitlab.com/golang-commonmark/markdown\u003c/code\u003e\u003c/a\u003e to implement this easily.\u003c/p\u003e\n\u003ch3 id=\"set-up\"\u003eSet up\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e$ go mod init example.com/markdown\n$ go get gitlab.com/golang-commonmark/markdown@bf3e522c626a\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn \u003ccode\u003emain.go\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epackage main\n\nimport (\n    \u0026#34;bytes\u0026#34;\n    \u0026#34;io\u0026#34;\n    \u0026#34;log\u0026#34;\n    \u0026#34;net/http\u0026#34;\n    _ \u0026#34;net/http/pprof\u0026#34;\n\n    \u0026#34;gitlab.com/golang-commonmark/markdown\u0026#34;\n)\n\nfunc render(w http.ResponseWriter, r *http.Request) {\n    if r.Method != \u0026#34;POST\u0026#34; {\n        http.Error(w, \u0026#34;Only POST allowed\u0026#34;, http.StatusMethodNotAllowed)\n        return\n    }\n\n    src, err := io.ReadAll(r.Body)\n    if err != nil {\n        log.Printf(\u0026#34;error reading body: %v\u0026#34;, err)\n        http.Error(w, \u0026#34;Internal Server Error\u0026#34;, http.StatusInternalServerError)\n        return\n    }\n\n    md := markdown.New(\n        markdown.XHTMLOutput(true),\n        markdown.Typographer(true),\n        markdown.Linkify(true),\n        markdown.Tables(true),\n    )\n\n    var buf bytes.Buffer\n    if err := md.Render(\u0026amp;buf, src); err != nil {\n        log.Printf(\u0026#34;error converting markdown: %v\u0026#34;, err)\n        http.Error(w, \u0026#34;Malformed markdown\u0026#34;, http.StatusBadRequest)\n        return\n    }\n\n    if _, err := io.Copy(w, \u0026amp;buf); err != nil {\n        log.Printf(\u0026#34;error writing response: %v\u0026#34;, err)\n        http.Error(w, \u0026#34;Internal Server Error\u0026#34;, http.StatusInternalServerError)\n        return\n    }\n}\n\nfunc main() {\n    http.HandleFunc(\u0026#34;/render\u0026#34;, render)\n    log.Printf(\u0026#34;Serving on port 8080...\u0026#34;)\n    log.Fatal(http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil))\n}\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eBuild and run the server:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go build -o markdown.nopgo.exe\n$ ./markdown.nopgo.exe\n2023/01/19 14:26:24 Serving on port 8080...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eLet’s try sending some Markdown from another terminal.\nWe can use the README from the Go project as a sample document:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ curl -o README.md -L \u0026#34;https://raw.githubusercontent.com/golang/go/c16c2c49e2fa98ae551fc6335215fadd62d33542/README.md\u0026#34;\n$ curl --data-binary @README.md http://localhost:8080/render\n\u0026lt;h1\u0026gt;The Go Programming Language\u0026lt;/h1\u0026gt;\n\u0026lt;p\u0026gt;Go is an open source programming language that makes it easy to build simple,\nreliable, and efficient software.\u0026lt;/p\u0026gt;\n...\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"profiling\"\u003eProfiling\u003c/h3\u003e\n\u003cp\u003eNow that we have a working service, let’s collect a profile and rebuild with PGO to see if we get better performance.\u003c/p\u003e\n\u003cp\u003eIn \u003ccode\u003emain.go\u003c/code\u003e, we imported \u003ca href=\"https://pkg.go.dev/net/http/pprof\" rel=\"noreferrer\" target=\"_blank\"\u003enet/http/pprof\u003c/a\u003e which automatically adds a \u003ccode\u003e/debug/pprof/profile\u003c/code\u003e endpoint to the server for fetching a CPU profile.\u003c/p\u003e\n\u003cp\u003eNormally you want to collect a profile from your production environment so that the compiler gets a representative view of behavior in production.\nSince this example doesn’t have a “production” environment, we will create a simple program to generate load while we collect a profile.\nCopy the source of \u003ca href=\"/play/p/yYH0kfsZcpL\"\u003ethis program\u003c/a\u003e to \u003ccode\u003eload/main.go\u003c/code\u003e and start the load generator (make sure the server is still running!).\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go run example.com/markdown/load\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhile that is running, download a profile from the server:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ curl -o cpu.pprof \u0026#34;http://localhost:8080/debug/pprof/profile?seconds=30\u0026#34;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce this completes, kill the load generator and the server.\u003c/p\u003e\n\u003ch3 id=\"using-the-profile\"\u003eUsing the profile\u003c/h3\u003e\n\u003cp\u003eWe can ask the Go toolchain to build with PGO using the \u003ccode\u003e-pgo\u003c/code\u003e flag to \u003ccode\u003ego build\u003c/code\u003e.\n\u003ccode\u003e-pgo\u003c/code\u003e takes either the path to the profile to use, or \u003ccode\u003eauto\u003c/code\u003e, which will use the \u003ccode\u003edefault.pgo\u003c/code\u003e file in the main package directory.\u003c/p\u003e\n\u003cp\u003eWe recommend committing \u003ccode\u003edefault.pgo\u003c/code\u003e profiles to your repository.\nStoring profiles alongside your source code ensures that users automatically have access to the profile simply by fetching the repository (either via the version control system, or via \u003ccode\u003ego get\u003c/code\u003e) and that builds remain reproducible.\nIn Go 1.20, \u003ccode\u003e-pgo=off\u003c/code\u003e is the default, so users still need to add \u003ccode\u003e-pgo=auto\u003c/code\u003e, but a future version of Go is expected to change the default to \u003ccode\u003e-pgo=auto\u003c/code\u003e, automatically giving anyone that builds the binary the benefit of PGO.\u003c/p\u003e\n\u003cp\u003eLet’s build:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ mv cpu.pprof default.pgo\n$ go build -pgo=auto -o markdown.withpgo.exe\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"evaluation\"\u003eEvaluation\u003c/h3\u003e\n\u003cp\u003eWe will use a Go benchmark version of the load generator to evaluate the effect of PGO on performance.\nCopy \u003ca href=\"/play/p/6FnQmHfRjbh\"\u003ethis benchmark\u003c/a\u003e to \u003ccode\u003eload/bench_test.go\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eFirst, we will benchmark the server without PGO. Start that server:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ ./markdown.nopgo.exe\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhile that is running, run several benchmark iterations:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go test example.com/markdown/load -bench=. -count=20 -source ../README.md \u0026gt; nopgo.txt\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce that completes, kill the original server and start the version with PGO:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ ./markdown.withpgo.exe\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhile that is running, run several benchmark iterations:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go test example.com/markdown/load -bench=. -count=20 -source ../README.md \u0026gt; withpgo.txt\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce that completes, let’s compare the results:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ go install golang.org/x/perf/cmd/benchstat@latest\n$ benchstat nopgo.txt withpgo.txt\ngoos: linux\ngoarch: amd64\npkg: example.com/markdown/load\ncpu: Intel(R) Xeon(R) W-2135 CPU @ 3.70GHz\n        │  nopgo.txt  │            withpgo.txt             │\n        │   sec/op    │   sec/op     vs base               │\nLoad-12   393.8µ ± 1%   383.6µ ± 1%  -2.59% (p=0.000 n=20)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe new version is around 2.6% faster!\nIn Go 1.20, workloads typically get between 2% and 4% CPU usage improvements from enabling PGO.\nProfiles contain a wealth of information about application behavior and Go 1.20 just begins to crack the surface by using this information for inlining.\nFuture releases will continue improving performance as more parts of the compiler take advantage of PGO.\u003c/p\u003e\n\u003ch2 id=\"next-steps\"\u003eNext steps\u003c/h2\u003e\n\u003cp\u003eIn this example, after collecting a profile, we rebuilt our server using the exact same source code used in the original build.\nIn a real-world scenario, there is always ongoing development.\nSo we may collect a profile from production, which is running last week’s code, and use it to build with today’s source code.\nThat is perfectly fine!\nPGO in Go can handle minor changes to source code without issue.\u003c/p\u003e\n\u003cp\u003eFor much more information on using PGO, best practices and caveats to be aware of, please see the \u003ca href=\"/doc/pgo\"\u003eprofile-guided optimization user guide\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003ePlease send us your feedback!\nPGO is still in preview and we’d love to hear about anything that is difficult to use, doesn’t work correctly, etc.\nPlease file issues at \u003ca href=\"/issue/new\"\u003ego.dev/issue/new\u003c/a\u003e.\u003c/p\u003e\n\n    \u003c/div\u003e",
  "Date": "2023-02-08T00:00:00Z",
  "Author": "Michael Pratt"
}