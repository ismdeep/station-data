{
  "Source": "go.dev",
  "Title": "Qihoo 360 and Go",
  "Link": "https://go.dev/blog/qihoo",
  "Content": "\u003cdiv class=\"Article\" data-slug=\"/blog/qihoo\"\u003e\n    \n    \u003ch1 class=\"small\"\u003e\u003ca href=\"/blog/\"\u003eThe Go Blog\u003c/a\u003e\u003c/h1\u003e\n    \n\n    \u003ch1\u003eQihoo 360 and Go\u003c/h1\u003e\n      \n      \u003cp class=\"author\"\u003e\n      Yang Zhou\u003cbr/\u003e\n      6 July 2015\n      \u003c/p\u003e\n      \n      \u003cp\u003e\u003cem\u003eThis guest blog post was written by Yang Zhou, Software Engineer at Qihoo 360.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://www.360safe.com/\" rel=\"noreferrer\" target=\"_blank\"\u003eQihoo 360\u003c/a\u003e is a major provider of Internet and\nmobile security products and services in China, and operates a major\nAndroid-based mobile distribution platform. At the end of June 2014, Qihoo had\nabout 500 million monthly active PC Internet users and over 640 million mobile\nusers. Qihoo also operates one of China’s most popular Internet browsers and PC\nsearch engines.\u003c/p\u003e\n\u003cp\u003eMy team, the Push Service Team, provides fundamental messaging services for\nmore than 50 products across the company (both PC and mobile), including\nthousands of Apps in our open platform.\u003c/p\u003e\n\u003cp\u003eOur “love affair” with Go dates back to 2012 when we first attempted to provide\npush services for one of Qihoo’s products. The initial version was built with\nnginx + lua + redis, which failed to satisfy our requirement for real-time\nperformance due to excessive load. Under these circumstances, the\nnewly-published Go 1.0.3 release came to our attention. We completed a\nprototype in a matter of weeks, largely thanks to the goroutine and channel\nfeatures it provided.\u003c/p\u003e\n\u003cp\u003eInitially, our Go-based system ran on 20 servers, with 20 million real-time\nconnections in total. The system sent 2 million messages a day. That system now\nruns on 400 servers, supporting 200 million+ real-time connections. It now\nsends over 10 billion messages daily.\u003c/p\u003e\n\u003cp\u003eWith rapid business expansion and increasing application needs for our push\nservice, the initial Go system quickly reached its bottleneck: heap size went\nup to 69G, with maximum garbage collection (GC) pauses of 3-6 seconds. Worse\nstill, we had to reboot the system every week to release memory. It wouldn’t be\nhonest if we didn’t consider relinquishing Go and instead, re-writing the\nentire core component with C. However, things didn’t go exactly as we planned,\nwe ran into trouble migrating the code of Business Logic Layer. As a result, it\nwas impossible for the only personnel at that time (myself) to maintain the Go\nsystem while ensuring the logic transfer to the C service framework.\u003c/p\u003e\n\u003cp\u003eTherefore, I made the decision to stay with Go system (probably the wisest one\nI had to make), and great headway was made soon enough.\u003c/p\u003e\n\u003cp\u003eHere are a few tweaks we made and key take-aways:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eReplace short connections with persistent ones (using a connection pool),\nto reduce creation of buffers and objects during communication.\u003c/li\u003e\n\u003cli\u003eUse Objects and Memory pools appropriately, to reduce the load on the GC.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"image\"\u003e\n  \u003cimg src=\"qihoo/image00.png\" alt=\"\"/\u003e\n\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a Task Pool, a mechanism with a group of long-lived goroutines consuming\nglobal task or message queues sent by connection goroutines,\nto replace short-lived goroutines.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMonitor and control goroutine numbers in the program.\nThe lack of control can cause unbearable burden on the GC,\nimposed by surges in goroutines due to uninhibited acceptance of external requests,\nas RPC invocations sent to inner servers may block goroutines recently created.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRemember to add \u003ca href=\"/pkg/net/#Conn\"\u003eread and write deadlines\u003c/a\u003e\nto connections when under a mobile network;\notherwise, it may lead to goroutine blockage.\nApply it properly and with caution when under a LAN network,\notherwise your RPC communication efficiency will be hurt.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eUse Pipeline (under Full Duplex feature of TCP) to enhance the communication efficiency of RPC framework.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAs a result, we successfully launched three iterations of our architecture,\nand two iterations of our RPC framework even with limited human resources.\nThis can all attributed to the development convenience of Go.\nBelow you can find the up-to-date system architecture:\u003c/p\u003e\n\u003cdiv class=\"image\"\u003e\n  \u003cimg src=\"qihoo/image01.png\" alt=\"\"/\u003e\n\u003c/div\u003e\n\u003cp\u003eThe continuous improvement journey can be illustrated by a table:\u003c/p\u003e\n\u003cdiv class=\"image\"\u003e\n  \u003cimg src=\"qihoo/table.png\" alt=\"\"/\u003e\n\u003c/div\u003e\n\u003cp\u003eAlso, no temporary release of memory or system reboot is required after these\noptimizations.\u003c/p\u003e\n\u003cp\u003eWhat’s more exciting is we developed an on-line real-time Visibility Platform\nfor profiling Go programs. We can now easily access and diagnose the system\nstatus, pinning down any potential risks. Here is a screen shot of the system\nin action:\u003c/p\u003e\n\u003cdiv class=\"image\"\u003e\n  \u003cimg src=\"qihoo/image02.png\" alt=\"\"/\u003e\n\u003c/div\u003e\n\u003cdiv class=\"image\"\u003e\n  \u003cimg src=\"qihoo/image03.png\" alt=\"\"/\u003e\n\u003c/div\u003e\n\u003cp\u003eThe great thing about this platform is that we can actually simulate the\nconnection and behavior of millions of online users, by applying the\nDistributed Stress Test Tool (also built using Go), and observe all real-time\nvisualized data. This allows us to evaluate the effectiveness of any\noptimization and preclude problems by identifying system bottlenecks.\u003c/p\u003e\n\u003cp\u003eAlmost every possible system optimization has been practiced so far. And we\nlook forward to more good news from the GC team so that we could be further\nrelieved from heavy development work. I guess our experience may also grow\nobsolete one day, as Go continues to evolve.\u003c/p\u003e\n\u003cp\u003eThis is why I want to conclude my sharing by extending my sincere appreciation\nto the opportunity to attend \u003ca href=\"http://gopherchina.org/\" rel=\"noreferrer\" target=\"_blank\"\u003eGopher China\u003c/a\u003e.\nIt was a gala for us to learn, to share and for offering a window showcasing\nGo’s popularity and prosperity in China. Many other teams within Qihoo have\nalready either got to know Go, or tried to use Go.\u003c/p\u003e\n\u003cp\u003eI am convinced that many more Chinese Internet firms will join us in\nre-creating their system in Go and the Go team’s efforts will benefit more\ndevelopers and enterprises in the foreseeable future.\u003c/p\u003e\n\n    \u003c/div\u003e",
  "Date": "2015-07-06T00:00:00Z",
  "Author": "Yang Zhou"
}