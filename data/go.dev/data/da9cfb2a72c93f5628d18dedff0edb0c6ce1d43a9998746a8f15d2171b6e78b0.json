{
  "Source": "go.dev",
  "Title": "Go GC: Prioritizing low latency and simplicity",
  "Link": "https://go.dev/blog/go15gc",
  "Content": "\u003cdiv class=\"Article\" data-slug=\"/blog/go15gc\"\u003e\n    \n    \u003ch1 class=\"small\"\u003e\u003ca href=\"/blog/\"\u003eThe Go Blog\u003c/a\u003e\u003c/h1\u003e\n    \n\n    \u003ch1\u003eGo GC: Prioritizing low latency and simplicity\u003c/h1\u003e\n      \n      \u003cp class=\"author\"\u003e\n      Richard Hudson\u003cbr/\u003e\n      31 August 2015\n      \u003c/p\u003e\n      \n      \u003ch2 id=\"the-setup\"\u003eThe Setup\u003c/h2\u003e\n\u003cp\u003eGo is building a garbage collector (GC) not only for 2015 but for 2025 and\nbeyond: A GC that supports today’s software development and scales along with\nnew software and hardware throughout the next decade. Such a future has no\nplace for stop-the-world GC pauses, which have been an impediment to broader\nuses of safe and secure languages such as Go.\u003c/p\u003e\n\u003cp\u003eGo 1.5, the first glimpse of this future, achieves GC latencies well below the\n10 millisecond goal we set a year ago. We presented some impressive numbers\nin \u003ca href=\"/talks/2015/go-gc.pdf\"\u003ea talk at Gophercon\u003c/a\u003e.\nThe latency improvements have generated a lot of attention;\nRobin Verlangen’s blog post\n\u003ca href=\"https://medium.com/@robin.verlangen/billions-of-request-per-day-meet-go-1-5-362bfefa0911\" rel=\"noreferrer\" target=\"_blank\"\u003e\u003cem\u003eBillions of requests per day meet Go 1.5\u003c/em\u003e\u003c/a\u003e\nvalidates our direction with end to end results.\nWe also particularly enjoyed\n\u003ca href=\"https://twitter.com/inconshreveable/status/620650786662555648\" rel=\"noreferrer\" target=\"_blank\"\u003eAlan Shreve’s production server graphs\u003c/a\u003e\nand his “Holy 85% reduction” comment.\u003c/p\u003e\n\u003cp\u003eToday 16 gigabytes of RAM costs $100 and CPUs come with many cores, each with\nmultiple hardware threads. In a decade this hardware will seem quaint but the\nsoftware being built in Go today will need to scale to meet expanding needs and\nthe next big thing. Given that hardware will provide the power to increase\nthroughput, Go’s garbage collector is being designed to favor low latency and\ntuning via only a single knob. Go 1.5 is the first big step down this path and\nthese first steps will forever influence Go and the applications it best\nsupports. This blog post gives a high-level overview of what we have done for\nthe Go 1.5 collector.\u003c/p\u003e\n\u003ch2 id=\"the-embellishment\"\u003eThe Embellishment\u003c/h2\u003e\n\u003cp\u003eTo create a garbage collector for the next decade, we turned to an algorithm\nfrom decades ago. Go’s new garbage collector is a \u003cem\u003econcurrent\u003c/em\u003e, \u003cem\u003etri-color\u003c/em\u003e,\n\u003cem\u003emark-sweep\u003c/em\u003e collector, an idea first proposed by\n\u003ca href=\"http://dl.acm.org/citation.cfm?id=359655\" rel=\"noreferrer\" target=\"_blank\"\u003eDijkstra in 1978\u003c/a\u003e.\nThis is a deliberate divergence from most “enterprise” grade garbage collectors\nof today, and one that we believe is well suited to the properties of modern\nhardware and the latency requirements of modern software.\u003c/p\u003e\n\u003cp\u003eIn a tri-color collector, every object is either white, grey, or black and we\nview the heap as a graph of connected objects. At the start of a GC cycle all\nobjects are white. The GC visits all \u003cem\u003eroots\u003c/em\u003e, which are objects directly\naccessible by the application such as globals and things on the stack, and\ncolors these grey. The GC then chooses a grey object, blackens it, and then\nscans it for pointers to other objects. When this scan finds a pointer to a\nwhite object, it turns that object grey. This process repeats until there are\nno more grey objects. At this point, white objects are known to be unreachable\nand can be reused.\u003c/p\u003e\n\u003cp\u003eThis all happens concurrently with the application, known as the \u003cem\u003emutator\u003c/em\u003e,\nchanging pointers while the collector is running. Hence, the mutator must\nmaintain the invariant that no black object points to a white object, lest the\ngarbage collector lose track of an object installed in a part of the heap it\nhas already visited. Maintaining this invariant is the job of the\n\u003cem\u003ewrite barrier\u003c/em\u003e, which is a small function run by the mutator whenever a\npointer in the heap is modified. Go’s write barrier colors the now-reachable\nobject grey if it is currently white, ensuring that the garbage collector will\neventually scan it for pointers.\u003c/p\u003e\n\u003cp\u003eDeciding when the job of finding all grey objects is done is subtle and can be\nexpensive and complicated if we want to avoid blocking the mutators. To keep\nthings simple Go 1.5 does as much work as it can concurrently and then briefly\nstops the world to inspect all potential sources of grey objects. Finding the\nsweet spot between the time needed for this final stop-the-world and the total\namount of work that this GC does is a major deliverable for Go 1.6.\u003c/p\u003e\n\u003cp\u003eOf course the devil is in the details. When do we start a GC cycle? What\nmetrics do we use to make that decision? How should the GC interact with the Go\nscheduler? How do we pause a mutator thread long enough to scan its stack?\n How do we represent white, grey, and black so we can efficiently find and scan\ngrey objects? How do we know where the roots are? How do we know where in an\nobject pointers are located? How do we minimize memory fragmentation? How do we\ndeal with cache performance issues? How big should the heap be? And on and on,\nsome related to allocation, some to finding reachable objects, some related to\nscheduling, but many related to performance. Low-level discussions of each of\nthese areas are beyond the scope of this blog post.\u003c/p\u003e\n\u003cp\u003eAt a higher level, one approach to solving performance problems is to add GC\nknobs, one for each performance issue. The programmer can then turn the knobs\nin search of appropriate settings for their application. The downside is that\nafter a decade with one or two new knobs each year you end up with the GC Knobs\nTurner Employment Act. Go is not going down that path. Instead we provide a\nsingle knob, called GOGC. This value controls the total size of the heap\nrelative to the size of reachable objects. The default value of 100 means that\ntotal heap size is now 100% bigger than (i.e., twice) the size of the reachable\nobjects after the last collection. 200 means total heap size is 200% bigger\nthan (i.e., three times) the size of the reachable objects. If you want to\nlower the total time spent in GC, increase GOGC. If you want to trade more GC\ntime for less memory, lower GOGC.\u003c/p\u003e\n\u003cp\u003eMore importantly as RAM doubles with the next generation of hardware, simply\ndoubling GOGC will halve the number of GC cycles. On the other hand since GOGC\nis based on reachable object size, doubling the load by doubling the reachable\nobjects requires no retuning. The application just scales.\nFurthermore, unencumbered by ongoing support for dozens of knobs, the runtime\nteam can focus on improving the runtime based on feedback from real customer\napplications.\u003c/p\u003e\n\u003ch2 id=\"the-punchline\"\u003eThe Punchline\u003c/h2\u003e\n\u003cp\u003eGo 1.5’s GC ushers in a future where stop-the-world pauses are no longer a\nbarrier to moving to a safe and secure language. It is a future where\napplications scale effortlessly along with hardware and as hardware becomes\nmore powerful the GC will not be an impediment to better, more scalable\nsoftware. It’s a good place to be for the next decade and beyond.\nFor more details about the 1.5 GC and how we eliminated latency issues see the\n\u003ca href=\"https://www.youtube.com/watch?v=aiv1JOfMjm0\" rel=\"noreferrer\" target=\"_blank\"\u003eGo GC: Latency Problem Solved presentation\u003c/a\u003e\nor \u003ca href=\"/talks/2015/go-gc.pdf\"\u003ethe slides\u003c/a\u003e.\u003c/p\u003e\n\n    \u003c/div\u003e",
  "Date": "2015-08-31T00:00:00Z",
  "Author": "Richard Hudson"
}