{
  "Source": "izsk.me",
  "Title": "Kong学习(解决诡异的Kong Error超时及重试问题)",
  "Link": "https://izsk.me/2020/11/17/Kong-upstream-timeout-60s-and-retry-5/",
  "Content": "\u003cdiv class=\"post-body\" itemprop=\"articleBody\"\u003e\n\n      \n      \n\n      \n        \u003cp\u003e现在业务使用的kong做为api gateway, 最近碰到一个的kong error超时及重试的问题，记录下排查过程\u003c/p\u003e\n\u003cspan id=\"more\"\u003e\u003c/span\u003e\n\n\n\n\u003cp\u003e在浏览器中下载后端一个好几G的文件，会出现Kong Error错误，如下图所示\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20201117193533.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e这里说一下，下载文件这个动作整个端到端的请求路径如下:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e浏览器 \u0026lt;--\u0026gt; kong \u0026lt;--\u0026gt; frontend(VUE + nginx) \u0026lt;--\u0026gt; k8s service \u0026lt;--\u0026gt; backend \u0026lt;--\u0026gt; resource-factory\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003ebackend是则java，提供数据下载，然后返回给前端\u003c/p\u003e\n\u003cp\u003efrontend与backend之间是通过k8s service 进行访问的\u003c/p\u003e\n\u003cp\u003e在frontend请求下载的过程中，backend需要先从resource-factory中获取文件保存在bakend本地，这个时间会比较长，backend下载完成之后才会返回到frontend\u003c/p\u003e\n\u003ch3 id=\"排查过程\"\u003e\u003ca href=\"#排查过程\" class=\"headerlink\" title=\"排查过程\"\u003e\u003c/a\u003e排查过程\u003c/h3\u003e\u003cp\u003e从kong的错误提示来看，很明显，\u003ccode\u003eupstream server\u003c/code\u003e超时（这个\u003ccode\u003eupstream\u003c/code\u003e很重要），最开始没注意，只关注到\u003ccode\u003etimeout\u003c/code\u003e这个关键字了\u003c/p\u003e\n\u003ch4 id=\"backend\"\u003e\u003ca href=\"#backend\" class=\"headerlink\" title=\"backend\"\u003e\u003c/a\u003ebackend\u003c/h4\u003e\u003cp\u003e先从backend的日志开始排查，意料之中，backend日志出现一堆的error，但是意料之外的是，在这过程中出现了每隔60s就会对文件重新下载， 总共进行了5次重新下载的操作，这个比较奇怪，正常只是在页面上点击了一次操作，为何会出现连续下载5次的流程，而且每次下载都没有下载完就进行重试，而且都是每隔60s， 像是有重试的操作，比较诡异\u003c/p\u003e\n\u003cp\u003e从日志可以肯定的是，\u003cstrong\u003e下载文件的代码逻辑是没有问题的\u003c/strong\u003e，因此在这里出现了两个问题:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e下载代码没问题，但下载为何会失败\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e60s, 5次下载是怎么产生的\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e下面主要是在排查问题2是如何产生的，还是比较有意思\u003c/p\u003e\n\u003ch4 id=\"frontend\"\u003e\u003ca href=\"#frontend\" class=\"headerlink\" title=\"frontend\"\u003e\u003c/a\u003efrontend\u003c/h4\u003e\u003cp\u003e从backend没有找到最有价值的信息，那么看看frontend打印的日志中有没有什么思路，由于frontend中包含了一个nginx，大部分的请求都会被记录下来，首先将nginx的日志调整为\u003ccode\u003edebug\u003c/code\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ccode\u003eclient xxx.xxx.xxx.xxx closed keepalive connection\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eepoll_wait() reported that client prematurely closed connection\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e出现nginx 499状态码\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20201117103815.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e关于第1个\u003ccode\u003e错误\u003c/code\u003e(后来被证实这不是错误)看到keepalive closed，那么是不是很自然地想到nginx中有关于keepalive的相关参数，keepalive默认情况下是75s,跟60s好像也不太符合，但是不是确实是这个值太小了呢? 因些作者还是调整了frontend中nginx的keepalive为600s, 但是问题依旧\u003c/p\u003e\n\u003cp\u003e因此转到第2个错误，网上查找了一翻发现这个跟上面两行出现代码499的原因一致，\u003ccode\u003enginx 499 \u003c/code\u003e这个状态码可能接触地比较少，当时也不是很明白这个状态码应对的含义，如果有不清楚的可以参考\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://imajinyun.xyz/2019/11/15/nginx-499-faq/\"\u003enginx-499-faq\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e499一句话概括就是: \u003cstrong\u003eNginx 把请求转发上游服务器，上游服务器慢吞吞的处理，客户端等不及了主动断开链接，Nginx 就负责记录了 \u003ccode\u003e499\u003c/code\u003e\u003c/strong\u003e, 是不是刚好跟epoll_wait那句话的意思相近。\u003c/p\u003e\n\u003cp\u003e因此出现错误499及错误2的原因就是客户端主动关闭了连接，\u003c/p\u003e\n\u003cp\u003e由于下载的文件非常大，大小在4G+， 作者还以为是nginx某些配置的timeout设置的不准确\u003c/p\u003e\n\u003cp\u003efrontend中的nginx主要调整过的配置项如下:\u003c/p\u003e\n\u003cfigure class=\"highlight bash\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e4\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003ekeepalive_timeout 1200s;\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003esend_timeout 1200s;\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003eproxy_read_timeout 1200s;\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003eproxy_send_timeout 1200s;\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\u003cp\u003e重启之后发现问题依旧, 这时作者怀疑是浏览器是不是也存在timeout不够长导致连接被断开了\u003c/p\u003e\n\u003cp\u003e因此直接使用\u003cstrong\u003ecurl的方式请求\u003c/strong\u003e，发现问题依旧，\u003cstrong\u003e因此可以排除浏览器的问题\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这时作者想起另外一个也同样使用VUE写的前端，VUE的axios(\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://blog.csdn.net/qq_36727756/article/details/93738441\"\u003e参考\u003c/a\u003e)是可以设置http请求的超时时间的，那是不是会由于前端对每个http设置的timeout太短了呢，经过询问前端的同事，果然，前端配置了这个时间为60s，这明显不够，作者欣喜若狂，以为见到了曙光, 然而\u003c/p\u003e\n\u003cp\u003e** too young, too simple**\u003c/p\u003e\n\u003cp\u003e前端将60s调整为600s，\u003cstrong\u003e问题依旧\u003c/strong\u003e 同样提示上面的错误，同样重复下载5次\u003c/p\u003e\n\u003cp\u003e** WHAT FXXK**\u003c/p\u003e\n\u003cp\u003e同时，作者跟前端同事反复确认frontend的逻辑中会不会有重试的代码，前端同事很明确地说：NO\u003c/p\u003e\n\u003cp\u003e冷静下来\u003c/p\u003e\n\u003cp\u003eVUE的axios超时时间一定有影响，消除这部分的影响问题依旧，那一定还有别的地方存在timeout从而引起重试机制，既然对于frotend的nginx来说，是客户端主动断开了连接，除了frontend代码本身，那客户端还有谁呢?\u003c/p\u003e\n\u003ch4 id=\"kong\"\u003e\u003ca href=\"#kong\" class=\"headerlink\" title=\"kong\"\u003e\u003c/a\u003ekong\u003c/h4\u003e\u003cp\u003e在frontend前面的就是kong了，那么它就是客户端，难道是kong这边把连接主动断开了？\u003c/p\u003e\n\u003cp\u003e为了验证是不是kong这边的问题，作者使用curl直接请求frontend，绕过了kong这一层，发现居然下载没问题了，同时，也不存在每隔60s重复下载一次的现象\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20201117110709.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e从下载的流程来看，前2分44s应该是backend向resource-factory中获取文件下载到本地的时间，果然时间比较长\u003c/p\u003e\n\u003cp\u003e后面的10分37s则是backend向frontend的nginx加传文件的时间，时间也比较长\u003c/p\u003e\n\u003cp\u003e好歹直接通过frontend可以下载文件成功.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e柳暗花明又一村\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e截止到现在归纳一下做过的调整\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e调整了VUE的axios的超时时间，这个是对每个经过frontend的请求都生效\u003c/li\u003e\n\u003cli\u003e调整了frontend中nginx的timeout配置\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e老规矩，看kong proxy的日志如下:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20201117114330.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e也是timeout,不过这次作者终于看到了\u003cstrong\u003eupstream\u003c/strong\u003e这个词了\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e这里说的upstream不就是frontend么, 难道是当backend向resource-factory下载文件的时候，也就是2分44s这个时间内，frontend没有收到backend返回的response，frontend也就没有response返回给kong， 在一定时间内(也就是日志中出现的60s)kong无法从frontend中获取到response，出现timeout,然后开始重试，重试5次之后frontend还是没有response，最后kong将这条请求断开了.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这个猜想其实是合理的，符合看到的日志报错，同时也符合5次重试的这个现象\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e但是5次重启到底是怎么回事，upstream真的就是frontend\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e作者这里也想到kong其实openresty, 不也是nginx呢?那是不是kong也需要设置一下nginx的timeout配置呢?\u003c/p\u003e\n\u003cp\u003e嗯，加上再说\u003c/p\u003e\n\u003cfigure class=\"highlight bash\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e4\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e5\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e6\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e7\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e8\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e9\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e10\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e11\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e12\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e13\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e14\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e- name: KONG_NGINX_PROXY_CLIENT_BODY_TIMEOUT\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  value: 600s\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e- name: KONG_NGINX_PROXY_CLIENT_HEADER_TIMEOUT\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  value: 600s\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e- name: KONG_NGINX_PROXY_KEEPALIVE_TIMEOUT\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  value: 600s\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e- name: KONG_NGINX_PROXY_PROXY_READ_TIMEOUT\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  value: 600s\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e- name: KONG_NGINX_PROXY_PROXY_SEND_TIMEOUT\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  value: 600s\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e- name: KONG_NGINX_PROXY_SEND_TIMEOUT\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  value: 600s\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e- name: KONG_NGINX_UPSTREAM_KEEPALIVE_TIMEOUT\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  value: 600s\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\u003cp\u003e按照\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://docs.konghq.com/1.1.x/configuration/\"\u003e官方文档\u003c/a\u003e将这些参数到容器的env中，然后重启kong\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e擦，问题依旧\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这里看到问题没有解决，第一时间难道是加的参数都没有生效，不能使用environment，作者还特意到容器中验证了一下验证\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20201117120250.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20201117120312.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e发现都是没有问题的，那为什么还是不行呢?\u003c/p\u003e\n\u003cp\u003e再次网上搜索一翻，发现kong中对于service(\u003cstrong\u003e是kong中的service,而不是k8s中的service\u003c/strong\u003e),还有3个timeout参数\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20201117225634.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e然后到kong中查看对应的service, 如下:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20201117164812.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e发现这3个timeout都是默认值，为60s， 而且，retries为5\u003c/strong\u003e，刚好跟重试的现象对应上了\u003c/p\u003e\n\u003cp\u003e先不管，使用如下命令更新一下这个记录，将timeout改长一点\u003c/p\u003e\n\u003cfigure class=\"highlight bash\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e4\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003ecurl -X PATCH --url https://127.0.0.1:8444/services/791f94ae-7971-54e5-8996-e66083af6617 \\\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e-d \u003cspan class=\"string\"\u003e\u0026#39;connect_timeout=800000\u0026#39;\u003c/span\u003e \\\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e-d \u003cspan class=\"string\"\u003e\u0026#39;read_timeout=800000\u0026#39;\u003c/span\u003e \\\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e-d \u003cspan class=\"string\"\u003e\u0026#39;write_timeout=800000\u0026#39;\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\u003cp\u003e发现提示下面的错误:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20201117170805.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e真是一步一个坎， 更新操作不支持，作者也试过删除操作，发现也是同样的错误\u003c/p\u003e\n\u003cp\u003e这个错误的原因在于作者使用的kong是DB-less的模式，对于db-less下是不能修改绑定在kong上的\u003ccode\u003eentities serivces\u003c/code\u003e的\u003c/p\u003e\n\u003cp\u003e那不能更新也不能删除，那么就只能重建了service了,kong中的service对应的是\u003ccode\u003ekongingress中的proxy\u003c/code\u003e,更新如下\u003c/p\u003e\n\u003cfigure class=\"highlight yaml\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e4\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e5\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e6\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e7\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e8\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e9\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e10\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e11\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e12\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e13\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e14\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e15\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"meta\"\u003e---\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"attr\"\u003eapiVersion:\u003c/span\u003e \u003cspan class=\"string\"\u003econfiguration.konghq.com/v1\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"attr\"\u003ekind:\u003c/span\u003e \u003cspan class=\"string\"\u003eKongIngress\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"attr\"\u003emetadata:\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  \u003cspan class=\"attr\"\u003ename:\u003c/span\u003e \u003cspan class=\"string\"\u003ekongingress-resource\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"attr\"\u003eproxy:\u003c/span\u003e  \u003cspan class=\"comment\"\u003e# proxy是新增的\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  \u003cspan class=\"attr\"\u003econnect_timeout:\u003c/span\u003e \u003cspan class=\"number\"\u003e800000\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  \u003cspan class=\"attr\"\u003epath:\u003c/span\u003e \u003cspan class=\"string\"\u003e/\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  \u003cspan class=\"attr\"\u003eport:\u003c/span\u003e \u003cspan class=\"number\"\u003e8080\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  \u003cspan class=\"attr\"\u003eprotocols:\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  \u003cspan class=\"bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"string\"\u003ehttp\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  \u003cspan class=\"bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"string\"\u003ehttps\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  \u003cspan class=\"attr\"\u003eread_timeout:\u003c/span\u003e \u003cspan class=\"number\"\u003e800000\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  \u003cspan class=\"attr\"\u003eretries:\u003c/span\u003e \u003cspan class=\"number\"\u003e0\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  \u003cspan class=\"attr\"\u003ewrite_timeout:\u003c/span\u003e \u003cspan class=\"number\"\u003e800000\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\u003cp\u003e这样更新之后会发现kong中serivce的记录还是不变，经过多次的实验，正确的操作如下:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e先将ingress删除后，会发现kong中的service记录也删除掉了\u003c/li\u003e\n\u003cli\u003e然后将k8s中的service加上annotations指定\u003ccode\u003ekonghq.com/override: kongingress-resource\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e再发布ingress, 同样指定\u003ccode\u003ekonghq.com/override: kongingress-resource\u003c/code\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e经过上面的3个操作之后，再来看kong中service的记录，更新成功\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20201117174434.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e这个时候再测试页面的下载功能，就没有再出现过超时及重试的现象了，\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e完美\u003c/strong\u003e\u003c/p\u003e\n\u003ch3 id=\"总结\"\u003e\u003ca href=\"#总结\" class=\"headerlink\" title=\"总结\"\u003e\u003c/a\u003e总结\u003c/h3\u003e\u003cp\u003e对于这次\u003ccode\u003e诡异\u003c/code\u003e的timeout问题可以看出， 中间的转发层一多，因为每一层都可能超时，原因排查起来就比较费力\u003c/p\u003e\n\u003cp\u003e在排查过程中，每个错误都可能是关键信息，不要选择性忽略，对于这次作者其实就忽略了\u003ccode\u003eupstream\u003c/code\u003e这个信息\u003c/p\u003e\n\u003cp\u003e当然如果从一开始就关注到upstream，也还是要将上面的排查过程走一遍，因为确实有好几个地方都是有问题的\u003c/p\u003e\n\u003cp\u003e比如UVE的axios的超时配置，nginx的超时配置，作者在这过程中甚至还想到过k8s中service的超时机制\u003c/p\u003e\n\u003cp\u003e有用的知识又增加了一些.\u003c/p\u003e\n\u003ch3 id=\"参考文章\"\u003e\u003ca href=\"#参考文章\" class=\"headerlink\" title=\"参考文章:\"\u003e\u003c/a\u003e\u003cstrong\u003e参考文章:\u003c/strong\u003e\u003c/h3\u003e\u003cblockquote\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://docs.konghq.com/1.1.x/configuration/\"\u003ehttps://docs.konghq.com/1.1.x/configuration/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://docs.konghq.com/1.1.x/configuration/\"\u003ehttps://docs.konghq.com/1.1.x/configuration/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/Kong/kubernetes-ingress-controller/issues/472\"\u003ehttps://github.com/Kong/kubernetes-ingress-controller/issues/472\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/Kong/kubernetes-ingress-controller/issues/905\"\u003ehttps://github.com/Kong/kubernetes-ingress-controller/issues/905\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://linuxops.org/blog/kong/admin.html\"\u003ehttps://linuxops.org/blog/kong/admin.html\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://docs.konghq.com/1.1.x/admin-api/#update-service\"\u003ehttps://docs.konghq.com/1.1.x/admin-api/#update-service\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://imajinyun.xyz/2019/11/15/nginx-499-faq/\"\u003ehttps://imajinyun.xyz/2019/11/15/nginx-499-faq/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://lanjingling.github.io/2016/06/11/nginx-https-keepalived-youhua/\"\u003ehttps://lanjingling.github.io/2016/06/11/nginx-https-keepalived-youhua/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://luanlengli.github.io/2019/07/02/Kong-Ingress-Controller%E9%83%A8%E7%BD%B2.html\"\u003ehttps://luanlengli.github.io/2019/07/02/Kong-Ingress-Controller%E9%83%A8%E7%BD%B2.html\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://blog.csdn.net/qq_36727756/article/details/93738441\"\u003ehttps://blog.csdn.net/qq_36727756/article/details/93738441\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"转载请注明原作者-周淑科-https-izsk-me\"\u003e\u003ca href=\"#转载请注明原作者-周淑科-https-izsk-me\" class=\"headerlink\" title=\"转载请注明原作者: 周淑科(https://izsk.me)\"\u003e\u003c/a\u003e\u003cstrong\u003e转载请注明原作者: 周淑科(\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://izsk.me/\"\u003ehttps://izsk.me\u003c/a\u003e)\u003c/strong\u003e\u003c/h3\u003e\n      \n    \u003c/div\u003e",
  "Date": "2020-11-17T23:40:53+08:00",
  "Author": "Z.S.K."
}