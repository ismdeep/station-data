{
  "Source": "izsk.me",
  "Title": "Kubernetes学习(使用lxcfs实现容器资源隔离)",
  "Link": "https://izsk.me/2023/01/09/Kubernetes-pod-xlcfs/",
  "Content": "\u003cdiv class=\"post-body\" itemprop=\"articleBody\"\u003e\n\n      \n      \n\n      \n        \u003cp\u003eLinuxs利用Cgroup实现了对容器的资源限制，但在容器内部依然缺省挂载了宿主机上的procfs(内存文件系统)的/proc目录，其包含如：meminfo, cpuinfo，stat， uptime等资源信息。一些监控工具如free/top或遗留应用还依赖上述文件内容获取资源配置和使用情况。当它们在容器中运行时，就会把宿主机的资源状态读取出来，引起错误和不便。\u003c/p\u003e\n \u003cspan id=\"more\"\u003e\u003c/span\u003e\n\n\n\u003ch3 id=\"背景\"\u003e\u003ca href=\"#背景\" class=\"headerlink\" title=\"背景\"\u003e\u003c/a\u003e背景\u003c/h3\u003e\u003cp\u003e最近就出现过类似的问题:\u003c/p\u003e\n\u003cp\u003e在kubernetes集群中部署了一个nginx用作ingress-nginx，出现一个很奇怪的现象是，隔一段时音就会有些连接被自动断开，排查后发现问题原因在于:\u003c/p\u003e\n\u003cp\u003e默认情况下,nginx会根据cpu的数量来启动worker的个数, 由于nginx容器所有的节点配置非常高，cpu为256, 导致nginx中启动了256个worker， 因为集群中有很多ing对象，ingress-nginx-controller会高频率地更新配置，每次的变更都需要同步到所有worker进行加载\u003c/p\u003e\n\u003cp\u003e因此这种情况下，要么手工显示地指定worker的数量，当然更好的办法是让nginx能够\u003cstrong\u003e正确地识别容器中cpu的个数\u003c/strong\u003e\u003cbr/\u003e是否可行呢？\u003c/p\u003e\n\u003ch3 id=\"lxcfs\"\u003e\u003ca href=\"#lxcfs\" class=\"headerlink\" title=\"lxcfs\"\u003e\u003c/a\u003elxcfs\u003c/h3\u003e\u003cp\u003e当然是可以的，\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/lxc/lxcfs\"\u003elxcfs\u003c/a\u003e作为一种CNCF推荐的方式,用于实现容器中的资源隔离, 主要有以下几种:\u003c/p\u003e\n\u003cfigure class=\"highlight bash\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e4\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e5\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e6\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e7\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e8\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e/proc/cpuinfo\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e/proc/diskstats\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e/proc/meminfo\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e/proc/stat\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e/proc/swaps\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e/proc/uptime\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e/proc/slabinfo\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e/sys/devices/system/cpu/online\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\u003ch4 id=\"流程\"\u003e\u003ca href=\"#流程\" class=\"headerlink\" title=\"流程\"\u003e\u003c/a\u003e流程\u003c/h4\u003e\u003cp\u003e总体说起来很简单，当容器启动时，/proc/xxx会被挂载成host上lxcfs的目录。当请求读取/proc/meminfo的信息时，请求就会被导向lxcfs，而lxcfs就会通过cgroup的信息来返回正确的值给容器内的请求方\u003c/p\u003e\n\u003ch4 id=\"流程图\"\u003e\u003ca href=\"#流程图\" class=\"headerlink\" title=\"流程图\"\u003e\u003c/a\u003e流程图\u003c/h4\u003e\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20230109192434.png\"/\u003e\u003c/p\u003e\n\u003ch4 id=\"具体实现\"\u003e\u003ca href=\"#具体实现\" class=\"headerlink\" title=\"具体实现\"\u003e\u003c/a\u003e具体实现\u003c/h4\u003e\u003cp\u003eLXCFS是基于FUSE(filesystems in user space)实现而成的一套用户态文件系统，和其他文件系统最本质的区别在于，文件系统通过用户态程序和内核FUSE模块交互完成。Linux内核从2.6.14版本开始通过FUSE模块支持在用户空间实现文件系统。通过LXCFS的源码可以看到，LXCFS主要通过调用底层fuse的lib库libfuse和内核模块fuse交互实现成一个用户态的文件系统。此外，LXCFS涉及到对cgroup文件系统的管理则是通过cgmanager用户态程序实现\u003cbr/\u003eFUSE的实现，感兴趣的可以看看\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://zhuanlan.zhihu.com/p/106719192\"\u003e5分钟搞懂用户空间文件系统FUSE工作原理\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"lxcfs-on-kubernetes\"\u003e\u003ca href=\"#lxcfs-on-kubernetes\" class=\"headerlink\" title=\"lxcfs on kubernetes\"\u003e\u003c/a\u003elxcfs on kubernetes\u003c/h3\u003e\u003cp\u003e在kubernetes中，已经有相应的解决方案\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/cndoit18/lxcfs-on-kubernetes\"\u003elxcfs-on-kubernetes\u003c/a\u003e\u003cbr/\u003eP.S. 推荐一个fork版本,去除了对cert-manager的依赖，作者亲测有效, 项目地址\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/AEGQ/lxcfs-on-kubernetes/commits/master\"\u003eAEGQ lxcfs-on-kubernetes\u003c/a\u003e,\u003cbr/\u003elxcfs-on-kubernetes安装方式也非常简单,helm几乎不需要改动即可发布，分为manager跟agent两个程序\u003cbr/\u003emanager就是一个webhook, 当有请求到达时，为相应的容器挂载lxcfs目录\u003cbr/\u003eagent就是一个lxcfs二进制程序, 做为daemonset运行在宿主机上\u003c/p\u003e\n\u003cp\u003e需要通过给namespace打label来开启自动挂载的功能\u003c/p\u003e\n\u003cfigure class=\"highlight bash\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003ekubectl label namespace default mount-lxcfs=enabled\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\u003cp\u003e重要的是， 如果pod中没有指定limit,则看到的还是node上所有的资源，因此，\u003cstrong\u003e必须指定limit，才能获取到正确的cgroup\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这样，发布到default里的pod都将得到正确的资源值\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e集群安全无小事，不放过每处细节\u003c/strong\u003e\u003c/p\u003e\n\u003ch3 id=\"参考文章\"\u003e\u003ca href=\"#参考文章\" class=\"headerlink\" title=\"参考文章:\"\u003e\u003c/a\u003e\u003cstrong\u003e参考文章:\u003c/strong\u003e\u003c/h3\u003e\u003ch3 id=\"转载请注明原作者-周淑科-https-izsk-me\"\u003e\u003ca href=\"#转载请注明原作者-周淑科-https-izsk-me\" class=\"headerlink\" title=\"转载请注明原作者: 周淑科(https://izsk.me)\"\u003e\u003c/a\u003e\u003cstrong\u003e转载请注明原作者: 周淑科(\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://izsk.me/\"\u003ehttps://izsk.me\u003c/a\u003e)\u003c/strong\u003e\u003c/h3\u003e\u003cblockquote\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/lxc/lxcfs\"\u003ehttps://github.com/lxc/lxcfs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://zhuanlan.zhihu.com/p/106719192\"\u003ehttps://zhuanlan.zhihu.com/p/106719192\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/cndoit18/lxcfs-on-kubernetes\"\u003ehttps://github.com/cndoit18/lxcfs-on-kubernetes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://www.yisu.com/zixun/9857.html\"\u003ehttps://www.yisu.com/zixun/9857.html\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n\n      \n    \u003c/div\u003e",
  "Date": "2023-01-09T17:30:53+08:00",
  "Author": "Z.S.K."
}