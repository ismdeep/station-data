{
  "Source": "leovan.me",
  "Title": "马尔科夫链蒙特卡洛方法和吉布斯采样 (MCMC and Gibbs Sampling)",
  "Link": "https://leovan.me/cn/2017/12/mcmc-and-gibbs-sampling/",
  "Content": "\u003carticle class=\"main\"\u003e\n    \u003cheader class=\"content-title\"\u003e\n    \n\u003ch1 class=\"title\"\u003e\n  \n  马尔科夫链蒙特卡洛方法和吉布斯采样 (MCMC and Gibbs Sampling)\n  \n\u003c/h1\u003e\n\n\n\n\n\n\n\n\u003ch2 class=\"author-date\"\u003e范叶亮 / \n2017-12-17\u003c/h2\u003e\n\n\n\n\u003ch3 class=\"post-meta\"\u003e\n\n\n\u003cstrong\u003e分类: \u003c/strong\u003e\n\u003ca href=\"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0\"\u003e机器学习\u003c/a\u003e\n\n\n\n\n/\n\n\n\n\n\u003cstrong\u003e标签: \u003c/strong\u003e\n\u003cspan\u003e马尔科夫链蒙特卡洛方法\u003c/span\u003e, \u003cspan\u003eMCMC\u003c/span\u003e, \u003cspan\u003e吉布斯采样\u003c/span\u003e, \u003cspan\u003eGibbs Sampling\u003c/span\u003e\n\n\n\n\n/\n\n\n\u003cstrong\u003e字数: \u003c/strong\u003e\n3496\n\u003c/h3\u003e\n\n\n\n\u003chr/\u003e\n\n\n\n    \n    \n    \u003cins class=\"adsbygoogle\" style=\"display:block; text-align:center;\" data-ad-layout=\"in-article\" data-ad-format=\"fluid\" data-ad-client=\"ca-pub-2608165017777396\" data-ad-slot=\"1261604535\"\u003e\u003c/ins\u003e\n    \u003cscript\u003e\n    (adsbygoogle = window.adsbygoogle || []).push({});\n    \u003c/script\u003e\n    \n    \n    \u003c/header\u003e\n\n\n\n\n\u003ch1 id=\"蒙特卡罗方法-monte-carlo-mc\"\u003e蒙特卡罗方法 (Monte Carlo, MC)\u003c/h1\u003e\n\u003cp\u003e蒙特卡罗方法 (Monte Carlo) 也称为统计模拟方法，是于 20 世纪 40 年代由冯·诺伊曼，斯塔尼斯拉夫·乌拉姆和尼古拉斯·梅特罗波利斯在洛斯阿拉莫斯国家实验室为核武器计划工作时 (曼哈顿计划) 发明。因为乌拉姆的叔叔经常在摩纳哥的蒙特卡罗赌场输钱，该方法被定名为蒙特卡罗方法。蒙特卡罗方法是以概率为基础的方法，与之对应的是确定性算法。\u003c/p\u003e\n\u003cp\u003e蒙特卡罗方法最早可以追述到 18 世纪的\u003ca href=\"https://zh.wikipedia.org/zh-hans/%E5%B8%83%E4%B8%B0%E6%8A%95%E9%92%88%E9%97%AE%E9%A2%98\"\u003e布丰投针问题\u003c/a\u003e，该方法通过一个平行且等距木纹铺成的地板，随意抛一支长度比木纹之间距离小的针，求针和其中一条木纹相交的概率的方法得出了一个求 \u003ccode\u003e$\\pi$\u003c/code\u003e 的蒙特卡罗方法。我们通过另一种方式使用蒙特卡罗方法计算圆周率 \u003ccode\u003e$\\pi$\u003c/code\u003e，对于一个边长为 \u003ccode\u003e$2r$\u003c/code\u003e 的正方形，其内切圆的半径即为 \u003ccode\u003e$r$\u003c/code\u003e，因此圆形的面积 \u003ccode\u003e$A_c$\u003c/code\u003e 与正方形的面积 \u003ccode\u003e$A_s$\u003c/code\u003e 的比值为\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\dfrac{A_c}{A_s} = \\dfrac{\\pi r^2}{\\left(2r\\right)^2} = \\dfrac{\\pi}{4} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2017-12-17-mcmc-and-gibbs-sampling/mc-pi.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cp\u003e如果我们在矩形内随机的生成均匀分布的点，则在圆内的点的个数的占比即为 \u003ccode\u003e$\\dfrac{\\pi}{4}$\u003c/code\u003e，因此通过模拟即可求出 \u003ccode\u003e$\\pi$\u003c/code\u003e 的近似值\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-r\"\u003elibrary(tidyverse)\n\n# 圆的中心点和半径\nr \u0026lt;- 2\ncenter_x \u0026lt;- r\ncenter_y \u0026lt;- r\n\n# 距离公式\ndistance \u0026lt;- function(point_x, point_y, center_x, center_y) {\n    sqrt((point_x - center_x)^2 + (point_y - center_y)^2)\n}\n\n# 点生成器\npoints_generator \u0026lt;- function(size) {\n    set.seed(112358)\n    points_x \u0026lt;- runif(size, min = 0, max = 2*r)\n    points_y \u0026lt;- runif(size, min = 0, max = 2*r)\n    \n    tibble(\n        x = points_x,\n        y = points_y,\n        in_cycle = ifelse(\n            distance(points_x, points_y, center_x, center_y) \u0026gt; r, 0, 1)\n    )\n}\n\n# 点的个数\nsizes \u0026lt;- c(1000, 10000, 100000, 1000000, 10000000)\n\n# 估计的 PI 值\nestimated_pi \u0026lt;- sapply(sizes, function(size) {\n    points \u0026lt;- points_generator(size)\n    sum(points$in_cycle) * 4 / size\n})\nprint(estimated_pi)\n# [1] 3.184000 3.146400 3.137880 3.143140 3.141889\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e模拟 \u003ccode\u003e$1000$\u003c/code\u003e 个随机点的结果如图所示\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2017-12-17-mcmc-and-gibbs-sampling/mc-pi-simulation.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cp\u003e对于简单的分布 \u003ccode\u003e$p\\left(x\\right)$\u003c/code\u003e，我们可以相对容易的生成其样本，但对于复杂的分布或高维的分布，样本的生成就比较困难了\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e，例如：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ccode\u003e$p\\left(x\\right) = \\dfrac{\\tilde{p}\\left(x\\right)}{\\int\\tilde{p}\\left(x\\right) dx}$\u003c/code\u003e，其中 \u003ccode\u003e$\\tilde{p}\\left(x\\right)$\u003c/code\u003e 是可以计算的，而分母中的积分是无法显式计算的。\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e$p\\left(x, y\\right)$\u003c/code\u003e 是一个二维分布函数，函数本身计算很困难，但其条件分布 \u003ccode\u003e$p\\left(x | y\\right)$\u003c/code\u003e 和 \u003ccode\u003e$p\\left(y | x\\right)$\u003c/code\u003e 计算相对简单。对于高维情况 \u003ccode\u003e$p\\left(\\boldsymbol{x}\\right)$\u003c/code\u003e，这种情况则更加明显。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e这时候则需要更加复杂的模拟方法来生成样本了。\u003c/p\u003e\n\u003ch1 id=\"马尔科夫链-markov-chain-mc\"\u003e马尔科夫链 (Markov Chain, MC)\u003c/h1\u003e\n\u003cp\u003e马尔可夫过程 (Markov Process) 是因俄国数学家安德雷·安德耶维齐·马尔可夫 (Андрей Андреевич Марков) 而得名一个随机过程，在该随机过程中，给定当前状态和过去所有状态的条件下，其下一个状态的条件概率分布仅依赖于当前状态，通常具备离散状态的马尔科夫过程称之为马尔科夫链 (Markov Chain)。因此，马尔科夫链可以理解为一个有限状态机，给定了当前状态为 \u003ccode\u003e$s_i$\u003c/code\u003e 时，下一时刻状态为 \u003ccode\u003e$s_j$\u003c/code\u003e 的概率，不同状态之间变换的概率称之为转移概率。下图描述了 3 个状态 \u003ccode\u003e$S_a, S_b, S_c$\u003c/code\u003e 之间转换状态的马尔科夫链。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2017-12-17-mcmc-and-gibbs-sampling/markov-chain-demo.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cp\u003e对于马尔科夫链，我们设 \u003ccode\u003e$X_t$\u003c/code\u003e 表示 \u003ccode\u003e$t$\u003c/code\u003e 时刻随机变量 \u003ccode\u003e$X$\u003c/code\u003e 的取值，则马尔科夫链可以表示为\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ P\\left(X_{t+1} = s_j | X_0 = s_{i0}, X_1 = s_{i1}, ..., X_t = s_i\\right) = P\\left(X_{t+1} | X_t = s_i\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$s_{i0}, s_{i1}, ..., s_i, s_j$\u003c/code\u003e 为随机变量 \u003ccode\u003e$X$\u003c/code\u003e 可能的状态。则定义从一个状态 \u003ccode\u003e$s_i$\u003c/code\u003e 到另一个状态 \u003ccode\u003e$s_j$\u003c/code\u003e 的转移概率为\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ P\\left(i \\to j\\right) = P_{ij} = P\\left(X_{t+1} | X_t = s_i\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e设 \u003ccode\u003e$\\pi_{k}^{\\left(t\\right)}$\u003c/code\u003e 表示随机变量 \u003ccode\u003e$X$\u003c/code\u003e 在 \u003ccode\u003e$t$\u003c/code\u003e 时刻取值为 \u003ccode\u003e$s_k$\u003c/code\u003e 的概率，则 \u003ccode\u003e$X$\u003c/code\u003e 在 \u003ccode\u003e$t+1$\u003c/code\u003e 时刻取值为 \u003ccode\u003e$s_i$\u003c/code\u003e 的概率为\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{equation} \\begin{split} \\pi_{i}^{\\left(t+1\\right)} \u0026amp;= P\\left(X_{t+1} = s_i\\right) \\\\ \u0026amp;= \\sum_{k}{P\\left(X_{t+1} = s_i | X_t = s_k\\right) \\cdot P\\left(X_t = s_k\\right)} \\\\ \u0026amp;= \\sum_{k}{P_{ki} \\cdot \\pi_{k}^{\\left(t\\right)}} \\end{split} \\end{equation} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e我们通过一个例子来理解一下马尔科夫链，我们使用 LDA 数学八卦\u003csup id=\"fnref1:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e一文中的例子，对于人口，我们将其经济状况分为 3 类：下层，中层和上层，其父代到子代收入阶层的转移情况如表所示\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth style=\"text-align:center\"\u003e父代阶层\\子代阶层\u003c/th\u003e\n\u003cth style=\"text-align:center\"\u003e下层\u003c/th\u003e\n\u003cth style=\"text-align:center\"\u003e中层\u003c/th\u003e\n\u003cth style=\"text-align:center\"\u003e下层\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:center\"\u003e下层\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0.65\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0.28\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0.07\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:center\"\u003e中层\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0.15\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0.67\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0.18\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:center\"\u003e上层\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0.12\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0.36\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0.52\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e我们利用矩阵的形式表示转移概率\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ P = \\left\\lgroup \\begin{array}{cccc} P_{11} \u0026amp; P_{12} \u0026amp; \\cdots \u0026amp; P_{1n} \\\\ P_{21} \u0026amp; P_{22} \u0026amp; \\cdots \u0026amp; P_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp;        \u0026amp; \\vdots \\\\ P_{n1} \u0026amp; P_{n2} \u0026amp; \\cdots \u0026amp; P_{nn} \\end{array} \\right\\rgroup $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e则\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\pi^{\\left(t+1\\right)} = \\pi^{\\left(t\\right)} P $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e假设初始概率分布为 \u003ccode\u003e$\\pi_0 = \\left(0.21, 0.68, 0.11\\right)$\u003c/code\u003e，则计算前 \u003ccode\u003e$n$\u003c/code\u003e 代人的阶层分布情况如下\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-r\"\u003e# 转移矩阵\np \u0026lt;- matrix(c(0.65, 0.28, 0.07,\n              0.15, 0.67, 0.18,\n              0.12, 0.36, 0.52),\n            3, 3, byrow = T)\n# 初始概率\npi \u0026lt;- matrix(c(0.21, 0.68, 0.11), 1, 3, byrow = T)\n\n# 迭代变化\nfor (i in 1:10) {\n    pi_current \u0026lt;- pi[i, ]\n    pi_next \u0026lt;- pi_current %*% p\n    pi \u0026lt;- rbind(pi, pi_next)\n}\n\ncolnames(pi) \u0026lt;- c(\u0026#39;下层\u0026#39;, \u0026#39;中层\u0026#39;, \u0026#39;上层\u0026#39;)\nrownames(pi) \u0026lt;- 0:10\nprint(pi)\n#         下层      中层      上层\n# 0  0.2100000 0.6800000 0.1100000\n# 1  0.2517000 0.5540000 0.1943000\n# 2  0.2700210 0.5116040 0.2183750\n# 3  0.2784592 0.4969956 0.2245452\n# 4  0.2824933 0.4917919 0.2257148\n# 5  0.2844752 0.4898560 0.2256688\n# 6  0.2854675 0.4890974 0.2254351\n# 7  0.2859707 0.4887828 0.2252465\n# 8  0.2862280 0.4886450 0.2251270\n# 9  0.2863602 0.4885817 0.2250581\n# 10 0.2864283 0.4885515 0.2250201\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e可以看出，从第 7 代人开始，分布就基本稳定下来了，如果将初值概率换成 \u003ccode\u003e$\\pi_0 = \\left(0.75, 0.15, 0.1\\right)$\u003c/code\u003e，结果会是如何呢？\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-r\"\u003epi \u0026lt;- matrix(c(0.75, 0.15, 0.1), 1, 3, byrow = T)\n\nfor (i in 1:10) {\n    pi_current \u0026lt;- pi[i, ]\n    pi_next \u0026lt;- pi_current %*% p\n    pi \u0026lt;- rbind(pi, pi_next)\n}\n\ncolnames(pi) \u0026lt;- c(\u0026#39;下层\u0026#39;, \u0026#39;中层\u0026#39;, \u0026#39;上层\u0026#39;)\nrownames(pi) \u0026lt;- 0:10\nprint(pi)\n#         下层      中层      上层\n# 0  0.7500000 0.1500000 0.1000000\n# 1  0.5220000 0.3465000 0.1315000\n# 2  0.4070550 0.4256550 0.1672900\n# 3  0.3485088 0.4593887 0.1921025\n# 4  0.3184913 0.4745298 0.2069789\n# 5  0.3030363 0.4816249 0.2153388\n# 6  0.2950580 0.4850608 0.2198812\n# 7  0.2909326 0.4867642 0.2223032\n# 8  0.2887972 0.4876223 0.2235805\n# 9  0.2876912 0.4880591 0.2242497\n# 10 0.2871181 0.4882830 0.2245989\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e可以看出从第 9 代人开始，分布又变得稳定了，这也就是说分布收敛情况是不随初始概率分布 \u003ccode\u003e$\\pi_0$\u003c/code\u003e 的变化而改变的。则对于具有如下特征的马尔科夫链\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e非周期性，可以简单理解为如果一个状态有自环，或者与一个非周期的状态互通，则是非周期的。\u003c/li\u003e\n\u003cli\u003e不可约性，即任意两个状态都是互通的。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e则这样的马尔科夫链，无论 \u003ccode\u003e$\\pi_0$\u003c/code\u003e 取值如何，最终随机变量的分布都会收敛于 \u003ccode\u003e$\\pi^*$\u003c/code\u003e，即\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\pi^* = \\lim_{t \\to \\infty}{\\pi^{\\left(0\\right)} \\boldsymbol{P}^t} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$\\pi^*$\u003c/code\u003e 称之为这个马尔科夫链的平稳分布。\u003c/p\u003e\n\u003ch1 id=\"马尔科夫链蒙特卡洛方法-mcmc\"\u003e马尔科夫链蒙特卡洛方法 (MCMC)\u003c/h1\u003e\n\u003cp\u003e构造一个转移矩阵为 \u003ccode\u003e$P$\u003c/code\u003e 的马尔科夫链，如果其能收敛到平稳分布 \u003ccode\u003e$p\\left(x\\right)$\u003c/code\u003e，则可以从任意一个状态 \u003ccode\u003e$x_0$\u003c/code\u003e 出发，得到一个状态转移序列 \u003ccode\u003e$x_0, x_1, ..., x_n, x_{n+1}, ...$\u003c/code\u003e，如果马尔科夫链在第 \u003ccode\u003e$n$\u003c/code\u003e 部收敛，我们就可以得到服从分布 \u003ccode\u003e$p\\left(x\\right)$\u003c/code\u003e 的样本 \u003ccode\u003e$x_n, x_{n+1}, ...$\u003c/code\u003e。因此，利用马尔科夫链的平稳性生成数据的样本的关键就在于如何构造一个状态转移矩阵 \u003ccode\u003e$P$\u003c/code\u003e，使得其平稳分布为 \u003ccode\u003e$p\\left(x\\right)$\u003c/code\u003e。\u003c/p\u003e\n\u003cp\u003e如果对于任意的 \u003ccode\u003e$i, j$\u003c/code\u003e，马尔科夫链的转移矩阵 \u003ccode\u003e$P$\u003c/code\u003e 和分布 \u003ccode\u003e$\\pi\\left(x\\right)$\u003c/code\u003e 满足\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\pi\\left(i\\right) P_{ij} = \\pi\\left(j\\right) P_{ji} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e则称 \u003ccode\u003e$\\pi\\left(x\\right)$\u003c/code\u003e 为马尔科夫链的平稳分布，这称为\u003cstrong\u003e细致平稳条件\u003c/strong\u003e。对于一个马尔科夫链，通常情况下\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ p\\left(i\\right) q\\left(i, j\\right) \\neq p\\left(j\\right) q\\left(j, i\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中 \u003ccode\u003e$p\\left(i, j\\right)$\u003c/code\u003e 表示状态从 \u003ccode\u003e$i$\u003c/code\u003e 转移到 \u003ccode\u003e$j$\u003c/code\u003e 的概率。因此，为了构造满足细致平稳条件，我们引入一个\u003cstrong\u003e接受概率\u003c/strong\u003e \u003ccode\u003e$\\alpha\\left(i, j\\right)$\u003c/code\u003e，使得\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ p\\left(i\\right) q\\left(i, j\\right) \\alpha\\left(i, j\\right) = p\\left(j\\right) q\\left(j, i\\right) \\alpha\\left(j, i\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e最简单的，我们取\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\alpha\\left(i, j\\right) = p\\left(j\\right) q\\left(j, i\\right), \\alpha\\left(j, i\\right) = p\\left(i\\right) q\\left(i, j\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e即可保证细致平稳性。通过引入接受概率，我们将原始的马尔科夫链改造为具有新的转移矩阵的马尔科夫链。在原始马尔科夫链上以概率 \u003ccode\u003e$q\\left(i, j\\right)$\u003c/code\u003e 从状态 \u003ccode\u003e$i$\u003c/code\u003e 转移到状态 \u003ccode\u003e$j$\u003c/code\u003e 时，我们以概率 \u003ccode\u003e$\\alpha\\left(i, j\\right)$\u003c/code\u003e 接受这个转移，因此在新的马尔科夫链上的转移概率为 \u003ccode\u003e$q\\left(i, j\\right) \\alpha\\left(i, j\\right)$\u003c/code\u003e。在新的马尔科夫链转移的过程中，如果接受概率 \u003ccode\u003e$\\alpha\\left(i, j\\right)$\u003c/code\u003e 过小，则可能导致存在大量的拒绝转移，马尔科夫链则很难收敛到平稳分布 \u003ccode\u003e$p\\left(x\\right)$\u003c/code\u003e，因此我们对 \u003ccode\u003e$\\alpha\\left(i, j\\right), \\alpha\\left(j, i\\right)$\u003c/code\u003e 进行同比例放大，将其中较大的数放大至 \u003ccode\u003e$1$\u003c/code\u003e，则可以增加接受跳转的概率，从而更快的收敛到平稳分布。因此，我们可以取\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\alpha\\left(i, j\\right) = \\min \\left\\lbrace\\dfrac{p\\left(j\\right) q\\left(j, i\\right)}{p\\left(i\\right) q\\left(i, j\\right)}, 1\\right\\rbrace $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e这样我们就得到了 Metropolis-Hastings 算法\u003c/p\u003e\n\n\n\u003clink rel=\"stylesheet\" type=\"text/css\" href=\"//cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css\"/\u003e\n\n\n\u003cdiv\u003e\u003cpre class=\"pseudocode\"\u003e\\begin{algorithm}\n\\caption{Metropolis-Hastings 算法}\n\\begin{algorithmic}\n\\STATE $X_0 \\gets x_0$\n\\FOR{$t = 0, 1, 2, ...$}\n    \\STATE $X_t = x_t$\n    \\STATE sample $y \\sim q\\left(x | x_t\\right)$\n    \\STATE sample $u \\sim Uniform[0, 1]$\n    \\IF{$u \u0026lt; \\alpha\\left(x_t, y\\right) = \\min\\left\\lbrace\\dfrac{p\\left(j\\right) q\\left(j, i\\right)}{p\\left(i\\right) q\\left(i, j\\right)}, 1\\right\\rbrace$}\n        \\STATE $X_{t+1} \\gets y$\n    \\ELSE\n        \\STATE $X_{t+1} \\gets x_t$\n    \\ENDIF\n\\ENDFOR\n\\end{algorithmic}\n\\end{algorithm}\n\u003c/pre\u003e\u003c/div\u003e\n\n\u003ch1 id=\"吉布斯采样-gibbs-sampling\"\u003e吉布斯采样 (Gibbs Sampling)\u003c/h1\u003e\n\u003cp\u003e对于 Metropolis-Hastings 算法，由于存在接受跳转概率 \u003ccode\u003e$\\alpha \u0026lt; 1$\u003c/code\u003e，因此为了提高算法效率，我们尝试构建一个转移矩阵，使得 \u003ccode\u003e$\\alpha = 1$\u003c/code\u003e。以二维情形为例，对于概率分布 \u003ccode\u003e$p\\left(x, y\\right)$\u003c/code\u003e，考虑两个点 \u003ccode\u003e$A\\left(x_1, y_1\\right)$\u003c/code\u003e 和 \u003ccode\u003e$B\\left(x_1, y_2\\right)$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{equation} \\begin{split} p\\left(x_1, y_1\\right) p\\left(y_2 | x_1\\right) \u0026amp;= p\\left(x_1\\right) p\\left(y_1 | x_1\\right) p\\left(y_2 | x_1\\right) \\\\ p\\left(x_1, y_2\\right) p\\left(y_1 | x_1\\right) \u0026amp;= p\\left(x_1\\right) p\\left(y_2 | x_1\\right) p\\left(y_1 | x_1\\right) \\end{split} \\end{equation} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e可得\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{equation} \\begin{split} p\\left(x_1, y_1\\right) p\\left(y_2 | x_1\\right) \u0026amp;= p\\left(x_1, y_2\\right) p\\left(y_1 | x_1\\right) \\\\ p\\left(A\\right) p\\left(y_2 | x_1\\right) \u0026amp;= p\\left(B\\right) p\\left(y_1 | x_1\\right) \\end{split} \\end{equation} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e可以得出在 \u003ccode\u003e$x = x_1$\u003c/code\u003e 上任意两点之间进行转移均满足细致平稳条件，同理可得在 \u003ccode\u003e$y = y_1$\u003c/code\u003e上也满足。因此，对于二维情况，我们构建满足如下调价的概率转移矩阵 \u003ccode\u003e$Q$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{equation} \\begin{split} \u0026amp;Q\\left(A \\to B\\right) = p\\left(y_B | x_1\\right), \\text{for} \\ x_A = x_B = x_1 \\\\ \u0026amp;Q\\left(A \\to C\\right) = p\\left(x_C | y_1\\right), \\text{for} \\ y_A = y_C = y_1 \\\\ \u0026amp;Q\\left(A \\to D\\right) = 0, \\text{others} \\end{split} \\end{equation} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e则对于平面上任意两点 \u003ccode\u003e$X, Y$\u003c/code\u003e 满足细致平稳条件\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ p\\left(X\\right) Q\\left(X \\to Y\\right) = p\\left(Y\\right) Q\\left(Y \\to X\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e对于如上过程，我们不难推广到多维情况，将 \u003ccode\u003e$x_1$\u003c/code\u003e 变为多维情形 \u003ccode\u003e$\\boldsymbol{x_1}$\u003c/code\u003e，容易验证细致平稳条件依旧成立。\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ p\\left(\\boldsymbol{x_1}, y_1\\right) p\\left(y_2 | \\boldsymbol{x_1}\\right) = p\\left(\\boldsymbol{x_1}, y_2\\right) p\\left(y_1 | \\boldsymbol{x_1}\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e对于 \u003ccode\u003e$n$\u003c/code\u003e 维的情况，通过不断的转移得到样本 \u003ccode\u003e$\\left(x_1^{\\left(1\\right)}, x_2^{\\left(1\\right)}, ..., x_n^{\\left(1\\right)}\\right)$\u003c/code\u003e, \u003ccode\u003e$\\left(x_1^{\\left(2\\right)}, x_2^{\\left(2\\right)}, ..., x_n^{\\left(2\\right)}\\right)$\u003c/code\u003e, …，当马尔科夫链收敛后，后续得到的样本即为 \u003ccode\u003e$p\\left(x_1, x_2, ..., x_n\\right)$\u003c/code\u003e 的样本，收敛之前的这一阶段我们称之为 \u003cstrong\u003eburn-in period\u003c/strong\u003e。在进行转移的时候，坐标轴轮换的采样方法并不是必须的，可以在坐标轴轮换中引入随机性。至此，我们就得到了吉布斯采样算法\u003c/p\u003e\n\n\n\u003cdiv\u003e\u003cpre class=\"pseudocode\"\u003e\\begin{algorithm}\n\\caption{Gibbs Sampling 算法}\n\\begin{algorithmic}\n\\STATE initialize $x^{\\left(0\\right)}, \\text{for} \\ i = 1, 2, ..., n$\n\\FOR{$t = 0, 1, 2, ...$}\n    \\STATE $x_1^{\\left(t+1\\right)} \\sim p\\left(x_1 | x_2^{\\left(t\\right)}, x_3^{\\left(t\\right)}, ..., x_n^{\\left(t\\right)}\\right)$\n    \\STATE $x_2^{\\left(t+1\\right)} \\sim p\\left(x_2 | x_1^{\\left(t\\right)}, x_3^{\\left(t\\right)}, ..., x_n^{\\left(t\\right)}\\right)$\n    \\STATE $...$\n    \\STATE $x_n^{\\left(t+1\\right)} \\sim p\\left(x_n | x_1^{\\left(t\\right)}, x_2^{\\left(t\\right)}, ..., x_{n-1}^{\\left(t\\right)}\\right)$\n\\ENDFOR\n\\end{algorithmic}\n\\end{algorithm}\n\u003c/pre\u003e\u003c/div\u003e\n\n\u003cp\u003e我们以二元高斯分布为例，演示如何用 Gibbs Sampling 方法进行采样，二元高斯分布定义为\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\left(X, Y\\right) \\sim \\mathcal{N}\\left(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\boldsymbol{\\mu} = \\left\\lgroup \\begin{array}{c} \\mu_X \\\\ \\mu_Y \\end{array} \\right\\rgroup, \\boldsymbol{\\Sigma} = \\left\\lgroup \\begin{array}{cc} \\sigma_X^2 \u0026amp; \\rho \\sigma_X \\sigma_Y \\\\ \\rho \\sigma_X \\sigma_Y \u0026amp; \\sigma_Y^2 \\end{array} \\right\\rgroup $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e因此可得\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{equation} \\begin{split} \\mu_{x|y} \u0026amp;= \\mu_x + \\sigma_x \\rho_x\\left(\\dfrac{y - \\mu_y}{\\sigma_y}\\right), \\sigma_{x|y}^2 = \\sigma_x^2 \\left(1 - \\rho^2\\right) \\\\ \\mu_{y|x} \u0026amp;= \\mu_y + \\sigma_y \\rho_y\\left(\\dfrac{y - \\mu_x}{\\sigma_x}\\right), \\sigma_{y|x}^2 = \\sigma_y^2 \\left(1 - \\rho^2\\right) \\end{split} \\end{equation} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e则\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{equation} \\begin{split} X|Y \u0026amp;= \\mu_{x|y} + \\sigma_{x|y} \\mathcal{N}\\left(0, 1\\right) \\\\ Y|X \u0026amp;= \\mu_{y|x} + \\sigma_{y|x} \\mathcal{N}\\left(0, 1\\right) \\end{split} \\end{equation} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e对于 \u003ccode\u003e$\\mu_x = 0, \\mu_y = 0, \\sigma_x = 10, \\sigma_y = 1, \\rho = 0.8$\u003c/code\u003e，采样过程如下\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-r\"\u003emu_x \u0026lt;- 0\nmu_y \u0026lt;- 0\nsigma_x \u0026lt;- 10\nsigma_y \u0026lt;- 1\nrho \u0026lt;- 0.8\n\niter \u0026lt;- 1000\nsamples \u0026lt;- matrix(c(mu_x, mu_y), 1, 2, byrow = T)\n\nset.seed(112358)\nfor (i in 1:iter) {\n    sample_x \u0026lt;- mu_x +\n        sigma_x * rho * (samples[i, 2] - mu_y) / sigma_y +\n        sigma_x * sqrt(1 - rho^2) * rnorm(1)\n    sample_y \u0026lt;- mu_y +\n        sigma_y * rho * (sample_x - mu_x) / sigma_x +\n        sigma_y * sqrt(1 - rho^2) * rnorm(1)\n    samples \u0026lt;- rbind(samples, c(sample_x, sample_y))\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e可视化结果如下\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2017-12-17-mcmc-and-gibbs-sampling/gibbs-sampling-bivariate-guassian-distribution.gif\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cdiv class=\"footnotes\" role=\"doc-endnotes\"\u003e\n\u003chr/\u003e\n\u003col\u003e\n\u003cli id=\"fn:1\"\u003e\n\u003cp\u003eLDA 数学八卦，靳志辉，2013 \u003ca href=\"#fnref:1\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e \u003ca href=\"#fnref1:1\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/div\u003e\n\n\n\n\n\n\u003cdiv class=\"donate\"\u003e\n  \u003cdiv class=\"donate-header\"\u003e\u003c/div\u003e\n  \u003cdiv class=\"donate-slug\" id=\"donate-slug\"\u003emcmc-and-gibbs-sampling\u003c/div\u003e\n  \u003cbutton class=\"donate-button\"\u003e赞 赏\u003c/button\u003e\n  \u003cdiv class=\"donate-footer\"\u003e「真诚赞赏，手留余香」\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv class=\"donate-modal-wrapper\"\u003e\n  \u003cdiv class=\"donate-modal\"\u003e\n    \u003cdiv class=\"donate-box\"\u003e\n      \u003cdiv class=\"donate-box-content\"\u003e\n        \u003cdiv class=\"donate-box-content-inner\"\u003e\n          \u003cdiv class=\"donate-box-header\"\u003e「真诚赞赏，手留余香」\u003c/div\u003e\n          \u003cdiv class=\"donate-box-body\"\u003e\n            \u003cdiv class=\"donate-box-money\"\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-2\" data-v=\"2\" data-unchecked=\"￥ 2\" data-checked=\"2 元\"\u003e￥ 2\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-5\" data-v=\"5\" data-unchecked=\"￥ 5\" data-checked=\"5 元\"\u003e￥ 5\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-10\" data-v=\"10\" data-unchecked=\"￥ 10\" data-checked=\"10 元\"\u003e￥ 10\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-50\" data-v=\"50\" data-unchecked=\"￥ 50\" data-checked=\"50 元\"\u003e￥ 50\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-100\" data-v=\"100\" data-unchecked=\"￥ 100\" data-checked=\"100 元\"\u003e￥ 100\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-custom\" data-v=\"custom\" data-unchecked=\"任意金额\" data-checked=\"任意金额\"\u003e任意金额\u003c/button\u003e\n            \u003c/div\u003e\n            \u003cdiv class=\"donate-box-pay\"\u003e\n              \u003cimg class=\"donate-box-pay-qrcode\" id=\"donate-box-pay-qrcode\" src=\"\"/\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n          \u003cdiv class=\"donate-box-footer\"\u003e\n            \u003cdiv class=\"donate-box-pay-method donate-box-pay-method-checked\" data-v=\"wechat-pay\"\u003e\n              \u003cimg class=\"donate-box-pay-method-image\" id=\"donate-box-pay-method-image-wechat-pay\" src=\"\"/\u003e\n            \u003c/div\u003e\n            \u003cdiv class=\"donate-box-pay-method\" data-v=\"alipay\"\u003e\n              \u003cimg class=\"donate-box-pay-method-image\" id=\"donate-box-pay-method-image-alipay\" src=\"\"/\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n      \u003c/div\u003e\n    \u003c/div\u003e\n    \u003cbutton type=\"button\" class=\"donate-box-close-button\"\u003e\n      \u003csvg class=\"donate-box-close-button-icon\" fill=\"#fff\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\"\u003e\u003cpath d=\"M13.486 12l5.208-5.207a1.048 1.048 0 0 0-.006-1.483 1.046 1.046 0 0 0-1.482-.005L12 10.514 6.793 5.305a1.048 1.048 0 0 0-1.483.005 1.046 1.046 0 0 0-.005 1.483L10.514 12l-5.208 5.207a1.048 1.048 0 0 0 .006 1.483 1.046 1.046 0 0 0 1.482.005L12 13.486l5.207 5.208a1.048 1.048 0 0 0 1.483-.006 1.046 1.046 0 0 0 .005-1.482L13.486 12z\" fill-rule=\"evenodd\"\u003e\u003c/path\u003e\u003c/svg\u003e\n    \u003c/button\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n\n\u003cscript type=\"text/javascript\" src=\"/js/donate.js\"\u003e\u003c/script\u003e\n\n\n  \u003cfooter\u003e\n  \n\u003cnav class=\"post-nav\"\u003e\n  \u003cspan class=\"nav-prev\"\u003e← \u003ca href=\"/cn/2017/12/evd-svd-and-pca/\"\u003e特征值分解，奇异值分解和主成份分析 (EVD, SVD and PCA)\u003c/a\u003e\u003c/span\u003e\n  \u003cspan class=\"nav-next\"\u003e\u003ca href=\"/cn/2018/01/ising-hopfield-and-rbm/\"\u003eIsing 模型，Hopfield 网络和受限的玻尔兹曼机 (Ising, Hopfield and RBM)\u003c/a\u003e →\u003c/span\u003e\n\u003c/nav\u003e\n\n\n\n\n\u003cins class=\"adsbygoogle\" style=\"display:block; text-align:center;\" data-ad-layout=\"in-article\" data-ad-format=\"fluid\" data-ad-client=\"ca-pub-2608165017777396\" data-ad-slot=\"8302038603\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n  (adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/js-cookie@3.0.5/dist/js.cookie.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/toggle-theme.js\"\u003e\u003c/script\u003e\n\n\n\u003cscript src=\"/js/no-highlight.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/math-code.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/heading-anchor.js\"\u003e\u003c/script\u003e\n\n\n\n\u003csection class=\"comments\"\u003e\n\u003cscript src=\"https://giscus.app/client.js\" data-repo=\"leovan/leovan.me\" data-repo-id=\"MDEwOlJlcG9zaXRvcnkxMTMxOTY0Mjc=\" data-category=\"Comments\" data-category-id=\"DIC_kwDOBr89i84CT-R7\" data-mapping=\"pathname\" data-strict=\"1\" data-reactions-enabled=\"1\" data-emit-metadata=\"0\" data-input-position=\"top\" data-theme=\"preferred_color_scheme\" data-lang=\"zh-CN\" data-loading=\"lazy\" crossorigin=\"anonymous\" defer=\"\"\u003e\n\u003c/script\u003e\n\u003c/section\u003e\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"//cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"//cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"//cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/toolbar/prism-toolbar.min.js\"\u003e\u003c/script\u003e\n\u003cscript\u003e\n  (function() {\n    if (!self.Prism) {\n      return;\n    }\n\n    \n    Prism.languages.dos = Prism.languages.powershell;\n    Prism.languages.gremlin = Prism.languages.groovy;\n\n    let languages = {\n      'r': 'R', 'python': 'Python', 'xml': 'XML', 'html': 'HTML',\n      'yaml': 'YAML', 'latex': 'LaTeX', 'tex': 'TeX',\n      'powershell': 'PowerShell', 'javascript': 'JavaScript',\n      'dos': 'DOS', 'qml': 'QML', 'json': 'JSON', 'bash': 'Bash',\n      'text': 'Text', 'txt': 'Text', 'sparql': 'SPARQL',\n      'gremlin': 'Gremlin', 'cypher': 'Cypher', 'ngql': 'nGQL',\n      'shell': 'Shell', 'sql': 'SQL', 'apacheconf': 'Apache Configuration', 'c': 'C', 'css': 'CSS'\n    };\n\n    Prism.hooks.add('before-highlight', function(env) {\n      if (env.language !== 'plain') {\n        let language = languages[env.language] || env.language;\n        env.element.setAttribute('data-language', language);\n      }\n    });\n\n    \n    let ClipboardJS = window.ClipboardJS || undefined;\n\n    Prism.plugins.toolbar.registerButton('copy-to-clipboard', function(env) {\n      let linkCopy = document.createElement('button');\n      linkCopy.classList.add('prism-button-copy');\n\n      registerClipboard();\n\n      return linkCopy;\n\n      function registerClipboard() {\n        let clip = new ClipboardJS(linkCopy, {\n          'text': function () {\n            return env.code;\n          }\n        });\n\n        clip.on('success', function() {\n          linkCopy.classList.add('prism-button-copy-success');\n          resetText();\n        });\n        clip.on('error', function () {\n          linkCopy.classList.add('prism-button-copy-error');\n          resetText();\n        });\n      }\n\n      function resetText() {\n        setTimeout(function () {\n          linkCopy.classList.remove('prism-button-copy-success');\n          linkCopy.classList.remove('prism-button-copy-error');\n        }, 1600);\n      }\n    });\n  })();\n\u003c/script\u003e\n\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js\"\u003e\u003c/script\u003e\n\u003cscript type=\"text/javascript\"\u003e\nlet pseudocodeCaptionCount = 0;\n(function(d) {\n  d.querySelectorAll(\".pseudocode\").forEach(function(elem) {\n    let pseudocode_options = {\n      indentSize: '1.2em',\n      commentDelimiter: '\\/\\/',\n      lineNumber:  true ,\n      lineNumberPunc: ':',\n      noEnd:  false \n    };\n    pseudocode_options.captionCount = pseudocodeCaptionCount;\n    pseudocodeCaptionCount += 1;\n    pseudocode.renderElement(elem, pseudocode_options);\n  });\n})(document);\n\u003c/script\u003e\n\n\n\n\n\n\n\n\n\n\n\n\u003cscript async=\"\" src=\"/js/center-img.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/right-quote.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/external-link.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/alt-title.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/figure.js\"\u003e\u003c/script\u003e\n\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js\"\u003e\u003c/script\u003e\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/vanilla-back-to-top@latest/dist/vanilla-back-to-top.min.js\"\u003e\u003c/script\u003e\n\u003cscript\u003e\naddBackToTop({\n  diameter: 48\n});\n\u003c/script\u003e\n\n  \u003chr/\u003e\n  \u003cdiv class=\"copyright no-border-bottom\"\u003e\n    \u003cdiv class=\"copyright-author-year\"\u003e\n      \u003cspan\u003eCopyright © 2017-2024 \u003ca href=\"/\"\u003e范叶亮 | Leo Van\u003c/a\u003e\u003c/span\u003e\n    \u003c/div\u003e\n  \u003c/div\u003e\n  \u003c/footer\u003e\n  \u003c/article\u003e",
  "Date": "2017-12-17T00:00:00Z",
  "Author": "范叶亮"
}