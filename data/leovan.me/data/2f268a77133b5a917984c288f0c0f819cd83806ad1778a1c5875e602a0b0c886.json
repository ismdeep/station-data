{
  "Source": "leovan.me",
  "Title": "Spark 集群搭建 (Spark Cluster Setup)",
  "Link": "https://leovan.me/cn/2021/06/spark-cluster-setup/",
  "Content": "\u003carticle class=\"main\"\u003e\n    \u003cheader class=\"content-title\"\u003e\n    \n\u003ch1 class=\"title\"\u003e\n  \n  Spark 集群搭建 (Spark Cluster Setup)\n  \n\u003c/h1\u003e\n\n\n\n\n\n\n\n\u003ch2 class=\"author-date\"\u003e范叶亮 / \n2021-06-19\u003c/h2\u003e\n\n\n\n\u003ch3 class=\"post-meta\"\u003e\n\n\n\u003cstrong\u003e分类: \u003c/strong\u003e\n\u003ca href=\"/categories/tech101\"\u003eTech101\u003c/a\u003e, \u003ca href=\"/categories/%E7%BC%96%E7%A8%8B\"\u003e编程\u003c/a\u003e\n\n\n\n\n/\n\n\n\n\n\u003cstrong\u003e标签: \u003c/strong\u003e\n\u003cspan\u003eSpark\u003c/span\u003e, \u003cspan\u003eScala\u003c/span\u003e, \u003cspan\u003eNFS\u003c/span\u003e, \u003cspan\u003ePySpark\u003c/span\u003e\n\n\n\n\n/\n\n\n\u003cstrong\u003e字数: \u003c/strong\u003e\n1166\n\u003c/h3\u003e\n\n\n\n\u003chr/\u003e\n\n\n\n    \n    \n    \u003cins class=\"adsbygoogle\" style=\"display:block; text-align:center;\" data-ad-layout=\"in-article\" data-ad-format=\"fluid\" data-ad-client=\"ca-pub-2608165017777396\" data-ad-slot=\"1261604535\"\u003e\u003c/ins\u003e\n    \u003cscript\u003e\n    (adsbygoogle = window.adsbygoogle || []).push({});\n    \u003c/script\u003e\n    \n    \n    \u003c/header\u003e\n\n\n\n\n\u003cp\u003e文本使用的软件版本分别为：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eJDK：1.8.0_291，\u003ca href=\"https://www.oracle.com/cn/java/technologies/javase/javase-jdk8-downloads.html\"\u003e下载地址\u003c/a\u003e。\u003c/li\u003e\n\u003cli\u003eScala：2.12.14，\u003ca href=\"https://www.scala-lang.org/download/\"\u003e下载地址\u003c/a\u003e。\u003c/li\u003e\n\u003cli\u003eHadoop：3.2.2，\u003ca href=\"https://hadoop.apache.org/releases.html\"\u003e下载地址\u003c/a\u003e。\u003c/li\u003e\n\u003cli\u003eSpark：3.1.2，\u003ca href=\"https://spark.apache.org/downloads.html\"\u003e下载地址\u003c/a\u003e。\u003c/li\u003e\n\u003cli\u003ePython：3.9，Miniconda3，\u003ca href=\"https://docs.conda.io/en/latest/miniconda.html\"\u003e下载地址\u003c/a\u003e。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e按照\u003ca href=\"/tech101/2021/06/virtual-env-preparation/\"\u003e虚拟环境准备 (Virtual Environment Preparation)\u003c/a\u003e 准备虚拟机。\u003c/p\u003e\n\u003cp\u003e按照 \u003ca href=\"/tech101/2021/06/hadoop-cluster-setup/\"\u003eHadoop 集群搭建 (Hadoop Cluster Setup)\u003c/a\u003e 搭建 Hadoop 集群。\u003c/p\u003e\n\u003cp\u003e本文以 Spark on YARN 模式介绍 Spark 集群的搭建。\u003c/p\u003e\n\u003ch1 id=\"scala-配置\"\u003eScala 配置\u003c/h1\u003e\n\u003cp\u003e将 Scala 安装包解压缩到 \u003ccode\u003e/opt\u003c/code\u003e 目录并创建软链接：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003ecd /opt\ntar -zxvf scala-2.12.14.tgz\nln -s /opt/scala-2.12.14 /opt/scala\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e将如下信息添加到 \u003ccode\u003e/etc/profile\u003c/code\u003e 中：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-txt\"\u003e# Scala\nexport SCALA_HOME=/opt/scala\nexport PATH=$PATH:$SCALA_HOME/bin\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e方便起见可以使用 \u003ccode\u003ersync\u003c/code\u003e 命令同步 Scala：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003ersync -auvp /opt/scala-2.12.14 leo@vm-02:/opt\nrsync -auvp /opt/scala-2.12.14 leo@vm-03:/opt\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1 id=\"spark-配置\"\u003eSpark 配置\u003c/h1\u003e\n\u003cp\u003e将 Spark 安装包解压缩到 \u003ccode\u003e/opt\u003c/code\u003e 目录并创建软链接：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003ecd /opt\ntar -zxvf spark-3.1.2-bin-hadoop3.2.tgz\nln -s /opt/spark-3.1.2-bin-hadoop3.2 /opt/spark\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e将如下信息添加到 \u003ccode\u003e/etc/profile\u003c/code\u003e 中：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-txt\"\u003e# Spark\nexport SPARK_HOME=/opt/spark\nexport PATH=$PATH:$SPARK_HOME/bin\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e复制环境变量文件：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003ecp /opt/spark/conf/spark-env.sh.template /opt/spark/conf/spark-env.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e在 \u003ccode\u003espark-env.sh\u003c/code\u003e 结尾添加如下内容：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eexport JAVA_HOME=/opt/jdk\nexport SCALA_HOME=/opt/scala\nexport HADOOP_HOME=/opt/hadoop\nexport HADOOP_CONF_DIR=$HADOOP_HOME/conf\nexport YARN_CONF_DIR=$HADOOP_HOME/conf\nexport SPAKR_HOME=/opt/spark\nexport SPARK_CONF_DIR=$SPAKR_HOME/conf\n\nexport SPARK_EXECUTOR_CORES=1\nexport SPARK_EXECUTOR_MEMORY=1G\nexport SPARK_DRIVER_MEMORY=1G\nexport SPARK_HISTORY_OPTS=\u0026#34;-Dspark.history.retainedApplications=10\u0026#34;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e复制配置文件：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003ecp /opt/spark/conf/spark-defaults.conf.template /opt/spark/conf/spark-defaults.conf\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e修改 \u003ccode\u003espark-defaults.conf\u003c/code\u003e 文件内容如下：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-txt\"\u003espark.eventLog.enabled              true\nspark.eventLog.compress             true\nspark.eventLog.dir                  hdfs://vm-01:9000/logs/spark\nspark.history.fs.logDirectory       hdfs://vm-01:9000/logs/spark\nspark.yarn.historyServer.address    vm-01:18080\nspark.yarn.jars                     hdfs://vm-01:9000/spark/jars/*\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e复制 Worker 节点列表文件：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003ecp /opt/spark/conf/workers.template /opt/spark/conf/workers\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e修改 \u003ccode\u003eworkers\u003c/code\u003e 文件内容如下：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-txt\"\u003evm-01\nvm-02\nvm-03\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e在 HDFS 上创建目录，并上传 Spark 相关 JAR 包：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003ehdfs dfs -mkdir -p /spark/jars\nhdfs dfs -put /opt/spark/jars/* /spark/jars/\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e方便起见可以使用 \u003ccode\u003ersync\u003c/code\u003e 命令同步 Spark：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003ersync -auvp /opt/spark-3.1.2-bin-hadoop3.2 leo@vm-02:/opt\nrsync -auvp /opt/spark-3.1.2-bin-hadoop3.2 leo@vm-03:/opt\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1 id=\"启动-spark\"\u003e启动 Spark\u003c/h1\u003e\n\u003cp\u003e在 vm-01，vm-02 和 vm-03 上启动 Zookeeper：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003ezkServer.sh start\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e启动 Hadoop：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003e/opt/hadoop/sbin/start-dfs.sh\n/opt/hadoop/sbin/start-yarn.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e获取并切换 YARN Resource Manager 的状态：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003eyarn rmadmin -getServiceState rm1\nyarn rmadmin -getServiceState rm2\n\nyarn rmadmin -transitionToActive rm1 --forcemanual\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e在 HDFS 上创建相关目录：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003ehdfs dfs -mkdir /logs\nhdfs dfs -mkdir /logs/spark\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e启动 Spark：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003e/opt/spark/sbin/start-all.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e通过 http://vm-01:8081 可以进入 Spark Web 页面：\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/tech101/2021-06-19-spark-cluster-setup/spark-master-web.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cp\u003e启动 Spark History Server：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003e/opt/spark/sbin/start-history-server.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e执行 PI 示例程序：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003espark-submit \\\n  --class org.apache.spark.examples.SparkPi \\\n  --master yarn \\\n  --deploy-mode cluster \\\n  --executor-memory 1G \\\n  --num-executors 3 \\\n  /opt/spark/examples/jars/spark-examples*.jar \\\n  10\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e在 YARN 中，通过 Application ID 查看对应的 Container 的 stdout 日志，可以得到示例程序的运行结果：\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/tech101/2021-06-19-spark-cluster-setup/spark-yarn-all-applications-web.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ePi is roughly 3.1424791424791425\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e通过 http://vm-01:18081 可以进入 Spark History Server 页面：\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/tech101/2021-06-19-spark-cluster-setup/spark-history-server-web.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003ch1 id=\"nfs-配置\"\u003eNFS 配置\u003c/h1\u003e\n\u003cp\u003e安装 NFS 相关软件：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003esudo apt install nfs-kernel-server nfs-common\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e在 vm-01，vm-02 和 vm-03 上创建 MFS 文件夹并设置权限：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003esudo mkdir /nfs\nsudo chown -R leo:leo /nfs\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e在 vm-01 上修改 \u003ccode\u003e/etc/exports\u003c/code\u003e 文件，配置 NFS 共享目录：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-txt\"\u003e/nfs 192.168.56.1/24(rw,sync,no_root_squash,no_subtree_check)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e相关参数定义可以通过 \u003ccode\u003eman nfs\u003c/code\u003e 获取。\u003c/p\u003e\n\u003cp\u003e导出共享目录并重启 NFS 服务：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003esudo exportfs -a\nsudo service nfs-kernel-server restart\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e在 vm-02 和 vm-03 上挂在 NFS：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003esudo mount vm-01:/nfs /nfs\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e在 \u003ccode\u003e/etc/fstab\u003c/code\u003e 中添加如下内容实现开机自动挂载：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-txt\"\u003evm-01:/nfs /nfs nfs rw\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1 id=\"python-配置\"\u003ePython 配置\u003c/h1\u003e\n\u003cp\u003e安装 Miniconda3 到 \u003ccode\u003e/nfs/miniconda3\u003c/code\u003e 目录：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003esh Miniconda3-py39_4.9.2-Linux-x86_64.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e在安装过程中安装选项如下：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003eMiniconda3 will now be installed into this location:\n/home/leo/miniconda3\n\n  - Press ENTER to confirm the location\n  - Press CTRL-C to abort the installation\n  - Or specify a different location below\n\n[/home/leo/miniconda3] \u0026gt;\u0026gt;\u0026gt; /nfs/miniconda3\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003eDo you wish the installer to initialize Miniconda3\nby running conda init? [yes|no]\n[no] \u0026gt;\u0026gt;\u0026gt; yes\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e修改 \u003ccode\u003e~/.condarc\u003c/code\u003e 更改 Anaconda 镜像：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-txt\"\u003echannels:\n  - defaults\nshow_channel_urls: true\ndefault_channels:\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2\ncustom_channels:\n  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e创建用于 Spark 的 Python 环境：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003econda create -n spark python=3.9\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e分别在 vm-02 和 vm-03 中将如下信息添加到 /etc/profile 中：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e# \u0026gt;\u0026gt;\u0026gt; conda initialize \u0026gt;\u0026gt;\u0026gt;\n# !! Contents within this block are managed by \u0026#39;conda init\u0026#39; !!\n__conda_setup=\u0026#34;$(\u0026#39;/nfs/miniconda3/bin/conda\u0026#39; \u0026#39;shell.bash\u0026#39; \u0026#39;hook\u0026#39; 2\u0026gt; /dev/null)\u0026#34;\nif [ $? -eq 0 ]; then\n    eval \u0026#34;$__conda_setup\u0026#34;\nelse\n    if [ -f \u0026#34;/nfs/miniconda3/etc/profile.d/conda.sh\u0026#34; ]; then\n        . \u0026#34;/nfs/miniconda3/etc/profile.d/conda.sh\u0026#34;\n    else\n        export PATH=\u0026#34;/nfs/miniconda3/bin:$PATH\u0026#34;\n    fi\nfi\nunset __conda_setup\n# \u0026lt;\u0026lt;\u0026lt; conda initialize \u0026lt;\u0026lt;\u0026lt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e分别在 vm-01，vm-02 和 vm-03 中将如下信息添加到 /etc/profile 中：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e# Python 3.9 for Spark\nconda activate spark\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1 id=\"pyspark-测试\"\u003ePySpark 测试\u003c/h1\u003e\n\u003cp\u003e输入 \u003ccode\u003epyspark\u003c/code\u003e 进入 PySaprk Shell：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-txt\"\u003eWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  \u0026#39;_/\n   /__ / .__/\\_,_/_/ /_/\\_\\   version 3.1.2\n      /_/\n\nUsing Python version 3.9.5 (default, Jun  4 2021 12:28:51)\nSpark context Web UI available at http://vm-01:4040\nSpark context available as \u0026#39;sc\u0026#39; (master = local[*], app id = local-1623876641615).\nSparkSession available as \u0026#39;spark\u0026#39;.\n\u0026gt;\u0026gt;\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e执行 PI 示例程序：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom random import random\nfrom operator import add\n\npartitions = 3\nn = 100000 * partitions\n\ndef f(_):\n    x = random() * 2 - 1\n    y = random() * 2 - 1\n    return 1 if x ** 2 + y ** 2 \u0026lt;= 1 else 0\n\ncount = spark.sparkContext.parallelize(range(1, n + 1), partitions).map(f).reduce(add)\nprint(\u0026#34;Pi is roughly %f\u0026#34; % (4.0 * count / n))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e运行结果如下：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ePi is roughly 3.147160\n\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\n\n\u003cdiv class=\"donate\"\u003e\n  \u003cdiv class=\"donate-header\"\u003e\u003c/div\u003e\n  \u003cdiv class=\"donate-slug\" id=\"donate-slug\"\u003espark-cluster-setup\u003c/div\u003e\n  \u003cbutton class=\"donate-button\"\u003e赞 赏\u003c/button\u003e\n  \u003cdiv class=\"donate-footer\"\u003e「真诚赞赏，手留余香」\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv class=\"donate-modal-wrapper\"\u003e\n  \u003cdiv class=\"donate-modal\"\u003e\n    \u003cdiv class=\"donate-box\"\u003e\n      \u003cdiv class=\"donate-box-content\"\u003e\n        \u003cdiv class=\"donate-box-content-inner\"\u003e\n          \u003cdiv class=\"donate-box-header\"\u003e「真诚赞赏，手留余香」\u003c/div\u003e\n          \u003cdiv class=\"donate-box-body\"\u003e\n            \u003cdiv class=\"donate-box-money\"\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-2\" data-v=\"2\" data-unchecked=\"￥ 2\" data-checked=\"2 元\"\u003e￥ 2\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-5\" data-v=\"5\" data-unchecked=\"￥ 5\" data-checked=\"5 元\"\u003e￥ 5\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-10\" data-v=\"10\" data-unchecked=\"￥ 10\" data-checked=\"10 元\"\u003e￥ 10\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-50\" data-v=\"50\" data-unchecked=\"￥ 50\" data-checked=\"50 元\"\u003e￥ 50\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-100\" data-v=\"100\" data-unchecked=\"￥ 100\" data-checked=\"100 元\"\u003e￥ 100\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-custom\" data-v=\"custom\" data-unchecked=\"任意金额\" data-checked=\"任意金额\"\u003e任意金额\u003c/button\u003e\n            \u003c/div\u003e\n            \u003cdiv class=\"donate-box-pay\"\u003e\n              \u003cimg class=\"donate-box-pay-qrcode\" id=\"donate-box-pay-qrcode\" src=\"\"/\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n          \u003cdiv class=\"donate-box-footer\"\u003e\n            \u003cdiv class=\"donate-box-pay-method donate-box-pay-method-checked\" data-v=\"wechat-pay\"\u003e\n              \u003cimg class=\"donate-box-pay-method-image\" id=\"donate-box-pay-method-image-wechat-pay\" src=\"\"/\u003e\n            \u003c/div\u003e\n            \u003cdiv class=\"donate-box-pay-method\" data-v=\"alipay\"\u003e\n              \u003cimg class=\"donate-box-pay-method-image\" id=\"donate-box-pay-method-image-alipay\" src=\"\"/\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n      \u003c/div\u003e\n    \u003c/div\u003e\n    \u003cbutton type=\"button\" class=\"donate-box-close-button\"\u003e\n      \u003csvg class=\"donate-box-close-button-icon\" fill=\"#fff\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\"\u003e\u003cpath d=\"M13.486 12l5.208-5.207a1.048 1.048 0 0 0-.006-1.483 1.046 1.046 0 0 0-1.482-.005L12 10.514 6.793 5.305a1.048 1.048 0 0 0-1.483.005 1.046 1.046 0 0 0-.005 1.483L10.514 12l-5.208 5.207a1.048 1.048 0 0 0 .006 1.483 1.046 1.046 0 0 0 1.482.005L12 13.486l5.207 5.208a1.048 1.048 0 0 0 1.483-.006 1.046 1.046 0 0 0 .005-1.482L13.486 12z\" fill-rule=\"evenodd\"\u003e\u003c/path\u003e\u003c/svg\u003e\n    \u003c/button\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n\n\u003cscript type=\"text/javascript\" src=\"/js/donate.js\"\u003e\u003c/script\u003e\n\n\n  \u003cfooter\u003e\n  \n\u003cnav class=\"post-nav\"\u003e\n  \u003cspan class=\"nav-prev\"\u003e← \u003ca href=\"/cn/2021/06/hive-setup/\"\u003eHive 安装和配置 (Hive Setup)\u003c/a\u003e\u003c/span\u003e\n  \u003cspan class=\"nav-next\"\u003e\u003ca href=\"/cn/2021/08/a-glimpse-of-design-language/\"\u003e设计语言初探 (A Glimpse of Design Language)\u003c/a\u003e →\u003c/span\u003e\n\u003c/nav\u003e\n\n\n\n\n\u003cins class=\"adsbygoogle\" style=\"display:block; text-align:center;\" data-ad-layout=\"in-article\" data-ad-format=\"fluid\" data-ad-client=\"ca-pub-2608165017777396\" data-ad-slot=\"8302038603\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n  (adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/js-cookie@3.0.5/dist/js.cookie.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/toggle-theme.js\"\u003e\u003c/script\u003e\n\n\n\u003cscript src=\"/js/no-highlight.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/math-code.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/heading-anchor.js\"\u003e\u003c/script\u003e\n\n\n\n\u003csection class=\"comments\"\u003e\n\u003cscript src=\"https://giscus.app/client.js\" data-repo=\"leovan/leovan.me\" data-repo-id=\"MDEwOlJlcG9zaXRvcnkxMTMxOTY0Mjc=\" data-category=\"Comments\" data-category-id=\"DIC_kwDOBr89i84CT-R7\" data-mapping=\"pathname\" data-strict=\"1\" data-reactions-enabled=\"1\" data-emit-metadata=\"0\" data-input-position=\"top\" data-theme=\"preferred_color_scheme\" data-lang=\"zh-CN\" data-loading=\"lazy\" crossorigin=\"anonymous\" defer=\"\"\u003e\n\u003c/script\u003e\n\u003c/section\u003e\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"//cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"//cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"//cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/toolbar/prism-toolbar.min.js\"\u003e\u003c/script\u003e\n\u003cscript\u003e\n  (function() {\n    if (!self.Prism) {\n      return;\n    }\n\n    \n    Prism.languages.dos = Prism.languages.powershell;\n    Prism.languages.gremlin = Prism.languages.groovy;\n\n    let languages = {\n      'r': 'R', 'python': 'Python', 'xml': 'XML', 'html': 'HTML',\n      'yaml': 'YAML', 'latex': 'LaTeX', 'tex': 'TeX',\n      'powershell': 'PowerShell', 'javascript': 'JavaScript',\n      'dos': 'DOS', 'qml': 'QML', 'json': 'JSON', 'bash': 'Bash',\n      'text': 'Text', 'txt': 'Text', 'sparql': 'SPARQL',\n      'gremlin': 'Gremlin', 'cypher': 'Cypher', 'ngql': 'nGQL',\n      'shell': 'Shell', 'sql': 'SQL', 'apacheconf': 'Apache Configuration', 'c': 'C', 'css': 'CSS'\n    };\n\n    Prism.hooks.add('before-highlight', function(env) {\n      if (env.language !== 'plain') {\n        let language = languages[env.language] || env.language;\n        env.element.setAttribute('data-language', language);\n      }\n    });\n\n    \n    let ClipboardJS = window.ClipboardJS || undefined;\n\n    Prism.plugins.toolbar.registerButton('copy-to-clipboard', function(env) {\n      let linkCopy = document.createElement('button');\n      linkCopy.classList.add('prism-button-copy');\n\n      registerClipboard();\n\n      return linkCopy;\n\n      function registerClipboard() {\n        let clip = new ClipboardJS(linkCopy, {\n          'text': function () {\n            return env.code;\n          }\n        });\n\n        clip.on('success', function() {\n          linkCopy.classList.add('prism-button-copy-success');\n          resetText();\n        });\n        clip.on('error', function () {\n          linkCopy.classList.add('prism-button-copy-error');\n          resetText();\n        });\n      }\n\n      function resetText() {\n        setTimeout(function () {\n          linkCopy.classList.remove('prism-button-copy-success');\n          linkCopy.classList.remove('prism-button-copy-error');\n        }, 1600);\n      }\n    });\n  })();\n\u003c/script\u003e\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003cscript async=\"\" src=\"/js/center-img.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/right-quote.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/external-link.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/alt-title.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/figure.js\"\u003e\u003c/script\u003e\n\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js\"\u003e\u003c/script\u003e\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/vanilla-back-to-top@latest/dist/vanilla-back-to-top.min.js\"\u003e\u003c/script\u003e\n\u003cscript\u003e\naddBackToTop({\n  diameter: 48\n});\n\u003c/script\u003e\n\n  \u003chr/\u003e\n  \u003cdiv class=\"copyright no-border-bottom\"\u003e\n    \u003cdiv class=\"copyright-author-year\"\u003e\n      \u003cspan\u003eCopyright © 2017-2024 \u003ca href=\"/\"\u003e范叶亮 | Leo Van\u003c/a\u003e\u003c/span\u003e\n    \u003c/div\u003e\n  \u003c/div\u003e\n  \u003c/footer\u003e\n  \u003c/article\u003e",
  "Date": "2021-06-19T00:00:00Z",
  "Author": "范叶亮"
}