{
  "Source": "leovan.me",
  "Title": "深度学习优化算法 (Optimization Methods for Deeplearning)",
  "Link": "https://leovan.me/cn/2018/02/optimization-methods-for-deeplearning/",
  "Content": "\u003carticle class=\"main\"\u003e\n    \u003cheader class=\"content-title\"\u003e\n    \n\u003ch1 class=\"title\"\u003e\n  \n  深度学习优化算法 (Optimization Methods for Deeplearning)\n  \n\u003c/h1\u003e\n\n\n\n\n\n\n\n\u003ch2 class=\"author-date\"\u003e范叶亮 / \n2018-02-24\u003c/h2\u003e\n\n\n\n\u003ch3 class=\"post-meta\"\u003e\n\n\n\u003cstrong\u003e分类: \u003c/strong\u003e\n\u003ca href=\"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0\"\u003e机器学习\u003c/a\u003e, \u003ca href=\"/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0\"\u003e深度学习\u003c/a\u003e\n\n\n\n\n/\n\n\n\n\n\u003cstrong\u003e标签: \u003c/strong\u003e\n\u003cspan\u003e梯度下降\u003c/span\u003e, \u003cspan\u003eSGD\u003c/span\u003e, \u003cspan\u003eMomentum\u003c/span\u003e, \u003cspan\u003eNAG\u003c/span\u003e, \u003cspan\u003eAdaGrad\u003c/span\u003e, \u003cspan\u003eAdadelta\u003c/span\u003e, \u003cspan\u003eRMSProp\u003c/span\u003e, \u003cspan\u003eAdam\u003c/span\u003e, \u003cspan\u003eAdamax\u003c/span\u003e, \u003cspan\u003eNadam\u003c/span\u003e, \u003cspan\u003eAMSGrad\u003c/span\u003e\n\n\n\n\n/\n\n\n\u003cstrong\u003e字数: \u003c/strong\u003e\n4043\n\u003c/h3\u003e\n\n\n\n\u003chr/\u003e\n\n\n\n    \n    \n    \u003cins class=\"adsbygoogle\" style=\"display:block; text-align:center;\" data-ad-layout=\"in-article\" data-ad-format=\"fluid\" data-ad-client=\"ca-pub-2608165017777396\" data-ad-slot=\"1261604535\"\u003e\u003c/ins\u003e\n    \u003cscript\u003e\n    (adsbygoogle = window.adsbygoogle || []).push({});\n    \u003c/script\u003e\n    \n    \n    \u003c/header\u003e\n\n\n\n\n\u003cp\u003e在构建神经网络模型的时候，除了网络结构设计以外，选取合适的优化算法也对网络起着至关重要的作用，本文将对神经网络中常用的优化算法进行简单的介绍和对比，本文部分参考了 Ruder 的关于梯度下降优化算法一文 \u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e。首先，我们对下文中使用的符号进行同意说明：网络中的参数同一表示为 \u003ccode\u003e$\\theta$\u003c/code\u003e，网络的假设函数为 \u003ccode\u003e$h_{\\boldsymbol{\\theta}}\\left(\\boldsymbol{x}\\right)$\u003c/code\u003e，网络的损失函数为 \u003ccode\u003e$J\\left(\\boldsymbol{\\theta}\\right)$\u003c/code\u003e，学习率为 \u003ccode\u003e$\\alpha$\u003c/code\u003e，假设训练数据中共包含 \u003ccode\u003e$m$\u003c/code\u003e 个样本，网络参数个数为 \u003ccode\u003e$n$\u003c/code\u003e。\u003c/p\u003e\n\u003ch1 id=\"梯度下降\"\u003e梯度下降\u003c/h1\u003e\n\u003cp\u003e在梯度下降算法中，常用的主要包含 3 种不同的形式，分别是批量梯度下降 (Batch Gradient Descent, BGD)，随机梯度下降 (Stochastic Gradient Descent, SGD) 和小批量梯度下降 (Mini-Batch Gradient Descent, MBGD)。一般情况下，我们在谈论梯度下降时，更多的是指小批量梯度下降。\u003c/p\u003e\n\u003ch2 id=\"bgd\"\u003eBGD\u003c/h2\u003e\n\u003cp\u003eBGD 为梯度下降算法中最基础的一个算法，其损失函数定义如下：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ J \\left(\\boldsymbol{\\theta}\\right) = \\dfrac{1}{2m} \\sum_{i=1}^{m}{\\left(h_{\\boldsymbol{\\theta}}\\left(x^{\\left(i\\right)}\\right) - y^{\\left(i\\right)}\\right)} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e针对任意参数 \u003ccode\u003e$\\theta_j$\u003c/code\u003e 我们可以求得其梯度为：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\nabla_{\\theta_j} = \\dfrac{\\partial J\\left(\\boldsymbol{\\theta}\\right)}{\\partial \\theta_j} = - \\dfrac{1}{m} \\sum_{i=1}^{m}{\\left(y^{\\left(i\\right)} - h_{\\boldsymbol{\\theta}} \\left(x^{\\left(i\\right)}\\right)\\right) x_j^{\\left(i\\right)}} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e之后，对于任意参数 \u003ccode\u003e$\\theta_j$\u003c/code\u003e 我们按照其\u003cstrong\u003e负梯度\u003c/strong\u003e方向进行更新：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\theta_j = \\theta_j + \\alpha \\left[\\dfrac{1}{m} \\sum_{i=1}^{m}{\\left(y^{\\left(i\\right)} - h_{\\boldsymbol{\\theta}} \\left(x^{\\left(i\\right)}\\right)\\right) x_j^{\\left(i\\right)}}\\right] $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e整个算法流程可以表示如下：\u003c/p\u003e\n\n\n\u003clink rel=\"stylesheet\" type=\"text/css\" href=\"//cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css\"/\u003e\n\n\n\u003cdiv\u003e\u003cpre class=\"pseudocode\"\u003e\\begin{algorithm}\n\\caption{BGD 算法}\n\\begin{algorithmic}\n\\FOR{$epoch = 1, 2, ...$}\n    \\FOR{$j = 1, 2, ..., n$}\n        \\STATE $J \\left(\\boldsymbol{\\theta}\\right) = \\dfrac{1}{2m} \\sum_{i=1}^{m}{\\left(h_{\\boldsymbol{\\theta}}\\left(x^{\\left(i\\right)}\\right) - y^{\\left(i\\right)}\\right)}$\n        \\STATE $\\theta_j = \\theta_j - \\alpha \\dfrac{\\partial J\\left(\\boldsymbol{\\theta}\\right)}{\\partial \\theta_j}$\n    \\ENDFOR\n\\ENDFOR\n\\end{algorithmic}\n\\end{algorithm}\n\u003c/pre\u003e\u003c/div\u003e\n\n\u003cp\u003e从上述算法流程中我们可以看到，BGD 算法每次计算梯度都使用了整个训练集，也就是说对于给定的一个初始点，其每一步的更新都是沿着全局梯度最大的负方向。但这同样是其问题，当 \u003ccode\u003e$m$\u003c/code\u003e 太大时，整个算法的计算开销就很高了。\u003c/p\u003e\n\u003ch2 id=\"sgd\"\u003eSGD\u003c/h2\u003e\n\u003cp\u003eSGD 相比于 BGD，其最主要的区别就在于计算梯度时不再利用整个数据集，而是针对单个样本计算梯度并更新权重，因此，其损失函数定义如下：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ J \\left(\\boldsymbol{\\theta}\\right) = \\dfrac{1}{2} \\left(h_{\\boldsymbol{\\theta}}\\left(x^{\\left(i\\right)}\\right) - y^{\\left(i\\right)}\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e整个算法流程可以表示如下：\u003c/p\u003e\n\n\n\u003cdiv\u003e\u003cpre class=\"pseudocode\"\u003e\\begin{algorithm}\n\\caption{SGD 算法}\n\\begin{algorithmic}\n\\FOR{$epoch = 1, 2, ...$}\n    \\STATE Randomly shuffle dataset\n    \\FOR{$i = 1, 2, ..., m$}\n        \\FOR{$j = 1, 2, ..., n$}\n            \\STATE $J \\left(\\boldsymbol{\\theta}\\right) = \\dfrac{1}{2} \\left(h_{\\boldsymbol{\\theta}}\\left(x^{\\left(i\\right)}\\right) - y^{\\left(i\\right)}\\right)$\n            \\STATE $\\theta_j = \\theta_j - \\alpha \\dfrac{\\partial J\\left(\\boldsymbol{\\theta}\\right)}{\\partial \\theta_j}$\n        \\ENDFOR\n    \\ENDFOR\n\\ENDFOR\n\\end{algorithmic}\n\\end{algorithm}\n\u003c/pre\u003e\u003c/div\u003e\n\n\u003cp\u003eSGD 相比于 BGD 具有训练速度快的优势，但同时由于权重改变的方向并不是全局梯度最大的负方向，甚至相反，因此不能够保证每次损失函数都会减小。\u003c/p\u003e\n\u003ch2 id=\"mbgd\"\u003eMBGD\u003c/h2\u003e\n\u003cp\u003e针对 BGD 和 SGD 的问题，MBGD 则是一个折中的方案，在每次更新参数时，MBGD 会选取 \u003ccode\u003e$b$\u003c/code\u003e 个样本计算的梯度，设第 \u003ccode\u003e$k$\u003c/code\u003e 批中数据的下标的集合为 \u003ccode\u003e$B_k$\u003c/code\u003e，则其损失函数定义如下：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\nabla_{\\theta_j} = \\dfrac{\\partial J\\left(\\boldsymbol{\\theta}\\right)}{\\partial \\theta_j} = - \\dfrac{1}{|B_k|} \\sum_{i \\in B_k}{\\left(y^{\\left(i\\right)} - h_{\\boldsymbol{\\theta}} \\left(x^{\\left(i\\right)}\\right)\\right) x_j^{\\left(i\\right)}} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e整个算法流程可以表示如下：\u003c/p\u003e\n\n\n\u003cdiv\u003e\u003cpre class=\"pseudocode\"\u003e\\begin{algorithm}\n\\caption{MBGD 算法}\n\\begin{algorithmic}\n\\FOR{$epoch = 1, 2, ...$}\n    \\FOR{$k = 1, 2, ..., m / b$}\n        \\FOR{$j = 1, 2, ..., n$}\n            \\STATE $J \\left(\\boldsymbol{\\theta}\\right) = \\dfrac{1}{|B_k|} \\sum_{i \\in B_k}{\\left(y^{\\left(i\\right)} - h_{\\boldsymbol{\\theta}} \\left(x^{\\left(i\\right)}\\right)\\right) x_j^{\\left(i\\right)}}$\n            \\STATE $\\theta_j = \\theta_j - \\alpha \\dfrac{\\partial J\\left(\\boldsymbol{\\theta}\\right)}{\\partial \\theta_j}$\n        \\ENDFOR\n    \\ENDFOR\n\\ENDFOR\n\\end{algorithmic}\n\\end{algorithm}\n\u003c/pre\u003e\u003c/div\u003e\n\n\u003ch1 id=\"momentum\"\u003eMomentum\u003c/h1\u003e\n\u003cp\u003e当梯度沿着一个方向要明显比其他方向陡峭，我们可以形象的称之为峡谷形梯度，这种情况多位于局部最优点附近。在这种情况下，SGD 通常会摇摆着通过峡谷的斜坡，这就导致了其到达局部最优值的速度过慢。因此，针对这种情况，Momentum \u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e 方法提供了一种解决方案。针对原始的 SGD 算法，参数每 \u003ccode\u003e$t$\u003c/code\u003e 步的变化量可以表示为\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\boldsymbol{v}_t = - \\alpha \\nabla_{\\boldsymbol{\\theta}} J \\left(\\boldsymbol{\\theta}_t\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eMomentum 算法则在其变化量中添加了一个动量分量，即\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{equation} \\begin{split} \\boldsymbol{v}_t \u0026amp;= - \\alpha \\nabla_{\\boldsymbol{\\theta}} J \\left(\\boldsymbol{\\theta}_t\\right) + \\gamma \\boldsymbol{v}_{t-1} \\\\ \\boldsymbol{\\theta}_t \u0026amp;= \\boldsymbol{\\theta}_{t-1} + \\boldsymbol{v}_t \\end{split} \\end{equation} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e对于添加的动量项，当第 \u003ccode\u003e$t$\u003c/code\u003e 步和第 \u003ccode\u003e$t-1$\u003c/code\u003e 步的梯度方向\u003cstrong\u003e相同\u003c/strong\u003e时，\u003ccode\u003e$\\boldsymbol{\\theta}$\u003c/code\u003e 则以更快的速度更新；当第 \u003ccode\u003e$t$\u003c/code\u003e 步和第 \u003ccode\u003e$t-1$\u003c/code\u003e 步的梯度方向\u003cstrong\u003e相反\u003c/strong\u003e时，\u003ccode\u003e$\\boldsymbol{\\theta}$\u003c/code\u003e 则以较慢的速度更新。利用 SGD 和 Momentum 两种方法，在峡谷行的二维梯度上更新参数的示意图如下所示\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2018-02-24-optimization-methods-for-deeplearning/sgd-and-momentum.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003ch1 id=\"nag\"\u003eNAG\u003c/h1\u003e\n\u003cp\u003eNAG (Nesterov Accelerated Gradient) \u003csup id=\"fnref:3\"\u003e\u003ca href=\"#fn:3\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e3\u003c/a\u003e\u003c/sup\u003e 是一种 Momentum 算法的变种，其核心思想会利用“下一步的梯度”确定“这一步的梯度”，当然这里“下一步的梯度”并非真正的下一步的梯度，而是指仅根据动量项更新后位置的梯度。Sutskever \u003csup id=\"fnref:4\"\u003e\u003ca href=\"#fn:4\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e4\u003c/a\u003e\u003c/sup\u003e 给出了一种更新参数的方法：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{equation} \\begin{split} \\boldsymbol{v}_t \u0026amp;= - \\alpha \\nabla_{\\boldsymbol{\\theta}} J \\left(\\boldsymbol{\\theta}_t + \\gamma \\boldsymbol{v}_{t-1}\\right) + \\gamma \\boldsymbol{v}_{t-1} \\\\ \\boldsymbol{\\theta}_t \u0026amp;= \\boldsymbol{\\theta}_{t-1} + \\boldsymbol{v}_t \\end{split} \\end{equation} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e针对 Momentum 和 NAG 两种不同的方法，其更新权重的差异如下图所示：\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2018-02-24-optimization-methods-for-deeplearning/momentum-and-nag.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003ch1 id=\"adagrad\"\u003eAdaGrad\u003c/h1\u003e\n\u003cp\u003eAdaGrad \u003csup id=\"fnref:5\"\u003e\u003ca href=\"#fn:5\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e5\u003c/a\u003e\u003c/sup\u003e 是一种具有自适应学习率的的方法，其对于低频特征的参数选择更大的更新量，对于高频特征的参数选择更小的更新量。因此，AdaGrad算法更加适用于处理稀疏数据。Pennington 等则利用该方法训练 GloVe \u003csup id=\"fnref:6\"\u003e\u003ca href=\"#fn:6\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e6\u003c/a\u003e\u003c/sup\u003e 词向量，因为对于出现次数较少的词应当获得更大的参数更新。\u003c/p\u003e\n\u003cp\u003e因为每个参数的学习速率不再一样，则在 \u003ccode\u003e$t$\u003c/code\u003e 时刻第 \u003ccode\u003e$i$\u003c/code\u003e 个参数的变化为\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\theta_{t, i} = \\theta_{t-1, i} - \\alpha \\nabla_{\\theta} J \\left(\\theta_{t-1, i}\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e根据 AdaGrad 方法的更新方式，我们对学习率做出如下变化\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\theta_{t, i} = \\theta_{t-1, i} - \\dfrac{\\alpha}{\\sqrt{G_{t, i}} + \\epsilon} \\nabla_{\\theta} J \\left(\\theta_{t-1, i}\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$G_t$\u003c/code\u003e 表示截止到 \u003ccode\u003e$t$\u003c/code\u003e 时刻梯度的平方和；\u003ccode\u003e$\\epsilon$\u003c/code\u003e 为平滑项，防止除数为零，一般设置为 \u003ccode\u003e$10^{-8}$\u003c/code\u003e。AdaGrad 最大的优势就在于其能够自动调节每个参数的学习率。\u003c/p\u003e\n\u003ch1 id=\"adadelta\"\u003eAdadelta\u003c/h1\u003e\n\u003cp\u003e上文中 AdaGrad 算法存在一个缺点，即其用于调节学习率的分母中包含的是一个梯度的平方累加项，随着训练的不断进行，这个值将会越来越大，也就是说学习率将会越来越小，最终导致模型不会再学习到任何知识。Adadelta \u003csup id=\"fnref:7\"\u003e\u003ca href=\"#fn:7\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e7\u003c/a\u003e\u003c/sup\u003e 方法针对 AdaGrad 的这个问题，做出了进一步改进，其不再计算历史所以梯度的平方和，而是使用一个固定长度 \u003ccode\u003e$w$\u003c/code\u003e 的滑动窗口内的梯度。\u003c/p\u003e\n\u003cp\u003e因为存储 \u003ccode\u003e$w$\u003c/code\u003e 的梯度平方并不高效，Adadelta 采用了一种递归的方式进行计算，定义 \u003ccode\u003e$t$\u003c/code\u003e 时刻梯度平方的均值为\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ E \\left[g^2\\right]_t = \\rho E \\left[g^2\\right]_{t-1} + \\left(1 - \\rho\\right) g^2_{t} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$g_t$\u003c/code\u003e 表示 \u003ccode\u003e$t$\u003c/code\u003e 时刻的梯度；\u003ccode\u003e$\\rho$\u003c/code\u003e 为一个衰减项，类似于 Momentum 中的衰减项。在更新参数过程中我们需要其平方根，即\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\text{RMS} \\left[g\\right]_t = \\sqrt{E \\left[g^2\\right]_t + \\epsilon} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e则参数的更新量为\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\Delta \\theta_t = - \\dfrac{\\alpha}{\\text{RMS} \\left[g\\right]_t} g_t $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e除此之外，作者还考虑到上述更新中更新量和参数的假设单位不一致的情况，在上述更新公式中添加了一个关于参数的衰减项\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\text{RMS} \\left[\\Delta \\theta\\right]_t = \\sqrt{E \\left[\\Delta \\theta^2\\right]_t + \\epsilon} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ E \\left[\\Delta \\theta^2\\right]_t = \\rho E \\left[\\Delta \\theta^2\\right]_{t-1} + \\left(1 - \\rho\\right) \\Delta \\theta_t^2 $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e在原始的论文中，作者直接用 \u003ccode\u003e$\\text{RMS} \\left[\\Delta \\theta^2\\right]_t$\u003c/code\u003e 替换了学习率，即\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\Delta \\theta_t = - \\dfrac{\\text{RMS} \\left[\\Delta \\theta\\right]_{t-1}}{\\text{RMS} \\left[g\\right]_t} g_t $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e而在 \u003ccode\u003eKeras\u003c/code\u003e 源码中，则保留了固定的学习率，即\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\Delta \\theta_t = - \\alpha \\dfrac{\\text{RMS} \\left[\\Delta \\theta\\right]_{t-1}}{\\text{RMS} \\left[g\\right]_t} g_t $$\u003c/code\u003e\u003c/p\u003e\n\u003ch1 id=\"rmsprop\"\u003eRMSprop\u003c/h1\u003e\n\u003cp\u003eRMSprop \u003csup id=\"fnref:8\"\u003e\u003ca href=\"#fn:8\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e8\u003c/a\u003e\u003c/sup\u003e 是由 Hinton 提出的一种针对 AdaGrad 的改进算法。参数的更新量为\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\Delta \\theta_t = - \\dfrac{\\alpha}{\\text{RMS} \\left[g\\right]_t} g_t $$\u003c/code\u003e\u003c/p\u003e\n\u003ch1 id=\"adam\"\u003eAdam\u003c/h1\u003e\n\u003cp\u003eAdam (Adaptive Moment Estimation) \u003csup id=\"fnref:9\"\u003e\u003ca href=\"#fn:9\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e9\u003c/a\u003e\u003c/sup\u003e 是另一种类型的自适应学习率方法，类似 Adadelta，Adam 对于每个参数都计算各自的学习率。Adam 方法中包含一个一阶梯度衰减项 \u003ccode\u003e$m_t$\u003c/code\u003e 和一个二阶梯度衰减项 \u003ccode\u003e$v_t$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{equation} \\begin{split} m_t \u0026amp;= \\beta_1 m_{t-1} + \\left(1 - \\beta_1\\right) g_t \\\\ v_t \u0026amp;= \\beta_2 v_{t-1} + \\left(1 - \\beta_2\\right) g_t^2 \\end{split} \\end{equation} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e算法中，\u003ccode\u003e$m_t$\u003c/code\u003e 和 \u003ccode\u003e$v_t$\u003c/code\u003e 初始化为零向量，作者发现两者会更加偏向 \u003ccode\u003e$0$\u003c/code\u003e，尤其是在训练的初始阶段和衰减率很小的时候 (即 \u003ccode\u003e$\\beta_1$\u003c/code\u003e 和 \u003ccode\u003e$\\beta_2$\u003c/code\u003e 趋近于1的时候)。因此，对其偏差做如下校正\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{equation} \\begin{split} \\hat{m}_t \u0026amp;= \\dfrac{m_t}{1 - \\beta_1^t} \\\\ \\hat{v}_t \u0026amp;= \\dfrac{v_t}{1 - \\beta_2^t} \\end{split} \\end{equation} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e最终得到 Adam 算法的参数更新量如下\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\Delta \\theta = - \\dfrac{\\alpha}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t $$\u003c/code\u003e\u003c/p\u003e\n\u003ch1 id=\"adamax\"\u003eAdamax\u003c/h1\u003e\n\u003cp\u003e在 Adam 中参数的更新方法利用了 \u003ccode\u003e$L_2$\u003c/code\u003e 正则形式的历史梯度 (\u003ccode\u003e$v_{t-1}$\u003c/code\u003e) 和当前梯度 (\u003ccode\u003e$|g_t|^2$\u003c/code\u003e)，因此，更一般的，我们可以使用 \u003ccode\u003e$L_p$\u003c/code\u003e 正则形式，即\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{equation} \\begin{split} v_t \u0026amp;= \\beta_2^p v_{t-1} + \\left(1 - \\beta_2^p\\right) |g_t|^p \\\\ \u0026amp;= \\left(1 - \\beta_2^p\\right) \\sum_{i=1}^{t} \\beta_2^{p\\left(t-i\\right)} \\cdot |g_t|^p \\end{split} \\end{equation} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e这样的变换对于值较大的 \u003ccode\u003e$p$\u003c/code\u003e 而言是很不稳定的，但对于极端的情况，当 \u003ccode\u003e$p$\u003c/code\u003e 趋近于无穷的时候，则变为了一个简单并且稳定的算法。则在 \u003ccode\u003e$t$\u003c/code\u003e 时刻对应的我们需要计算 \u003ccode\u003e$v_t^{1/p}$\u003c/code\u003e，令 \u003ccode\u003e$u_t = \\lim_{p \\to \\infty} \\left(v_t\\right)^{1/p}$\u003c/code\u003e，则有\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{equation} \\begin{split} u_t \u0026amp;= \\lim_{p \\to \\infty} \\left(\\left(1 - \\beta_2^p\\right) \\sum_{i=1}^{t} \\beta_2^{p\\left(t-i\\right)} \\cdot |g_t|^p\\right)^{1/p} \\\\ \u0026amp;= \\lim_{p \\to \\infty} \\left(1 - \\beta_2^p\\right)^{1/p} \\left(\\sum_{i=1}^{t} \\beta_2^{p\\left(t-i\\right)} \\cdot |g_t|^p\\right)^{1/p} \\\\ \u0026amp;= \\lim_{p \\to \\infty} \\left(\\sum_{i=1}^{t} \\beta_2^{p\\left(t-i\\right)} \\cdot |g_t|^p\\right)^{1/p} \\\\ \u0026amp;= \\max \\left(\\beta_2^{t-1} |g_1|, \\beta_2^{t-2} |g_2|, ..., \\beta_{t-1} |g_t|\\right) \\end{split} \\end{equation} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e写成递归的形式，则有\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ u_t = \\max \\left(\\beta_2 \\cdot u_{t-1}, |g_t|\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e则 Adamax 算法的参数更新量为\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\Delta \\theta = - \\dfrac{\\alpha}{u_t} \\hat{m}_t $$\u003c/code\u003e\u003c/p\u003e\n\u003ch1 id=\"nadam\"\u003eNadam\u003c/h1\u003e\n\u003cp\u003eAdam 算法可以看做是对 RMSprop 和 Momentum 的结合：历史平方梯度的衰减项 \u003ccode\u003e$v_t$\u003c/code\u003e (RMSprop) 和 历史梯度的衰减项 \u003ccode\u003e$m_t$\u003c/code\u003e (Momentum)。Nadam (Nesterov-accelerated Adaptive Moment Estimation) \u003csup id=\"fnref:10\"\u003e\u003ca href=\"#fn:10\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e10\u003c/a\u003e\u003c/sup\u003e 则是将 Adam 同 NAG 进行了进一步结合。我们利用 Adam 中的符号重新回顾一下 NAG 算法\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{equation} \\begin{split} g_t \u0026amp;= \\nabla_{\\theta} J \\left(\\theta_t - \\gamma m_{t-1}\\right) \\\\ m_t \u0026amp;= \\gamma m_{t-1} + \\alpha g_t \\\\ \\theta_t \u0026amp;= \\theta_{t-1} - m_t \\end{split} \\end{equation} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eNAG 算法的核心思想会利用“下一步的梯度”确定“这一步的梯度”，在 Nadam 算法中，作者在考虑“下一步的梯度”时对 NAG 进行了改动，修改为\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{equation} \\begin{split} g_t \u0026amp;= \\nabla_{\\theta} J \\left(\\theta_t\\right) \\\\ m_t \u0026amp;= \\gamma m_{t-1} + \\alpha g_t \\\\ \\theta_t \u0026amp;= \\theta_{t-1} - \\left(\\gamma m_t + \\alpha g_t\\right) \\end{split} \\end{equation} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e对于 Adam，根据\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\hat{m}_t = \\dfrac{\\beta_1 m_{t-1}}{1 - \\beta_1^t} + \\dfrac{\\left(1 - \\beta_1\\right) g_t}{1 - \\beta_1^t} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e则有\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{equation} \\begin{split} \\Delta \\theta \u0026amp;= - \\dfrac{\\alpha}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t \\\\ \u0026amp;= - \\dfrac{\\alpha}{\\sqrt{\\hat{v}_t} + \\epsilon} \\left(\\dfrac{\\beta_1 m_{t-1}}{1 - \\beta_1^t} + \\dfrac{\\left(1 - \\beta_1\\right) g_t}{1 - \\beta_1^t}\\right) \\end{split} \\end{equation} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e上式中，仅 \u003ccode\u003e$\\dfrac{\\beta_1 m_{t-1}}{1 - \\beta_1^t}$\u003c/code\u003e 和动量项相关，因此我们类似上文中对 NAG 的改动，通过简单的替换加入 Nesterov 动量项，最终得到 Nadam 方法的参数的更新量\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\Delta \\theta = - \\dfrac{\\alpha}{\\sqrt{\\hat{v}_t} + \\epsilon} \\left(\\dfrac{\\beta_1 m_{t-1}}{1 - \\beta_1^{t+1}} + \\dfrac{\\left(1 - \\beta_1\\right) g_t}{1 - \\beta_1^t}\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003ch1 id=\"amsgrad\"\u003eAMSGrad\u003c/h1\u003e\n\u003cp\u003e对于前面提到的 Adadelta，RMSprop，Adam 和 Nadam 方法，他们均采用了平方梯度的指数平滑平均值迭代产生新的梯度，但根据观察，在一些情况下这些算法并不能收敛到最优解。Reddi 等提出了一种新的 Adam 变体算法 AMSGrad \u003csup id=\"fnref:11\"\u003e\u003ca href=\"#fn:11\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e11\u003c/a\u003e\u003c/sup\u003e，在文中作者解释了为什么 RMSprop 和 Adam 算法无法收敛到一个最优解的问题。通过分析表明，为了保证得到一个收敛的最优解需要保留过去梯度的“长期记忆”，因此在 AMSGrad 算法中使用了历史平方梯度的最大值而非滑动平均进行更新参数，即\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{equation} \\begin{split} m_t \u0026amp;= \\beta_1 m_{t-1} + \\left(1 - \\beta_1\\right) g_t \\\\ v_t \u0026amp;= \\beta_2 v_{t-1} + \\left(1 - \\beta_2\\right) g_t^2 \\\\ \\hat{v}_t \u0026amp;= \\max \\left(\\hat{v}_{t-1}, v_t\\right) \\\\ \\Delta \\theta \u0026amp;= - \\dfrac{\\alpha}{\\sqrt{\\hat{v}_t} + \\epsilon} m_t \\end{split} \\end{equation} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e作者在一些小数据集和 CIFAR-10 数据集上得到了相比于 Adam 更好的效果，但与此同时一些其他的 \u003ca href=\"https://fdlm.github.io/post/amsgrad/\"\u003e实验\u003c/a\u003e 却得到了相比与 Adam 类似或更差的结果，因此对于 AMSGrad 算法的效果还有待进一步确定。\u003c/p\u003e\n\u003ch1 id=\"算法可视化\"\u003e算法可视化\u003c/h1\u003e\n\u003cp\u003e正所谓一图胜千言，\u003ca href=\"https://imgur.com/a/Hqolp\"\u003eAlec Radford\u003c/a\u003e 提供了 2 张图形象了描述了不同优化算法之间的区别\u003c/p\u003e\n\u003cimg src=\"/images/cn/2018-02-24-optimization-methods-for-deeplearning/contours-evaluation-optimizers.gif\" style=\"float: left; width: 50%;\"/\u003e\n\u003cimg src=\"/images/cn/2018-02-24-optimization-methods-for-deeplearning/saddle-point-evaluation-optimizers.gif\" style=\"clear: right; width: 50%;\"/\u003e\n\u003cp\u003e左图为 \u003ca href=\"https://en.wikipedia.org/wiki/Test_functions_for_optimization\"\u003eBeale Function\u003c/a\u003e 在二维平面上的等高线，从图中可以看出 AdaGrad，Adadelta 和 RMSprop 算法很快的找到正确的方向并迅速的收敛到最优解；Momentum 和 NAG 则在初期出现了偏离，但偏离之后调整了方向并收敛到最优解；而 SGD 尽管方向正确，但收敛速度过慢。\u003c/p\u003e\n\u003cp\u003e右图为包含鞍点的一个三维图像，图像函数为 \u003ccode\u003e$z = x^2 - y^2$\u003c/code\u003e，从图中可以看出 AdaGrad，Adadelta 和 RMSprop 算法能够相对很快的逃离鞍点，而 Momentum，NAG 和 SGD 则相对比较困难逃离鞍点。\u003c/p\u003e\n\u003cp\u003e很不幸没能找到 Alec Radford 绘图的原始代码，不过 Louis Tiao 在 \u003ca href=\"http://louistiao.me/notes/visualizing-and-animating-optimization-algorithms-with-matplotlib/\"\u003e博客\u003c/a\u003e 中给出了绘制类似动图的方法。因此，本文参考该博客和 \u003ccode\u003eKeras\u003c/code\u003e 源码中对不同优化算法的实现重新绘制了 2 张类似图像，详细过程参见 \u003ca href=\"https://github.com/leovan/leovan.me/tree/main/static/codes/cn/2018-02-24-optimization-methods-for-deeplearning\"\u003e源代码\u003c/a\u003e，动图如下所示：\u003c/p\u003e\n\u003cimg src=\"/images/cn/2018-02-24-optimization-methods-for-deeplearning/beales-2d-anim.gif\" style=\"float: left; clear: both; width: 50%;\"/\u003e\n\u003cimg src=\"/images/cn/2018-02-24-optimization-methods-for-deeplearning/saddle-3d-anim.gif\" style=\"clear: both; width: 50%;\"/\u003e\n\u003cdiv class=\"footnotes\" role=\"doc-endnotes\"\u003e\n\u003chr/\u003e\n\u003col\u003e\n\u003cli id=\"fn:1\"\u003e\n\u003cp\u003eRuder, Sebastian. “An overview of gradient descent optimization algorithms.” \u003cem\u003earXiv preprint arXiv:1609.04747\u003c/em\u003e (2016). \u003ca href=\"#fnref:1\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:2\"\u003e\n\u003cp\u003eQian, Ning. “On the momentum term in gradient descent learning algorithms.” \u003cem\u003eNeural networks\u003c/em\u003e 12.1 (1999): 145-151. \u003ca href=\"#fnref:2\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:3\"\u003e\n\u003cp\u003eNesterov, Yurii. “A method for unconstrained convex minimization problem with the rate of convergence O (1/k^2).” \u003cem\u003eDoklady AN USSR.\u003c/em\u003e Vol. 269. 1983. \u003ca href=\"#fnref:3\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:4\"\u003e\n\u003cp\u003eSutskever, Ilya. “Training recurrent neural networks.” University of Toronto, Toronto, Ont., Canada (2013). \u003ca href=\"#fnref:4\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:5\"\u003e\n\u003cp\u003eDuchi, John, Elad Hazan, and Yoram Singer. “Adaptive subgradient methods for online learning and stochastic optimization.” \u003cem\u003eJournal of Machine Learning Research\u003c/em\u003e 12.Jul (2011): 2121-2159. \u003ca href=\"#fnref:5\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:6\"\u003e\n\u003cp\u003ePennington, Jeffrey, Richard Socher, and Christopher Manning. “Glove: Global vectors for word representation.” \u003cem\u003eProceedings of the 2014 conference on empirical methods in natural language processing (EMNLP).\u003c/em\u003e 2014. \u003ca href=\"#fnref:6\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:7\"\u003e\n\u003cp\u003eZeiler, Matthew D. “ADADELTA: an adaptive learning rate method.” \u003cem\u003earXiv preprint arXiv:1212.5701\u003c/em\u003e (2012). \u003ca href=\"#fnref:7\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:8\"\u003e\n\u003cp\u003eHinton, G., Nitish Srivastava, and Kevin Swersky. “Rmsprop: Divide the gradient by a running average of its recent magnitude.” \u003cem\u003eNeural networks for machine learning, Coursera lecture 6e\u003c/em\u003e (2012). \u003ca href=\"#fnref:8\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:9\"\u003e\n\u003cp\u003eKingma, Diederik P., and Jimmy Ba. “Adam: A method for stochastic optimization.” \u003cem\u003earXiv preprint arXiv:1412.6980\u003c/em\u003e (2014). \u003ca href=\"#fnref:9\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:10\"\u003e\n\u003cp\u003eDozat, Timothy. “Incorporating nesterov momentum into adam.” (2016). \u003ca href=\"#fnref:10\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:11\"\u003e\n\u003cp\u003eReddi, Sashank J., Satyen Kale, and Sanjiv Kumar. “On the convergence of adam and beyond.” International Conference on Learning Representations. 2018. \u003ca href=\"#fnref:11\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/div\u003e\n\n\n\n\n\n\u003cdiv class=\"donate\"\u003e\n  \u003cdiv class=\"donate-header\"\u003e\u003c/div\u003e\n  \u003cdiv class=\"donate-slug\" id=\"donate-slug\"\u003eoptimization-methods-for-deeplearning\u003c/div\u003e\n  \u003cbutton class=\"donate-button\"\u003e赞 赏\u003c/button\u003e\n  \u003cdiv class=\"donate-footer\"\u003e「真诚赞赏，手留余香」\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv class=\"donate-modal-wrapper\"\u003e\n  \u003cdiv class=\"donate-modal\"\u003e\n    \u003cdiv class=\"donate-box\"\u003e\n      \u003cdiv class=\"donate-box-content\"\u003e\n        \u003cdiv class=\"donate-box-content-inner\"\u003e\n          \u003cdiv class=\"donate-box-header\"\u003e「真诚赞赏，手留余香」\u003c/div\u003e\n          \u003cdiv class=\"donate-box-body\"\u003e\n            \u003cdiv class=\"donate-box-money\"\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-2\" data-v=\"2\" data-unchecked=\"￥ 2\" data-checked=\"2 元\"\u003e￥ 2\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-5\" data-v=\"5\" data-unchecked=\"￥ 5\" data-checked=\"5 元\"\u003e￥ 5\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-10\" data-v=\"10\" data-unchecked=\"￥ 10\" data-checked=\"10 元\"\u003e￥ 10\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-50\" data-v=\"50\" data-unchecked=\"￥ 50\" data-checked=\"50 元\"\u003e￥ 50\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-100\" data-v=\"100\" data-unchecked=\"￥ 100\" data-checked=\"100 元\"\u003e￥ 100\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-custom\" data-v=\"custom\" data-unchecked=\"任意金额\" data-checked=\"任意金额\"\u003e任意金额\u003c/button\u003e\n            \u003c/div\u003e\n            \u003cdiv class=\"donate-box-pay\"\u003e\n              \u003cimg class=\"donate-box-pay-qrcode\" id=\"donate-box-pay-qrcode\" src=\"\"/\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n          \u003cdiv class=\"donate-box-footer\"\u003e\n            \u003cdiv class=\"donate-box-pay-method donate-box-pay-method-checked\" data-v=\"wechat-pay\"\u003e\n              \u003cimg class=\"donate-box-pay-method-image\" id=\"donate-box-pay-method-image-wechat-pay\" src=\"\"/\u003e\n            \u003c/div\u003e\n            \u003cdiv class=\"donate-box-pay-method\" data-v=\"alipay\"\u003e\n              \u003cimg class=\"donate-box-pay-method-image\" id=\"donate-box-pay-method-image-alipay\" src=\"\"/\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n      \u003c/div\u003e\n    \u003c/div\u003e\n    \u003cbutton type=\"button\" class=\"donate-box-close-button\"\u003e\n      \u003csvg class=\"donate-box-close-button-icon\" fill=\"#fff\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\"\u003e\u003cpath d=\"M13.486 12l5.208-5.207a1.048 1.048 0 0 0-.006-1.483 1.046 1.046 0 0 0-1.482-.005L12 10.514 6.793 5.305a1.048 1.048 0 0 0-1.483.005 1.046 1.046 0 0 0-.005 1.483L10.514 12l-5.208 5.207a1.048 1.048 0 0 0 .006 1.483 1.046 1.046 0 0 0 1.482.005L12 13.486l5.207 5.208a1.048 1.048 0 0 0 1.483-.006 1.046 1.046 0 0 0 .005-1.482L13.486 12z\" fill-rule=\"evenodd\"\u003e\u003c/path\u003e\u003c/svg\u003e\n    \u003c/button\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n\n\u003cscript type=\"text/javascript\" src=\"/js/donate.js\"\u003e\u003c/script\u003e\n\n\n  \u003cfooter\u003e\n  \n\u003cnav class=\"post-nav\"\u003e\n  \u003cspan class=\"nav-prev\"\u003e← \u003ca href=\"/cn/2018/02/gan-introduction/\"\u003e生成对抗网络简介 (GAN Introduction)\u003c/a\u003e\u003c/span\u003e\n  \u003cspan class=\"nav-next\"\u003e\u003ca href=\"/cn/2018/03/manifold-learning/\"\u003e流形学习 (Manifold Learning)\u003c/a\u003e →\u003c/span\u003e\n\u003c/nav\u003e\n\n\n\n\n\u003cins class=\"adsbygoogle\" style=\"display:block; text-align:center;\" data-ad-layout=\"in-article\" data-ad-format=\"fluid\" data-ad-client=\"ca-pub-2608165017777396\" data-ad-slot=\"8302038603\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n  (adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/js-cookie@3.0.5/dist/js.cookie.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/toggle-theme.js\"\u003e\u003c/script\u003e\n\n\n\u003cscript src=\"/js/no-highlight.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/math-code.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/heading-anchor.js\"\u003e\u003c/script\u003e\n\n\n\n\u003csection class=\"comments\"\u003e\n\u003cscript src=\"https://giscus.app/client.js\" data-repo=\"leovan/leovan.me\" data-repo-id=\"MDEwOlJlcG9zaXRvcnkxMTMxOTY0Mjc=\" data-category=\"Comments\" data-category-id=\"DIC_kwDOBr89i84CT-R7\" data-mapping=\"pathname\" data-strict=\"1\" data-reactions-enabled=\"1\" data-emit-metadata=\"0\" data-input-position=\"top\" data-theme=\"preferred_color_scheme\" data-lang=\"zh-CN\" data-loading=\"lazy\" crossorigin=\"anonymous\" defer=\"\"\u003e\n\u003c/script\u003e\n\u003c/section\u003e\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"//cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"//cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"//cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/toolbar/prism-toolbar.min.js\"\u003e\u003c/script\u003e\n\u003cscript\u003e\n  (function() {\n    if (!self.Prism) {\n      return;\n    }\n\n    \n    Prism.languages.dos = Prism.languages.powershell;\n    Prism.languages.gremlin = Prism.languages.groovy;\n\n    let languages = {\n      'r': 'R', 'python': 'Python', 'xml': 'XML', 'html': 'HTML',\n      'yaml': 'YAML', 'latex': 'LaTeX', 'tex': 'TeX',\n      'powershell': 'PowerShell', 'javascript': 'JavaScript',\n      'dos': 'DOS', 'qml': 'QML', 'json': 'JSON', 'bash': 'Bash',\n      'text': 'Text', 'txt': 'Text', 'sparql': 'SPARQL',\n      'gremlin': 'Gremlin', 'cypher': 'Cypher', 'ngql': 'nGQL',\n      'shell': 'Shell', 'sql': 'SQL', 'apacheconf': 'Apache Configuration', 'c': 'C', 'css': 'CSS'\n    };\n\n    Prism.hooks.add('before-highlight', function(env) {\n      if (env.language !== 'plain') {\n        let language = languages[env.language] || env.language;\n        env.element.setAttribute('data-language', language);\n      }\n    });\n\n    \n    let ClipboardJS = window.ClipboardJS || undefined;\n\n    Prism.plugins.toolbar.registerButton('copy-to-clipboard', function(env) {\n      let linkCopy = document.createElement('button');\n      linkCopy.classList.add('prism-button-copy');\n\n      registerClipboard();\n\n      return linkCopy;\n\n      function registerClipboard() {\n        let clip = new ClipboardJS(linkCopy, {\n          'text': function () {\n            return env.code;\n          }\n        });\n\n        clip.on('success', function() {\n          linkCopy.classList.add('prism-button-copy-success');\n          resetText();\n        });\n        clip.on('error', function () {\n          linkCopy.classList.add('prism-button-copy-error');\n          resetText();\n        });\n      }\n\n      function resetText() {\n        setTimeout(function () {\n          linkCopy.classList.remove('prism-button-copy-success');\n          linkCopy.classList.remove('prism-button-copy-error');\n        }, 1600);\n      }\n    });\n  })();\n\u003c/script\u003e\n\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js\"\u003e\u003c/script\u003e\n\u003cscript type=\"text/javascript\"\u003e\nlet pseudocodeCaptionCount = 0;\n(function(d) {\n  d.querySelectorAll(\".pseudocode\").forEach(function(elem) {\n    let pseudocode_options = {\n      indentSize: '1.2em',\n      commentDelimiter: '\\/\\/',\n      lineNumber:  true ,\n      lineNumberPunc: ':',\n      noEnd:  false \n    };\n    pseudocode_options.captionCount = pseudocodeCaptionCount;\n    pseudocodeCaptionCount += 1;\n    pseudocode.renderElement(elem, pseudocode_options);\n  });\n})(document);\n\u003c/script\u003e\n\n\n\n\n\n\n\n\n\n\n\n\u003cscript async=\"\" src=\"/js/center-img.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/right-quote.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/external-link.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/alt-title.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/figure.js\"\u003e\u003c/script\u003e\n\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js\"\u003e\u003c/script\u003e\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/vanilla-back-to-top@latest/dist/vanilla-back-to-top.min.js\"\u003e\u003c/script\u003e\n\u003cscript\u003e\naddBackToTop({\n  diameter: 48\n});\n\u003c/script\u003e\n\n  \u003chr/\u003e\n  \u003cdiv class=\"copyright no-border-bottom\"\u003e\n    \u003cdiv class=\"copyright-author-year\"\u003e\n      \u003cspan\u003eCopyright © 2017-2024 \u003ca href=\"/\"\u003e范叶亮 | Leo Van\u003c/a\u003e\u003c/span\u003e\n    \u003c/div\u003e\n  \u003c/div\u003e\n  \u003c/footer\u003e\n  \u003c/article\u003e",
  "Date": "2018-02-24T00:00:00Z",
  "Author": "范叶亮"
}