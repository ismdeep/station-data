{
  "Source": "leovan.me",
  "Title": "大数据 SQL 性能调优 (Big Data SQL Performance Tuning)",
  "Link": "https://leovan.me/cn/2021/05/big-data-sql-performance-tuning/",
  "Content": "\u003carticle class=\"main\"\u003e\n    \u003cheader class=\"content-title\"\u003e\n    \n\u003ch1 class=\"title\"\u003e\n  \n  大数据 SQL 性能调优 (Big Data SQL Performance Tuning)\n  \n\u003c/h1\u003e\n\n\n\n\n\n\n\n\u003ch2 class=\"author-date\"\u003e范叶亮 / \n2021-05-23\u003c/h2\u003e\n\n\n\n\u003ch3 class=\"post-meta\"\u003e\n\n\n\u003cstrong\u003e分类: \u003c/strong\u003e\n\u003ca href=\"/categories/%E7%BC%96%E7%A8%8B\"\u003e编程\u003c/a\u003e\n\n\n\n\n/\n\n\n\n\n\u003cstrong\u003e标签: \u003c/strong\u003e\n\u003cspan\u003eSQL\u003c/span\u003e, \u003cspan\u003e计算资源量\u003c/span\u003e, \u003cspan\u003e计算数据量\u003c/span\u003e, \u003cspan\u003e计算复杂度\u003c/span\u003e, \u003cspan\u003e执行引擎\u003c/span\u003e, \u003cspan\u003eHive\u003c/span\u003e, \u003cspan\u003eHadoop\u003c/span\u003e, \u003cspan\u003eMapReduce\u003c/span\u003e, \u003cspan\u003eWork Count\u003c/span\u003e, \u003cspan\u003eSplitting\u003c/span\u003e, \u003cspan\u003eMapping\u003c/span\u003e, \u003cspan\u003eShuffling\u003c/span\u003e, \u003cspan\u003eReducing\u003c/span\u003e, \u003cspan\u003eSpark\u003c/span\u003e, \u003cspan\u003eRDD\u003c/span\u003e, \u003cspan\u003eResilient Distributed Dataset\u003c/span\u003e, \u003cspan\u003e弹性分布式数据集\u003c/span\u003e, \u003cspan\u003eDAG\u003c/span\u003e, \u003cspan\u003eDirected Acyclic Graph\u003c/span\u003e, \u003cspan\u003e有向无环图\u003c/span\u003e, \u003cspan\u003eDriver Program\u003c/span\u003e, \u003cspan\u003eSparkContext\u003c/span\u003e, \u003cspan\u003eCluster Manager\u003c/span\u003e, \u003cspan\u003eWorker Node\u003c/span\u003e, \u003cspan\u003eExecutor\u003c/span\u003e, \u003cspan\u003eApplication\u003c/span\u003e, \u003cspan\u003eTask\u003c/span\u003e, \u003cspan\u003eStage\u003c/span\u003e, \u003cspan\u003eJob\u003c/span\u003e, \u003cspan\u003eDAGScheduler\u003c/span\u003e, \u003cspan\u003eTaskScheduler\u003c/span\u003e, \u003cspan\u003ePresto\u003c/span\u003e, \u003cspan\u003eOLAP\u003c/span\u003e, \u003cspan\u003e数据分区\u003c/span\u003e, \u003cspan\u003e数据倾斜\u003c/span\u003e, \u003cspan\u003eData Skew\u003c/span\u003e, \u003cspan\u003eCommon Table Expressions\u003c/span\u003e, \u003cspan\u003eCTEs\u003c/span\u003e, \u003cspan\u003e参数调优\u003c/span\u003e, \u003cspan\u003e动态分区\u003c/span\u003e, \u003cspan\u003eDynamic Partition\u003c/span\u003e, \u003cspan\u003e资源申请\u003c/span\u003e, \u003cspan\u003e动态分配\u003c/span\u003e, \u003cspan\u003eDynamic Allocation\u003c/span\u003e, \u003cspan\u003e小文件合并\u003c/span\u003e, \u003cspan\u003eShuffle\u003c/span\u003e, \u003cspan\u003eORC\u003c/span\u003e, \u003cspan\u003e自适应执行\u003c/span\u003e, \u003cspan\u003eAdaptive Execution\u003c/span\u003e, \u003cspan\u003e推测执行\u003c/span\u003e, \u003cspan\u003eSpeculation\u003c/span\u003e\n\n\n\n\n/\n\n\n\u003cstrong\u003e字数: \u003c/strong\u003e\n5400\n\u003c/h3\u003e\n\n\n\n\u003chr/\u003e\n\n\n\n    \n    \n    \u003cins class=\"adsbygoogle\" style=\"display:block; text-align:center;\" data-ad-layout=\"in-article\" data-ad-format=\"fluid\" data-ad-client=\"ca-pub-2608165017777396\" data-ad-slot=\"1261604535\"\u003e\u003c/ins\u003e\n    \u003cscript\u003e\n    (adsbygoogle = window.adsbygoogle || []).push({});\n    \u003c/script\u003e\n    \n    \n    \u003c/header\u003e\n\n\n\n\n\u003cp\u003e在日常工作中，数据处理和分析在研发、产品和运营等多个领域起着重要的作用。在海量数据处理和分析中，SQL 是一项基础且重要的能力。一个优秀的 SQL Boy 和茶树姑的 SQL 代码除了保持简单、可读和易于维护的\u003ca href=\"/cn/2021/05/sql-style-guide/\"\u003e样式风格\u003c/a\u003e外，还需要具备良好的执行性能，准确且高效的计算出结果才能让你在工作中决胜于千里之外。\u003c/p\u003e\n\u003cp\u003e影响 SQL 执行性能的主要因素可以总结为如下几项：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e计算资源量（CPU，内存，网络等）\u003c/li\u003e\n\u003cli\u003e计算数据量（输入和输出的记录数）\u003c/li\u003e\n\u003cli\u003e计算复杂度（业务逻辑复杂程度和对应的 SQL 实现和执行）\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e计算资源量是一个前置制约因素，理论上更多的资源能够带来更快的计算效果。计算数据量也可以认为是一个前置制约因素，理论上更大的数据量会导致计算速度降低，但对于复杂的计算逻辑，通过合理的 SQL 可以更好的控制计算过程中的数据量，从而提升 SQL 性能。计算复杂度是影响 SQL 性能的关键因素，复杂的业务逻辑必然比简单的业务逻辑处理时间要长，相同业务逻辑的不同 SQL 实现也会影响运行效率，这就要求我们对业务逻辑进行全面的理解，对实现 SQL 进行合理优化，从而提升计算速度。\u003c/p\u003e\n\u003ch1 id=\"执行引擎\"\u003e执行引擎\u003c/h1\u003e\n\u003cp\u003eSQL 是用于一种用于数据定义和数据操纵的特定目的的编程语言 \u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e。SQL 虽然有 ISO 标准 \u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e，但大部分 SQL 代码在不同的数据库系统中并不具有完全的跨平台性。不同的执行引擎也会对 SQL 的语法有相应的改动和扩展，同时对于 SQL 的执行也会进行不同的适配和优化。因此，脱离执行引擎的 SQL 性能优化是不可取的。\u003c/p\u003e\n\u003ch2 id=\"hive\"\u003eHive\u003c/h2\u003e\n\u003cp\u003eApache Hive 是一个建立在 Hadoop 架构之上的数据仓库。可以将结构化的数据文件映射为一张数据库表，并提供简单的 SQL 查询功能，可以将 SQL 语句转换为 MapReduce 任务进行运行。因此 MapReduce 是 Hive SQL 运行的核心和根基。\u003c/p\u003e\n\u003cp\u003e我们以 Word Count 为例简单介绍一下 MapReduce 的原理和过程，Word Count 的 MapReduce 处理过程如下图所示：\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2021-05-23-big-data-sql-performance-tuning/word-count-mapreduce.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eInput\u003c/strong\u003e：程序的输入数据。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSplitting\u003c/strong\u003e：讲输入数据分割为若干部分。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMapping\u003c/strong\u003e：针对 Splitting 分割的每个部分，对应有一个 Map 程序处理。本例中将分割后的文本统计成 \u003ccode\u003e\u0026lt;K,V\u0026gt;\u003c/code\u003e 格式，其中 \u003ccode\u003eK\u003c/code\u003e 为单词，\u003ccode\u003eV\u003c/code\u003e 为该单词在这个 Map 中出现的次数。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eShuffling\u003c/strong\u003e：对 Mapping 的相关输出结果进行合并。本例中将具有相同 \u003ccode\u003eK\u003c/code\u003e 的统计结果合并到一起。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReducing\u003c/strong\u003e：对 Shuffling 合并的结果进行汇总。本例中讲相同 \u003ccode\u003eK\u003c/code\u003e 的 \u003ccode\u003eV\u003c/code\u003e 值进行加和操作并返回单个统计结果。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMerged\u003c/strong\u003e：对 Reducing 的结果进行融合形成最终输出。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"spark\"\u003eSpark\u003c/h2\u003e\n\u003cp\u003eApache Spark 是一个用于大规模数据处理的统一分析引擎，Spark SQL 则作为 Apache Spark 用于处理结构化数据的模块。\u003c/p\u003e\n\u003cp\u003eSpark 中常见的概念有：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eRDD\u003c/strong\u003e：Resilient Distributed Dataset，弹性分布式数据集，是分布式内存中一个抽象概念，提供了一种高度受限的共享内存模型。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDAG\u003c/strong\u003e：Directed Acyclic Graph，有向无环图，反应了 RDD 之间的依赖关系。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDriver Program\u003c/strong\u003e：控制程序，负责为 Application 创建 DAG，通常用 \u003ccode\u003eSparkContext\u003c/code\u003e 代表 Driver Program。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCluster Manager\u003c/strong\u003e：集群管理器，负责分配计算资源。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWorker Node\u003c/strong\u003e：工作节点，负责具体计算。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExecutor\u003c/strong\u003e：运行在 Worker Node 上的一个\u003ca href=\"/cn/2021/04/process-thread-and-coroutine-theory/\"\u003e进程\u003c/a\u003e，负责运行 Task，并为 Application 存储数据。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eApplication\u003c/strong\u003e：Spark 应用程序，包含多个 Executor。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTask\u003c/strong\u003e：任务，运行在 Executor 上的工作单元，是 Executor 中的一个\u003ca href=\"/cn/2021/04/process-thread-and-coroutine-theory/\"\u003e线程\u003c/a\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eStage\u003c/strong\u003e：一组并行的 Task，Spark 一般会根据 Shuffle 类算子（例如：\u003ccode\u003ereduceByKey\u003c/code\u003e 或 \u003ccode\u003ejoin\u003c/code\u003e 等）划分 Stage。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eJob\u003c/strong\u003e：一组 Stage 的集合，一个 Job 包含多个 RDD 及作用于 RDD 上的操作。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e相关概念构成了 Spark 的整体架构，如下图所示：\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2021-05-23-big-data-sql-performance-tuning/spark-architecture.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cp\u003e在 Spark 中，一个任务的执行过程大致分为 4 个阶段，如下图所示：\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2021-05-23-big-data-sql-performance-tuning/spark-scheduling.jpeg\" alt=\"\"/\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e定义 RDD 的 Transformations 和 Actions 算子 \u003csup id=\"fnref:3\"\u003e\u003ca href=\"#fn:3\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e3\u003c/a\u003e\u003c/sup\u003e，并根据这些算子形成 DAG。\u003c/li\u003e\n\u003cli\u003e根据形成的 DAG，DAGScheduler 将其划分为多个 Stage，每个 Stage 包含多个 Task。\u003c/li\u003e\n\u003cli\u003eDAGScheduler 将 TaskSet 交由 TaskScheduler 运行，并将执行完毕后的结果返回给 DAGScheduler。\u003c/li\u003e\n\u003cli\u003eTaskScheduler 将任务分发到每一个 Worker 去执行，并将执行完毕后的结果返回给 TaskScheduler。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eSpark 相比于 Hadoop 的主要改进有如下几点：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eHadoop 的 MapReduce 的中间结果都会持久化到磁盘上，而 Spark 则采用基于内存的计算（内存不足时也可选持久化到磁盘上），从而减少 Shuffle 数据，进而提升计算速度。\u003c/li\u003e\n\u003cli\u003eSpark 采用的 DAG 相比于 Hadoop 的 MapReduce 具有更好的容错性和可恢复性，由于 Spark 预先计算出了整个任务的 DAG，相比于 MapReduce 中各个操作之间是独立的，这更有助于进行全局优化。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"presto\"\u003ePresto\u003c/h2\u003e\n\u003cp\u003ePresto 是一种用于大数据的高性能分布式 SQL 查询引擎。Presto 与 Hive 执行任务过程的差异如下图所示：\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2021-05-23-big-data-sql-performance-tuning/hive-vs-presto.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cp\u003ePresto 的优点主要有如下几点：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e基于内存计算，减少了磁盘 IO，从而计算速度更快。\u003c/li\u003e\n\u003cli\u003e能够连接多个数据源，跨数据源连表查询。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e虽然 Presto 能够处理 PB 级数据，但并不代表 Presto 会把 PB 级别数据都放在内存中计算。而是根据场景，例如 \u003ccode\u003eCOUNT\u003c/code\u003e 和 \u003ccode\u003eAVG\u003c/code\u003e 等聚合操作，是边读数据边计算，再清理内存，再读取数据计算，这种情况消耗的内存并不高。但是连表查询，可能产生大量的临时数据，从而速度会变慢。\u003c/p\u003e\n\u003ch1 id=\"性能调优\"\u003e性能调优\u003c/h1\u003e\n\u003cp\u003e本节关于 SQL 性能调优的建议主要针对 Hive，Spark 和 Presto 这类大数据 OLAP 执行引擎设计，其他执行引擎不一定完全适用。\u003c/p\u003e\n\u003cp\u003e下文性能调优中均以如下两张表为例进行说明：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sql\"\u003eCREATE TABLE IF NOT EXISTS sku_order\n(\n  order_id STRING \u0026#39;订单 ID\u0026#39;,\n  sku_id STRING \u0026#39;商品 ID\u0026#39;,\n  sale_quantity BIGINT \u0026#39;销售数量\u0026#39; \n)\nCOMMENT \u0026#39;商品订单表\u0026#39;\nPARTITIONED BY\n(\n  dt STRING COMMENT \u0026#39;日期分区\u0026#39;\n)\n;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-sql\"\u003eCREATE TABLE IF NOT EXISTS sku_info\n(\n  sku_id STRING \u0026#39;商品 ID\u0026#39;,\n  sku_name STRING \u0026#39;商品名称\u0026#39;,\n  category_id STRING \u0026#39;品类 ID\u0026#39;,\n  category_name STRING \u0026#39;品类名称\u0026#39;\n)\nCOMMENT \u0026#39;商品信息表\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"减少数据量\"\u003e减少数据量\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e限定查询分区。对于包含分区的数据表（例如：日期分区），通过合理限定分区来减少数据量，避免全表扫描。\u003c/li\u003e\n\u003cli\u003e限定查询字段。避免使用 \u003ccode\u003eSELECT *\u003c/code\u003e，仅选择需要的字段。\u003ccode\u003eSELECT *\u003c/code\u003e 会通过查询元数据获取字段信息，同时查询所有字段会造成更大的网络开销。\u003c/li\u003e\n\u003cli\u003e在关联前过滤数据。应在进行数据表关联之前按照业务逻辑进行数据过滤，从而提升执行效率。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"数据倾斜\"\u003e数据倾斜\u003c/h2\u003e\n\u003cp\u003e在 Shuffle 阶段，需要将各节点上相同的 Key 拉取到某个节点（Task）上处理，如果某个 Key 对应的数据量特别大则会产生数据倾斜。结果就是该 Task 运行的时间要远远大于其他 Task 的运行时间，从而造成作业整体运行缓慢，数据量过大甚至可能导致某个 Task 出现 OOM。\u003c/p\u003e\n\u003cp\u003e在 SQL 中主要有如下几种情况会产生数据倾斜：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eJOIN\u003c/code\u003e 导致的数据倾斜：两表关联，关联字段的无效值（例如：\u003ccode\u003eNULL\u003c/code\u003e）或有效值过多，可能会导致数据倾斜。\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eGROUP BY\u003c/code\u003e 导致的数据倾斜：当 \u003ccode\u003eGROUP BY\u003c/code\u003e 的字段（或字段组合）中，Key 分布不均，可能会导致数据倾斜。\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eDISTINCT\u003c/code\u003e 导致的数据倾斜：当 \u003ccode\u003eDISTINCT\u003c/code\u003e 的字段（或字段组合）中，Key 分布不均，可能会导致数据倾斜。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e对于不同的数据倾斜情况，解决方案如下：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e对于 \u003ccode\u003eJOIN\u003c/code\u003e 中的无效值进行过滤。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sql\"\u003eSELECT\n  category_name,\n  SUM(sale_quantity) AS sale_quantity\nFROM\n  (\n    SELECT\n      sku_id,\n      sale_quantity\n    FROM\n      sku_order\n    WHERE\n      dt = \u0026#39;20210523\u0026#39;\n      AND sku_id IS NOT NULL\n  ) AS sku_order_filtered\nLEFT JOIN\n  sku_info\nON\n  sku_order_filtered.sku_id = sku_info.sku_id\nGROUP BY\n  category_name\n;\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e对于 \u003ccode\u003eJOIN\u003c/code\u003e 开启 Map Join 或 Broadcast Join 策略，将小表广播到每个 Executor 上来避免产生 Shuffle，从而使得 \u003ccode\u003eJOIN\u003c/code\u003e 能够快速完成。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003eset spark.sql.autoBroadcastJoinThreshold=10485760;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e对于 \u003ccode\u003eJOIN\u003c/code\u003e 中存在数据倾斜的 KEY 进行打散处理。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sql\"\u003eSELECT\n  category_name,\n  SUM(sale_quantity) AS sale_quantity\nFROM\n  (\n    SELECT\n      IF(sku_id IN (0000, 9999), CONCAT(sku_id, \u0026#39;_\u0026#39;, CEIL(RAND() * 10)), sku_id) AS sku_id,\n      sale_quantity\n    FROM\n      sku_order\n    WHERE\n      dt = \u0026#39;20210523\u0026#39;\n  ) AS sku_order_modified\nLEFT JOIN\n  (\n    SELECT\n      sku_id,\n      category_name,\n    FROM\n      sku_info\n    WHERE\n      sku_id NOT IN (0000, 9999)\n    UNION ALL\n    SELECT\n      CONCAT(sku_id, \u0026#39;_\u0026#39;, suffix) AS sku_id,\n      category_name\n    FROM\n      (\n        SELECT\n          sku_id,\n          SPLIT(\u0026#39;1,2,3,4,5,6,7,8,9,10\u0026#39;, \u0026#39;,\u0026#39;) AS suffix_list,\n          category_name\n        FROM\n          sku_info\n        WHERE\n          sku_id IN (0000, 9999)\n      ) sku_info_tmp LATERAL VIEW EXPLODE(suffix_list) sku_info_suffix AS suffix\n  ) sku_info_all\nON\n  sku_order_modified.sku_id = sku_info_all.sku_id\nGROUP BY\n  category_name\n;\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e对于 \u003ccode\u003eGROUP BY\u003c/code\u003e 导致的数据倾斜采用两步聚合。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sql\"\u003eSELECT\n  IF(sku_is_null = 1, NULL, sku_id) AS sku_id,\n  SUM(sale_quantity) AS sale_quantity\nFROM\n  (\n    SELECT\n      sku_id,\n      sku_is_null,\n      SUM(sale_quantity) AS sale_quantity\n    FROM\n    (\n      SELECT\n        IF(sku_id IS NULL, CONCAT(sku_id, CEIL(RAND() * 10)), sku_id) AS sku_id,\n        IF(sku_id IS NULL, 1, 0) AS sku_is_null,\n        sale_quantity\n      FROM\n        sku_order\n      WHERE\n        dt = \u0026#39;20210523\u0026#39;\n    ) sku_order_modified\n    GROUP BY\n      sku_id,\n      sku_is_null\n  ) sku_order_group\nGROUP BY\n  IF(sku_is_null = 1, NULL, sku_id)\n;\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e对于 \u003ccode\u003eDISTINCT\u003c/code\u003e 导致的数据倾斜，可以改写为 \u003ccode\u003eGROUP BY\u003c/code\u003e 实现，从而通过多个 Task 计算避免数据倾斜。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sql\"\u003e/* COUNT DISTINCT */\nSELECT\n  COUNT(DISTINCT sku_id) AS cnt\nFROM\n  sku_order\nWHERE\n  dt = \u0026#39;20210523\u0026#39;\n;\n\n/* GROUP BY */\nSELECT\n  COUNT(1) AS cnt\nFROM\n  (\n    SELECT\n      sku_id\n    FROM\n      sku_order\n    WHERE\n      dt = \u0026#39;20210523\u0026#39;\n    GROUP BY\n      sku_id\n  ) AS sku_stats\n;\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"其他建议\"\u003e其他建议\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e使用 \u003ca href=\"https://en.wikipedia.org/wiki/Hierarchical_and_recursive_queries_in_SQL#Common_table_expression\"\u003eCommon Table Expressions (CTEs)\u003c/a\u003e 而非子查询。\u003ccode\u003eWITH\u003c/code\u003e 语句产生的结果类似临时表，可以重复使用，从而避免相同逻辑业务重复计算。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e使用 \u003ccode\u003eLEFT SEMI JOIN\u003c/code\u003e 而非 \u003ccode\u003eIN\u003c/code\u003e 和子查询。Hive 在 0.13 后的版本中才在 \u003ccode\u003eIN\u003c/code\u003e 和 \u003ccode\u003eNOT IN\u003c/code\u003e 中支持子查询。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sql\"\u003e/* BAD */\nSELECT\n  order_id,\n  sku_id,\n  sale_quantity\nFROM\n  sku_order\nWHERE\n  sku_id IN (SELECT sku_id FROM sku_info)\n;\n\n/* GOOD */\nSELECT\n  order_id,\n  sku_id,\n  sale_quantity\nFROM\n  sku_order\nLEFT SEMI JOIN\n  sku_info\nON\n  sku_order.sku_id = sku_info.sku_id\n;\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"参数调优\"\u003e参数调优\u003c/h1\u003e\n\u003cp\u003e除了 SQL 本身逻辑的优化外，执行引擎的相关参数设置也会影响 SQL 的执行性能。本小节以 Spark 引擎为例，总结相关参数的设置及其影响。\u003c/p\u003e\n\u003ch2 id=\"动态分区\"\u003e动态分区\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003e/* 以下 Hive 参数对 Spark 同样有效 */\n\n/* 是否启用动态分区功能 */\nset hive.exec.dynamic.partition=true;\n\n/* strict 表示至少需要指定一个分区，nonstrict 表示可以全部动态指定分区 */\nset hive.exec.dynamic.partition.mode=nonstrict;\n\n/* 动态生成分区的最大数量 */\nset hive.exec.max.dynamic.partitions=1000;\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"资源申请\"\u003e资源申请\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003e/* 每个 Executor 中的核数 */\nset spark.executor.cores=2;\n\n/* Executor 的内存总量。YARN 中 Container 的内存限制为 spark.executor.memory + spark.yarn.executor.memoryOverhead \u0026lt;= 16G。 */\nset spark.executor.memory=4G;\n\n/* Executor 的堆外内存大小，由 YARN 控制，单位为 MB。YARN 中 Container 的内存限制为 spark.executor.memory + spark.yarn.executor.memoryOverhead \u0026lt;= 16G。 */\nset spark.yarn.executor.memoryOverhead=1024;\n\n/* Driver 的内存总量，主要用于存放任务执行过程中 Shuffle 元数据，以及任务中 Collect 的数据，Broadcast 的小表也会先存放在 Driver 中。YARN 中 Container 的内存限制为 spark.executor.memory + spark.yarn.executor.memoryOverhead \u0026lt;= 16G。 */\nset spark.driver.memory=8G;\n\n/* Driver 的堆外内存，由 YARN 控制，单位为 MB。YARN 中 Container 的内存限制为 spark.executor.memory + spark.yarn.executor.memoryOverhead \u0026lt;= 16G。 */\nset spark.yarn.driver.memoryOverhead=1024;\n\n/* storage memory + execution memory 占总内存（java heap-reserved memory）的比例。executor jvm 中内存分为 storage、execution 和 other 内存。storage 存放缓存 RDD 数据，execution 存放 Shuffle 过程的中间数据，other 存放用户定义的数据结构或 Spark 内部元数据。如果用户自定义数据结构较少，可以将该参数比例适当上调。 */\nset spark.memory.fraction=0.7;\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"动态分配\"\u003e动态分配\u003c/h2\u003e\n\u003cp\u003e开启动态分配，Spark 可以根据当前作业负载动态申请和释放资源：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003eset spark.dynamicAllocation.enabled=true;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e同时需要设置同一时刻可以申请的最小和最大 Executor 数量：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003eset spark.dynamicAllocation.minExecutors=10;\nset spark.dynamicAllocation.maxExecutors=100;\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"小文件合并\"\u003e小文件合并\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003e/* 小文件合并阈值，如果生成的文件平均大小低于阈值会额外启动一轮 Stage 进行小文件的合并，默认不合并小文件。 */\nset spark.sql.mergeSmallFileSize=67108864;\n\n/* \t设置额外的合并 Job 时的 Map 端输入大小 */\nset spark.sql.targetBytesInPartitionWhenMerge=67108864;\n\n/* 设置 Map 端输入的合并文件大小 */\nset spark.hadoopRDD.targetBytesInPartition=67108864;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e在决定一个目录是否需要合并小文件时，会统计目录下的平均大小，然后和 \u003ccode\u003espark.sql.mergeSmallFileSize\u003c/code\u003e 比较。在合并文件时，一个 Map Task 读取的数据量取决于下面三者的较大值：\u003ccode\u003espark.sql.mergeSmallFileSize\u003c/code\u003e，\u003ccode\u003espark.sql.targetBytesInPartitionWhenMerge\u003c/code\u003e，\u003ccode\u003espark.hadoopRDD.targetBytesInPartition\u003c/code\u003e。\u003c/p\u003e\n\u003ch2 id=\"shuffle-相关\"\u003eShuffle 相关\u003c/h2\u003e\n\u003cp\u003e当大表 \u003ccode\u003eJOIN\u003c/code\u003e 小表时，如果小表足够小，可以将小表广播到所有 Executor 中，在 Map 阶段完成 \u003ccode\u003eJOIN\u003c/code\u003e。如果该值设置太大，容易导致 Executor 出现 OOM。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003e/* 10 * 1024 * 1024, 10MB */\nset spark.sql.autoBroadcastJoinThreshold=10485760;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e设置 Reduce 阶段的分区数：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003eset spark.sql.shuffle.partitions=1000;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e设置过大可能导致很多 Reducer 同时向一个 Mapper 拉取数据，导致 Mapper 由于请求压力过大而挂掉或响应缓慢，从而 fetch failed。\u003c/p\u003e\n\u003cp\u003e一些其他 Shuffle 相关的配置如下：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003e/* 同一时刻一个 Reducer 可以同时拉取的数据量大小 */\nset spark.reducer.maxSizeInFlight=25165824;\n\n/* 同一时刻一个 Reducer 可以同时产生的请求数 */\nset spark.reducer.maxReqsInFlight=10;\n\n/* 同一时刻一个 Reducer 向同一个上游 Executor 拉取的最多 Block 数 */\nset spark.reducer.maxBlocksInFlightPerAddress=1;\n\n/* Shufle 请求的 Block 超过该阈值就会强制落盘，防止一大堆并发请求将内存占满 */\nset spark.reducer.maxReqSizeShuffleToMem=536870911;\n\n/* Shuffle 中连接超时时间，超过该时间会 fetch failed */\nset spark.shuffle.io.connectionTimeout=120;\n\n/* Shuffle 中拉取数据的最大重试次数 */\nset spark.shuffle.io.maxRetries=3;\n\n/* Shuffle 重试的等待间隔 */\nset spark.shuffle.io.retryWait=5;\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"orc-相关\"\u003eORC 相关\u003c/h2\u003e\n\u003cp\u003eORC 文件的格式如下图所示：\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2021-05-23-big-data-sql-performance-tuning/orc-file-layout.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cp\u003e其中，Postscript 为文件描述信息，包括 File Footer 和元数据长度、文件版本、压缩格式等；File Footer 是文件的元数据信息，包括数据量、每列的统计信息等；文件中的数据为 Stripe，每个 Stripe 包括索引数据、行数据和 Stripe Footer。更多有关 ORC 文件格式的信息请参见 \u003ca href=\"https://orc.apache.org/specification/ORCv1/\"\u003eORC Specification v1\n\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e在读取 ORC 压缩表时，可以控制生成 Split 的策略，包括：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eBI\u003c/strong\u003e：以文件为力度进行 Split 划分\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eETL\u003c/strong\u003e：将文件进行切分，多个 Stripe 组成一个 Split\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eHYBRID\u003c/strong\u003e：当文件的平均大小大于 Hadoop 最大 Split 值时使用 ETL 策略，否则使用 BI 策略\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e对于一些较大的 ORC 表，可能其 Footer 较大，ETL 策略可能会导致从 HDFS 拉取大量的数据来切分 Split，甚至会导致 Driver 端 OOM，因此这类表的读取建议采用 BI 策略。对于一些较小，尤其是有数据倾斜的表（即大量 Stripe 存储于少数文件中），建议使用 ETL 策略。\u003c/p\u003e\n\u003cp\u003e一些其他 ORC 相关的配置如下：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003e/* ORC 谓词下推，默认是关闭 */\nset spark.sql.orc.filterPushdown=true;\n\n/* \t开启后，在 Split 划分时会使用 Footer 信息 */\nset spark.sql.orc.splits.include.file.footer=true;\n\n/* 设置每个 Stripe 可以缓存的大小 */\nset spark.sql.orc.cache.stripe.details.size=10000;\n\n/* 当为 true 时，Spark SQL 的谓语将被下推到 Hive Metastore 中，更早的消除不匹配的分区。 */\nset spark.sql.hive.metastorePartitionPruning=true;\n\n/* 读 ORC 表时，设置小文件合并的阈值，低于该值的 Split 会合并在一个 Task 中执行 */\nset spark.hadoop.mapreduce.input.fileinputformat.split.minsize=67108864;\n\n/* 读 ORC 表时，设置一个 Split 的最大阈值，大于该值的 Split 会切分成多个 Split。 */\nset spark.hadoop.mapreduce.input.fileinputformat.split.maxsize=268435456;\n\n/* 文件提交到HDFS上的算法：1. version=1 是按照文件提交。2. version=2 是批量按照目录进行提交，可以极大节约文件提交到 HDFS 的时间，减轻 NameNode 压力。 */\nset spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version=2;\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"自适应执行\"\u003e自适应执行\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003e/* 开启动态执行 */\nset spark.sql.adaptive.enabled=true;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e当自适应执行开启后，调整 \u003ccode\u003espark.sql.adaptive.shuffle.targetPostShuffleInputSize\u003c/code\u003e，当 Mapper 端两个 Partition 的数据合并后小于该值时，Spark 会将两个 Partition 合并到一个 Reducer 进行处理。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003eset spark.sql.adaptive.shuffle.targetPostShuffleInputSize=67108864;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e当自适应执行开启后，有时会导致过多分区被合并，为了防止分区过少影响性能，可以设置如下参数：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003eset spark.sql.adaptive.minNumPostShufflePartitions=10;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e一些其他自适应执行相关的配置如下：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003e/* 开启动态调整 Join */\nset spark.sql.adaptive.join.enabled=true;\n\n/* 设置 SortMergeJoin 转 BroadcastJoin 的阈值，如果不设置该参数，该阈值和 spark.sql.autoBroadcastJoinThreshold 值相等。 */\nset spark.sql.adaptiveBroadcastJoinThreshold=33554432;\n\n/* 是否允许为了优化 Join 而增加 Shuffle，默认是 false */\nset spark.sql.adaptive.allowAddititionalShuffle=false;\n\n/* 开启自动处理 Join 时的数据倾斜 */\nset spark.sql.adaptive.skewedJoin.enabled=true;\n\n/* 控制处理一个倾斜 Partition 的 Task 个数上限，默认值是 5 */\nset spark.sql.adaptive.skewedPartitionMaxSplits=100;\n\n/* 设置一个 Partition 被视为倾斜 Partition 的行数下限，行数低于该值的 Partition 不会被当做倾斜 Partition 处理。 */\nset spark.sql.adaptive.skewedPartitionRowCountThreshold=10000000;\n\n/* 设置一个 Partition 被视为倾斜 Partition 的大小下限，大小小于该值的 Partition 不会被当做倾斜 Partition 处理。 */\nset spark.sql.adaptive.skewedPartitionSizeThreshold=536870912;\n\n/* 设置倾斜因子，当一个 Partition 满足以下两个条件之一，就会被视为倾斜 Partition：1. 大小大于 spark.sql.adaptive.skewedPartitionSizeThreshold 的同时大于各 Partition 大小中位数与该因子的乘积。2. 行数大于 spark.sql.adaptive.skewedRowCountThreshold 的同时大于各 Partition 行数中位数与该因子的乘积。*/\nset spark.sql.adaptive.skewedPartitionFactor=10;\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"推测执行\"\u003e推测执行\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003e/* Spark 推测执行开关，默认是 true */\nset spark.speculation=true;\n\n/* 开启推测执行后，每隔该值时间会检测是否有需要推测执行的 Task */\nset spark.speculation.interval=1000ms;\n\n/* 当成功 Task 占总 Task 的比例超过 spark.speculation.quantile，统计成功 Task 运行时间中位数乘以 spark.speculation.multiplier 得到推测执行阈值，当在运行的任务超过这个阈值就会启动推测执行。当资源充足时，可以适当减小这两个值。 */\nset spark.speculation.quantile=0.99;\nset spark.speculation.multiplier=3;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"footnotes\" role=\"doc-endnotes\"\u003e\n\u003chr/\u003e\n\u003col\u003e\n\u003cli id=\"fn:1\"\u003e\n\u003cp\u003e\u003ca href=\"https://zh.wikipedia.org/wiki/SQL\"\u003ehttps://zh.wikipedia.org/wiki/SQL\u003c/a\u003e \u003ca href=\"#fnref:1\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:2\"\u003e\n\u003cp\u003e\u003ca href=\"https://www.iso.org/committee/45342.html\"\u003ehttps://www.iso.org/committee/45342.html\u003c/a\u003e \u003ca href=\"#fnref:2\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:3\"\u003e\n\u003cp\u003e\u003ca href=\"https://spark.apache.org/docs/latest/rdd-programming-guide.html\"\u003ehttps://spark.apache.org/docs/latest/rdd-programming-guide.html\u003c/a\u003e \u003ca href=\"#fnref:3\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/div\u003e\n\n\n\n\n\n\u003cdiv class=\"donate\"\u003e\n  \u003cdiv class=\"donate-header\"\u003e\u003c/div\u003e\n  \u003cdiv class=\"donate-slug\" id=\"donate-slug\"\u003ebig-data-sql-performance-tuning\u003c/div\u003e\n  \u003cbutton class=\"donate-button\"\u003e赞 赏\u003c/button\u003e\n  \u003cdiv class=\"donate-footer\"\u003e「真诚赞赏，手留余香」\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv class=\"donate-modal-wrapper\"\u003e\n  \u003cdiv class=\"donate-modal\"\u003e\n    \u003cdiv class=\"donate-box\"\u003e\n      \u003cdiv class=\"donate-box-content\"\u003e\n        \u003cdiv class=\"donate-box-content-inner\"\u003e\n          \u003cdiv class=\"donate-box-header\"\u003e「真诚赞赏，手留余香」\u003c/div\u003e\n          \u003cdiv class=\"donate-box-body\"\u003e\n            \u003cdiv class=\"donate-box-money\"\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-2\" data-v=\"2\" data-unchecked=\"￥ 2\" data-checked=\"2 元\"\u003e￥ 2\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-5\" data-v=\"5\" data-unchecked=\"￥ 5\" data-checked=\"5 元\"\u003e￥ 5\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-10\" data-v=\"10\" data-unchecked=\"￥ 10\" data-checked=\"10 元\"\u003e￥ 10\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-50\" data-v=\"50\" data-unchecked=\"￥ 50\" data-checked=\"50 元\"\u003e￥ 50\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-100\" data-v=\"100\" data-unchecked=\"￥ 100\" data-checked=\"100 元\"\u003e￥ 100\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-custom\" data-v=\"custom\" data-unchecked=\"任意金额\" data-checked=\"任意金额\"\u003e任意金额\u003c/button\u003e\n            \u003c/div\u003e\n            \u003cdiv class=\"donate-box-pay\"\u003e\n              \u003cimg class=\"donate-box-pay-qrcode\" id=\"donate-box-pay-qrcode\" src=\"\"/\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n          \u003cdiv class=\"donate-box-footer\"\u003e\n            \u003cdiv class=\"donate-box-pay-method donate-box-pay-method-checked\" data-v=\"wechat-pay\"\u003e\n              \u003cimg class=\"donate-box-pay-method-image\" id=\"donate-box-pay-method-image-wechat-pay\" src=\"\"/\u003e\n            \u003c/div\u003e\n            \u003cdiv class=\"donate-box-pay-method\" data-v=\"alipay\"\u003e\n              \u003cimg class=\"donate-box-pay-method-image\" id=\"donate-box-pay-method-image-alipay\" src=\"\"/\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n      \u003c/div\u003e\n    \u003c/div\u003e\n    \u003cbutton type=\"button\" class=\"donate-box-close-button\"\u003e\n      \u003csvg class=\"donate-box-close-button-icon\" fill=\"#fff\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\"\u003e\u003cpath d=\"M13.486 12l5.208-5.207a1.048 1.048 0 0 0-.006-1.483 1.046 1.046 0 0 0-1.482-.005L12 10.514 6.793 5.305a1.048 1.048 0 0 0-1.483.005 1.046 1.046 0 0 0-.005 1.483L10.514 12l-5.208 5.207a1.048 1.048 0 0 0 .006 1.483 1.046 1.046 0 0 0 1.482.005L12 13.486l5.207 5.208a1.048 1.048 0 0 0 1.483-.006 1.046 1.046 0 0 0 .005-1.482L13.486 12z\" fill-rule=\"evenodd\"\u003e\u003c/path\u003e\u003c/svg\u003e\n    \u003c/button\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n\n\u003cscript type=\"text/javascript\" src=\"/js/donate.js\"\u003e\u003c/script\u003e\n\n\n  \u003cfooter\u003e\n  \n\u003cnav class=\"post-nav\"\u003e\n  \u003cspan class=\"nav-prev\"\u003e← \u003ca href=\"/cn/2021/05/sql-style-guide/\"\u003eSQL 样式指南 (SQL Style Guide)\u003c/a\u003e\u003c/span\u003e\n  \u003cspan class=\"nav-next\"\u003e\u003ca href=\"/cn/2021/06/virtual-env-preparation/\"\u003e虚拟环境准备 (Virtual Environment Preparation)\u003c/a\u003e →\u003c/span\u003e\n\u003c/nav\u003e\n\n\n\n\n\u003cins class=\"adsbygoogle\" style=\"display:block; text-align:center;\" data-ad-layout=\"in-article\" data-ad-format=\"fluid\" data-ad-client=\"ca-pub-2608165017777396\" data-ad-slot=\"8302038603\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n  (adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/js-cookie@3.0.5/dist/js.cookie.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/toggle-theme.js\"\u003e\u003c/script\u003e\n\n\n\u003cscript src=\"/js/no-highlight.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/math-code.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/heading-anchor.js\"\u003e\u003c/script\u003e\n\n\n\n\u003csection class=\"comments\"\u003e\n\u003cscript src=\"https://giscus.app/client.js\" data-repo=\"leovan/leovan.me\" data-repo-id=\"MDEwOlJlcG9zaXRvcnkxMTMxOTY0Mjc=\" data-category=\"Comments\" data-category-id=\"DIC_kwDOBr89i84CT-R7\" data-mapping=\"pathname\" data-strict=\"1\" data-reactions-enabled=\"1\" data-emit-metadata=\"0\" data-input-position=\"top\" data-theme=\"preferred_color_scheme\" data-lang=\"zh-CN\" data-loading=\"lazy\" crossorigin=\"anonymous\" defer=\"\"\u003e\n\u003c/script\u003e\n\u003c/section\u003e\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"//cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"//cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"//cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/toolbar/prism-toolbar.min.js\"\u003e\u003c/script\u003e\n\u003cscript\u003e\n  (function() {\n    if (!self.Prism) {\n      return;\n    }\n\n    \n    Prism.languages.dos = Prism.languages.powershell;\n    Prism.languages.gremlin = Prism.languages.groovy;\n\n    let languages = {\n      'r': 'R', 'python': 'Python', 'xml': 'XML', 'html': 'HTML',\n      'yaml': 'YAML', 'latex': 'LaTeX', 'tex': 'TeX',\n      'powershell': 'PowerShell', 'javascript': 'JavaScript',\n      'dos': 'DOS', 'qml': 'QML', 'json': 'JSON', 'bash': 'Bash',\n      'text': 'Text', 'txt': 'Text', 'sparql': 'SPARQL',\n      'gremlin': 'Gremlin', 'cypher': 'Cypher', 'ngql': 'nGQL',\n      'shell': 'Shell', 'sql': 'SQL', 'apacheconf': 'Apache Configuration', 'c': 'C', 'css': 'CSS'\n    };\n\n    Prism.hooks.add('before-highlight', function(env) {\n      if (env.language !== 'plain') {\n        let language = languages[env.language] || env.language;\n        env.element.setAttribute('data-language', language);\n      }\n    });\n\n    \n    let ClipboardJS = window.ClipboardJS || undefined;\n\n    Prism.plugins.toolbar.registerButton('copy-to-clipboard', function(env) {\n      let linkCopy = document.createElement('button');\n      linkCopy.classList.add('prism-button-copy');\n\n      registerClipboard();\n\n      return linkCopy;\n\n      function registerClipboard() {\n        let clip = new ClipboardJS(linkCopy, {\n          'text': function () {\n            return env.code;\n          }\n        });\n\n        clip.on('success', function() {\n          linkCopy.classList.add('prism-button-copy-success');\n          resetText();\n        });\n        clip.on('error', function () {\n          linkCopy.classList.add('prism-button-copy-error');\n          resetText();\n        });\n      }\n\n      function resetText() {\n        setTimeout(function () {\n          linkCopy.classList.remove('prism-button-copy-success');\n          linkCopy.classList.remove('prism-button-copy-error');\n        }, 1600);\n      }\n    });\n  })();\n\u003c/script\u003e\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003cscript async=\"\" src=\"/js/center-img.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/right-quote.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/external-link.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/alt-title.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/figure.js\"\u003e\u003c/script\u003e\n\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js\"\u003e\u003c/script\u003e\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/vanilla-back-to-top@latest/dist/vanilla-back-to-top.min.js\"\u003e\u003c/script\u003e\n\u003cscript\u003e\naddBackToTop({\n  diameter: 48\n});\n\u003c/script\u003e\n\n  \u003chr/\u003e\n  \u003cdiv class=\"copyright no-border-bottom\"\u003e\n    \u003cdiv class=\"copyright-author-year\"\u003e\n      \u003cspan\u003eCopyright © 2017-2024 \u003ca href=\"/\"\u003e范叶亮 | Leo Van\u003c/a\u003e\u003c/span\u003e\n    \u003c/div\u003e\n  \u003c/div\u003e\n  \u003c/footer\u003e\n  \u003c/article\u003e",
  "Date": "2021-05-23T00:00:00Z",
  "Author": "范叶亮"
}