{
  "Source": "leovan.me",
  "Title": "特征值分解，奇异值分解和主成份分析 (EVD, SVD and PCA)",
  "Link": "https://leovan.me/cn/2017/12/evd-svd-and-pca/",
  "Content": "\u003carticle class=\"main\"\u003e\n    \u003cheader class=\"content-title\"\u003e\n    \n\u003ch1 class=\"title\"\u003e\n  \n  特征值分解，奇异值分解和主成份分析 (EVD, SVD and PCA)\n  \n\u003c/h1\u003e\n\n\n\n\n\n\n\n\u003ch2 class=\"author-date\"\u003e范叶亮 / \n2017-12-11\u003c/h2\u003e\n\n\n\n\u003ch3 class=\"post-meta\"\u003e\n\n\n\u003cstrong\u003e分类: \u003c/strong\u003e\n\u003ca href=\"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0\"\u003e机器学习\u003c/a\u003e\n\n\n\n\n/\n\n\n\n\n\u003cstrong\u003e标签: \u003c/strong\u003e\n\u003cspan\u003eEVD\u003c/span\u003e, \u003cspan\u003eSVD\u003c/span\u003e, \u003cspan\u003ePCA\u003c/span\u003e, \u003cspan\u003e降维\u003c/span\u003e, \u003cspan\u003eDimensionality Reduction\u003c/span\u003e\n\n\n\n\n/\n\n\n\u003cstrong\u003e字数: \u003c/strong\u003e\n2553\n\u003c/h3\u003e\n\n\n\n\u003chr/\u003e\n\n\n\n    \n    \n    \u003cins class=\"adsbygoogle\" style=\"display:block; text-align:center;\" data-ad-layout=\"in-article\" data-ad-format=\"fluid\" data-ad-client=\"ca-pub-2608165017777396\" data-ad-slot=\"1261604535\"\u003e\u003c/ins\u003e\n    \u003cscript\u003e\n    (adsbygoogle = window.adsbygoogle || []).push({});\n    \u003c/script\u003e\n    \n    \n    \u003c/header\u003e\n\n\n\n\n\u003ch1 id=\"准备知识\"\u003e准备知识\u003c/h1\u003e\n\u003ch2 id=\"向量与基\"\u003e向量与基\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003e$\\renewcommand{\\diag}{\\operatorname{diag}}\\renewcommand{\\cov}{\\operatorname{cov}}$\u003c/code\u003e首先，定义 \u003ccode\u003e$\\boldsymbol{\\alpha}$\u003c/code\u003e 为列向量，则维度相同的两个向量 \u003ccode\u003e$\\boldsymbol{\\alpha}, \\boldsymbol{\\beta}$\u003c/code\u003e 的内积可以表示为：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$\\boldsymbol{\\alpha} \\cdot \\boldsymbol{\\beta} = \\boldsymbol{\\alpha}^T \\boldsymbol{\\beta} = \\sum_{i=1}^{n}{\\alpha_i b_i}$$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e后续为了便于理解，我们以二维向量为例，则 \u003ccode\u003e$\\boldsymbol{\\alpha} = \\left(x_1, y_1\\right)^T, \\boldsymbol{\\beta} = \\left(x_2, y_2\\right)^T$\u003c/code\u003e，在直角座标系中可以两个向量表示如下：\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2017-12-11-evd-svd-and-pca/vector-inner-product-and-projection.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cp\u003e我们从 \u003ccode\u003e$A$\u003c/code\u003e 点向向量 \u003ccode\u003e$\\boldsymbol{\\beta}$\u003c/code\u003e 的方向做一条垂线，交于点 \u003ccode\u003e$C$\u003c/code\u003e，则称 \u003ccode\u003e$OC$\u003c/code\u003e 为 \u003ccode\u003e$OA$\u003c/code\u003e 在 \u003ccode\u003e$OB$\u003c/code\u003e 方向上的投影。设向量 \u003ccode\u003e$\\boldsymbol{\\alpha}$\u003c/code\u003e 和向量 \u003ccode\u003e$\\boldsymbol{\\beta}$\u003c/code\u003e 的夹角为 \u003ccode\u003e$\\theta$\u003c/code\u003e，则：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$\\cos \\left(\\theta\\right) = \\dfrac{\\boldsymbol{\\alpha} \\cdot \\boldsymbol{\\beta}}{\\lvert\\boldsymbol{\\alpha}\\rvert \\lvert\\boldsymbol{\\beta}\\rvert}$$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$\\lvert\\boldsymbol{\\alpha}\\rvert = \\sqrt{x_1^2 + y_1^2}$\u003c/code\u003e，则 \u003ccode\u003e$OC$\u003c/code\u003e 的长度为 \u003ccode\u003e$\\lvert\\boldsymbol{\\alpha}\\rvert \\cos\\left(\\theta\\right)$\u003c/code\u003e。\u003c/p\u003e\n\u003cp\u003e在 \u003ccode\u003e$n$\u003c/code\u003e 维的线性空间 \u003ccode\u003e$V$\u003c/code\u003e 中，\u003ccode\u003e$n$\u003c/code\u003e 个线性无关的向量 \u003ccode\u003e$\\boldsymbol{\\epsilon_1, \\epsilon_2, ..., \\epsilon_n}$\u003c/code\u003e 称为 \u003ccode\u003e$V$\u003c/code\u003e 的一组\u003cstrong\u003e基\u003c/strong\u003e。则对于 \u003ccode\u003e$V$\u003c/code\u003e 中的任一向量 \u003ccode\u003e$\\boldsymbol{\\alpha}$\u003c/code\u003e 可以由这组基线性表示出来：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$\\boldsymbol{\\alpha} = x_1 \\boldsymbol{\\epsilon_1} + x_2 \\boldsymbol{\\epsilon_2} + ... + x_n \\boldsymbol{\\epsilon_n}$$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e则对于向量 \u003ccode\u003e$\\boldsymbol{\\alpha} = \\left(3, 2\\right)^T$\u003c/code\u003e，可以表示为：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$\\boldsymbol{\\alpha} = 2 \\left(1, 0\\right)^T + 3 \\left(0, 1\\right)^T$$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中 \u003ccode\u003e$\\left(1, 0\\right)^T$\u003c/code\u003e 和 \u003ccode\u003e$\\left(0, 1\\right)^T$\u003c/code\u003e 为二维空间中的一组基。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2017-12-11-evd-svd-and-pca/vector-bases.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cp\u003e因此，当我们确定好一组基之后，我们仅需利用向量在基上的投影值即可表示对应的向量。一般情况下，我们会选择由坐标轴方向上的单位向量构成的基作为默认的基来表示向量，但我们仍可选择其他的基。例如，我们选择 \u003ccode\u003e$\\left(-\\dfrac{1}{\\sqrt{2}}, \\dfrac{1}{\\sqrt{2}}\\right)$\u003c/code\u003e 和 \u003ccode\u003e$\\left(\\dfrac{1}{\\sqrt{2}}, \\dfrac{1}{\\sqrt{2}}\\right)$\u003c/code\u003e 作为一组基，则向量在这组基上的坐标为 \u003ccode\u003e$\\left(-\\dfrac{1}{\\sqrt{2}}, \\dfrac{5}{\\sqrt{2}}\\right)$\u003c/code\u003e，示例如下：\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2017-12-11-evd-svd-and-pca/vector-change-of-bases.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003ch2 id=\"线性变换\"\u003e线性变换\u003c/h2\u003e\n\u003cp\u003e以二维空间为例，定义一个如下矩阵\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ A = \\left\\lgroup \\begin{array}{cc} a_{11} \u0026amp; a_{12} \\\\ a_{21} \u0026amp; a_{22} \\end{array} \\right\\rgroup $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e则对于二维空间中一个向量 \u003ccode\u003e$\\boldsymbol{\\alpha} = \\left(x, y\\right)^T$\u003c/code\u003e ，通过同上述矩阵进行乘法运算，可得\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\boldsymbol{\\alpha\u0026#39;} = A \\boldsymbol{\\alpha} = \\left\\lgroup \\begin{array}{cc} a_{11} \u0026amp; a_{12} \\\\ a_{21} \u0026amp; a_{22} \\end{array} \\right\\rgroup \\left\\lgroup \\begin{array}{c} x \\\\ y \\end{array} \\right\\rgroup =  \\left\\lgroup \\begin{array}{c} x\u0026#39; \\\\ y\u0026#39; \\end{array} \\right\\rgroup $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e(1) 通过变换将任意一个点 \u003ccode\u003e$x$\u003c/code\u003e 变成它关于 \u003ccode\u003e$x$\u003c/code\u003e 轴对称的点 \u003ccode\u003e$x\u0026#39;$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ x\u0026#39; = \\left\\lgroup \\begin{array}{cc} 1 \u0026amp; 0 \\\\ 0 \u0026amp; -1 \\end{array} \\right\\rgroup \\left\\lgroup \\begin{array}{c} x \\\\ y \\end{array} \\right\\rgroup =  \\left\\lgroup \\begin{array}{c} x \\\\ -y \\end{array} \\right\\rgroup $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2017-12-11-evd-svd-and-pca/vector-linear-transformation-1.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cp\u003e(2) 通过变换将任意一个点 \u003ccode\u003e$x$\u003c/code\u003e 变成它关于 \u003ccode\u003e$y = x$\u003c/code\u003e 对称的点 \u003ccode\u003e$x\u0026#39;$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ x\u0026#39; = \\left\\lgroup \\begin{array}{cc} 0 \u0026amp; 1 \\\\ 1 \u0026amp; 0 \\end{array} \\right\\rgroup \\left\\lgroup \\begin{array}{c} x \\\\ y \\end{array} \\right\\rgroup =  \\left\\lgroup \\begin{array}{c} y \\\\ x \\end{array} \\right\\rgroup $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2017-12-11-evd-svd-and-pca/vector-linear-transformation-2.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cp\u003e(3) 变换将任意一个点 \u003ccode\u003e$x$\u003c/code\u003e 变成在它与原点连线上，与原点距离伸缩为 \u003ccode\u003e$|\\lambda|$\u003c/code\u003e 倍的点 \u003ccode\u003e$x\u0026#39;$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ x\u0026#39; = \\left\\lgroup \\begin{array}{cc} \\lambda \u0026amp; 0 \\\\ 0 \u0026amp; \\lambda \\end{array} \\right\\rgroup \\left\\lgroup \\begin{array}{c} x \\\\ y \\end{array} \\right\\rgroup =  \\left\\lgroup \\begin{array}{c} \\lambda x \\\\ \\lambda y \\end{array} \\right\\rgroup $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2017-12-11-evd-svd-and-pca/vector-linear-transformation-3.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cp\u003e(4) 通过变换将任意一个点 \u003ccode\u003e$x$\u003c/code\u003e 绕原点旋转了角度 \u003ccode\u003e$\\theta$\u003c/code\u003e 的点 \u003ccode\u003e$x\u0026#39;$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{equation} \\begin{split} x\u0026#39;\u0026amp; = \\left\\lgroup \\begin{array}{cc} \\cos \\theta \u0026amp; -\\sin \\theta \\\\ \\sin \\theta \u0026amp; \\cos \\theta \\end{array} \\right\\rgroup \\left\\lgroup \\begin{array}{c} x \\\\ y \\end{array} \\right\\rgroup \\\\ \u0026amp; =  \\left\\lgroup \\begin{array}{cc} \\cos \\theta \u0026amp; -\\sin \\theta \\\\ \\sin \\theta \u0026amp; \\cos \\theta \\end{array} \\right\\rgroup \\left\\lgroup \\begin{array}{c} r \\cos \\phi \\\\ r \\sin \\phi \\end{array} \\right\\rgroup \\\\ \u0026amp; =  \\left\\lgroup \\begin{array}{c} r \\cos \\left(\\phi + \\theta\\right) \\\\ r \\sin \\left(\\phi + \\theta\\right) \\end{array} \\right\\rgroup \\end{split} \\end{equation} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2017-12-11-evd-svd-and-pca/vector-linear-transformation-4.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cp\u003e(5) 变换将任意一个点 \u003ccode\u003e$x$\u003c/code\u003e 变成它在 \u003ccode\u003e$x$\u003c/code\u003e 轴上 的投影点 \u003ccode\u003e$x\u0026#39;$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ x\u0026#39; = \\left\\lgroup \\begin{array}{cc} 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \\end{array} \\right\\rgroup \\left\\lgroup \\begin{array}{c} x \\\\ y \\end{array} \\right\\rgroup =  \\left\\lgroup \\begin{array}{c} x \\\\ 0 \\end{array} \\right\\rgroup $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2017-12-11-evd-svd-and-pca/vector-linear-transformation-5.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003ch1 id=\"特征值分解\"\u003e特征值分解\u003c/h1\u003e\n\u003cp\u003e设 \u003ccode\u003e$A$\u003c/code\u003e 是线性空间 \u003ccode\u003e$V$\u003c/code\u003e 上的一个线性变换，对于一个非零向量 \u003ccode\u003e$\\boldsymbol{\\alpha} = \\left(x_1, x_2, ..., x_n\\right)^T$\u003c/code\u003e 使得\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$A \\boldsymbol{\\alpha} = \\lambda \\boldsymbol{\\alpha}$$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e则 \u003ccode\u003e$\\lambda$\u003c/code\u003e 称为 \u003ccode\u003e$A$\u003c/code\u003e 的一个\u003cstrong\u003e特征值\u003c/strong\u003e，\u003ccode\u003e$\\boldsymbol{\\alpha}$\u003c/code\u003e 称为 \u003ccode\u003e$A$\u003c/code\u003e 的一个\u003cstrong\u003e特征向量\u003c/strong\u003e。通过\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{equation} \\begin{split} A \\boldsymbol{\\alpha} \u0026amp;= \\lambda \\boldsymbol{\\alpha} \\\\ A \\boldsymbol{\\alpha} - \\lambda \\boldsymbol{\\alpha} \u0026amp;= 0 \\\\ \\left(A - \\lambda E\\right) \\boldsymbol{\\alpha} \u0026amp;= 0 \\\\ A - \\lambda E \u0026amp;= 0 \\end{split} \\end{equation} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中 \u003ccode\u003e$E = \\diag \\left(1, 1, ..., 1\\right)$\u003c/code\u003e 为单位对角阵，即可求解其特征值，进而求解特征向量。若 \u003ccode\u003e$A$\u003c/code\u003e 是一个可逆矩阵，则上式可以改写为：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ A = Q \\sum Q^{-1} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e这样，一个方阵 \u003ccode\u003e$A$\u003c/code\u003e 就被一组特征值和特征向量表示了。例如，对于如下矩阵进行特征值分解\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ A = \\left\\lgroup \\begin{array}{cccc} 3 \u0026amp; -2 \u0026amp; -0.9 \u0026amp; 0 \\\\ -2 \u0026amp; 4 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; -1 \u0026amp; 0 \\\\ -0.5 \u0026amp; -0.5 \u0026amp; 0.1 \u0026amp; 1 \\end{array} \\right\\rgroup $$\u003c/code\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-r\"\u003eA \u0026lt;- matrix(c(3, -2, -0.9, 0,\n              -2, 4, 1, 0,\n              0, 0, -1, 0,\n              -0.5, -0.5, 0.1, 1),\n            4, 4, byrow = T)\nA_eig \u0026lt;- eigen(A)\nprint(A_eig)\n\n# eigen() decomposition\n# $values\n# [1]  5.561553  1.438447  1.000000 -1.000000\n# \n# $vectors\n#             [,1]       [,2] [,3]        [,4]\n# [1,] -0.61530186  0.4176225    0  0.15282144\n# [2,]  0.78806410  0.3260698    0 -0.13448286\n# [3,]  0.00000000  0.0000000    0  0.97805719\n# [4,] -0.01893678 -0.8480979    1 -0.04431822\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e则利用特征值和特征向量，可以还原原矩阵\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-r\"\u003eA_re \u0026lt;- A_eig$vectors %*%\n    diag(A_eig$values) %*%\n    solve(A_eig$vectors)\nprint(A_re)\n\n#      [,1] [,2] [,3] [,4]\n# [1,]  3.0 -2.0 -0.9    0\n# [2,] -2.0  4.0  1.0    0\n# [3,]  0.0  0.0 -1.0    0\n# [4,] -0.5 -0.5  0.1    1\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1 id=\"奇异值分解\"\u003e奇异值分解\u003c/h1\u003e\n\u003cp\u003e特征值分解针对的是方阵，对于一个 \u003ccode\u003e$m*n$\u003c/code\u003e 的矩阵是无法进行特征值分解的，这时我们就需要使用奇异值分解来解决这个问题。对于 \u003ccode\u003e$m*n$\u003c/code\u003e 的矩阵 \u003ccode\u003e$A$\u003c/code\u003e，可得 \u003ccode\u003e$A A^T$\u003c/code\u003e 是一个 \u003ccode\u003e$m*m$\u003c/code\u003e 的方阵，则针对 \u003ccode\u003e$A A^T$\u003c/code\u003e，通过 \u003ccode\u003e$\\left(A A^T\\right) \\boldsymbol{\\alpha} = \\lambda \\boldsymbol{\\alpha}$\u003c/code\u003e，即可求解这个方阵的特征值和特征向量。针对矩阵 \u003ccode\u003e$A$\u003c/code\u003e，奇异值分解是将原矩阵分解为三个部分\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ A_{m*n} = U_{m*r} \\sum\\nolimits_{r*r} V_{r*n}^T $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中 \u003ccode\u003e$U$\u003c/code\u003e 称之为左奇异向量，即为 \u003ccode\u003e$A A^T$\u003c/code\u003e 单位化后的特征向量；\u003ccode\u003e$V$\u003c/code\u003e 称之为右奇异向量，即为 \u003ccode\u003e$A^T A$\u003c/code\u003e 单位化后的特征向量；\u003ccode\u003e$\\sum$\u003c/code\u003e矩阵对角线上的值称之为奇异值，即为 \u003ccode\u003e$A A^T$\u003c/code\u003e 或 \u003ccode\u003e$A^T A$\u003c/code\u003e 特征值的平方根。\u003c/p\u003e\n\u003cp\u003e我们利用经典的 lena 图片展示一下 SVD 的作用，lena图片为一张 \u003ccode\u003e$512*512$\u003c/code\u003e 像素的彩色图片\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2017-12-11-evd-svd-and-pca/lena-std.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cp\u003e我们对原始图片进行灰度处理后，进行特征值分解，下图中从左到右，从上到下分别是原始的灰度图像，利用 20 个左奇异向量和 20 个右奇异向量重构图像，利用 50 个左奇异向量和 100 个右奇异向量重构图像，利用 200 个左奇异向量和 200 个右奇异向量重构图像。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2017-12-11-evd-svd-and-pca/lena-reconstruction.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cp\u003e从图中可以看出，我们仅用了 200 个左奇异向量和 200 个右奇异向量重构图像与原始灰度图像已经基本看不出任何区别。因此，我们利用 SVD 可以通过仅保留较大的奇异值实现数据的压缩。\u003c/p\u003e\n\u003ch1 id=\"主成份分析\"\u003e主成份分析\u003c/h1\u003e\n\u003cp\u003e主成份分析\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e可以通俗的理解为一种降维方法。其目标可以理解为将一个 \u003ccode\u003e$m$\u003c/code\u003e 维的数据转换称一个 \u003ccode\u003e$k$\u003c/code\u003e 维的数据，其中 \u003ccode\u003e$k \u0026lt; m$\u003c/code\u003e。对于具有 \u003ccode\u003e$n$\u003c/code\u003e 个样本的数据集，设 \u003ccode\u003e$\\boldsymbol{x_i}$\u003c/code\u003e 表示 \u003ccode\u003e$m$\u003c/code\u003e 维的列向量，则\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ X_{m*n} = \\left(\\boldsymbol{x_1}, \\boldsymbol{x_2}, ..., \\boldsymbol{x_n}\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e对每一个维度进行零均值化，即减去这一维度的均值\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ X\u0026#39;_{m*n} = X - \\boldsymbol{u}\\boldsymbol{h} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$\\boldsymbol{u}$\u003c/code\u003e 是一个 \u003ccode\u003e$m$\u003c/code\u003e 维的行向量，\u003ccode\u003e$\\boldsymbol{u}[m] = \\dfrac{1}{n} \\sum_{i=1}^{n} X[m, i]$\u003c/code\u003e；\u003ccode\u003e$h$\u003c/code\u003e 是一个值全为 \u003ccode\u003e$1$\u003c/code\u003e 的 \u003ccode\u003e$n$\u003c/code\u003e 维行向量。\u003c/p\u003e\n\u003cp\u003e对于两个随机变量，我们可以利用协方差简单表示这两个变量之间的相关性\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\cov \\left(x, y\\right) = E \\left(\\left(x - \\mu_x\\right) \\left(x - \\mu_x\\right)\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e对于已经零均值化后的矩阵 \u003ccode\u003e$X\u0026#39;$\u003c/code\u003e，计算得出如下矩阵\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ C = \\dfrac{1}{n} X\u0026#39; X\u0026#39;^T = \\left\\lgroup \\begin{array}{cccc} \\dfrac{1}{n} \\sum_{i=1}^{n} x_{1i}^2 \u0026amp; \\dfrac{1}{n} \\sum_{i=1}^{n} x_{1i} x_{2i} \u0026amp; \\cdots \u0026amp; \\dfrac{1}{n} \\sum_{}^{} x_{1i} x_{ni} \\\\ \\dfrac{1}{n} \\sum_{i=1}^{n} x_{2i} x_{1i} \u0026amp; \\dfrac{1}{n} \\sum_{i=1}^{n} x_{2i}^2 \u0026amp; \\cdots \u0026amp; \\dfrac{1}{n} \\sum_{}^{} x_{2i} x_{ni} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \u0026amp; \\vdots \\\\ \\dfrac{1}{n} \\sum_{i=1}^{n} x_{mi} x_{1i} \u0026amp; \\dfrac{1}{n} \\sum_{i=1}^{n} x_{mi} x_{2i} \u0026amp; \\cdots \u0026amp; \\dfrac{1}{n} \\sum_{}^{} x_{mi}^2 \\\\ \\end{array} \\right\\rgroup $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e因为矩阵 \u003ccode\u003e$X\u0026#39;$\u003c/code\u003e 已经经过了零均值化处理，因此矩阵 \u003ccode\u003e$C$\u003c/code\u003e 中对角线上的元素为维度 \u003ccode\u003e$m$\u003c/code\u003e 的方差，其他元素则为两个维度之间的协方差。\u003c/p\u003e\n\u003cp\u003e从 PCA 的目标来看，我们则可以通过求解矩阵 \u003ccode\u003e$C$\u003c/code\u003e 的特征值和特征向量，将其特征值按照从大到小的顺序按行重排其对应的特征向量，则取前 \u003ccode\u003e$k$\u003c/code\u003e 个，则实现了数据从 \u003ccode\u003e$m$\u003c/code\u003e 维降至 \u003ccode\u003e$k$\u003c/code\u003e 维。\u003c/p\u003e\n\u003cp\u003e例如，我们将二维数据\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\left\\lgroup \\begin{array} -1 \u0026amp; -1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 2 \\\\ -2 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 1 \\end{array} \\right\\rgroup $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e降至一维\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-r\"\u003ex \u0026lt;- matrix(c(-1, -1, 0, 0, 2,\n              -2, 0, 0, 1, 1),\n            5, 2, byrow = F)\nx_pca \u0026lt;- prcomp(x)\n\nprint(pca)\n# Standard deviations (1, .., p=2):\n# [1] 1.5811388 0.7071068\n# \n# Rotation (n x k) = (2 x 2):\n#            PC1        PC2\n# [1,] 0.7071068  0.7071068\n# [2,] 0.7071068 -0.7071068\n\nsummary(pca)\n# Importance of components:\n#                           PC1    PC2\n# Standard deviation     1.5811 0.7071\n# Proportion of Variance 0.8333 0.1667\n# Cumulative Proportion  0.8333 1.0000\n\nx_ \u0026lt;- predict(x_pca, x)\nprint(x_)\n#             PC1        PC2\n# [1,] -2.1213203  0.7071068\n# [2,] -0.7071068 -0.7071068\n# [3,]  0.0000000  0.0000000\n# [4,]  0.7071068 -0.7071068\n# [5,]  2.1213203  0.7071068\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e降维的投影结果如图所示\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/cn/2017-12-11-evd-svd-and-pca/pca-projection.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cdiv class=\"footnotes\" role=\"doc-endnotes\"\u003e\n\u003chr/\u003e\n\u003col\u003e\n\u003cli id=\"fn:1\"\u003e\n\u003cp\u003eWold, Svante, Kim Esbensen, and Paul Geladi. “Principal component analysis.” \u003cem\u003eChemometrics and intelligent laboratory systems\u003c/em\u003e 2.1-3 (1987): 37-52. \u003ca href=\"#fnref:1\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/div\u003e\n\n\n\n\n\n\u003cdiv class=\"donate\"\u003e\n  \u003cdiv class=\"donate-header\"\u003e\u003c/div\u003e\n  \u003cdiv class=\"donate-slug\" id=\"donate-slug\"\u003eevd-svd-and-pca\u003c/div\u003e\n  \u003cbutton class=\"donate-button\"\u003e赞 赏\u003c/button\u003e\n  \u003cdiv class=\"donate-footer\"\u003e「真诚赞赏，手留余香」\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv class=\"donate-modal-wrapper\"\u003e\n  \u003cdiv class=\"donate-modal\"\u003e\n    \u003cdiv class=\"donate-box\"\u003e\n      \u003cdiv class=\"donate-box-content\"\u003e\n        \u003cdiv class=\"donate-box-content-inner\"\u003e\n          \u003cdiv class=\"donate-box-header\"\u003e「真诚赞赏，手留余香」\u003c/div\u003e\n          \u003cdiv class=\"donate-box-body\"\u003e\n            \u003cdiv class=\"donate-box-money\"\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-2\" data-v=\"2\" data-unchecked=\"￥ 2\" data-checked=\"2 元\"\u003e￥ 2\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-5\" data-v=\"5\" data-unchecked=\"￥ 5\" data-checked=\"5 元\"\u003e￥ 5\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-10\" data-v=\"10\" data-unchecked=\"￥ 10\" data-checked=\"10 元\"\u003e￥ 10\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-50\" data-v=\"50\" data-unchecked=\"￥ 50\" data-checked=\"50 元\"\u003e￥ 50\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-100\" data-v=\"100\" data-unchecked=\"￥ 100\" data-checked=\"100 元\"\u003e￥ 100\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-custom\" data-v=\"custom\" data-unchecked=\"任意金额\" data-checked=\"任意金额\"\u003e任意金额\u003c/button\u003e\n            \u003c/div\u003e\n            \u003cdiv class=\"donate-box-pay\"\u003e\n              \u003cimg class=\"donate-box-pay-qrcode\" id=\"donate-box-pay-qrcode\" src=\"\"/\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n          \u003cdiv class=\"donate-box-footer\"\u003e\n            \u003cdiv class=\"donate-box-pay-method donate-box-pay-method-checked\" data-v=\"wechat-pay\"\u003e\n              \u003cimg class=\"donate-box-pay-method-image\" id=\"donate-box-pay-method-image-wechat-pay\" src=\"\"/\u003e\n            \u003c/div\u003e\n            \u003cdiv class=\"donate-box-pay-method\" data-v=\"alipay\"\u003e\n              \u003cimg class=\"donate-box-pay-method-image\" id=\"donate-box-pay-method-image-alipay\" src=\"\"/\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n      \u003c/div\u003e\n    \u003c/div\u003e\n    \u003cbutton type=\"button\" class=\"donate-box-close-button\"\u003e\n      \u003csvg class=\"donate-box-close-button-icon\" fill=\"#fff\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\"\u003e\u003cpath d=\"M13.486 12l5.208-5.207a1.048 1.048 0 0 0-.006-1.483 1.046 1.046 0 0 0-1.482-.005L12 10.514 6.793 5.305a1.048 1.048 0 0 0-1.483.005 1.046 1.046 0 0 0-.005 1.483L10.514 12l-5.208 5.207a1.048 1.048 0 0 0 .006 1.483 1.046 1.046 0 0 0 1.482.005L12 13.486l5.207 5.208a1.048 1.048 0 0 0 1.483-.006 1.046 1.046 0 0 0 .005-1.482L13.486 12z\" fill-rule=\"evenodd\"\u003e\u003c/path\u003e\u003c/svg\u003e\n    \u003c/button\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n\n\u003cscript type=\"text/javascript\" src=\"/js/donate.js\"\u003e\u003c/script\u003e\n\n\n  \u003cfooter\u003e\n  \n\u003cnav class=\"post-nav\"\u003e\n  \u003cspan class=\"nav-prev\"\u003e← \u003ca href=\"/cn/2017/08/trip-to-melbourne/\"\u003e墨尔本之行 (Trip to Melbourne)\u003c/a\u003e\u003c/span\u003e\n  \u003cspan class=\"nav-next\"\u003e\u003ca href=\"/cn/2017/12/mcmc-and-gibbs-sampling/\"\u003e马尔科夫链蒙特卡洛方法和吉布斯采样 (MCMC and Gibbs Sampling)\u003c/a\u003e →\u003c/span\u003e\n\u003c/nav\u003e\n\n\n\n\n\u003cins class=\"adsbygoogle\" style=\"display:block; text-align:center;\" data-ad-layout=\"in-article\" data-ad-format=\"fluid\" data-ad-client=\"ca-pub-2608165017777396\" data-ad-slot=\"8302038603\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n  (adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/js-cookie@3.0.5/dist/js.cookie.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/toggle-theme.js\"\u003e\u003c/script\u003e\n\n\n\u003cscript src=\"/js/no-highlight.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/math-code.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/heading-anchor.js\"\u003e\u003c/script\u003e\n\n\n\n\u003csection class=\"comments\"\u003e\n\u003cscript src=\"https://giscus.app/client.js\" data-repo=\"leovan/leovan.me\" data-repo-id=\"MDEwOlJlcG9zaXRvcnkxMTMxOTY0Mjc=\" data-category=\"Comments\" data-category-id=\"DIC_kwDOBr89i84CT-R7\" data-mapping=\"pathname\" data-strict=\"1\" data-reactions-enabled=\"1\" data-emit-metadata=\"0\" data-input-position=\"top\" data-theme=\"preferred_color_scheme\" data-lang=\"zh-CN\" data-loading=\"lazy\" crossorigin=\"anonymous\" defer=\"\"\u003e\n\u003c/script\u003e\n\u003c/section\u003e\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"//cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"//cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"//cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/toolbar/prism-toolbar.min.js\"\u003e\u003c/script\u003e\n\u003cscript\u003e\n  (function() {\n    if (!self.Prism) {\n      return;\n    }\n\n    \n    Prism.languages.dos = Prism.languages.powershell;\n    Prism.languages.gremlin = Prism.languages.groovy;\n\n    let languages = {\n      'r': 'R', 'python': 'Python', 'xml': 'XML', 'html': 'HTML',\n      'yaml': 'YAML', 'latex': 'LaTeX', 'tex': 'TeX',\n      'powershell': 'PowerShell', 'javascript': 'JavaScript',\n      'dos': 'DOS', 'qml': 'QML', 'json': 'JSON', 'bash': 'Bash',\n      'text': 'Text', 'txt': 'Text', 'sparql': 'SPARQL',\n      'gremlin': 'Gremlin', 'cypher': 'Cypher', 'ngql': 'nGQL',\n      'shell': 'Shell', 'sql': 'SQL', 'apacheconf': 'Apache Configuration', 'c': 'C', 'css': 'CSS'\n    };\n\n    Prism.hooks.add('before-highlight', function(env) {\n      if (env.language !== 'plain') {\n        let language = languages[env.language] || env.language;\n        env.element.setAttribute('data-language', language);\n      }\n    });\n\n    \n    let ClipboardJS = window.ClipboardJS || undefined;\n\n    Prism.plugins.toolbar.registerButton('copy-to-clipboard', function(env) {\n      let linkCopy = document.createElement('button');\n      linkCopy.classList.add('prism-button-copy');\n\n      registerClipboard();\n\n      return linkCopy;\n\n      function registerClipboard() {\n        let clip = new ClipboardJS(linkCopy, {\n          'text': function () {\n            return env.code;\n          }\n        });\n\n        clip.on('success', function() {\n          linkCopy.classList.add('prism-button-copy-success');\n          resetText();\n        });\n        clip.on('error', function () {\n          linkCopy.classList.add('prism-button-copy-error');\n          resetText();\n        });\n      }\n\n      function resetText() {\n        setTimeout(function () {\n          linkCopy.classList.remove('prism-button-copy-success');\n          linkCopy.classList.remove('prism-button-copy-error');\n        }, 1600);\n      }\n    });\n  })();\n\u003c/script\u003e\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003cscript async=\"\" src=\"/js/center-img.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/right-quote.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/external-link.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/alt-title.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/figure.js\"\u003e\u003c/script\u003e\n\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js\"\u003e\u003c/script\u003e\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/vanilla-back-to-top@latest/dist/vanilla-back-to-top.min.js\"\u003e\u003c/script\u003e\n\u003cscript\u003e\naddBackToTop({\n  diameter: 48\n});\n\u003c/script\u003e\n\n  \u003chr/\u003e\n  \u003cdiv class=\"copyright no-border-bottom\"\u003e\n    \u003cdiv class=\"copyright-author-year\"\u003e\n      \u003cspan\u003eCopyright © 2017-2024 \u003ca href=\"/\"\u003e范叶亮 | Leo Van\u003c/a\u003e\u003c/span\u003e\n    \u003c/div\u003e\n  \u003c/div\u003e\n  \u003c/footer\u003e\n  \u003c/article\u003e",
  "Date": "2017-12-11T00:00:00Z",
  "Author": "范叶亮"
}