{
  "Source": "leovan.me",
  "Title": "图嵌入 (Graph Embedding) 和图神经网络 (Graph Neural Network)",
  "Link": "https://leovan.me/cn/2020/04/graph-embedding-and-gnn/",
  "Content": "\u003carticle class=\"main\"\u003e\n    \u003cheader class=\"content-title\"\u003e\n    \n\u003ch1 class=\"title\"\u003e\n  \n  图嵌入 (Graph Embedding) 和图神经网络 (Graph Neural Network)\n  \n\u003c/h1\u003e\n\n\n\n\n\n\n\n\u003ch2 class=\"author-date\"\u003e范叶亮 / \n2020-04-11\u003c/h2\u003e\n\n\n\n\u003ch3 class=\"post-meta\"\u003e\n\n\n\u003cstrong\u003e分类: \u003c/strong\u003e\n\u003ca href=\"/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0\"\u003e深度学习\u003c/a\u003e, \u003ca href=\"/categories/%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0\"\u003e表示学习\u003c/a\u003e\n\n\n\n\n/\n\n\n\n\n\u003cstrong\u003e标签: \u003c/strong\u003e\n\u003cspan\u003e图嵌入\u003c/span\u003e, \u003cspan\u003e网络嵌入\u003c/span\u003e, \u003cspan\u003e图表示学习\u003c/span\u003e, \u003cspan\u003e网络表示学习\u003c/span\u003e, \u003cspan\u003eGraph Embedding\u003c/span\u003e, \u003cspan\u003eRandom Walk\u003c/span\u003e, \u003cspan\u003eDeepWalk\u003c/span\u003e, \u003cspan\u003enode2vec\u003c/span\u003e, \u003cspan\u003eAPP\u003c/span\u003e, \u003cspan\u003eMatrix Fractorization\u003c/span\u003e, \u003cspan\u003eGraRep\u003c/span\u003e, \u003cspan\u003eHOPE\u003c/span\u003e, \u003cspan\u003eMeta Paths\u003c/span\u003e, \u003cspan\u003emetapath2vec\u003c/span\u003e, \u003cspan\u003eHIN2Vec\u003c/span\u003e, \u003cspan\u003eSDNE\u003c/span\u003e, \u003cspan\u003eDNGR\u003c/span\u003e, \u003cspan\u003eLINE\u003c/span\u003e, \u003cspan\u003e图神经网络\u003c/span\u003e, \u003cspan\u003eGraph Neural Networks\u003c/span\u003e, \u003cspan\u003eGNN\u003c/span\u003e, \u003cspan\u003eGraph Convolutional Networks\u003c/span\u003e, \u003cspan\u003eGCN\u003c/span\u003e, \u003cspan\u003eChebNet\u003c/span\u003e, \u003cspan\u003eDCNN\u003c/span\u003e, \u003cspan\u003eGraphSAGE\u003c/span\u003e, \u003cspan\u003eGraph Recurrent Networks\u003c/span\u003e, \u003cspan\u003eGGNN\u003c/span\u003e, \u003cspan\u003eTree LSTM\u003c/span\u003e, \u003cspan\u003eGraph LSTM\u003c/span\u003e, \u003cspan\u003eGraph Attention Networks\u003c/span\u003e, \u003cspan\u003eGAT\u003c/span\u003e\n\n\n\n\n/\n\n\n\u003cstrong\u003e字数: \u003c/strong\u003e\n10740\n\u003c/h3\u003e\n\n\n\n\u003chr/\u003e\n\n\n\n    \n    \n    \u003cins class=\"adsbygoogle\" style=\"display:block; text-align:center;\" data-ad-layout=\"in-article\" data-ad-format=\"fluid\" data-ad-client=\"ca-pub-2608165017777396\" data-ad-slot=\"1261604535\"\u003e\u003c/ins\u003e\n    \u003cscript\u003e\n    (adsbygoogle = window.adsbygoogle || []).push({});\n    \u003c/script\u003e\n    \n    \n    \u003c/header\u003e\n\n\n\n\u003cdiv class=\"toc-depth-2\"\u003e\u003cnav id=\"TableOfContents\"\u003e\n  \u003cul\u003e\n    \u003cli\u003e\u003ca href=\"#图嵌入\"\u003e图嵌入\u003c/a\u003e\n      \u003cul\u003e\n        \u003cli\u003e\u003ca href=\"#random-walk\"\u003eRandom Walk\u003c/a\u003e\n          \u003cul\u003e\n            \u003cli\u003e\u003ca href=\"#deepwalk\"\u003eDeepWalk\u003c/a\u003e\u003c/li\u003e\n            \u003cli\u003e\u003ca href=\"#node2vec\"\u003enode2vec\u003c/a\u003e\u003c/li\u003e\n            \u003cli\u003e\u003ca href=\"#app\"\u003eAPP\u003c/a\u003e\u003c/li\u003e\n          \u003c/ul\u003e\n        \u003c/li\u003e\n        \u003cli\u003e\u003ca href=\"#matrix-fractorization\"\u003eMatrix Fractorization\u003c/a\u003e\n          \u003cul\u003e\n            \u003cli\u003e\u003ca href=\"#grarep\"\u003eGraRep\u003c/a\u003e\u003c/li\u003e\n            \u003cli\u003e\u003ca href=\"#hope\"\u003eHOPE\u003c/a\u003e\u003c/li\u003e\n          \u003c/ul\u003e\n        \u003c/li\u003e\n        \u003cli\u003e\u003ca href=\"#meta-paths\"\u003eMeta Paths\u003c/a\u003e\n          \u003cul\u003e\n            \u003cli\u003e\u003ca href=\"#metapath2vec\"\u003emetapath2vec\u003c/a\u003e\u003c/li\u003e\n            \u003cli\u003e\u003ca href=\"#hin2vec\"\u003eHIN2Vec\u003c/a\u003e\u003c/li\u003e\n          \u003c/ul\u003e\n        \u003c/li\u003e\n        \u003cli\u003e\u003ca href=\"#deep-learning\"\u003eDeep Learning\u003c/a\u003e\n          \u003cul\u003e\n            \u003cli\u003e\u003ca href=\"#sdne\"\u003eSDNE\u003c/a\u003e\u003c/li\u003e\n            \u003cli\u003e\u003ca href=\"#dngr\"\u003eDNGR\u003c/a\u003e\u003c/li\u003e\n          \u003c/ul\u003e\n        \u003c/li\u003e\n        \u003cli\u003e\u003ca href=\"#others\"\u003eOthers\u003c/a\u003e\n          \u003cul\u003e\n            \u003cli\u003e\u003ca href=\"#line\"\u003eLINE\u003c/a\u003e\u003c/li\u003e\n          \u003c/ul\u003e\n        \u003c/li\u003e\n      \u003c/ul\u003e\n    \u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#图神经网络\"\u003e图神经网络\u003c/a\u003e\n      \u003cul\u003e\n        \u003cli\u003e\u003ca href=\"#graph-neural-networks\"\u003eGraph Neural Networks\u003c/a\u003e\u003c/li\u003e\n        \u003cli\u003e\u003ca href=\"#graph-convolutional-networks\"\u003eGraph Convolutional Networks\u003c/a\u003e\n          \u003cul\u003e\n            \u003cli\u003e\u003ca href=\"#基于频谱的方法-spectral-methods\"\u003e基于频谱的方法（Spectral Methods）\u003c/a\u003e\u003c/li\u003e\n            \u003cli\u003e\u003ca href=\"#基于空间的方法-spatial-methods\"\u003e基于空间的方法（Spatial Methods）\u003c/a\u003e\u003c/li\u003e\n          \u003c/ul\u003e\n        \u003c/li\u003e\n        \u003cli\u003e\u003ca href=\"#graph-recurrent-networks\"\u003eGraph Recurrent Networks\u003c/a\u003e\u003c/li\u003e\n        \u003cli\u003e\u003ca href=\"#graph-attention-networks\"\u003eGraph Attention Networks\u003c/a\u003e\u003c/li\u003e\n        \u003cli\u003e\u003ca href=\"#应用\"\u003e应用\u003c/a\u003e\u003c/li\u003e\n      \u003c/ul\u003e\n    \u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#开放资源\"\u003e开放资源\u003c/a\u003e\n      \u003cul\u003e\n        \u003cli\u003e\u003ca href=\"#开源实现\"\u003e开源实现\u003c/a\u003e\u003c/li\u003e\n        \u003cli\u003e\u003ca href=\"#论文列表和评测\"\u003e论文列表和评测\u003c/a\u003e\u003c/li\u003e\n      \u003c/ul\u003e\n    \u003c/li\u003e\n  \u003c/ul\u003e\n\u003c/nav\u003e\u003c/div\u003e\n\n\n\u003cp\u003e图（Graph / Network）数据类型可以自然地表达物体和物体之间的联系，在我们的日常生活与工作中无处不在。例如：微信和新浪微博等构成了人与人之间的社交网络；互联网上成千上万个页面构成了网页链接网络；国家城市间的运输交通构成了物流网络。\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/graph.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \u003cfigcaption class=\"kai\"\u003e图片来源：\u003ca href=\"https://www.allthingsdistributed.com/2019/12/power-of-relationships.html\"\u003eThe power of relationships in data\u003c/a\u003e\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003cp\u003e通常定义一个图 \u003ccode\u003e$G = \\left(V, E\\right)$\u003c/code\u003e，其中 \u003ccode\u003e$V$\u003c/code\u003e 为\u003cstrong\u003e顶点（Vertices）\u003cstrong\u003e集合，\u003ccode\u003e$E$\u003c/code\u003e 为\u003c/strong\u003e边（Edges）\u003cstrong\u003e集合。对于一条边 \u003ccode\u003e$e = u, v$\u003c/code\u003e 包含两个\u003c/strong\u003e端点（Endpoints）\u003c/strong\u003e \u003ccode\u003e$u$\u003c/code\u003e 和 \u003ccode\u003e$v$\u003c/code\u003e，同时 \u003ccode\u003e$u$\u003c/code\u003e 可以称为 \u003ccode\u003e$v$\u003c/code\u003e 的\u003cstrong\u003e邻居（Neighbor）\u003c/strong\u003e。当所有的边为有向边时，图称之为\u003cstrong\u003e有向（Directed）\u003cstrong\u003e图，当所有边为无向边时，图称之为\u003c/strong\u003e无向（Undirected）\u003cstrong\u003e图。对于一个顶点 \u003ccode\u003e$v$\u003c/code\u003e，令 \u003ccode\u003e$d \\left(v\\right)$\u003c/code\u003e 表示连接的边的数量，称之为\u003c/strong\u003e度（Degree）\u003c/strong\u003e。对于一个图 \u003ccode\u003e$G = \\left(V, E\\right)$\u003c/code\u003e，其\u003cstrong\u003e邻接矩阵（Adjacency Matrix）\u003c/strong\u003e \u003ccode\u003e$A \\in \\mathbb{A}^{|V| \\times |V|}$\u003c/code\u003e 定义为：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ A_{i j}=\\left\\{\\begin{array}{ll} 1 \u0026amp; \\text { if }\\left\\{v_{i}, v_{j}\\right\\} \\in E \\text { and } i \\neq j \\\\ 0 \u0026amp; \\text { otherwise } \\end{array}\\right. $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e作为一个典型的非欧式数据，对于图数据的分析主要集中在节点分类，链接预测和聚类等。对于图数据而言，**图嵌入（Graph / Network Embedding）\u003cstrong\u003e和\u003c/strong\u003e图神经网络（Graph Neural Networks, GNN）**是两个类似的研究领域。图嵌入旨在将图的节点表示成一个低维向量空间，同时保留网络的拓扑结构和节点信息，以便在后续的图分析任务中可以直接使用现有的机器学习算法。一些基于深度学习的图嵌入同时也属于图神经网络，例如一些基于图自编码器和利用无监督学习的图卷积神经网络等。下图描述了图嵌入和图神经网络之间的差异：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/graph-embedding-vs-graph-neural-networks.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003clink rel=\"stylesheet\" href=\"/css/admonition.css\"/\u003e\n\u003cdiv class=\"admonition admonition-warn  kai\"\u003e\n  \u003cdiv class=\"admonition-content\"\u003e本文中\u003cstrong\u003e图嵌入\u003c/strong\u003e和\u003cstrong\u003e网络表示学习\u003c/strong\u003e均表示 Graph / Network Embedding。\u003c/div\u003e\n\u003c/div\u003e\n\u003ch1 id=\"图嵌入\"\u003e图嵌入\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e本节内容主要参考自：\u003cbr/\u003e\nA Comprehensive Survey of Graph Embedding: Problems, Techniques and Applications \u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e\u003cbr/\u003e\nGraph Embedding Techniques, Applications, and Performance: A Survey \u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e\u003cbr/\u003e\nRepresentation Learning on Graphs: Methods and Applications \u003csup id=\"fnref:3\"\u003e\u003ca href=\"#fn:3\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e3\u003c/a\u003e\u003c/sup\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e使用邻接矩阵的网络表示存在计算效率的问题，邻接矩阵 \u003ccode\u003e$A$\u003c/code\u003e 使用 \u003ccode\u003e$|V| \\times |V|$\u003c/code\u003e 的存储空间表示一个图，随着节点个数的增长，这种表示所需的空间成指数增长。同时，在邻接矩阵中绝大多数是 0，数据的稀疏性使得快速有效的学习方式很难被应用。\u003c/p\u003e\n\u003cp\u003e网路表示学习是指学习得到网络中节点的低维向量表示，形式化地，网络表示学习的目标是对每个节点 \u003ccode\u003e$v \\in V$\u003c/code\u003e 学习一个实值向量 \u003ccode\u003e$R_v \\in \\mathbb{R}^k$\u003c/code\u003e，其中 \u003ccode\u003e$k \\ll |V|$\u003c/code\u003e 表示向量的维度。经典的 Zachary’s karate club 网络的嵌入可视化如下图所示：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/karate-graph-embedding.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003ch2 id=\"random-walk\"\u003eRandom Walk\u003c/h2\u003e\n\u003cp\u003e基于随机游走的图嵌入通过使得图上一个短距的随机游走中共现的节点具有更相似的表示的方式来优化节点的嵌入。\u003c/p\u003e\n\u003ch3 id=\"deepwalk\"\u003eDeepWalk\u003c/h3\u003e\n\u003cp\u003eDeepWalk \u003csup id=\"fnref:4\"\u003e\u003ca href=\"#fn:4\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e4\u003c/a\u003e\u003c/sup\u003e 算法主要包含两个部分：一个随机游走序列生成器和一个更新过程。随机游走序列生成器首先在图 \u003ccode\u003e$G$\u003c/code\u003e 中均匀地随机抽样一个随机游走 \u003ccode\u003e$\\mathcal{W}_{v_i}$\u003c/code\u003e 的根节点 \u003ccode\u003e$v_i$\u003c/code\u003e，接着从节点的邻居中均匀地随机抽样一个节点直到达到设定的最大长度 \u003ccode\u003e$t$\u003c/code\u003e。对于一个生成的以 \u003ccode\u003e$v_i$\u003c/code\u003e 为中心左右窗口为 \u003ccode\u003e$w$\u003c/code\u003e 的随机游走序列 \u003ccode\u003e$v_{i-w}, \\dotsc, v_{i-1}, v_i, v_{i+1}, \\dotsc, v_{i+m}$\u003c/code\u003e，DeepWalk 利用 SkipGram 算法通过最大化以 \u003ccode\u003e$v_i$\u003c/code\u003e 为中心，左右 \u003ccode\u003e$w$\u003c/code\u003e 为窗口的同其他节点共现概率来优化模型：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\text{Pr} \\left(\\left\\{v_{i-w}, \\dotsc, v_{i+w}\\right\\} \\setminus v_i \\mid \\Phi \\left(v_i\\right)\\right) = \\prod_{j=i-w, j \\neq i}^{i+w} \\text{Pr} \\left(v_j \\mid \\Phi \\left(v_i\\right)\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eDeepWalk 和 Word2Vec 的类比如下表所示：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e模型\u003c/th\u003e\n\u003cth\u003e目标\u003c/th\u003e\n\u003cth\u003e输入\u003c/th\u003e\n\u003cth\u003e输出\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eWord2Vec\u003c/td\u003e\n\u003ctd\u003e词\u003c/td\u003e\n\u003ctd\u003e句子\u003c/td\u003e\n\u003ctd\u003e词嵌入\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eDeepWalk\u003c/td\u003e\n\u003ctd\u003e节点\u003c/td\u003e\n\u003ctd\u003e节点序列\u003c/td\u003e\n\u003ctd\u003e节点嵌入\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"node2vec\"\u003enode2vec\u003c/h3\u003e\n\u003cp\u003enode2vec \u003csup id=\"fnref:5\"\u003e\u003ca href=\"#fn:5\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e5\u003c/a\u003e\u003c/sup\u003e 通过改变随机游走序列生成的方式进一步扩展了 DeepWalk 算法。DeepWalk 选取随机游走序列中下一个节点的方式是均匀随机分布的，而 node2vec 通过引入两个参数 \u003ccode\u003e$p$\u003c/code\u003e 和 \u003ccode\u003e$q$\u003c/code\u003e，将\u003cstrong\u003e宽度优先搜索\u003c/strong\u003e和\u003cstrong\u003e深度优先搜索\u003c/strong\u003e引入了随机游走序列的生成过程。 宽度优先搜索注重邻近的节点并刻画了相对局部的一种网络表示， 宽度优先中的节点一般会出现很多次，从而降低刻画中心节点的邻居节点的方差， 深度优先搜索反映了更高层面上的节点之间的同质性。\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/node2vec.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003enode2vec 中的两个参数 \u003ccode\u003e$p$\u003c/code\u003e 和 \u003ccode\u003e$q$\u003c/code\u003e 控制随机游走序列的跳转概率。假设上一步游走的边为 \u003ccode\u003e$\\left(t, v\\right)$\u003c/code\u003e， 那么对于节点 \u003ccode\u003e$v$\u003c/code\u003e 的不同邻居，node2vec 根据 \u003ccode\u003e$p$\u003c/code\u003e 和 \u003ccode\u003e$q$\u003c/code\u003e 定义了不同的邻居的跳转概率，\u003ccode\u003e$p$\u003c/code\u003e 控制跳向上一个节点的邻居的概率，\u003ccode\u003e$q$\u003c/code\u003e 控制跳向上一个节点的非邻居的概率，具体的未归一的跳转概率值 \u003ccode\u003e$\\pi_{vx} = \\alpha_{pq} \\left(t, x\\right)$\u003c/code\u003e 如下所示：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\alpha_{p q}(t, x)=\\left\\{\\begin{array}{cl} \\dfrac{1}{p}, \u0026amp; \\text { if } d_{t x}=0 \\\\ 1, \u0026amp; \\text { if } d_{t x}=1 \\\\ \\dfrac{1}{q}, \u0026amp; \\text { if } d_{t x}=2 \\end{array}\\right. $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$d_{tx}$\u003c/code\u003e 表示节点 \u003ccode\u003e$t$\u003c/code\u003e 和 \u003ccode\u003e$x$\u003c/code\u003e 之间的最短距离。为了获得最优的超参数 \u003ccode\u003e$p$\u003c/code\u003e 和 \u003ccode\u003e$q$\u003c/code\u003e 的取值，node2vec 通过半监督形式，利用网格搜索最合适的参数学习节点表示。\u003c/p\u003e\n\u003ch3 id=\"app\"\u003eAPP\u003c/h3\u003e\n\u003cp\u003e之前的基于随机游走的图嵌入方法，例如：DeepWalk，node2vec 等，都无法保留图中的非对称信息。然而非对称性在很多问题，例如：社交网络中的链路预测、电商中的推荐等，中至关重要。在有向图和无向图中，非对称性如下图所示：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/asymmetric-proximity.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e为了保留图的非对称性，对于每个节点 \u003ccode\u003e$v$\u003c/code\u003e 设置两个不同的角色：源和目标，分别用 \u003ccode\u003e$\\overrightarrow{s_{v}}$\u003c/code\u003e 和 \u003ccode\u003e$\\overrightarrow{t_{v}}$\u003c/code\u003e 表示。对于每个从 \u003ccode\u003e$u$\u003c/code\u003e 开始以 \u003ccode\u003e$v$\u003c/code\u003e 结尾的采样序列，利用 \u003ccode\u003e$(u, v)$\u003c/code\u003e 表示采样的节点对。则利用源节点 \u003ccode\u003e$u$\u003c/code\u003e 预测目标节点 \u003ccode\u003e$v$\u003c/code\u003e 的概率如下：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ p(v | u)=\\frac{\\exp (\\overrightarrow{s_{u}} \\cdot \\overrightarrow{t_{v}})}{\\sum_{n \\in V} \\exp (\\overrightarrow{s_{u}} \\cdot \\overrightarrow{t_{n}})} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e通过 Skip-Gram 和负采样对模型进行优化，损失函数如下：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{aligned} \\ell \u0026amp;= \\log \\sigma(\\overrightarrow{s_{u}} \\cdot \\overrightarrow{t_{v}})+k \\cdot E_{t_{n} \\sim P_{D}}[\\log \\sigma(-\\overrightarrow{s_{u}} \\cdot \\overrightarrow{t_{n}})] \\\\ \u0026amp;= \\sum_{u} \\sum_{v} \\# \\text {Sampled}_{u}(v) \\cdot \\left(\\log \\sigma(\\overrightarrow{s_{u}} \\cdot \\overrightarrow{t_{v}}) + k \\cdot E_{t_{n} \\sim P_{D}}[\\log \\sigma(-\\overrightarrow{s_{u}} \\cdot \\overrightarrow{t_{n}})]\\right) \\end{aligned} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，我们根据分布 \u003ccode\u003e$P_D \\left(n\\right) \\sim \\dfrac{1}{|V|}$\u003c/code\u003e 随机负采样 \u003ccode\u003e$k$\u003c/code\u003e 个节点对，\u003ccode\u003e$\\# \\text{Sampled}_{u}(v)$\u003c/code\u003e 为采样的 \u003ccode\u003e$\\left(u, v\\right)$\u003c/code\u003e 对的个数，\u003ccode\u003e$\\sigma$\u003c/code\u003e 为 sigmoid 函数。通常情况下，\u003ccode\u003e$\\# \\text{Sampled}_{u}(v) \\neq \\# \\text{Sampled}_{v}(u)$\u003c/code\u003e，即 \u003ccode\u003e$\\left(u, v\\right)$\u003c/code\u003e 和 \u003ccode\u003e$\\left(v, u\\right)$\u003c/code\u003e 的观测数量是不同的。模型利用 Monte-Carlo End-Point 采样方法 \u003csup id=\"fnref:6\"\u003e\u003ca href=\"#fn:6\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e6\u003c/a\u003e\u003c/sup\u003e 随机的以 \u003ccode\u003e$v$\u003c/code\u003e 为起点和 \u003ccode\u003e$\\alpha$\u003c/code\u003e 为停止概率采样 \u003ccode\u003e$p$\u003c/code\u003e 条路径。这种采样方式可以用于估计任意一个节点对之间的 Rooted PageRank \u003csup id=\"fnref:7\"\u003e\u003ca href=\"#fn:7\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e7\u003c/a\u003e\u003c/sup\u003e 值，模型利用这个值估计由 \u003ccode\u003e$v$\u003c/code\u003e 到达 \u003ccode\u003e$u$\u003c/code\u003e 的概率。\u003c/p\u003e\n\u003ch2 id=\"matrix-fractorization\"\u003eMatrix Fractorization\u003c/h2\u003e\n\u003ch3 id=\"grarep\"\u003eGraRep\u003c/h3\u003e\n\u003cp\u003eGraRep \u003csup id=\"fnref:8\"\u003e\u003ca href=\"#fn:8\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e8\u003c/a\u003e\u003c/sup\u003e 提出了一种基于矩阵分解的图嵌入方法。对于一个图 \u003ccode\u003e$G$\u003c/code\u003e，利用邻接矩阵 \u003ccode\u003e$S$\u003c/code\u003e 定义图的度矩阵：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ D_{i j}=\\left\\{\\begin{array}{ll} \\sum_{p} S_{i p}, \u0026amp; \\text { if } i=j \\\\ 0, \u0026amp; \\text { if } i \\neq j \\end{array}\\right. $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e则一阶转移概率矩阵定义如下：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ A = D^{-1} S $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$A_{i, j}$\u003c/code\u003e 表示通过一步由 \u003ccode\u003e$v_i$\u003c/code\u003e 转移到 \u003ccode\u003e$v_j$\u003c/code\u003e 的概率。所谓的全局特征包含两个部分：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e捕获两个节点之间的长距离特征\u003c/li\u003e\n\u003cli\u003e分别考虑按照不同转移步数的连接\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e下图展示了 \u003ccode\u003e$k = 1, 2, 3, 4$\u003c/code\u003e 情况下的强（上）弱（下）关系：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/grarep.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e利用 Skip-Gram 和 NCE（noise contrastive estimation）方法，对于一个 \u003ccode\u003e$k$\u003c/code\u003e 阶转移，可以将模型归结到一个矩阵 \u003ccode\u003e$Y_{i, j}^k$\u003c/code\u003e 的分解问题：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ Y_{i, j}^{k}=W_{i}^{k} \\cdot C_{j}^{k}=\\log \\left(\\frac{A_{i, j}^{k}}{\\sum_{t} A_{t, j}^{k}}\\right)-\\log (\\beta) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$W$\u003c/code\u003e 和 \u003ccode\u003e$C$\u003c/code\u003e 的每一行分别为节点 \u003ccode\u003e$w$\u003c/code\u003e 和 \u003ccode\u003e$c$\u003c/code\u003e 的表示，\u003ccode\u003e$\\beta = \\lambda / N$\u003c/code\u003e，\u003ccode\u003e$\\lambda$\u003c/code\u003e 为负采样的数量，\u003ccode\u003e$N$\u003c/code\u003e 为图中边的个数。\u003c/p\u003e\n\u003cp\u003e之后为了减少噪音，模型将 \u003ccode\u003e$Y^k$\u003c/code\u003e 中所有的负值替换为 0，通过 SVD（方法详情见参见\u003ca href=\"/cn/2017/12/evd-svd-and-pca/\"\u003e之前博客\u003c/a\u003e）得到节点的 \u003ccode\u003e$d$\u003c/code\u003e 维表示：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{aligned} X_{i, j}^{k} \u0026amp;= \\max \\left(Y_{i, j}^{k}, 0\\right) \\\\ X^{k} \u0026amp;= U^{k} \\Sigma^{k}\\left(V^{k}\\right)^{T} \\\\ X^{k} \\approx X_{d}^{k} \u0026amp;= U_{d}^{k} \\Sigma_{d}^{k}\\left(V_{d}^{k}\\right)^{T} \\\\ X^{k} \\approx X_{d}^{k} \u0026amp;= W^{k} C^{k} \\\\ W^{k} \u0026amp;= U_{d}^{k}\\left(\\Sigma_{d}^{k}\\right)^{\\frac{1}{2}} \\\\ C^{k} \u0026amp;= \\left(\\Sigma_{d}^{k}\\right)^{\\frac{1}{2}} V_{d}^{k T} \\end{aligned} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e最终，通过对不同 \u003ccode\u003e$k$\u003c/code\u003e 的表示进行拼接得到节点最终的表示。\u003c/p\u003e\n\u003ch3 id=\"hope\"\u003eHOPE\u003c/h3\u003e\n\u003cp\u003eHOPE \u003csup id=\"fnref:9\"\u003e\u003ca href=\"#fn:9\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e9\u003c/a\u003e\u003c/sup\u003e 对于每个节点最终生成两个嵌入表示：一个是作为源节点的嵌入表示，另一个是作为目标节点的嵌入表示。模型通过近似高阶相似性来保留非对称传递性，其优化目标为：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\min \\left\\|\\mathbf{S}-\\mathbf{U}^{s} \\cdot \\mathbf{U}^{t^{\\top}}\\right\\|_{F}^{2} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$\\mathbf{S}$\u003c/code\u003e 为相似矩阵，\u003ccode\u003e$\\mathbf{U}^s$\u003c/code\u003e 和 \u003ccode\u003e$\\mathbf{U}^t$\u003c/code\u003e 分别为源节点和目标节点的向量表示。下图展示了嵌入向量可以很好的保留非对称传递性：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/hope.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e对于 \u003ccode\u003e$\\mathbf{S}$\u003c/code\u003e 有多种可选近似度量方法：Katz Index，Rooted PageRank（RPR），Common Neighbors（CN），Adamic-Adar（AA）。这些度量方法可以分为两类：全局近似（Katz Index 和 RPR）和局部近似（CN 和 AA）。\u003c/p\u003e\n\u003cp\u003e算法采用了一个广义 SVD 算法（JDGSVD）来解决使用原始 SVD 算法计算复杂度为\u003ccode\u003e$O \\left(N^3\\right)$\u003c/code\u003e 过高的问题，从而使得算法可以应用在更大规模的图上。\u003c/p\u003e\n\u003ch2 id=\"meta-paths\"\u003eMeta Paths\u003c/h2\u003e\n\u003ch3 id=\"metapath2vec\"\u003emetapath2vec\u003c/h3\u003e\n\u003cp\u003emetapath2vec \u003csup id=\"fnref:10\"\u003e\u003ca href=\"#fn:10\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e10\u003c/a\u003e\u003c/sup\u003e 提出了一种基于元路径的异构网络表示学习方法。在此我们引入 3 个定义：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e**异构网络（(Heterogeneous information network，HIN）**可以定义为一个有向图 \u003ccode\u003e$G = \\left(V, E\\right)$\u003c/code\u003e，一个节点类型映射 \u003ccode\u003e$\\tau: V \\to A$\u003c/code\u003e 和一个边类型映射 \u003ccode\u003e$\\phi: E \\to R$\u003c/code\u003e，其中对于 \u003ccode\u003e$v \\in V$\u003c/code\u003e 有 \u003ccode\u003e$\\tau \\left(v\\right) \\in A$\u003c/code\u003e，\u003ccode\u003e$e \\in E$\u003c/code\u003e 有 \u003ccode\u003e$\\phi \\left(e\\right) \\in R$\u003c/code\u003e，且 \u003ccode\u003e$|A| + |R| \u0026gt; 1$\u003c/code\u003e。\u003c/li\u003e\n\u003cli\u003e**网络模式（Network schema）**定义为 \u003ccode\u003e$T_G = \\left(A, R\\right)$\u003c/code\u003e，为一个包含节点类型映射 \u003ccode\u003e$\\tau \\left(v\\right) \\in A$\u003c/code\u003e 和边映射 \u003ccode\u003e$\\phi \\left(e\\right) \\in R$\u003c/code\u003e 异构网络的 \u003ccode\u003e$G = \\left(V, E\\right)$\u003c/code\u003e 的元模板。\u003c/li\u003e\n\u003cli\u003e**元路径（Meta-path）**定义为网络模式 \u003ccode\u003e$T_G = \\left(A, R\\right)$\u003c/code\u003e 上的一条路径 \u003ccode\u003e$P$\u003c/code\u003e，形式为 \u003ccode\u003e$A_{1} \\stackrel{R_{1}}{\\longrightarrow} A_{2} \\stackrel{R_{2}}{\\longrightarrow} \\cdots \\stackrel{R_{l}}{\\longrightarrow} A_{l+1}$\u003c/code\u003e。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e下图展示了一个学术网络和部分元路径：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/metapaths.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e其中，APA 表示一篇论文的共同作者，APVPA 表示两个作者在同一个地方发表过论文。\u003c/p\u003e\n\u003cp\u003emetapath2vec 采用了基于元路径的随机游走来生成采样序列，这样就可以保留原始网络中的语义信息。对于一个给定的元路径模板 \u003ccode\u003e$P: A_{1} \\stackrel{R_{1}}{\\longrightarrow} A_{2} \\stackrel{R_{2}}{\\longrightarrow} \\cdots A_{t} \\stackrel{R_{t}}{\\longrightarrow} A_{t+1} \\cdots \\stackrel{R_{l}}{\\longrightarrow} A_{l}$\u003c/code\u003e，第 \u003ccode\u003e$i$\u003c/code\u003e 步的转移概率为：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ p\\left(v^{i+1} | v_{t}^{i}, P\\right)=\\left\\{\\begin{array}{ll} \\dfrac{1}{\\left|N_{t+1}\\left(v_{t}^{i}\\right)\\right|} \u0026amp; \\left(v_{t}^{i}, v^{i+1}\\right) \\in E, \\phi\\left(v^{i+1}\\right)=A_{t+1} \\\\ 0 \u0026amp; \\left(v_{t}^{i}, v^{i+1}\\right) \\in E, \\phi\\left(v^{i+1}\\right) \\neq A_{t+1} \\\\ 0 \u0026amp; \\left(v_{t}^{i}, v^{i+1}\\right) \\notin E \\end{array}\\right. $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$v^i_t \\in A_t$\u003c/code\u003e，\u003ccode\u003e$N_{t+1} \\left(v^i_t\\right)$\u003c/code\u003e 表示节点 \u003ccode\u003e$v^i_t$\u003c/code\u003e 类型为 \u003ccode\u003e$A_{t+1}$\u003c/code\u003e 的邻居。之后，则采用了类似 DeepWalk 的方式进行训练得到节点表示。\u003c/p\u003e\n\u003ch3 id=\"hin2vec\"\u003eHIN2Vec\u003c/h3\u003e\n\u003cp\u003eHIN2Vec \u003csup id=\"fnref:11\"\u003e\u003ca href=\"#fn:11\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e11\u003c/a\u003e\u003c/sup\u003e 提出了一种利用多任务学习通过多种关系进行节点和元路径表示学习的方法。模型最初是希望通过一个多分类模型来预测任意两个节点之间所有可能的关系。假设对于任意两个节点，所有可能的关系集合为 \u003ccode\u003e$R = \\{\\text{P-P, P-A, A-P, P-P-P, P-P-A, P-A-P, A-P-P, A-P-A}\\}$\u003c/code\u003e。假设一个实例 \u003ccode\u003e$P_1$\u003c/code\u003e 和 \u003ccode\u003e$A_1$\u003c/code\u003e 包含两种关系：\u003ccode\u003e$\\text{P-A}$\u003c/code\u003e 和 \u003ccode\u003e$\\text{P-P-A}$\u003c/code\u003e，则对应的训练数据为 \u003ccode\u003e$\\langle x: P_1, y: A_1, output: \\left[0, 1, 0, 0, 1, 0, 0, 0\\right] \\rangle$\u003c/code\u003e。\u003c/p\u003e\n\u003cp\u003e但实际上，扫描整个网络寻找所有可能的关系是不现实的，因此 HIN2Vec 将问题简化为一个给定两个节点判断之间是否存在一个关系的二分类问题，如下图所示：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/hin2vec.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e模型的三个输入分别为节点 \u003ccode\u003e$x$\u003c/code\u003e 和 \u003ccode\u003e$y$\u003c/code\u003e，以及关系 \u003ccode\u003e$r$\u003c/code\u003e。在隐含层输入被转换为向量 \u003ccode\u003e$W_{X}^{\\prime} \\vec{x}, W_{Y}^{\\prime} \\vec{y}$\u003c/code\u003e 和 \u003ccode\u003e$f_{01}\\left(W_{R}^{\\prime} \\vec{r}\\right)$\u003c/code\u003e。需要注意对于关系 \u003ccode\u003e$r$\u003c/code\u003e，模型应用了一个正则化函数 \u003ccode\u003e$f_{01} \\left(\\cdot\\right)$\u003c/code\u003e 使得 \u003ccode\u003e$r$\u003c/code\u003e 的向量介于 \u003ccode\u003e$0$\u003c/code\u003e 和 \u003ccode\u003e$1$\u003c/code\u003e 之间。之后采用逐元素相乘对三个向量进行汇总 \u003ccode\u003e$W_{X}^{\\prime} \\vec{x} \\odot W_{Y}^{\\prime} \\vec{y} \\odot f_{01}\\left(W_{R}^{\\prime} \\vec{r}\\right)$\u003c/code\u003e。在最后的输出层，通过计算 \u003ccode\u003e$sigmoid \\left(\\sum W_{X}^{\\prime} \\vec{x} \\odot W_{Y}^{\\prime} \\vec{y} \\odot f_{01}\\left(W_{R}^{\\prime} \\vec{r}\\right)\\right)$\u003c/code\u003e 得到最终的预测值。\u003c/p\u003e\n\u003cp\u003e在生成训练数据时，HIN2Vec 采用了完全随机游走进行节点采样，而非 metapath2vec 中的按照给定的元路径的方式。通过随机替换 \u003ccode\u003e$x, y, r$\u003c/code\u003e 中的任何一个可以生成负样本，但当网络中的关系数量较少，节点数量远远大于关系数量时，这种方式很可能产生错误的负样本，因此 HIN2Vec 只随机替换 \u003ccode\u003e$x, y$\u003c/code\u003e，保持 \u003ccode\u003e$r$\u003c/code\u003e 不变。\u003c/p\u003e\n\u003ch2 id=\"deep-learning\"\u003eDeep Learning\u003c/h2\u003e\n\u003ch3 id=\"sdne\"\u003eSDNE\u003c/h3\u003e\n\u003cp\u003eSDNE \u003csup id=\"fnref:12\"\u003e\u003ca href=\"#fn:12\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e12\u003c/a\u003e\u003c/sup\u003e 提出了一种利用自编码器同时优化一阶和二阶相似度的图嵌入算法，学习得到的向量能够保留局部和全局的结构信息。SDNE 使用的网络结构如下图所示：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/sdne.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e对于二阶相似度，自编码器的目标是最小化输入和输出的重构误差。SDNE 采用邻接矩阵作为自编码器的输入，\u003ccode\u003e$\\mathbf{x}_i = \\mathbf{s}_i$\u003c/code\u003e，每个 \u003ccode\u003e$\\mathbf{s}_i$\u003c/code\u003e 包含了节点 \u003ccode\u003e$v_i$\u003c/code\u003e 的邻居结构信息。模型的损失函数如下：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\mathcal{L}=\\sum_{i=1}^{n}\\left\\|\\hat{\\mathbf{x}}_{i}-\\mathbf{x}_{i}\\right\\|_{2}^{2} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e由于网络的稀疏性，邻接矩阵中的非零元素远远少于零元素，因此模型采用了一个带权的损失函数：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{aligned} \\mathcal{L}_{2nd} \u0026amp;=\\sum_{i=1}^{n}\\left\\|\\left(\\hat{\\mathbf{x}}_{i}-\\mathbf{x}_{i}\\right) \\odot \\mathbf{b}_{i}\\right\\|_{2}^{2} \\\\ \u0026amp;=\\|(\\hat{X}-X) \\odot B\\|_{F}^{2} \\end{aligned} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$\\odot$\u003c/code\u003e 表示按位乘，\u003ccode\u003e$\\mathbf{b}_i = \\left\\{b_{i, j}\\right\\}_{j=1}^{n}$\u003c/code\u003e，如果 \u003ccode\u003e$s_{i, j} = 0$\u003c/code\u003e 则 \u003ccode\u003e$b_{i, j} = 1$\u003c/code\u003e 否则 \u003ccode\u003e$b_{i, j} = \\beta \u0026gt; 1$\u003c/code\u003e。\u003c/p\u003e\n\u003cp\u003e对于一阶相似度，模型利用了一个监督学习模块最小化节点在隐含空间中距离。损失函数如下：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{aligned} \\mathcal{L}_{1st} \u0026amp;=\\sum_{i, j=1}^{n} s_{i, j}\\left\\|\\mathbf{y}_{i}^{(K)}-\\mathbf{y}_{j}^{(K)}\\right\\|_{2}^{2} \\\\ \u0026amp;=\\sum_{i, j=1}^{n} s_{i, j}\\left\\|\\mathbf{y}_{i}-\\mathbf{y}_{j}\\right\\|_{2}^{2} \\end{aligned} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e最终，模型联合损失函数如下：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{aligned} \\mathcal{L}_{mix} \u0026amp;=\\mathcal{L}_{2nd}+\\alpha \\mathcal{L}_{1st}+\\nu \\mathcal{L}_{reg} \\\\ \u0026amp;=\\|(\\hat{X}-X) \\odot B\\|_{F}^{2}+\\alpha \\sum_{i, j=1}^{n} s_{i, j}\\left\\|\\mathbf{y}_{i}-\\mathbf{y}_{j}\\right\\|_{2}^{2}+\\nu \\mathcal{L}_{reg} \\end{aligned} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$\\mathcal{L}_{reg}$\u003c/code\u003e 为 L2 正则项。\u003c/p\u003e\n\u003ch3 id=\"dngr\"\u003eDNGR\u003c/h3\u003e\n\u003cp\u003eDNGR \u003csup id=\"fnref:13\"\u003e\u003ca href=\"#fn:13\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e13\u003c/a\u003e\u003c/sup\u003e 提出了一种利用基于 Stacked Denoising Autoencoder（SDAE）提取特征的网络表示学习算法。算法的流程如下图所示：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/dngr.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e模型首先利用 Random Surfing 得到一个概率共现（PCO）矩阵，之后利用其计算得到 PPMI 矩阵，最后利用 SDAE 进行特征提取得到节点的向量表示。\u003c/p\u003e\n\u003cp\u003e对于传统的将图结构转换为一个线性序列方法存在几点缺陷：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e采样序列边缘的节点的上下文信息很难被捕捉。\u003c/li\u003e\n\u003cli\u003e很难直接确定游走的长度和步数等超参数，尤其是对于大型网络来说。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e受 PageRank 思想影响，作者采用了 Random Surfing 模型。定义转移矩阵 \u003ccode\u003e$A$\u003c/code\u003e，引入行向量 \u003ccode\u003e$p_k$\u003c/code\u003e，第 \u003ccode\u003e$j$\u003c/code\u003e 个元素表示通过 \u003ccode\u003e$k$\u003c/code\u003e 步转移之后到达节点 \u003ccode\u003e$j$\u003c/code\u003e 的概率。\u003ccode\u003e$p_0$\u003c/code\u003e 为一个初始向量，其仅第 \u003ccode\u003e$i$\u003c/code\u003e 个元素为 1，其它均为 0。在考虑以 \u003ccode\u003e$1 - \\alpha$\u003c/code\u003e 的概率返回初始节点的情况下有：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ p_{k}=\\alpha \\cdot p_{k-1} A+(1-\\alpha) p_{0} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e在不考虑返回初始节点的情况下有：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ p_{k}^{*}=p_{k-1}^{*} A=p_{0} A^{k} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e直观而言，两个节点越近，两者的关系越亲密，因此通过同当前节点的相对距离来衡量上下文节点的重要性是合理的。基于此，第 \u003ccode\u003e$i$\u003c/code\u003e 个节点的表示可以用如下方式构造：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ r=\\sum_{k=1}^{K} w(k) \\cdot p_{k}^{*} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$w \\left(\\cdot\\right)$\u003c/code\u003e 是一个衰减函数。\u003c/p\u003e\n\u003cp\u003e利用 PCO 计算得到 PPMI 后，再利用一个 SDAE 进行特征提取。Stacking 策略可以通过不同的网络层学习得到不同层级的表示，Denoising 策略则通过去除数据中的噪声，增加结果的鲁棒性。同时，SNGR 相比基于 SVD 的方法效率更高。\u003c/p\u003e\n\u003ch2 id=\"others\"\u003eOthers\u003c/h2\u003e\n\u003ch3 id=\"line\"\u003eLINE\u003c/h3\u003e\n\u003cp\u003eLINE \u003csup id=\"fnref:14\"\u003e\u003ca href=\"#fn:14\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e14\u003c/a\u003e\u003c/sup\u003e 提出了一个用于大规模网络嵌入的方法，其满足如下 3 个要求：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e同时保留节点之间的一阶相似性（first-order proximity）和二阶相似性（second-order proximity）。\u003c/li\u003e\n\u003cli\u003e可以处理大规模网络，例如：百万级别的顶点和十亿级别的边。\u003c/li\u003e\n\u003cli\u003e可以处理有向，无向和带权的多种类型的图结构。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e给定一个无向边 \u003ccode\u003e$\\left(i, j\\right)$\u003c/code\u003e，点 \u003ccode\u003e$v_i$\u003c/code\u003e 和 \u003ccode\u003e$v_j$\u003c/code\u003e 的联合概率如下：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ p_{1}\\left(v_{i}, v_{j}\\right)=\\frac{1}{1+\\exp \\left(-\\vec{u}_{i}^{T} \\cdot \\vec{u}_{j}\\right)} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$\\vec{u}_{i} \\in R^{d}$\u003c/code\u003e 为节点 \u003ccode\u003e$v_i$\u003c/code\u003e 的低维向量表示。在空间 \u003ccode\u003e$V \\times V$\u003c/code\u003e 上，分布 \u003ccode\u003e$p \\left(\\cdot, \\cdot\\right)$\u003c/code\u003e 的经验概率为 \u003ccode\u003e$\\hat{p}_1 \\left(i, j\\right) = \\dfrac{w_{ij}}{V}$\u003c/code\u003e，其中 \u003ccode\u003e$W = \\sum_{\\left(i, j\\right) \\in E} w_{ij}$\u003c/code\u003e。通过最小化两个分布的 KL 散度来优化模型，则目标函数定义如下：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ O_{1}=-\\sum_{(i, j) \\in E} w_{i j} \\log p_{1}\\left(v_{i}, v_{j}\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e需要注意的是一阶相似度仅可用于无向图，通过最小化上述目标函数，我们可以将任意顶点映射到一个 \u003ccode\u003e$d$\u003c/code\u003e 维空间向量。\u003c/p\u003e\n\u003cp\u003e二阶相似度既可以用于无向图，也可以用于有向图。二阶相似度假设共享大量同其他节点连接的节点之间是相似的，每个节点被视为一个特定的上下文，则在上下文上具有类似分布的节点是相似的。在此，引入两个向量 \u003ccode\u003e$\\vec{u}_{i}$\u003c/code\u003e 和 \u003ccode\u003e$\\vec{u}_{\\prime i}$\u003c/code\u003e，其中 \u003ccode\u003e$\\vec{u}_{i}$\u003c/code\u003e 是 \u003ccode\u003e$v_i$\u003c/code\u003e 做为节点的表示，\u003ccode\u003e$\\vec{u}_{\\prime i}$\u003c/code\u003e 是 \u003ccode\u003e$v_i$\u003c/code\u003e 做为上下文的表示。对于一个有向边 \u003ccode\u003e$\\left(i, j\\right)$\u003c/code\u003e，由 \u003ccode\u003e$v_i$\u003c/code\u003e 生成上下文 \u003ccode\u003e$v_j$\u003c/code\u003e 的概率为：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ p_{2}\\left(v_{j} | v_{i}\\right)=\\frac{\\exp \\left(\\vec{u}_{j}^{\\prime T} \\cdot \\vec{u}_{i}\\right)}{\\sum_{k=1}^{|V|} \\exp \\left(\\vec{u}_{k}^{\\prime T} \\cdot \\vec{u}_{i}\\right)} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$|V|$\u003c/code\u003e 为节点或上下文的数量。在此我们引入一个参数 \u003ccode\u003e$\\lambda_i$\u003c/code\u003e 用于表示节点 \u003ccode\u003e$v_i$\u003c/code\u003e 的重要性程度，重要性程度可以利用度或者 PageRank 算法进行估计。经验分布 \u003ccode\u003e$\\hat{p}_{2}\\left(\\cdot \\mid v_{i}\\right)$\u003c/code\u003e 定义为 \u003ccode\u003e$\\hat{p}_{2}\\left(v_{j} \\mid v_{i}\\right)=\\dfrac{w_{i j}}{d_{i}}$\u003c/code\u003e，其中 \u003ccode\u003e$w_{ij}$\u003c/code\u003e 为边 \u003ccode\u003e$\\left(i, j\\right)$\u003c/code\u003e 的权重，\u003ccode\u003e$d_i$\u003c/code\u003e 为节点 \u003ccode\u003e$v_i$\u003c/code\u003e 的出度。LINE 中采用 \u003ccode\u003e$d_i$\u003c/code\u003e 作为节点的重要性 \u003ccode\u003e$\\lambda_i$\u003c/code\u003e，利用 KL 散度同时忽略一些常量，目标函数定义如下：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ O_{2}=-\\sum_{(i, j) \\in E} w_{i j} \\log p_{2}\\left(v_{j} \\mid v_{i}\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eLINE 采用负采样的方式对模型进行优化，同时利用 Alias 方法 \u003csup id=\"fnref:15\"\u003e\u003ca href=\"#fn:15\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e15\u003c/a\u003e\u003c/sup\u003e \u003csup id=\"fnref:16\"\u003e\u003ca href=\"#fn:16\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e16\u003c/a\u003e\u003c/sup\u003e 加速采样过程。\u003c/p\u003e\n\u003ch1 id=\"图神经网络\"\u003e图神经网络\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e本节内容主要参考自：\u003cbr/\u003e\nDeep Learning on Graphs: A Survey \u003csup id=\"fnref:17\"\u003e\u003ca href=\"#fn:17\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e17\u003c/a\u003e\u003c/sup\u003e\u003cbr/\u003e\nA Comprehensive Survey on Graph Neural Networks \u003csup id=\"fnref:18\"\u003e\u003ca href=\"#fn:18\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e18\u003c/a\u003e\u003c/sup\u003e\u003cbr/\u003e\nGraph Neural Networks: A Review of Methods and Applications \u003csup id=\"fnref:19\"\u003e\u003ca href=\"#fn:19\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e19\u003c/a\u003e\u003c/sup\u003e\u003cbr/\u003e\nIntroduction to Graph Neural Networks \u003csup id=\"fnref:20\"\u003e\u003ca href=\"#fn:20\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e20\u003c/a\u003e\u003c/sup\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e图神经网络（Graph Neural Network，GNN）最早由 Scarselli 等人 \u003csup id=\"fnref:21\"\u003e\u003ca href=\"#fn:21\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e21\u003c/a\u003e\u003c/sup\u003e 提出。图中的一个节点可以通过其特征和相关节点进行定义，GNN 的目标是学习一个状态嵌入 \u003ccode\u003e$\\mathbf{h}_v \\in \\mathbb{R}^s$\u003c/code\u003e 用于表示每个节点的邻居信息。状态嵌入 \u003ccode\u003e$\\mathbf{h}_v$\u003c/code\u003e 可以生成输出向量 \u003ccode\u003e$\\mathbf{o}_v$\u003c/code\u003e 用于作为预测节点标签的分布等。\u003c/p\u003e\n\u003cp\u003e下面三张图分别从图的类型，训练方法和传播过程角度列举了不同 GNN 的变种 \u003csup id=\"fnref1:19\"\u003e\u003ca href=\"#fn:19\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e19\u003c/a\u003e\u003c/sup\u003e。\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/gnn-graph-types.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/gnn-training-methods.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/gnn-propagation-steps.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e下面我们主要从模型的角度分别介绍不同种类的 GNN。\u003c/p\u003e\n\u003ch2 id=\"graph-neural-networks\"\u003eGraph Neural Networks\u003c/h2\u003e\n\u003cp\u003e为了根据邻居更新节点的状态，定义一个用于所有节点的函数 \u003ccode\u003e$f$\u003c/code\u003e，称之为 \u003cem\u003elocal transition function\u003c/em\u003e。定义一个函数 \u003ccode\u003e$g$\u003c/code\u003e，用于生成节点的输出，称之为 \u003cem\u003elocal output function\u003c/em\u003e。有：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{array}{c} \\mathbf{h}_{v}=f\\left(\\mathbf{x}_{v}, \\mathbf{x}_{co[v]}, \\mathbf{h}_{ne[v]}, \\mathbf{x}_{ne[v])}\\right. \\\\ \\mathbf{o}_{v}=g\\left(\\mathbf{h}_{v}, \\mathbf{x}_{v}\\right) \\end{array} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$\\mathbf{x}$\u003c/code\u003e 表示输入特征，\u003ccode\u003e$\\mathbf{h}$\u003c/code\u003e 表示隐含状态。\u003ccode\u003e$co[v]$\u003c/code\u003e 为连接到节点 \u003ccode\u003e$v$\u003c/code\u003e 的边集，\u003ccode\u003e$ne[v]$\u003c/code\u003e 为节点 \u003ccode\u003e$v$\u003c/code\u003e 的邻居。\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/graph-example.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e上图中，\u003ccode\u003e$\\mathbf{x}_1$\u003c/code\u003e 表示 \u003ccode\u003e$l_1$\u003c/code\u003e 的输入特征，\u003ccode\u003e$co[l_1]$\u003c/code\u003e 包含了边 \u003ccode\u003e$l_{(1, 4)}, l_{(6, 1)}, l_{(1, 2)}$\u003c/code\u003e 和 \u003ccode\u003e$l_{(3, 1)}$\u003c/code\u003e，\u003ccode\u003e$ne[l_1]$\u003c/code\u003e 包含了节点 \u003ccode\u003e$l_2, k_3, l_4$\u003c/code\u003e 和 \u003ccode\u003e$l_6$\u003c/code\u003e。\u003c/p\u003e\n\u003cp\u003e令 \u003ccode\u003e$\\mathbf{H}, \\mathbf{O}, \\mathbf{X}$\u003c/code\u003e 和 \u003ccode\u003e$\\mathbf{X}_N$\u003c/code\u003e 分别表示状态、输出、特征和所有节点特征的向量，有：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{aligned} \u0026amp;\\mathbf{H}=F(\\mathbf{H}, \\mathbf{X})\\\\ \u0026amp;\\mathbf{O}=G\\left(\\mathbf{H}, \\mathbf{X}_{N}\\right) \\end{aligned} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$F$\u003c/code\u003e 为 \u003cem\u003eglobal transition function\u003c/em\u003e，\u003ccode\u003e$G$\u003c/code\u003e 为 \u003cem\u003eglobal output function\u003c/em\u003e，分别为图中所有节点的 local transition function \u003ccode\u003e$f$\u003c/code\u003e 和 local output function \u003ccode\u003e$g$\u003c/code\u003e 的堆叠版本。依据 Banach 的 Fixed Point Theorem \u003csup id=\"fnref:22\"\u003e\u003ca href=\"#fn:22\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e22\u003c/a\u003e\u003c/sup\u003e，GNN 利用传统的迭代方式计算状态：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\mathbf{H}^{t+1}=F\\left(\\mathbf{H}^{t}, \\mathbf{X}\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$\\mathbf{H}^t$\u003c/code\u003e 表示第  \u003ccode\u003e$t$\u003c/code\u003e 论循环 \u003ccode\u003e$\\mathbf{H}$\u003c/code\u003e 的值。\u003c/p\u003e\n\u003cp\u003e介绍完 GNN 的框架后，下一个问题就是如果学习得到 local transition function \u003ccode\u003e$f$\u003c/code\u003e 和 local output function \u003ccode\u003e$g$\u003c/code\u003e。在包含目标信息（\u003ccode\u003e$\\mathbf{t}_v$\u003c/code\u003e 对于特定节点）的监督学习情况下，损失为：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ loss = \\sum_{i=1}^{p} \\left(\\mathbf{t}_i - \\mathbf{o}_i\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$p$\u003c/code\u003e 为用于监督学习的节点数量。利用基于梯度下降的学习方法优化模型后，我们可以得到针对特定任务的训练模型和图中节点的隐含状态。\u003c/p\u003e\n\u003cp\u003e尽管实验结果表明 GNN 是一个用于建模结构数据的强大模型，但对于一般的 GNN 模型仍存在如下缺陷：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e对于固定点，隐含状态的更新是低效地。\u003c/li\u003e\n\u003cli\u003eGNN 在每一轮计算中共享参数，而常见的神经网络结构在不同层使用不同的参数。同时，隐含节点状态的更新可以进一步应用 RNN 的思想。\u003c/li\u003e\n\u003cli\u003e边上的一些信息特征并没有被有效的建模，同时如何学习边的隐含状态也是一个重要问题。\u003c/li\u003e\n\u003cli\u003e如果我们更关注节点的表示而非图的表示，当迭代轮数 \u003ccode\u003e$T$\u003c/code\u003e 很大时使用固定点是不合适的。这是因为固定点表示的分布在数值上会更加平滑，从而缺少用于区分不同节点的信息。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"graph-convolutional-networks\"\u003eGraph Convolutional Networks\u003c/h2\u003e\n\u003cp\u003e图卷积神经网络是将用于传统数据（例如：图像）的卷积操作应用到图结构的数据中。核心思想在于学习一个函数 \u003ccode\u003e$f$\u003c/code\u003e，通过聚合节点 \u003ccode\u003e$v_i$\u003c/code\u003e 自身的特征 \u003ccode\u003e$\\mathbf{X}_i$\u003c/code\u003e 和邻居的特征 \u003ccode\u003e$\\mathbf{X}_j$\u003c/code\u003e 获得节点的表示，其中 \u003ccode\u003e$j \\in N\\left(v_i\\right)$\u003c/code\u003e 为节点的邻居。\u003c/p\u003e\n\u003cp\u003e下图展示了一个用于节点表示学习的 GCN 过程：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/gcn.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003eGCN 在构建更复杂的图神经网路中扮演了一个核心角色：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/gcn-classification.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n  \u003cfigcaption class=\"kai\"\u003e包含 Pooling 模块用于图分类的 GCN\u003c/figcaption\u003e\n  \n\u003c/figure\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/gcn-auto-encoder.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n  \u003cfigcaption class=\"kai\"\u003e包含 GCN 的图自编码器\u003c/figcaption\u003e\n  \n\u003c/figure\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/gcn-graph-spatial-temporal-network.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n  \u003cfigcaption class=\"kai\"\u003e包含 GCN 的图时空网络\u003c/figcaption\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003eGCN 方法可以分为两大类：基于频谱（Spectral Methods）和基于空间（Spatial Methods）的方法。\u003c/p\u003e\n\u003ch3 id=\"基于频谱的方法-spectral-methods\"\u003e基于频谱的方法（Spectral Methods）\u003c/h3\u003e\n\u003cp\u003e基于频谱的方法将图视为无向图进行处理，图的一种鲁棒的数学表示为标准化的图拉普拉斯矩阵：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\mathbf{L}=\\mathbf{I}_{\\mathbf{n}}-\\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$\\mathbf{A}$\u003c/code\u003e 为图的邻接矩阵，\u003ccode\u003e$\\mathbf{D}$\u003c/code\u003e 为节点度的对角矩阵，\u003ccode\u003e$\\mathbf{D}_{ii} = \\sum_{j} \\left(\\mathbf{A}_{i, j}\\right)$\u003c/code\u003e。标准化的拉普拉斯矩阵具有实对称半正定的性质，因此可以分解为：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\mathbf{L}=\\mathbf{U} \\mathbf{\\Lambda} \\mathbf{U}^{T} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$\\mathbf{U}=\\left[\\mathbf{u}_{\\mathbf{0}}, \\mathbf{u}_{\\mathbf{1}}, \\cdots, \\mathbf{u}_{\\mathbf{n}-\\mathbf{1}}\\right] \\in \\mathbf{R}^{N \\times N}$\u003c/code\u003e 是由 \u003ccode\u003e$\\mathbf{L}$\u003c/code\u003e 的特征向量构成的矩阵，\u003ccode\u003e$\\mathbf{\\Lambda}$\u003c/code\u003e 为特征值的对角矩阵，\u003ccode\u003e$\\mathbf{\\Lambda}_{ii} = \\lambda_i$\u003c/code\u003e。在图信号处理过程中，一个图信号 \u003ccode\u003e$\\mathbf{x} \\in \\mathbb{R}^N$\u003c/code\u003e 是一个由图的节点构成的特征向量，其中 \u003ccode\u003e$\\mathbf{x}_i$\u003c/code\u003e 表示第 \u003ccode\u003e$i$\u003c/code\u003e 个节点的值。对于信号 \u003ccode\u003e$\\mathbf{x}$\u003c/code\u003e，图上的傅里叶变换可以定义为：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\mathscr{F}(\\mathbf{x})=\\mathbf{U}^{T} \\mathbf{x} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e傅里叶反变换定义为：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\mathscr{F}^{-1}(\\hat{\\mathbf{x}})=\\mathbf{U} \\hat{\\mathbf{x}} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$\\hat{\\mathbf{x}}$\u003c/code\u003e 为傅里叶变换后的结果。\u003c/p\u003e\n\u003cp\u003e转变后信号 \u003ccode\u003e$\\hat{\\mathbf{x}}$\u003c/code\u003e 的元素为新空间图信号的坐标，因此输入信号可以表示为：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\mathbf{x}=\\sum_{i} \\hat{\\mathbf{x}}_{i} \\mathbf{u}_{i} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e这正是傅里叶反变换的结果。那么对于输入信号 \u003ccode\u003e$\\mathbf{x}$\u003c/code\u003e 的图卷积可以定义为：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{aligned} \\mathbf{x} *_{G} \\mathbf{g} \u0026amp;=\\mathscr{F}^{-1}(\\mathscr{F}(\\mathbf{x}) \\odot \\mathscr{F}(\\mathbf{g})) \\\\ \u0026amp;=\\mathbf{U}\\left(\\mathbf{U}^{T} \\mathbf{x} \\odot \\mathbf{U}^{T} \\mathbf{g}\\right) \\end{aligned} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$\\mathbf{g} \\in \\mathbb{R}^N$\u003c/code\u003e 为滤波器，\u003ccode\u003e$\\odot$\u003c/code\u003e 表示逐元素乘。假设定义一个滤波器 \u003ccode\u003e$\\mathbf{g}_{\\theta}=\\operatorname{diag}\\left(\\mathbf{U}^{T} \\mathbf{g}\\right)$\u003c/code\u003e，则图卷积可以简写为：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\mathbf{x} *_{G} \\mathbf{g}_{\\theta}=\\mathbf{U} \\mathbf{g}_{\\theta} \\mathbf{U}^{T} \\mathbf{x} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e基于频谱的图卷积网络都遵循这样的定义，不同之处在于不同滤波器的选择。\u003c/p\u003e\n\u003cp\u003e一些代表模型及其聚合和更新方式如下表所示：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e模型\u003c/th\u003e\n\u003cth\u003e聚合方式\u003c/th\u003e\n\u003cth\u003e更新方式\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eChebNet \u003csup id=\"fnref:23\"\u003e\u003ca href=\"#fn:23\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e23\u003c/a\u003e\u003c/sup\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\mathbf{N}_{k}=\\mathbf{T}_{k}(\\tilde{\\mathbf{L}}) \\mathbf{X}$\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\mathbf{H}=\\sum_{k=0}^{K} \\mathbf{N}_{k} \\mathbf{\\Theta}_{k}$\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e1st-order model\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\begin{array}{l} \\mathbf{N}_{0}=\\mathbf{X} \\\\ \\mathbf{N}_{1}=\\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{X} \\end{array}$\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\mathbf{H}=\\mathbf{N}_{0} \\mathbf{\\Theta}_{0}+\\mathbf{N}_{1} \\mathbf{\\Theta}_{1}$\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eSingle parameter\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\mathbf{N}=\\left(\\mathbf{I}_{N}+\\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}}\\right) \\mathbf{X}$\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\mathbf{H}=\\mathbf{N} \\mathbf{\\Theta}$\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eGCN \u003csup id=\"fnref:24\"\u003e\u003ca href=\"#fn:24\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e24\u003c/a\u003e\u003c/sup\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\mathbf{N}=\\tilde{\\mathbf{D}}^{-\\frac{1}{2}} \\tilde{\\mathbf{A}} \\tilde{\\mathbf{D}}^{-\\frac{1}{2}} \\mathbf{X}$\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\mathbf{H}=\\mathbf{N} \\mathbf{\\Theta}$\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"基于空间的方法-spatial-methods\"\u003e基于空间的方法（Spatial Methods）\u003c/h3\u003e\n\u003cp\u003e基于空间的方法通过节点的空间关系来定义图卷积操作。为了将图像和图关联起来，可以将图像视为一个特殊形式的图，每个像素点表示一个节点，如下图所示：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/spatial-based-gcn.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e每个像素同周围的像素相连，以 \u003ccode\u003e$3 \\times 3$\u003c/code\u003e 为窗口，每个节点被 8 个邻居节点所包围。通过对中心节点和周围邻居节点的像素值进行加权平均来应用一个 \u003ccode\u003e$3 \\times 3$\u003c/code\u003e 大小的滤波器。由于邻居节点的特定顺序，可以在不同位置共享权重。同样对于一般的图，基于空间的图卷积通过对中心和邻居节点的聚合得到节点新的表示。\u003c/p\u003e\n\u003cp\u003e为了使节点可以感知更深和更广的范围，通常的做法是将多个图卷积层堆叠在一起。根据堆叠方式的不同，基于空间的图卷积可以进一步分为两类：基于循环（Recurrent-based）和基于组合（Composition-based）的。基于循环的方法使用相同的图卷积层来更新隐含表示，基于组合的方式使用不同的图卷积层更新隐含表示，两者差异如下图所示：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/recurrent-based-vs-composition-based.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e一些代表模型及其聚合和更新方式如下表所示：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e模型\u003c/th\u003e\n\u003cth\u003e聚合方式\u003c/th\u003e\n\u003cth\u003e更新方式\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eNeural FPs \u003csup id=\"fnref:25\"\u003e\u003ca href=\"#fn:25\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e25\u003c/a\u003e\u003c/sup\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\mathbf{h}_{\\mathcal{N}_{v}}^{t}=\\mathbf{h}_{v}^{t-1}+\\sum_{k=1}^{\\mathcal{N}_{v}} \\mathbf{h}_{k}^{t-1}$\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\mathbf{h}_{v}^{t}=\\sigma\\left(\\mathbf{h}_{\\mathcal{N}_{v}}^{t} \\mathbf{W}_{L}^{\\mathcal{N}_{v}}\\right)$\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eDCNN \u003csup id=\"fnref:26\"\u003e\u003ca href=\"#fn:26\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e26\u003c/a\u003e\u003c/sup\u003e\u003c/td\u003e\n\u003ctd\u003eNode classification:\u003cbr/\u003e\u003ccode\u003e$\\mathbf{N}=\\mathbf{P}^{*} \\mathbf{X}$\u003c/code\u003e\u003cbr/\u003e Graph classification:\u003cbr/\u003e\u003ccode\u003e$\\mathbf{N}=1_{N}^{T} \\mathbf{P}^{*} \\mathbf{X} / N$\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\mathbf{H}=f\\left(\\mathbf{W}^{c} \\odot \\mathbf{N}\\right)$\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eGraphSAGE \u003csup id=\"fnref:27\"\u003e\u003ca href=\"#fn:27\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e27\u003c/a\u003e\u003c/sup\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\mathbf{h}_{\\mathcal{N}_{v}}^{t}=\\text{AGGREGATE}_{t}\\left(\\left\\{\\mathbf{h}_{u}^{t-1}, \\forall u \\in \\mathcal{N}_{v}\\right\\}\\right)$\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\mathbf{h}_{v}^{t}=\\sigma\\left(\\mathbf{W}^{t} \\cdot\\left[\\mathbf{h}_{v}^{t-1} \\Vert \\mathbf{h}_{\\mathcal{N}_{v}}^{t}\\right]\\right)$\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"graph-recurrent-networks\"\u003eGraph Recurrent Networks\u003c/h2\u003e\n\u003cp\u003e一些研究尝试利用门控机制（例如：GRU 或 LSTM）用于减少之前 GNN 模型在传播过程中的限制，同时改善在图结构中信息的长距离传播。GGNN \u003csup id=\"fnref:28\"\u003e\u003ca href=\"#fn:28\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e28\u003c/a\u003e\u003c/sup\u003e 提出了一种使用 GRU 进行传播的方法。它将 RNN 展开至一个固定 \u003ccode\u003e$T$\u003c/code\u003e 步，然后通过基于时间的传导计算梯度。传播模型的基础循环方式如下：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\begin{aligned} \u0026amp;\\mathbf{a}_{v}^{t}=\\mathbf{A}_{v}^{T}\\left[\\mathbf{h}_{1}^{t-1} \\ldots \\mathbf{h}_{N}^{t-1}\\right]^{T}+\\mathbf{b}\\\\ \u0026amp;\\mathbf{z}_{v}^{t}=\\sigma\\left(\\mathbf{W}^{z} \\mathbf{a}_{v}^{t}+\\mathbf{U}^{z} \\mathbf{h}_{v}^{t-1}\\right)\\\\ \u0026amp;\\mathbf{r}_{v}^{t}=\\sigma\\left(\\mathbf{W}^{r} \\mathbf{a}_{v}^{t}+\\mathbf{U}^{r} \\mathbf{h}_{v}^{t-1}\\right)\\\\ \u0026amp;\\begin{array}{l} \\widetilde{\\mathbf{h}}_{v}^{t}=\\tanh \\left(\\mathbf{W} \\mathbf{a}_{v}^{t}+\\mathbf{U}\\left(\\mathbf{r}_{v}^{t} \\odot \\mathbf{h}_{v}^{t-1}\\right)\\right) \\\\ \\mathbf{h}_{v}^{t}=\\left(1-\\mathbf{z}_{v}^{t}\\right) \\odot \\mathbf{h}_{v}^{t-1}+\\mathbf{z}_{v}^{t} \\odot \\widetilde{\\mathbf{h}}_{v}^{t} \\end{array} \\end{aligned} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e节点 \u003ccode\u003e$v$\u003c/code\u003e 首先从邻居汇总信息，其中 \u003ccode\u003e$\\mathbf{A}_v$\u003c/code\u003e 为图邻接矩阵 \u003ccode\u003e$\\mathbf{A}$\u003c/code\u003e 的子矩阵表示节点 \u003ccode\u003e$v$\u003c/code\u003e 及其邻居的连接。类似 GRU 的更新函数，通过结合其他节点和上一时间的信息更新节点的隐状态。\u003ccode\u003e$\\mathbf{a}$\u003c/code\u003e 用于获取节点 \u003ccode\u003e$v$\u003c/code\u003e 邻居的信息，\u003ccode\u003e$\\mathbf{z}$\u003c/code\u003e 和 \u003ccode\u003e$\\mathbf{r}$\u003c/code\u003e 分别为更新和重置门。\u003c/p\u003e\n\u003cp\u003eGGNN 模型设计用于解决序列生成问题，而之前的模型主要关注单个输出，例如：节点级别或图级别的分类问题。研究进一步提出了 Gated Graph Sequence Neural Networks（GGS-NNs），使用多个 GGNN 产生一个输出序列 \u003ccode\u003e$\\mathbf{o}^{(1)}, \\cdots, \\mathbf{o}^{(K)}$\u003c/code\u003e，如下图所示：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/ggs-nn.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e上图中使用了两个 GGNN，\u003ccode\u003e$\\mathcal{F}_o^{(k)}$\u003c/code\u003e 用于从 \u003ccode\u003e$\\mathcal{\\boldsymbol{X}}^{(k)}$\u003c/code\u003e 预测 \u003ccode\u003e$\\mathbf{o}^{(k)}$\u003c/code\u003e，\u003ccode\u003e$\\mathcal{F}_x^{(k)}$\u003c/code\u003e 用于从 \u003ccode\u003e$\\mathcal{\\boldsymbol{X}}^{(k)}$\u003c/code\u003e 预测 \u003ccode\u003e$\\mathcal{\\boldsymbol{X}}^{(k+1)}$\u003c/code\u003e。令 \u003ccode\u003e$\\mathcal{\\boldsymbol{H}}^{(k, t)}$\u003c/code\u003e 表示第 \u003ccode\u003e$k$\u003c/code\u003e 步输出的第 \u003ccode\u003e$t$\u003c/code\u003e 步传播，\u003ccode\u003e$\\mathcal{\\boldsymbol{H}}^{(k, 1)}$\u003c/code\u003e 在任意 \u003ccode\u003e$k$\u003c/code\u003e 步初始化为 \u003ccode\u003e$\\mathcal{\\boldsymbol{X}}^{(k)}$\u003c/code\u003e，\u003ccode\u003e$\\mathcal{\\boldsymbol{H}}^{(t, 1)}$\u003c/code\u003e 在任意 \u003ccode\u003e$t$\u003c/code\u003e 步初始化为 \u003ccode\u003e$\\mathcal{\\boldsymbol{X}}^{(t)}$\u003c/code\u003e，\u003ccode\u003e$\\mathcal{F}_o^{(k)}$\u003c/code\u003e 和 \u003ccode\u003e$\\mathcal{F}_x^{(k)}$\u003c/code\u003e 可以为不同模型也可以共享权重。\u003c/p\u003e\n\u003cp\u003e一些代表模型及其聚合和更新方式如下表所示：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e模型\u003c/th\u003e\n\u003cth\u003e聚合方式\u003c/th\u003e\n\u003cth\u003e更新方式\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eGGNN \u003csup id=\"fnref1:28\"\u003e\u003ca href=\"#fn:28\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e28\u003c/a\u003e\u003c/sup\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\mathbf{h}_{\\mathcal{N}_{v}}^{t}=\\sum_{k \\in \\mathcal{N}_{v}} \\mathbf{h}_{k}^{t-1}+\\mathbf{b}$\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\begin{aligned} \u0026amp;\\mathbf{z}_{v}^{t}=\\sigma\\left(\\mathbf{W}^{z} \\mathbf{h}_{\\mathcal{N}_{v}}^{t}+\\mathbf{U}^{z} \\mathbf{h}_{v}^{t-1}\\right)\\\\ \u0026amp;\\mathbf{r}_{v}^{t}=\\sigma\\left(\\mathbf{W}^{r} \\mathbf{h}_{\\mathcal{N}_{v}}^{z}+\\mathbf{U}^{r} \\mathbf{h}_{v}^{t-1}\\right)\\\\ \u0026amp;\\begin{array}{l} \\widetilde{\\mathbf{h}}_{v}^{t}=\\tanh \\left(\\mathbf{W h}_{\\mathcal{N}_{v}}^{t}+\\mathbf{U}\\left(\\mathbf{r}_{v}^{t} \\odot \\mathbf{h}_{v}^{t-1}\\right)\\right) \\\\ \\mathbf{h}_{v}^{t}=\\left(1-\\mathbf{z}_{v}^{t}\\right) \\odot \\mathbf{h}_{v}^{t-1}+\\mathbf{z}_{v}^{t} \\odot \\widetilde{\\mathbf{h}}_{v}^{t} \\end{array} \\end{aligned}$\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eTree LSTM (Child sum) \u003csup id=\"fnref:29\"\u003e\u003ca href=\"#fn:29\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e29\u003c/a\u003e\u003c/sup\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\mathbf{h}_{\\mathcal{N}_{v}}^{t}=\\sum_{k \\in \\mathcal{N}_{v}} \\mathbf{h}_{k}^{t-1}$\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\begin{aligned} \u0026amp;\\mathbf{i}_{v}^{t}=\\sigma\\left(\\mathbf{W}^{i} \\mathbf{x}_{v}^{t}+\\mathbf{U}^{i} \\mathbf{h}_{\\mathcal{N}_{v}}^{t}+\\mathbf{b}^{i}\\right)\\\\ \u0026amp;\\mathbf{f}_{v k}^{t}=\\sigma\\left(\\mathbf{W}^{f} \\mathbf{x}_{v}^{t}+\\mathbf{U}^{f} \\mathbf{h}_{k}^{t-1}+\\mathbf{b}^{f}\\right)\\\\ \u0026amp;\\mathbf{o}_{v}^{t}=\\sigma\\left(\\mathbf{W}^{o} \\mathbf{x}_{v}^{t}+\\mathbf{U}^{o} \\mathbf{h}_{\\mathcal{N}_{v}}^{t}+\\mathbf{b}^{o}\\right)\\\\ \u0026amp;\\mathbf{u}_{v}^{t}=\\tanh \\left(\\mathbf{W}^{u} \\mathbf{x}_{v}^{t}+\\mathbf{U}^{u} \\mathbf{h}_{\\mathcal{N}_{v}}^{t}+\\mathbf{b}^{u}\\right)\\\\ \u0026amp;\\begin{array}{l} \\mathbf{c}_{v}^{t}=\\mathbf{i}_{v}^{t} \\odot \\mathbf{u}_{v}^{t}+\\sum_{k \\in \\mathcal{N}_{v}} \\mathbf{f}_{v k}^{t} \\odot \\mathbf{c}_{k}^{t-1} \\\\ \\mathbf{h}_{v}^{t}=\\mathbf{o}_{v}^{t} \\odot \\tanh \\left(\\mathbf{c}_{v}^{t}\\right) \\end{array} \\end{aligned}$\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eTree LSTM (N-ary) \u003csup id=\"fnref1:29\"\u003e\u003ca href=\"#fn:29\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e29\u003c/a\u003e\u003c/sup\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\begin{aligned} \u0026amp;\\mathbf{h}_{\\mathcal{N}_{v}}^{t i}=\\sum_{l=1}^{K} \\mathbf{U}_{l}^{i} \\mathbf{h}_{v l}^{t-1}\\\\ \u0026amp;\\mathbf{h}_{\\mathcal{N}_{v} k}^{t f}=\\sum_{l=1}^{K} \\mathbf{U}_{k l}^{f} \\mathbf{h}_{v l}^{t-1}\\\\ \u0026amp;\\mathbf{h}_{\\mathcal{N}_{v}}^{t o}=\\sum_{l=1}^{K} \\mathbf{U}_{l}^{o} \\mathbf{h}_{v l}^{t-1}\\\\ \u0026amp;\\mathbf{h}_{\\mathcal{N}_{v}}^{t u}=\\sum_{l=1}^{K} \\mathbf{U}_{l}^{u} \\mathbf{h}_{v l}^{t-1} \\end{aligned}$\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\begin{aligned} \u0026amp;\\mathbf{i}_{v}^{t}=\\sigma\\left(\\mathbf{W}^{i} \\mathbf{x}_{v}^{t}+\\mathbf{h}_{\\mathcal{N}_{v},}^{t i}+\\mathbf{b}^{i}\\right)\\\\ \u0026amp;\\mathbf{f}_{v k}^{t}=\\sigma\\left(\\mathbf{W}^{f} \\mathbf{x}_{v}^{t}+\\mathbf{h}_{\\mathcal{N}_{v} k}^{f f}+\\mathbf{b}^{f}\\right)\\\\ \u0026amp;\\mathbf{o}_{v}^{t}=\\sigma\\left(\\mathbf{W}^{o} \\mathbf{x}_{v}^{t}+\\mathbf{h}_{\\mathcal{N}_{v}}^{t o}+\\mathbf{b}^{o}\\right)\\\\ \u0026amp;\\mathbf{u}_{v}^{t}=\\tanh \\left(\\mathbf{W}^{u} \\mathbf{x}_{v}^{t}+\\mathbf{h}_{\\mathcal{N}_{v}}^{t u}+\\mathbf{b}^{u}\\right)\\\\ \u0026amp;\\mathbf{c}_{v}^{t}=\\mathbf{i}_{v}^{t} \\odot \\mathbf{u}_{v}^{t}+\\sum_{l=1}^{K} \\mathbf{f}_{v l}^{t} \\odot \\mathbf{c}_{v l}^{t-1}\\\\ \u0026amp;\\mathbf{h}_{v}^{t}=\\mathbf{o}_{v}^{t} \\odot \\tanh \\left(\\mathbf{c}_{v}^{t}\\right) \\end{aligned}$\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eGraph LSTM \u003csup id=\"fnref:30\"\u003e\u003ca href=\"#fn:30\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e30\u003c/a\u003e\u003c/sup\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\begin{aligned} \\mathbf{h}_{\\mathcal{N}_{v}}^{t i}=\\sum_{k \\in \\mathcal{N}_{v}} \\mathbf{U}_{m(v, k)}^{i} \\mathbf{h}_{k}^{t-1} \\\\ \\mathbf{h}_{\\mathcal{N}_{v}}^{t o}=\\sum_{k \\in \\mathcal{N}_{v}} \\mathbf{U}_{m(v, k)}^{o} \\mathbf{h}_{k}^{t-1} \\\\ \\mathbf{h}_{\\mathcal{N}_{v}}^{t u}=\\sum_{k \\in \\mathcal{N}_{v}} \\mathbf{U}_{m(v, k)}^{u} \\mathbf{h}_{k}^{t-1} \\end{aligned}$\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\begin{aligned} \u0026amp;\\mathbf{i}_{v}^{t}=\\sigma\\left(\\mathbf{W}^{i} \\mathbf{x}_{v}^{t}+\\mathbf{h}_{\\mathcal{N}_{v}}^{t i}+\\mathbf{b}^{i}\\right)\\\\ \u0026amp;\\mathbf{f}_{v k}^{t}=\\sigma\\left(\\mathbf{W}^{f} \\mathbf{x}_{v}^{t}+\\mathbf{U}_{m(v, k)}^{f} \\mathbf{h}_{k}^{t-1}+\\mathbf{b}^{f}\\right)\\\\ \u0026amp;\\mathbf{o}_{v}^{t}=\\sigma\\left(\\mathbf{W}^{o} \\mathbf{x}_{v}^{t}+\\mathbf{h}_{\\mathcal{N}_{v}}^{t o}+\\mathbf{b}^{o}\\right)\\\\ \u0026amp;\\mathbf{u}_{v}^{t}=\\tanh \\left(\\mathbf{W}^{u} \\mathbf{x}_{v}^{t}+\\mathbf{h}_{\\mathcal{N}_{v}}^{t u}+\\mathbf{b}^{u}\\right)\\\\ \u0026amp;\\begin{array}{l} \\mathbf{c}_{v}^{t}=\\mathbf{i}_{v}^{t} \\odot \\mathbf{u}_{v}^{t}+\\sum_{k \\in \\mathcal{N}_{v}} \\mathbf{f}_{v k}^{t} \\odot \\mathbf{c}_{k}^{t-1} \\\\ \\mathbf{h}_{v}^{t}=\\mathbf{o}_{v}^{t} \\odot \\tanh \\left(\\mathbf{c}_{v}^{t}\\right) \\end{array} \\end{aligned}$\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"graph-attention-networks\"\u003eGraph Attention Networks\u003c/h2\u003e\n\u003cp\u003e与 GCN 对于节点所有的邻居平等对待相比，注意力机制可以为每个邻居分配不同的注意力评分，从而识别更重要的邻居。\u003c/p\u003e\n\u003cp\u003eGAT \u003csup id=\"fnref:31\"\u003e\u003ca href=\"#fn:31\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e31\u003c/a\u003e\u003c/sup\u003e 将注意力机制引入传播过程，其遵循自注意力机制，通过对每个节点邻居的不同关注更新隐含状态。GAT 定义了一个图注意力层（\u003cem\u003egraph attentional layer\u003c/em\u003e），通过堆叠构建图注意力网络。对于节点对 \u003ccode\u003e$\\left(i, j\\right)$\u003c/code\u003e，基于注意力机制的系数计算方式如下：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\alpha_{i j}=\\frac{\\exp \\left(\\text { LeakyReLU }\\left(\\overrightarrow{\\mathbf{a}}^{T}\\left[\\mathbf{W} \\vec{h}_{i} \\| \\mathbf{W} \\vec{h}_{j}\\right]\\right)\\right)}{\\sum_{k \\in N_{i}} \\exp \\left(\\text { LeakyReLU }\\left(\\overrightarrow{\\mathbf{a}}^{T}\\left[\\mathbf{W} \\vec{h}_{i} \\| \\mathbf{W} \\vec{h}_{k}\\right]\\right)\\right)} $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$\\alpha_{i j}$\u003c/code\u003e 表示节点 \u003ccode\u003e$j$\u003c/code\u003e 对 \u003ccode\u003e$i$\u003c/code\u003e 的注意力系数，\u003ccode\u003e$N_i$\u003c/code\u003e 表示节点 \u003ccode\u003e$i$\u003c/code\u003e 的邻居。令 \u003ccode\u003e$\\mathbf{h}=\\left\\{\\vec{h}_{1}, \\vec{h}_{2}, \\ldots, \\vec{h}_{N}\\right\\}, \\vec{h}_{i} \\in \\mathbb{R}^{F}$\u003c/code\u003e 表示输入节点特征，其中 \u003ccode\u003e$N$\u003c/code\u003e 为节点的数量，\u003ccode\u003e$F$\u003c/code\u003e 为特征维度，则节点的输出特征（可能为不同维度 \u003ccode\u003e$F^{\\prime}$\u003c/code\u003e）为 \u003ccode\u003e$\\mathbf{h}^{\\prime}=\\left\\{\\vec{h}_{1}^{\\prime}, \\vec{h}_{2}^{\\prime}, \\ldots, \\vec{h}_{N}^{\\prime}\\right\\}, \\vec{h}_{i}^{\\prime} \\in \\mathbb{R}^{F^{\\prime}}$\u003c/code\u003e。\u003ccode\u003e$\\mathbf{W} \\in \\mathbb{R}^{F^{\\prime} \\times F}$\u003c/code\u003e 为所有节点共享的线性变换的权重矩阵，\u003ccode\u003e$a: \\mathbb{R}^{F^{\\prime}} \\times \\mathbb{R}^{F^{\\prime}} \\rightarrow \\mathbb{R}$\u003c/code\u003e 用于计算注意力系数。最后的输出特征计算方式如下：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\vec{h}_{i}^{\\prime}=\\sigma\\left(\\sum_{j \\in \\mathcal{N}_{i}} \\alpha_{i j} \\mathbf{W} \\vec{h}_{j}\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e注意力层采用多头注意力机制来稳定学习过程，之后应用 \u003ccode\u003e$K$\u003c/code\u003e 个独立的注意力机制计算隐含状态，最后通过拼接或平均得到输出表示：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\vec{h}_{i}^{\\prime}=\\Vert_{k=1}^{K} \\sigma\\left(\\sum_{j \\in \\mathcal{N}_{i}} \\alpha_{i j}^{k} \\mathbf{W}^{k} \\vec{h}_{j}\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ \\vec{h}_{i}^{\\prime}=\\sigma\\left(\\frac{1}{K} \\sum_{k=1}^{K} \\sum_{j \\in \\mathcal{N}_{i}} \\alpha_{i j}^{k} \\mathbf{W}^{k} \\vec{h}_{j}\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$\\Vert$\u003c/code\u003e 表示连接操作，\u003ccode\u003e$\\alpha_{ij}^k$\u003c/code\u003e 表示第 \u003ccode\u003e$k$\u003c/code\u003e 个注意力机制计算得到的标准化的注意力系数。整个模型如下图所示：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/gat.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003eGAT 中的注意力架构有如下几个特点：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e针对节点对的计算是并行的，因此计算过程是高效的。\u003c/li\u003e\n\u003cli\u003e可以处理不同度的节点并对邻居分配对应的权重。\u003c/li\u003e\n\u003cli\u003e可以容易地应用到归纳学习问题中去。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"应用\"\u003e应用\u003c/h2\u003e\n\u003cp\u003e图神经网络已经被应用在监督、半监督、无监督和强化学习等多个领域。下图列举了 GNN 在不同领域内相关问题中的应用，具体模型论文请参考 Graph Neural Networks: A Review of Methods and Applications 原文 \u003csup id=\"fnref2:19\"\u003e\u003ca href=\"#fn:19\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e19\u003c/a\u003e\u003c/sup\u003e。\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-04-11-graph-embedding-and-gnn/applications.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003ch1 id=\"开放资源\"\u003e开放资源\u003c/h1\u003e\n\u003ch2 id=\"开源实现\"\u003e开源实现\u003c/h2\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e项目\u003c/th\u003e\n\u003cth\u003e框架\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/rusty1s/pytorch_geometric\"\u003erusty1s/pytorch_geometric\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-pytorch\"\u003ePyTorch\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/dmlc/dgl\"\u003edmlc/dgl\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-pytorch\"\u003ePyTorch\u003c/i\u003e, \u003ci class=\"icon icon-tensorflow\"\u003eTF\u003c/i\u003e \u0026amp; \u003ci class=\"icon icon-mxnet\"\u003eMXNet\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/alibaba/euler\"\u003ealibaba/euler\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-tensorflow\"\u003eTF\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/alibaba/graph-learn\"\u003ealibaba/graph-learn\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-tensorflow\"\u003eTF\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/deepmind/graph_nets\"\u003edeepmind/graph_nets\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-tensorflow\"\u003eTF\u003c/i\u003e \u0026amp; \u003ci class=\"icon icon-sonnet\"\u003eSonnet\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/facebookresearch/PyTorch-BigGraph\"\u003efacebookresearch/PyTorch-BigGraph\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-pytorch\"\u003ePyTorch\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/tencent/plato\"\u003etencent/plato\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/PaddlePaddle/PGL\"\u003ePaddlePaddle/PGL\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-paddlepaddle\"\u003e\u003c/i\u003e PaddlePaddle\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/Accenture/AmpliGraph\"\u003eAccenture/AmpliGraph\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-tensorflow\"\u003eTF\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/danielegrattarola/spektral\"\u003edanielegrattarola/spektral\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-tensorflow\"\u003eTF\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/THUDM/cogdl/\"\u003eTHUDM/cogdl\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-pytorch\"\u003ePyTorch\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/DeepGraphLearning/graphvite\"\u003eDeepGraphLearning/graphvite\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-pytorch\"\u003ePyTorch\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"论文列表和评测\"\u003e论文列表和评测\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/thunlp/NRLPapers\"\u003eMust-read papers on network representation learning (NRL) / network embedding (NE)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/thunlp/GNNPapers\"\u003eMust-read papers on graph neural networks (GNN)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/DeepGraphLearning/LiteratureDL4Graph\"\u003eDeepGraphLearning/LiteratureDL4Graph\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/nnzhan/Awesome-Graph-Neural-Networks\"\u003ennzhan/Awesome-Graph-Neural-Networks\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/graphdeeplearning/benchmarking-gnns\"\u003egraphdeeplearning/benchmarking-gnns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ogb.stanford.edu/\"\u003eOpen Graph Benchmark\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"footnotes\" role=\"doc-endnotes\"\u003e\n\u003chr/\u003e\n\u003col\u003e\n\u003cli id=\"fn:1\"\u003e\n\u003cp\u003eCai, H., Zheng, V. W., \u0026amp; Chang, K. C. C. (2018). A comprehensive survey of graph embedding: Problems, techniques, and applications. \u003cem\u003eIEEE Transactions on Knowledge and Data Engineering\u003c/em\u003e, 30(9), 1616-1637. \u003ca href=\"#fnref:1\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:2\"\u003e\n\u003cp\u003eGoyal, P., \u0026amp; Ferrara, E. (2018). Graph embedding techniques, applications, and performance: A survey. \u003cem\u003eKnowledge-Based Systems\u003c/em\u003e, 151, 78-94. \u003ca href=\"#fnref:2\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:3\"\u003e\n\u003cp\u003eHamilton, W. L., Ying, R., \u0026amp; Leskovec, J. (2017). Representation learning on graphs: Methods and applications. \u003cem\u003earXiv preprint arXiv:1709.05584\u003c/em\u003e. \u003ca href=\"#fnref:3\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:4\"\u003e\n\u003cp\u003ePerozzi, B., Al-Rfou, R., \u0026amp; Skiena, S. (2014). Deepwalk: Online learning of social representations. In \u003cem\u003eProceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining\u003c/em\u003e (pp. 701-710). \u003ca href=\"#fnref:4\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:5\"\u003e\n\u003cp\u003eGrover, A., \u0026amp; Leskovec, J. (2016). node2vec: Scalable feature learning for networks. In \u003cem\u003eProceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining\u003c/em\u003e (pp. 855-864). \u003ca href=\"#fnref:5\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:6\"\u003e\n\u003cp\u003eFogaras, D., Rácz, B., Csalogány, K., \u0026amp; Sarlós, T. (2005). Towards scaling fully personalized pagerank: Algorithms, lower bounds, and experiments. \u003cem\u003eInternet Mathematics\u003c/em\u003e, 2(3), 333-358. \u003ca href=\"#fnref:6\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:7\"\u003e\n\u003cp\u003eHaveliwala, T. H. (2002). Topic-sensitive PageRank. In \u003cem\u003eProceedings of the 11th international conference on World Wide Web\u003c/em\u003e (pp. 517-526). \u003ca href=\"#fnref:7\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:8\"\u003e\n\u003cp\u003eCao, S., Lu, W., \u0026amp; Xu, Q. (2015). Grarep: Learning graph representations with global structural information. In \u003cem\u003eProceedings of the 24th ACM international on conference on information and knowledge management\u003c/em\u003e (pp. 891-900). \u003ca href=\"#fnref:8\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:9\"\u003e\n\u003cp\u003eOu, M., Cui, P., Pei, J., Zhang, Z., \u0026amp; Zhu, W. (2016). Asymmetric transitivity preserving graph embedding. In \u003cem\u003eProceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining\u003c/em\u003e (pp. 1105-1114). \u003ca href=\"#fnref:9\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:10\"\u003e\n\u003cp\u003eDong, Y., Chawla, N. V., \u0026amp; Swami, A. (2017). metapath2vec: Scalable representation learning for heterogeneous networks. In \u003cem\u003eProceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining\u003c/em\u003e (pp. 135-144). \u003ca href=\"#fnref:10\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:11\"\u003e\n\u003cp\u003eFu, T. Y., Lee, W. C., \u0026amp; Lei, Z. (2017). Hin2vec: Explore meta-paths in heterogeneous information networks for representation learning. In \u003cem\u003eProceedings of the 2017 ACM on Conference on Information and Knowledge Management\u003c/em\u003e (pp. 1797-1806). \u003ca href=\"#fnref:11\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:12\"\u003e\n\u003cp\u003eWang, D., Cui, P., \u0026amp; Zhu, W. (2016). Structural deep network embedding. In \u003cem\u003eProceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining\u003c/em\u003e (pp. 1225-1234). \u003ca href=\"#fnref:12\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:13\"\u003e\n\u003cp\u003eCao, S., Lu, W., \u0026amp; Xu, Q. (2016). Deep neural networks for learning graph representations. In \u003cem\u003eThirtieth AAAI conference on artificial intelligence\u003c/em\u003e. \u003ca href=\"#fnref:13\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:14\"\u003e\n\u003cp\u003eTang, J., Qu, M., Wang, M., Zhang, M., Yan, J., \u0026amp; Mei, Q. (2015). Line: Large-scale information network embedding. In \u003cem\u003eProceedings of the 24th international conference on world wide web\u003c/em\u003e (pp. 1067-1077). \u003ca href=\"#fnref:14\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:15\"\u003e\n\u003cp\u003eWalker, A. J. (1974). New fast method for generating discrete random numbers with arbitrary frequency distributions. \u003cem\u003eElectronics Letters\u003c/em\u003e, 10(8), 127-128. \u003ca href=\"#fnref:15\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:16\"\u003e\n\u003cp\u003eWalker, A. J. (1977). An efficient method for generating discrete random variables with general distributions. \u003cem\u003eACM Transactions on Mathematical Software (TOMS)\u003c/em\u003e, 3(3), 253-256. \u003ca href=\"#fnref:16\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:17\"\u003e\n\u003cp\u003eZhang, Z., Cui, P., \u0026amp; Zhu, W. (2020). Deep learning on graphs: A survey. \u003cem\u003eIEEE Transactions on Knowledge and Data Engineering\u003c/em\u003e. \u003ca href=\"#fnref:17\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:18\"\u003e\n\u003cp\u003eWu, Z., Pan, S., Chen, F., Long, G., Zhang, C., \u0026amp; Philip, S. Y. (2020). A comprehensive survey on graph neural networks. \u003cem\u003eIEEE Transactions on Neural Networks and Learning Systems\u003c/em\u003e. \u003ca href=\"#fnref:18\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:19\"\u003e\n\u003cp\u003eZhou, J., Cui, G., Zhang, Z., Yang, C., Liu, Z., Wang, L., … \u0026amp; Sun, M. (2018). Graph neural networks: A review of methods and applications. \u003cem\u003earXiv preprint arXiv:1812.08434\u003c/em\u003e. \u003ca href=\"#fnref:19\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e \u003ca href=\"#fnref1:19\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e \u003ca href=\"#fnref2:19\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:20\"\u003e\n\u003cp\u003eLiu, Z., \u0026amp; Zhou, J. (2020). Introduction to Graph Neural Networks. \u003cem\u003eSynthesis Lectures on Artificial Intelligence and Machine Learning\u003c/em\u003e, 14(2), 1–127. \u003ca href=\"#fnref:20\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:21\"\u003e\n\u003cp\u003eScarselli, F., Gori, M., Tsoi, A. C., Hagenbuchner, M., \u0026amp; Monfardini, G. (2008). The graph neural network model. \u003cem\u003eIEEE Transactions on Neural Networks\u003c/em\u003e, 20(1), 61-80. \u003ca href=\"#fnref:21\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:22\"\u003e\n\u003cp\u003eKhamsi, M. A., \u0026amp; Kirk, W. A. (2011). \u003cem\u003eAn introduction to metric spaces and fixed point theory\u003c/em\u003e (Vol. 53). John Wiley \u0026amp; Sons. \u003ca href=\"#fnref:22\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:23\"\u003e\n\u003cp\u003eDefferrard, M., Bresson, X., \u0026amp; Vandergheynst, P. (2016). Convolutional neural networks on graphs with fast localized spectral filtering. In \u003cem\u003eAdvances in neural information processing systems\u003c/em\u003e (pp. 3844-3852). \u003ca href=\"#fnref:23\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:24\"\u003e\n\u003cp\u003eKipf, T. N., \u0026amp; Welling, M. (2016). Semi-supervised classification with graph convolutional networks. \u003cem\u003earXiv preprint arXiv:1609.02907\u003c/em\u003e. \u003ca href=\"#fnref:24\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:25\"\u003e\n\u003cp\u003eDuvenaud, D. K., Maclaurin, D., Iparraguirre, J., Bombarell, R., Hirzel, T., Aspuru-Guzik, A., \u0026amp; Adams, R. P. (2015). Convolutional networks on graphs for learning molecular fingerprints. In \u003cem\u003eAdvances in neural information processing systems\u003c/em\u003e (pp. 2224-2232). \u003ca href=\"#fnref:25\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:26\"\u003e\n\u003cp\u003eAtwood, J., \u0026amp; Towsley, D. (2016). Diffusion-convolutional neural networks. In \u003cem\u003eAdvances in neural information processing systems\u003c/em\u003e (pp. 1993-2001). \u003ca href=\"#fnref:26\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:27\"\u003e\n\u003cp\u003eHamilton, W., Ying, Z., \u0026amp; Leskovec, J. (2017). Inductive representation learning on large graphs. In \u003cem\u003eAdvances in neural information processing systems\u003c/em\u003e (pp. 1024-1034). \u003ca href=\"#fnref:27\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:28\"\u003e\n\u003cp\u003eLi, Y., Tarlow, D., Brockschmidt, M., \u0026amp; Zemel, R. (2015). Gated graph sequence neural networks. \u003cem\u003earXiv preprint arXiv:1511.05493.\u003c/em\u003e \u003ca href=\"#fnref:28\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e \u003ca href=\"#fnref1:28\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:29\"\u003e\n\u003cp\u003eTai, K. S., Socher, R., \u0026amp; Manning, C. D. (2015). Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks. In \u003cem\u003eProceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing\u003c/em\u003e (Volume 1: Long Papers) (pp. 1556-1566). \u003ca href=\"#fnref:29\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e \u003ca href=\"#fnref1:29\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:30\"\u003e\n\u003cp\u003ePeng, N., Poon, H., Quirk, C., Toutanova, K., \u0026amp; Yih, W. T. (2017). Cross-sentence n-ary relation extraction with graph lstms. \u003cem\u003eTransactions of the Association for Computational Linguistics\u003c/em\u003e, 5, 101-115. \u003ca href=\"#fnref:30\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:31\"\u003e\n\u003cp\u003eVeličković, P., Cucurull, G., Casanova, A., Romero, A., Lio, P., \u0026amp; Bengio, Y. (2017). Graph attention networks. \u003cem\u003earXiv preprint arXiv:1710.10903.\u003c/em\u003e \u003ca href=\"#fnref:31\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/div\u003e\n\n\n\n\n\n\u003cdiv class=\"donate\"\u003e\n  \u003cdiv class=\"donate-header\"\u003e\u003c/div\u003e\n  \u003cdiv class=\"donate-slug\" id=\"donate-slug\"\u003egraph-embedding-and-gnn\u003c/div\u003e\n  \u003cbutton class=\"donate-button\"\u003e赞 赏\u003c/button\u003e\n  \u003cdiv class=\"donate-footer\"\u003e「真诚赞赏，手留余香」\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv class=\"donate-modal-wrapper\"\u003e\n  \u003cdiv class=\"donate-modal\"\u003e\n    \u003cdiv class=\"donate-box\"\u003e\n      \u003cdiv class=\"donate-box-content\"\u003e\n        \u003cdiv class=\"donate-box-content-inner\"\u003e\n          \u003cdiv class=\"donate-box-header\"\u003e「真诚赞赏，手留余香」\u003c/div\u003e\n          \u003cdiv class=\"donate-box-body\"\u003e\n            \u003cdiv class=\"donate-box-money\"\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-2\" data-v=\"2\" data-unchecked=\"￥ 2\" data-checked=\"2 元\"\u003e￥ 2\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-5\" data-v=\"5\" data-unchecked=\"￥ 5\" data-checked=\"5 元\"\u003e￥ 5\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-10\" data-v=\"10\" data-unchecked=\"￥ 10\" data-checked=\"10 元\"\u003e￥ 10\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-50\" data-v=\"50\" data-unchecked=\"￥ 50\" data-checked=\"50 元\"\u003e￥ 50\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-100\" data-v=\"100\" data-unchecked=\"￥ 100\" data-checked=\"100 元\"\u003e￥ 100\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-custom\" data-v=\"custom\" data-unchecked=\"任意金额\" data-checked=\"任意金额\"\u003e任意金额\u003c/button\u003e\n            \u003c/div\u003e\n            \u003cdiv class=\"donate-box-pay\"\u003e\n              \u003cimg class=\"donate-box-pay-qrcode\" id=\"donate-box-pay-qrcode\" src=\"\"/\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n          \u003cdiv class=\"donate-box-footer\"\u003e\n            \u003cdiv class=\"donate-box-pay-method donate-box-pay-method-checked\" data-v=\"wechat-pay\"\u003e\n              \u003cimg class=\"donate-box-pay-method-image\" id=\"donate-box-pay-method-image-wechat-pay\" src=\"\"/\u003e\n            \u003c/div\u003e\n            \u003cdiv class=\"donate-box-pay-method\" data-v=\"alipay\"\u003e\n              \u003cimg class=\"donate-box-pay-method-image\" id=\"donate-box-pay-method-image-alipay\" src=\"\"/\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n      \u003c/div\u003e\n    \u003c/div\u003e\n    \u003cbutton type=\"button\" class=\"donate-box-close-button\"\u003e\n      \u003csvg class=\"donate-box-close-button-icon\" fill=\"#fff\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\"\u003e\u003cpath d=\"M13.486 12l5.208-5.207a1.048 1.048 0 0 0-.006-1.483 1.046 1.046 0 0 0-1.482-.005L12 10.514 6.793 5.305a1.048 1.048 0 0 0-1.483.005 1.046 1.046 0 0 0-.005 1.483L10.514 12l-5.208 5.207a1.048 1.048 0 0 0 .006 1.483 1.046 1.046 0 0 0 1.482.005L12 13.486l5.207 5.208a1.048 1.048 0 0 0 1.483-.006 1.046 1.046 0 0 0 .005-1.482L13.486 12z\" fill-rule=\"evenodd\"\u003e\u003c/path\u003e\u003c/svg\u003e\n    \u003c/button\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n\n\u003cscript type=\"text/javascript\" src=\"/js/donate.js\"\u003e\u003c/script\u003e\n\n\n  \u003cfooter\u003e\n  \n\u003cnav class=\"post-nav\"\u003e\n  \u003cspan class=\"nav-prev\"\u003e← \u003ca href=\"/cn/2020/03/pre-trained-model-for-nlp/\"\u003e预训练自然语言模型 (Pre-trained Models for NLP)\u003c/a\u003e\u003c/span\u003e\n  \u003cspan class=\"nav-next\"\u003e\u003ca href=\"/cn/2020/05/hmm-crf-and-sequence-labeling/\"\u003e隐马尔可夫 (Hidden Markov Model, HMM)，条件随机场 (Conditional Random Fields, CRF) 和序列标注 (Sequence Labeling)\u003c/a\u003e →\u003c/span\u003e\n\u003c/nav\u003e\n\n\n\n\n\u003cins class=\"adsbygoogle\" style=\"display:block; text-align:center;\" data-ad-layout=\"in-article\" data-ad-format=\"fluid\" data-ad-client=\"ca-pub-2608165017777396\" data-ad-slot=\"8302038603\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n  (adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/js-cookie@3.0.5/dist/js.cookie.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/toggle-theme.js\"\u003e\u003c/script\u003e\n\n\n\u003cscript src=\"/js/no-highlight.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/math-code.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/heading-anchor.js\"\u003e\u003c/script\u003e\n\n\n\n\u003csection class=\"comments\"\u003e\n\u003cscript src=\"https://giscus.app/client.js\" data-repo=\"leovan/leovan.me\" data-repo-id=\"MDEwOlJlcG9zaXRvcnkxMTMxOTY0Mjc=\" data-category=\"Comments\" data-category-id=\"DIC_kwDOBr89i84CT-R7\" data-mapping=\"pathname\" data-strict=\"1\" data-reactions-enabled=\"1\" data-emit-metadata=\"0\" data-input-position=\"top\" data-theme=\"preferred_color_scheme\" data-lang=\"zh-CN\" data-loading=\"lazy\" crossorigin=\"anonymous\" defer=\"\"\u003e\n\u003c/script\u003e\n\u003c/section\u003e\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003cscript async=\"\" src=\"/js/center-img.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/right-quote.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/external-link.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/alt-title.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/figure.js\"\u003e\u003c/script\u003e\n\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js\"\u003e\u003c/script\u003e\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/vanilla-back-to-top@latest/dist/vanilla-back-to-top.min.js\"\u003e\u003c/script\u003e\n\u003cscript\u003e\naddBackToTop({\n  diameter: 48\n});\n\u003c/script\u003e\n\n  \u003chr/\u003e\n  \u003cdiv class=\"copyright no-border-bottom\"\u003e\n    \u003cdiv class=\"copyright-author-year\"\u003e\n      \u003cspan\u003eCopyright © 2017-2024 \u003ca href=\"/\"\u003e范叶亮 | Leo Van\u003c/a\u003e\u003c/span\u003e\n    \u003c/div\u003e\n  \u003c/div\u003e\n  \u003c/footer\u003e\n  \u003c/article\u003e",
  "Date": "2020-04-11T00:00:00Z",
  "Author": "范叶亮"
}