{
  "Source": "leovan.me",
  "Title": "最近邻搜索 (Nearest Neighbor Search)",
  "Link": "https://leovan.me/cn/2020/08/nearest-neighbor-search/",
  "Content": "\u003carticle class=\"main\"\u003e\n    \u003cheader class=\"content-title\"\u003e\n    \n\u003ch1 class=\"title\"\u003e\n  \n  最近邻搜索 (Nearest Neighbor Search)\n  \n\u003c/h1\u003e\n\n\n\n\n\n\n\n\u003ch2 class=\"author-date\"\u003e范叶亮 / \n2020-08-01\u003c/h2\u003e\n\n\n\n\u003ch3 class=\"post-meta\"\u003e\n\n\n\u003cstrong\u003e分类: \u003c/strong\u003e\n\u003ca href=\"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0\"\u003e机器学习\u003c/a\u003e\n\n\n\n\n/\n\n\n\n\n\u003cstrong\u003e标签: \u003c/strong\u003e\n\u003cspan\u003e最近邻搜索\u003c/span\u003e, \u003cspan\u003eNearest Neighbor Search\u003c/span\u003e, \u003cspan\u003eNNS\u003c/span\u003e, \u003cspan\u003e近似最近邻\u003c/span\u003e, \u003cspan\u003eApproximate Nearest Neighbor\u003c/span\u003e, \u003cspan\u003eANN\u003c/span\u003e, \u003cspan\u003e暴力查找\u003c/span\u003e, \u003cspan\u003eBrute-force Search\u003c/span\u003e, \u003cspan\u003ek-D 树\u003c/span\u003e, \u003cspan\u003ek-D Tree\u003c/span\u003e, \u003cspan\u003eBall 树\u003c/span\u003e, \u003cspan\u003eBall Tree\u003c/span\u003e, \u003cspan\u003e局部敏感哈希\u003c/span\u003e, \u003cspan\u003eLocality Sensitive Hashing\u003c/span\u003e, \u003cspan\u003eLSH\u003c/span\u003e, \u003cspan\u003eMinHash\u003c/span\u003e, \u003cspan\u003eSimHash\u003c/span\u003e, \u003cspan\u003ep-stable 分布\u003c/span\u003e, \u003cspan\u003e哈希学习\u003c/span\u003e, \u003cspan\u003eLearning to Hash\u003c/span\u003e, \u003cspan\u003eL2H\u003c/span\u003e, \u003cspan\u003e矢量量化\u003c/span\u003e, \u003cspan\u003e向量量化\u003c/span\u003e, \u003cspan\u003eVector Quantization\u003c/span\u003e, \u003cspan\u003eProduct Quantization\u003c/span\u003e, \u003cspan\u003eIVFADC\u003c/span\u003e, \u003cspan\u003eIterative Quantization\u003c/span\u003e, \u003cspan\u003eOptimized Product Quantization\u003c/span\u003e, \u003cspan\u003eNavigable Small World\u003c/span\u003e, \u003cspan\u003eNSW\u003c/span\u003e, \u003cspan\u003eHierarchical Navigable Small World\u003c/span\u003e, \u003cspan\u003eHNSW\u003c/span\u003e, \u003cspan\u003eMonotonic Relative Neighborhood Graph\u003c/span\u003e, \u003cspan\u003eMRNG\u003c/span\u003e, \u003cspan\u003eNavigating Spreading-out Graph\u003c/span\u003e, \u003cspan\u003eNSG\u003c/span\u003e\n\n\n\n\n/\n\n\n\u003cstrong\u003e字数: \u003c/strong\u003e\n7061\n\u003c/h3\u003e\n\n\n\n\u003chr/\u003e\n\n\n\n    \n    \n    \u003cins class=\"adsbygoogle\" style=\"display:block; text-align:center;\" data-ad-layout=\"in-article\" data-ad-format=\"fluid\" data-ad-client=\"ca-pub-2608165017777396\" data-ad-slot=\"1261604535\"\u003e\u003c/ins\u003e\n    \u003cscript\u003e\n    (adsbygoogle = window.adsbygoogle || []).push({});\n    \u003c/script\u003e\n    \n    \n    \u003c/header\u003e\n\n\n\n\n\u003cp\u003e**最近邻搜索（Nearest Neighbor Search）**是指在一个确定的距离度量和一个搜索空间内寻找与给定查询项距离最小的元素。更精确地，对于一个包含 \u003ccode\u003e$N$\u003c/code\u003e 个元素的集合 \u003ccode\u003e$\\mathcal{X} = \\left\\{\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_n\\right\\}$\u003c/code\u003e，给定查询项 \u003ccode\u003e$\\mathbf{q}$\u003c/code\u003e 的最近邻 \u003ccode\u003e$NN \\left(\\mathbf{q}\\right) = \\arg\\min_{\\mathbf{x} \\in \\mathcal{X}} dist \\left(\\mathbf{q}, \\mathbf{x}\\right)$\u003c/code\u003e，其中 \u003ccode\u003e$dist \\left(\\mathbf{q}, \\mathbf{x}\\right)$\u003c/code\u003e 为 \u003ccode\u003e$\\mathbf{q}$\u003c/code\u003e 和 \u003ccode\u003e$\\mathbf{x}$\u003c/code\u003e 之间的距离。由于\u003ca href=\"/cn/2018/10/word-embeddings/#%E7%BB%B4%E6%95%B0%E7%81%BE%E9%9A%BE-the-curse-of-dimensionality\"\u003e维数灾难\u003c/a\u003e，我们很难在高维欧式空间中以较小的代价找到精确的最近邻。**近似最近邻搜索（Approximate Nearest Neighbor Search）**则是一种通过牺牲精度来换取时间和空间的方式从大量样本中获取最近邻的方法。\u003c/p\u003e\n\u003ch1 id=\"精确搜索\"\u003e精确搜索\u003c/h1\u003e\n\u003ch2 id=\"暴力查找-brute-force-search\"\u003e暴力查找（Brute-force Search）\u003c/h2\u003e\n\u003cp\u003e最简单的最邻近搜索便是遍历整个点集，计算它们和目标点之间的距离，同时记录目前的最近点。这样的算法较为初级，可以为较小规模的点集所用，但是对于点集的尺寸和空间的维数稍大的情况则不适用。对于 \u003ccode\u003e$D$\u003c/code\u003e 维的 \u003ccode\u003e$N$\u003c/code\u003e 个样本而言，暴力查找方法的复杂度为 \u003ccode\u003e$O \\left(DN\\right)$\u003c/code\u003e。\u003c/p\u003e\n\u003ch2 id=\"k-d-树\"\u003ek-D 树\u003c/h2\u003e\n\u003cp\u003ek-D 树（k-Dimesion Tree）\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e 是一种可以高效处理 \u003ccode\u003e$k$\u003c/code\u003e 维空间信息的数据结构。k-D 树具有二叉搜索树的形态，二叉搜索树上的每个结点都对应 \u003ccode\u003e$k$\u003c/code\u003e 维空间内的一个点。其每个子树中的点都在一个 \u003ccode\u003e$k$\u003c/code\u003e 维的超长方体内，这个超长方体内的所有点也都在这个子树中。k-D 树的构建过程如下：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e若当前超长方体中只有一个点，返回这个点。\u003c/li\u003e\n\u003cli\u003e选择一个维度，将当前超长方体按照这个维度分割为两个超长方体。\u003c/li\u003e\n\u003cli\u003e选择一个切割点，将小于这个点的归入其中一个超长方体（左子树），其余归入另一个超长方体（右子树）。\u003c/li\u003e\n\u003cli\u003e递归地对分出的两个超长方体构建左右子树。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e一个 \u003ccode\u003e$k = 2$\u003c/code\u003e 的例子如下：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-08-01-nearest-neighbor-search/k-d-tree.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e构建 k-D 树目前最优方法的时间复杂度为 \u003ccode\u003e$O \\left(n \\log n\\right)$\u003c/code\u003e。对于单次查询，当 \u003ccode\u003e$2$\u003c/code\u003e 维时，查询时间复杂度最优为 \u003ccode\u003e$O \\left(\\log n\\right)$\u003c/code\u003e，最坏为 \u003ccode\u003e$O \\left(\\sqrt{n}\\right)$\u003c/code\u003e，扩展至 \u003ccode\u003e$k$\u003c/code\u003e 维，最坏为 \u003ccode\u003e$O \\left(n^{1 - \\frac{1}{k}}\\right)$\u003c/code\u003e。k-D 树对于低维度最近邻搜索比较好，但当 \u003ccode\u003e$k$\u003c/code\u003e 增长到很大时，搜索的效率就变得很低，这也是“维数灾难”的一种体现。\u003c/p\u003e\n\u003ch2 id=\"ball-树\"\u003eBall 树\u003c/h2\u003e\n\u003cp\u003e为了解决 k-D 树在高维数据上的问题，Ball 树 \u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e 结构被提了出来。k-D 树是沿着笛卡尔积（坐标轴）方向迭代分割数据，而 Ball 树是通过一系列的超球体分割数据而非超长方体。Ball 树的构建过程如下：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e若当前超球体中只有一个点，返回这个点。\u003c/li\u003e\n\u003cli\u003e定义所有点的质心为 \u003ccode\u003e$c$\u003c/code\u003e，离质心 \u003ccode\u003e$c$\u003c/code\u003e 最远的点为 \u003ccode\u003e$c_1$\u003c/code\u003e，离 \u003ccode\u003e$c_1$\u003c/code\u003e 最远的点为 \u003ccode\u003e$c_2$\u003c/code\u003e。\u003c/li\u003e\n\u003cli\u003e将 \u003ccode\u003e$c_1$\u003c/code\u003e 和 \u003ccode\u003e$c_2$\u003c/code\u003e 作为聚类中心对数据点进行聚类得到两个簇 \u003ccode\u003e$\\left(c_1, r_1\\right), \\left(c_2, r_2\\right)$\u003c/code\u003e，将其归入左子树和右子树，其中 \u003ccode\u003e$r$\u003c/code\u003e 为超球的半径。\u003c/li\u003e\n\u003cli\u003e递归的对分出的两个超球体构建左右子树。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e一个二维的例子如下：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-08-01-nearest-neighbor-search/ball-tree.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e每个点必须只能隶属于一个簇，但不同簇的超球体之间是可以相交的。在利用 Ball 树进行查询时，首先自上而下的找到包含查询点的叶子簇 \u003ccode\u003e$\\left(c, r\\right)$\u003c/code\u003e，在这个簇中找到距离查询点最近的观测点，这两个点的距离 \u003ccode\u003e$d_{upper}$\u003c/code\u003e 即为\u003cstrong\u003e最近邻的距离上界\u003c/strong\u003e。之后检查该叶子簇的所有兄弟簇是否包含比这个上界更小的观测点，在检查时，如果查询节点距离兄弟簇圆心的距离大于兄弟簇的半径与之前计算的上界 \u003ccode\u003e$d_{upper}$\u003c/code\u003e 之和，则这个兄弟节点不可能包含所需要的最近邻。\u003c/p\u003e\n\u003cp\u003e构建 Ball 树的时间复杂度为 \u003ccode\u003e$O \\left(n \\left(\\log n\\right)^2\\right)$\u003c/code\u003e，查询时间复杂度为 \u003ccode\u003e$O \\left(\\log \\left(n\\right)\\right)$\u003c/code\u003e。\u003c/p\u003e\n\u003ch1 id=\"近似搜索\"\u003e近似搜索\u003c/h1\u003e\n\u003ch2 id=\"基于哈希的算法\"\u003e基于哈希的算法\u003c/h2\u003e\n\u003cp\u003e基于哈希的算法的目标是将一个高维数据点转换为哈希编码的表示方式，主要包含两类方法：\u003cstrong\u003e局部敏感哈希（Local Sensitive Hash, LSH）\u003cstrong\u003e和\u003c/strong\u003e哈希学习（Learning to Hash, L2H）\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3 id=\"局部敏感哈希\"\u003e局部敏感哈希\u003c/h3\u003e\n\u003cp\u003e局部敏感哈希采用的是与数据无关的哈希函数，也就是说整个学习处理过程不依赖于任何的数据内容信息。LSH 通过一个局部敏感哈希函数将相似的数据点以更高的概率映射到相同的哈希编码上去。这样我们在进行查询时就可以先找到查询样本落入那个哈希桶，然后再在这个哈希桶内进行遍历比较就可以找到最近邻了。\u003c/p\u003e\n\u003cp\u003e要使得相近的数据点通过哈希后落入相同的桶中，哈希函数需要满足如下条件：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e如果 \u003ccode\u003e$d \\left(x, y\\right) \\leq d_1$\u003c/code\u003e，则 \u003ccode\u003e$Pr \\left[h \\left(x\\right), h \\left(y\\right)\\right] \\geq p_1$\u003c/code\u003e。\u003c/li\u003e\n\u003cli\u003e如果 \u003ccode\u003e$d \\left(x, y\\right) \\geq d_2$\u003c/code\u003e，则 \u003ccode\u003e$Pr \\left[h \\left(x\\right), h \\left(y\\right)\\right] \\leq p_2$\u003c/code\u003e。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e其中，\u003ccode\u003e$x, y \\in \\mathbb{R}^n$\u003c/code\u003e 表示 \u003ccode\u003e$n$\u003c/code\u003e 维度数据点，\u003ccode\u003e$d \\left(x, y\\right)$\u003c/code\u003e 表示 \u003ccode\u003e$x, y$\u003c/code\u003e 之间的距离，\u003ccode\u003e$h$\u003c/code\u003e 为哈希函数。满足上述两个条件的哈希函数称为是 \u003ccode\u003e$\\left(d_1, d_2, p_1, p_2\\right)$\u003c/code\u003e 敏感的。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMinHash（Jaccard 距离）\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eMinHash 算法的思路是：采用一种哈希函数将元素的位置均匀打乱，然后在新顺序下每个集合的第一个元素作为该集合的特征值。我们以 \u003ccode\u003e$s_1 = \\left\\{a, d\\right\\}$\u003c/code\u003e，\u003ccode\u003e$s_2 = \\left\\{c\\right\\}$\u003c/code\u003e，\u003ccode\u003e$s_3 = \\left\\{b, d, e\\right\\}$\u003c/code\u003e，\u003ccode\u003e$s_4 = \\left\\{a, c, d\\right\\}$\u003c/code\u003e 为例，集合中可能的元素为 \u003ccode\u003e$\\left\\{a, b, c, d, e\\right\\}$\u003c/code\u003e，则这四个集合可以表示为：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth style=\"text-align:center\"\u003e元素\u003c/th\u003e\n\u003cth style=\"text-align:center\"\u003e\u003ccode\u003e$s_1$\u003c/code\u003e\u003c/th\u003e\n\u003cth style=\"text-align:center\"\u003e\u003ccode\u003e$s_2$\u003c/code\u003e\u003c/th\u003e\n\u003cth style=\"text-align:center\"\u003e\u003ccode\u003e$s_3$\u003c/code\u003e\u003c/th\u003e\n\u003cth style=\"text-align:center\"\u003e\u003ccode\u003e$s_4$\u003c/code\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:center\"\u003e\u003ccode\u003e$a$\u003c/code\u003e\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e1\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e1\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:center\"\u003e\u003ccode\u003e$b$\u003c/code\u003e\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e1\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:center\"\u003e\u003ccode\u003e$c$\u003c/code\u003e\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e1\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e1\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:center\"\u003e\u003ccode\u003e$d$\u003c/code\u003e\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e1\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e1\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e1\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:center\"\u003e\u003ccode\u003e$e$\u003c/code\u003e\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e1\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e对矩阵进行随机打乱后有：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth style=\"text-align:center\"\u003e元素\u003c/th\u003e\n\u003cth style=\"text-align:center\"\u003e\u003ccode\u003e$s_1$\u003c/code\u003e\u003c/th\u003e\n\u003cth style=\"text-align:center\"\u003e\u003ccode\u003e$s_2$\u003c/code\u003e\u003c/th\u003e\n\u003cth style=\"text-align:center\"\u003e\u003ccode\u003e$s_3$\u003c/code\u003e\u003c/th\u003e\n\u003cth style=\"text-align:center\"\u003e\u003ccode\u003e$s_4$\u003c/code\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:center\"\u003e\u003ccode\u003e$b$\u003c/code\u003e\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e1\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:center\"\u003e\u003ccode\u003e$e$\u003c/code\u003e\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e1\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:center\"\u003e\u003ccode\u003e$a$\u003c/code\u003e\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e1\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e1\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:center\"\u003e\u003ccode\u003e$d$\u003c/code\u003e\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e1\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e1\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e1\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:center\"\u003e\u003ccode\u003e$c$\u003c/code\u003e\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e1\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e1\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e我们利用每个集合的第一个元素作为该集合的特征值，则有 \u003ccode\u003e$h \\left(s_1\\right) = a$\u003c/code\u003e，\u003ccode\u003e$h \\left(s_2\\right) = c$\u003c/code\u003e，\u003ccode\u003e$h \\left(s_3\\right) = b$\u003c/code\u003e，\u003ccode\u003e$h \\left(s_4\\right) = a$\u003c/code\u003e，可以看出 \u003ccode\u003e$h \\left(s_1\\right) = h \\left(s_4\\right)$\u003c/code\u003e。MinHash 能够保证在哈希函数均匀分布的情况下，哈希值相等的概率等于两个集合的 Jaccard 相似度，即：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ Pr \\left(MinHash \\left(s_1\\right) = MinHash \\left(s_2\\right)\\right) = Jaccard \\left(s_1, s_2\\right) $$\u003c/code\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSimHash（汉明距离）\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSimHash 是由 Manku 等人 \u003csup id=\"fnref:3\"\u003e\u003ca href=\"#fn:3\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e3\u003c/a\u003e\u003c/sup\u003e 提出的一种用于用于进行网页去重的哈希算法。SimHash 作为局部敏感哈希算法的一种其主要思想是将高维特征映射到低维特征，再通过两个向量的汉明距离来确定是否存在重复或相似。算法步骤如下：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e对文本进行特征抽取（例如：分词），并为每个特征赋予一定的权重（例如：词频）。\u003c/li\u003e\n\u003cli\u003e计算每个特征的二进制哈希值。\u003c/li\u003e\n\u003cli\u003e计算加权后的哈希值，当哈希值为 1 时，则对应位置为 \u003ccode\u003e$w_i$\u003c/code\u003e，否则为 \u003ccode\u003e$-w_i$\u003c/code\u003e，其中 \u003ccode\u003e$w_i$\u003c/code\u003e 为该特征对应的权重。\u003c/li\u003e\n\u003cli\u003e将所有特征加权后的哈希值按对应的位置进行累加合并。\u003c/li\u003e\n\u003cli\u003e如果累加位置大于 0 则置为 1，否则置为 0，最终得到哈希结果。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e算法流程如下图所示：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-08-01-nearest-neighbor-search/simhash.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e在得到 SimHash 的值后，我们可以通过比较之间的汉明距离来判断相似性。为了提高海量数据的去重效率，以 64 位指纹为例，我们可以将其切分为 4 份 16 位的数据块，根据\u003ca href=\"https://zh.wikipedia.org/wiki/%E9%B4%BF%E5%B7%A2%E5%8E%9F%E7%90%86\"\u003e鸽巢原理\u003c/a\u003e，汉明距离为 3 的两个文档必定有一个数据块是相等的。将这 4 分数据利用 KV 数据库和倒排索引进行存储，Key 为 16 位的截断指纹，Value  为剩余的指纹集合，从而提高查询的效率。同时可以选择 16，8 和 4 位进行索引，位数越小越精确，但所需的存储空间越大。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ep-stable 分布（欧式距离）\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e当一个在 \u003ccode\u003e$\\Re$\u003c/code\u003e 上的分布 \u003ccode\u003e$\\mathcal{D}$\u003c/code\u003e 为 \u003ccode\u003e$p\\text{-stable}$\u003c/code\u003e 时，存在 \u003ccode\u003e$p \\geq 0$\u003c/code\u003e 使得对于任意 \u003ccode\u003e$n$\u003c/code\u003e 个实数 \u003ccode\u003e$v_1, \\cdots, v_n$\u003c/code\u003e 和独立同分布 \u003ccode\u003e$\\mathcal{D}$\u003c/code\u003e 下的变量 \u003ccode\u003e$X_1, \\cdots, X_n$\u003c/code\u003e，有随机变量 \u003ccode\u003e$\\sum_{i}{v_i X_i}$\u003c/code\u003e 和 \u003ccode\u003e$\\left(\\sum_{i}{\\left|v_i\\right|^p}\\right)^{1/p} X$\u003c/code\u003e 具有相同的分布，其中 \u003ccode\u003e$X$\u003c/code\u003e 为分布 \u003ccode\u003e$\\mathcal{D}$\u003c/code\u003e 下的随机变量 \u003csup id=\"fnref:4\"\u003e\u003ca href=\"#fn:4\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e4\u003c/a\u003e\u003c/sup\u003e。常见的 p-stable 分布有：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e柯西分布：密度函数为 \u003ccode\u003e$c \\left(x\\right) = \\dfrac{1}{\\pi} \\dfrac{1}{1 + x^2}$\u003c/code\u003e，为 \u003ccode\u003e$1\\text{-stable}$\u003c/code\u003e。\u003c/li\u003e\n\u003cli\u003e正态分布：密度函数为 \u003ccode\u003e$g \\left(x\\right) = \\dfrac{1}{\\sqrt{2 \\pi}} e^{-x^2 / 2}$\u003c/code\u003e，为 \u003ccode\u003e$2\\text{-stable}$\u003c/code\u003e。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003ep-stable 分布主要可以用于估计 \u003ccode\u003e$\\left\\|v\\right\\|_p$\u003c/code\u003e，对于两个相似的 \u003ccode\u003e$v_1, v_2$\u003c/code\u003e，它们应该具有更小的 \u003ccode\u003e$\\left\\|v_1 - v_2\\right\\|_p$\u003c/code\u003e，也就是对应的哈希值有更大的概率发生碰撞。对于 \u003ccode\u003e$v_1, v_2$\u003c/code\u003e，距离的映射 \u003ccode\u003e$a \\cdot v_1 - a \\cdot v_2$\u003c/code\u003e 和 \u003ccode\u003e$\\left\\|v_1 - v_2\\right\\|_p \\cdot X$\u003c/code\u003e 具有相同的分布。\u003ccode\u003e$a \\cdot v$\u003c/code\u003e 将向量 \u003ccode\u003e$v$\u003c/code\u003e 映射到实数集，如果将实轴以宽度 \u003ccode\u003e$w$\u003c/code\u003e 进行等分，\u003ccode\u003e$a \\cdot v$\u003c/code\u003e 落在哪个区间中就将其编号赋予它，这样构造的哈希函数具有局部保持特性。构造的哈希函数族的形式为：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ h_{a, b} \\left(v\\right) = \\left\\lfloor \\dfrac{a \\cdot v + b}{w} \\right\\rfloor $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，向量 \u003ccode\u003e$a$\u003c/code\u003e 的元素 \u003ccode\u003e$a_i \\sim N \\left(0, 1\\right)$\u003c/code\u003e，\u003ccode\u003e$b \\sim U \\left(0, w\\right)$\u003c/code\u003e。令 \u003ccode\u003e$c = \\left\\|u - v \\right\\|_p$\u003c/code\u003e，则两个向量在被分配到一个桶中的概率为：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e$$ Pr \\left[h_{a, b} \\left(u\\right) = h_{a, b} \\left(v\\right)\\right] = \\int_{0}^{w} \\dfrac{1}{c} \\cdot f_p \\left(\\dfrac{t}{u}\\right) \\left(1 - \\dfrac{t}{w}\\right) dt $$\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e其中，\u003ccode\u003e$f_p$\u003c/code\u003e 为概率密度函数。从上式中不难看出，随着距离 \u003ccode\u003e$c$\u003c/code\u003e 的减小，两个向量发生碰撞的概率增加。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e相关问题\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e局部敏感哈希可以在次线性时间内完成搜索，但缺点在于需要比较长的比特哈希码和比较多的哈希表才能达到预期的性能。\u003c/p\u003e\n\u003cp\u003e在单表哈希中，当哈希编码位数 \u003ccode\u003e$K$\u003c/code\u003e 过小时，每个哈希桶中数据个数较多，从而会增加查询的响应时间。当哈希编码位数 \u003ccode\u003e$K$\u003c/code\u003e 较大时，查询样本同最近邻落入同一个桶中的概率会很小。针对这个问题，我们可以通过重复 \u003ccode\u003e$L$\u003c/code\u003e 次来增加最近邻的召回率。这个操作可以转化为构建 \u003ccode\u003e$L$\u003c/code\u003e 个哈希表，给定一个查询样本，我们可以找到 \u003ccode\u003e$L$\u003c/code\u003e 个哈希桶，然后再遍历这 \u003ccode\u003e$L$\u003c/code\u003e 个哈希桶中的数据。但这样会增加内存的消耗，因此需要选择合理的 \u003ccode\u003e$K$\u003c/code\u003e 和 \u003ccode\u003e$L$\u003c/code\u003e 来获得更好的性能。\u003c/p\u003e\n\u003cp\u003eMulti-probe LSH \u003csup id=\"fnref:5\"\u003e\u003ca href=\"#fn:5\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e5\u003c/a\u003e\u003c/sup\u003e 引入了一种新的策略解决召回的问题。Multi-probe LSH 不仅仅会遍历查询样本所在桶内的元素，同时还会查询一些其他有可能包含最近邻的桶，从而在避免构建多个哈希表的情况下增加召回率。\u003c/p\u003e\n\u003ch3 id=\"哈希学习\"\u003e哈希学习\u003c/h3\u003e\n\u003cp\u003e哈希学习（Learning to Hash）是由 Salakhutdinov 和 Hinton \u003csup id=\"fnref:6\"\u003e\u003ca href=\"#fn:6\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e6\u003c/a\u003e\u003c/sup\u003e 引入到机器学习领域，通过机器学习机制将数据映射成二进制串的形式，能显著减少数据的存储和通信开销，从而有效提高学习系统的效率 \u003csup id=\"fnref:7\"\u003e\u003ca href=\"#fn:7\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e7\u003c/a\u003e\u003c/sup\u003e。从原空间中的特征表示直接学习得到二进制的哈希编码是一个 NP-Hard 问题。现在很多的哈希学习方法都采用两步学习策略：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e先对原空间的样本采用度量学习（Metric Learning）进行降维，得到 1 个低维空间的实数向量表示。\u003c/li\u003e\n\u003cli\u003e对得到的实数向量进行量化（即离散化）得到二进制哈希码。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e现有的方法对第二步的处理大多很简单，即通过某个阈值函数将实数转换成二进制位。通常使用的量化方法为 1 个阈值为 0 的符号函数，即如果向量中某个元素大于 0，则该元素被量化为 1，否则如果小于或等于 0，则该元素被量化为 0。\u003c/p\u003e\n\u003cp\u003e哈希学习相关的具体算法不再一一展开，更多细节请参见下文提供的相关 Survey。\u003c/p\u003e\n\u003ch2 id=\"矢量量化算法\"\u003e矢量量化算法\u003c/h2\u003e\n\u003cp\u003e**矢量量化（Vector Quantization）**是信息论中一种用于数据压缩的方法，其目的是减少表示空间的维度。一个量化器可以表示为由 \u003ccode\u003e$D$\u003c/code\u003e 维向量 \u003ccode\u003e$x \\in \\mathbb{R}^D$\u003c/code\u003e 到一个向量 \u003ccode\u003e$q \\left(x\\right) \\in \\mathcal{C} = \\left\\{c_i; i \\in \\mathcal{I}\\right\\}$\u003c/code\u003e 的映射 \u003ccode\u003e$q$\u003c/code\u003e，其中下标集合 \u003ccode\u003e$\\mathcal{I}$\u003c/code\u003e 为有限集合，即 \u003ccode\u003e$\\mathcal{I} = 0, \\cdots, k-1$\u003c/code\u003e。\u003ccode\u003e$c_i$\u003c/code\u003e 称之为形心（centroids），\u003ccode\u003e$\\mathcal{C}$\u003c/code\u003e 称之为大小为 \u003ccode\u003e$k$\u003c/code\u003e 的码本（codebook）。映射后的向量到一个给定下标 \u003ccode\u003e$i$\u003c/code\u003e 的集合 \u003ccode\u003e$\\mathcal{V}_i \\triangleq \\left\\{x \\in \\mathbb{R}^D: q \\left(x\\right) = c_i\\right\\}$\u003c/code\u003e（Voronoi），称之为一个单元（cell）。\u003c/p\u003e\n\u003cp\u003e以一个图像编码为例，我们通过 K-Means 算法得到 \u003ccode\u003e$k$\u003c/code\u003e 个 centroids，然后用这些 centroids 的像素值来替换对应簇中所有点的像素值。当 \u003ccode\u003e$k = 2, 10, 100$\u003c/code\u003e 时，压缩后的图像和原始图像的对比结果如下图所示：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-08-01-nearest-neighbor-search/lena-vq.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e当 \u003ccode\u003e$k = 100$\u003c/code\u003e 时，压缩后的图像和原始图像已经非常接近了，相关代码请参见\u003ca href=\"https://github.com/leovan/leovan.me/tree/main/static/codes/cn/2020-08-01-nearest-neighbor-search/vector-quantization.py\"\u003e这里\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e矢量量化以乘积量化（Product Quantization，PQ）最为典型，乘积量化的核心思想还是聚类，乘积量化生成码本和量化过程如下图所示：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-08-01-nearest-neighbor-search/product-quantization.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e在训练阶段，以维度为 128 的 \u003ccode\u003e$N$\u003c/code\u003e 个样本为例，我们将其切分为 4 个子空间，则每个子空间的维度为 32 维。对每一个子空间利用 K-Means 对其进行聚类，令聚类个数为 256，这样每个子空间就能得到一个 256 大小的码本。样本的每个子段都可以用子空间的聚类中心来近似，对应的编码即为类中心的 ID。利用这种编码方式可以将样本用一个很短的编码进行表示，从而达到量化的目的。\u003c/p\u003e\n\u003cp\u003e在查询阶段，我们将查询样本分成相同的子段，然后在每个子空间中计算子段到该子空间中所有聚类中心的距离，这样我们就得到了 \u003ccode\u003e$4 \\times 256$\u003c/code\u003e 个距离。在计算某个样本到查询样本的距离时，我们仅需要从计算得到的 4 组距离中将对应编码的距离取出相加即可，所有距离计算完毕排序后即可得到结果。\u003c/p\u003e\n\u003cp\u003e乘积量化有两种计算距离的方式 \u003csup id=\"fnref:8\"\u003e\u003ca href=\"#fn:8\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e8\u003c/a\u003e\u003c/sup\u003e：\u003cstrong\u003e对称距离\u003c/strong\u003e和\u003cstrong\u003e非对称距离\u003c/strong\u003e，如下图所示：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-08-01-nearest-neighbor-search/vq-symmetric-asymmetric-distance.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e对于 \u003ccode\u003e$x$\u003c/code\u003e 和 \u003ccode\u003e$y$\u003c/code\u003e 的距离 \u003ccode\u003e$d \\left(x, y\\right)$\u003c/code\u003e，对称距离利用 \u003ccode\u003e$d \\left(q \\left(x\\right), q \\left(y\\right)\\right)$\u003c/code\u003e 进行估计，非对称距离利用 \u003ccode\u003e$d \\left(x, q \\left(y\\right)\\right)$\u003c/code\u003e 进行估计。对称距离和非对称距离在不同阶段的时间复杂度如下表所示：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003e对称距离\u003c/th\u003e\n\u003cth\u003e非对称距离\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e编码 \u003ccode\u003e$x$\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$k^* D$\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e0\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e计算 \u003ccode\u003e$d \\left(u_j \\left(x\\right), c_{j, i}\\right)$\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e0\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$k^* D$\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e对于 \u003ccode\u003e$y \\in \\mathcal{Y}$\u003c/code\u003e，计算 \u003ccode\u003e$\\hat{d} \\left(x, y\\right)$\u003c/code\u003e 或 \u003ccode\u003e$\\tilde{d} \\left(x, y\\right)$\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$nm$\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$nm$\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e查找最小 \u003ccode\u003e$k$\u003c/code\u003e 个距离\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$n + k$\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003e$\\log k \\log \\log n$\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e其中，\u003ccode\u003e$k^*$\u003c/code\u003e 为 centroids 个数，\u003ccode\u003e$D$\u003c/code\u003e 为向量维度，\u003ccode\u003e$n$\u003c/code\u003e 为样本个数，\u003ccode\u003e$m$\u003c/code\u003e 为分割个数。通常情况下我们采用非对称距离，其更接近真实距离。\u003c/p\u003e\n\u003cp\u003eIVFADC \u003csup id=\"fnref1:8\"\u003e\u003ca href=\"#fn:8\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e8\u003c/a\u003e\u003c/sup\u003e 是乘积量化的的加速版本，乘积量化在计算距离时仍需逐个遍历相加计算。倒排乘积量化首先对 \u003ccode\u003e$N$\u003c/code\u003e 个样本采用 K-Means 进行聚类，此处的聚类中心相比乘积量化应设置较小的数值。在得到聚类中心后，针对每一个样本 \u003ccode\u003e$x_i$\u003c/code\u003e 找到距离最近的类中心 \u003ccode\u003e$c_i$\u003c/code\u003e，两者相减后得到残差 \u003ccode\u003e$x_i - c_i$\u003c/code\u003e，然后对残差再进行乘积量化的全过程。在查询阶段，通过先前较粗力度的量化快速定位隶属于哪一个 \u003ccode\u003e$c_i$\u003c/code\u003e，然后在 \u003ccode\u003e$c_i$\u003c/code\u003e 区域利用乘积量化获取最终结果。整个流程如下图所示：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-08-01-nearest-neighbor-search/ivfadc.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003eOptimized Product Quantization (OPQ) \u003csup id=\"fnref:9\"\u003e\u003ca href=\"#fn:9\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e9\u003c/a\u003e\u003c/sup\u003e 是乘积量化的一个优化方法。通常用于检索的原始特征维度较高，实践中利用乘积量化之前会对高维特征利用 PCA 等方法进行降维处理。这样在降低维度的时候还能够使得对向量进行子段切分的时候各个维度不相关。在利用 PCA 降维后，采用顺序切分子段仍存在一些问题，以 Iterative Quantization (ITQ) \u003csup id=\"fnref:10\"\u003e\u003ca href=\"#fn:10\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e10\u003c/a\u003e\u003c/sup\u003e 中的一个二维平面例子来说明，如下图所示：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-08-01-nearest-neighbor-search/itq.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e在利用乘积量化进行编码时，对于切分的各个子空间，应尽可能使得各个子空间的方差接近。上图中 \u003ccode\u003e$(a)$\u003c/code\u003e 图在 x 和 y 轴上的方差较大，而 \u003ccode\u003e$(c)$\u003c/code\u003e 图在两个方向上比较接近。OPQ 致力解决的问题就是对各个子空间方差上的均衡，OPQ 对于该问题的求解分为非参数求解方法和参数求解方法两种，更多算法细节请参见 ITQ 和 OPQ 原文。\u003c/p\u003e\n\u003ch2 id=\"基于图的算法\"\u003e基于图的算法\u003c/h2\u003e\n\u003cp\u003eNSW（Navigable Small World）\u003csup id=\"fnref:11\"\u003e\u003ca href=\"#fn:11\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e11\u003c/a\u003e\u003c/sup\u003e 算法是一种由 Malkov 等人提出的基于图的索引的方法。我们将 Navigable Small World 网络表示为一个图 \u003ccode\u003e$G \\left(V, E\\right)$\u003c/code\u003e，其中数据集合 \u003ccode\u003e$X$\u003c/code\u003e 的点被唯一映射到集合 \u003ccode\u003e$V$\u003c/code\u003e 中的一条边，边集 \u003ccode\u003e$E$\u003c/code\u003e 由构造算法确定。对于与一个节点 \u003ccode\u003e$v_i$\u003c/code\u003e 共享一条边的所有节点，我们称之为该节点的“友集”。\u003c/p\u003e\n\u003cp\u003e之后我们可以利用一个贪婪搜索的变种算法实现一个基本的 KNN 搜索算法。通过选择友集中未被访问过的距离查询样本最近的节点，可以在图中一个接一个的访问不同的节点，直到达到停止准则。整个过程如下图所示：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-08-01-nearest-neighbor-search/nsw.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e上图中的边扮演着两种不同的角色：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e短距离边的子集作为 \u003ca href=\"https://en.wikipedia.org/wiki/Delaunay_triangulation\"\u003eDelaunay 图\u003c/a\u003e的近似用于贪婪搜索算法。\u003c/li\u003e\n\u003cli\u003e长距离边的子集用于对数尺度的贪婪搜索，负责构造图的 Navigable Small World 属性。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e其中，黑色的边为短距离边，红色的边为长距离边，箭头为迭代查询路径。整个结构的构建可以通过元素的连续插入实现，对于新的元素，我们从当前结构中找到最接近的邻居集合与之相连。随着越来越多的元素插入到结构中，之前的短距离连接就变成了长距离连接。\u003c/p\u003e\n\u003cp\u003eNSW 的 KNN 查询过程如下所示：\u003c/p\u003e\n\n\n\u003clink rel=\"stylesheet\" type=\"text/css\" href=\"//cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css\"/\u003e\n\n\n\u003cdiv\u003e\u003cpre class=\"pseudocode\"\u003e\\begin{algorithm}\n\\caption{NSW 的 KNN 查询}\n\\begin{algorithmic}\n\\REQUIRE 查询样本 $q$，查询结果数量 $k$，最大迭代次数 $m$\n\\STATE $V_{cand} \\gets \\varnothing, V_{visited} \\gets \\varnothing, V_{res} \\gets \\varnothing$\n\\FOR{$i \\gets 1$ \\TO $m$}\n  \\STATE $V_{tmp} \\gets \\varnothing$\n  \\STATE $v_{rand} \\gets $ 随机初始节点\n  \\STATE $V_{cand} \\gets V_{cand} \\cup v_{rand}$\n  \\WHILE{True}\n    \\STATE $v_c \\gets V_{cand}$ 中距离 $q$ 最近的元素\n    \\STATE $V_{cand} \\gets V_{cand} \\setminus v_c$\n    \\IF{$v_c$ 比结果中的 $k$ 个元素距离 $q$ 还远}\n      \\BREAK\n    \\ENDIF\n    \\FOR{$v_e \\in v_c$ 的“友集”}\n      \\IF{$v_e \\notin V_{visited}$}\n        \\STATE $V_{visited} \\gets V_{visited} \\cup v_e, V_{cand} \\gets V_{cand} \\cup v_e, V_{tmp} \\gets V_{tmp} \\cup v_e$\n      \\ENDIF\n    \\ENDFOR\n  \\ENDWHILE\n  \\STATE $V_{res} \\gets V_{res} \\cup V_{tmp}$\n\\ENDFOR\n\\RETURN{$V_{res}$ 中与查询样本最近的 $k$ 个元素}\n\\end{algorithmic}\n\\end{algorithm}\n\u003c/pre\u003e\u003c/div\u003e\n\n\u003cp\u003eHNSW（Hierarchical Navigable Small World）\u003csup id=\"fnref:12\"\u003e\u003ca href=\"#fn:12\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e12\u003c/a\u003e\u003c/sup\u003e 是对 NSW 的一种改进。HNSW 的思想是根据连接的长度（距离）将连接划分为不同的层，然后就可以在多层图中进行搜索。在这种结构中，搜索从较长的连接（上层）开始，贪婪地遍历所有元素直到达到局部最小值，之后再切换到较短的连接（下层），然后重复该过程，如下图所示：\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-08-01-nearest-neighbor-search/hnsw.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n\u003c/figure\u003e\n\u003cp\u003e利用这种结构可以将原来 NSW 的多重对数（Polylogarithmic）计算复杂度降低至对数（Logarithmic）复杂度。更多关于数据插入和搜索的细节请参见原文。\u003c/p\u003e\n\u003cp\u003eNSG \u003csup id=\"fnref:13\"\u003e\u003ca href=\"#fn:13\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e13\u003c/a\u003e\u003c/sup\u003e 提出了一种新的图结构 Monotonic Relative Neighborhood Graph (MRNG) 用于保证一个平均的低搜索时间复杂度（接近对数复杂度）。同时为了进一步降低索引复杂度，作者从确保连接性、降低平均出度、缩短搜索路径和降低索引大小 4 个方面考虑，提出了一个用于近似 MRNG 的 Spreading-out Graph (NSG)。\u003c/p\u003e\n\u003cp\u003e基于图的方法 HNSW 和基于乘积量化的方法 OPQ 之间的特性对比如下：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e特点\u003c/th\u003e\n\u003cth\u003eOPQ\u003c/th\u003e\n\u003cth\u003eHNSW\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e内存占用\u003c/td\u003e\n\u003ctd\u003e小\u003c/td\u003e\n\u003ctd\u003e大\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e召回率\u003c/td\u003e\n\u003ctd\u003e较高\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e数据动态增删\u003c/td\u003e\n\u003ctd\u003e灵活\u003c/td\u003e\n\u003ctd\u003e不易\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e本文部分内容参考自 \u003ca href=\"https://yongyuan.name/blog/vector-ann-search.html\"\u003e图像检索：向量索引\u003c/a\u003e。\u003c/p\u003e\n\u003ch2 id=\"算法对比\"\u003e算法对比\u003c/h2\u003e\n\u003cp\u003e常用算法的开源实现的评测如下，更多评测结果请参见 \u003ca href=\"https://github.com/erikbern/ann-benchmarks/\"\u003eerikbern/ann-benchmarks\u003c/a\u003e。\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-08-01-nearest-neighbor-search/glove-100-k-10.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n  \u003cfigcaption class=\"kai\"\u003eGlove-100-Angular (K=10)\u003c/figcaption\u003e\n  \n\u003c/figure\u003e\n\u003cfigure\u003e\n  \u003cimg class=\"lazyload\" data-src=\"/images/cn/2020-08-01-nearest-neighbor-search/sift-128-k-10.png\" data-large-max-width=\"100%\" data-middle-max-width=\"100%\" data-small-max-width=\"100%\"/\u003e\n  \n  \u003cfigcaption class=\"kai\"\u003eSIFT-128-Euclidean (K=10)\u003c/figcaption\u003e\n  \n\u003c/figure\u003e\n\u003ch1 id=\"开放资源\"\u003e开放资源\u003c/h1\u003e\n\u003ch2 id=\"survey\"\u003eSurvey\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eA Survey on Learning to Hash \u003csup id=\"fnref:14\"\u003e\u003ca href=\"#fn:14\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e14\u003c/a\u003e\u003c/sup\u003e\u003c/li\u003e\n\u003cli\u003eA Survey on Nearest Neighbor Search Methods \u003csup id=\"fnref:15\"\u003e\u003ca href=\"#fn:15\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e15\u003c/a\u003e\u003c/sup\u003e\u003c/li\u003e\n\u003cli\u003eAn Investigation of Practical Approximate Nearest Neighbor Algorithms \u003csup id=\"fnref:16\"\u003e\u003ca href=\"#fn:16\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e16\u003c/a\u003e\u003c/sup\u003e\u003c/li\u003e\n\u003cli\u003eApproximate Nearest Neighbor Search on High Dimensional Data - Experiments, Analyses, and Improvement \u003csup id=\"fnref:17\"\u003e\u003ca href=\"#fn:17\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e17\u003c/a\u003e\u003c/sup\u003e\u003c/li\u003e\n\u003cli\u003eBinary Hashing for Approximate Nearest Neighbor Search on Big Data: A Survey \u003csup id=\"fnref:18\"\u003e\u003ca href=\"#fn:18\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e18\u003c/a\u003e\u003c/sup\u003e\u003c/li\u003e\n\u003cli\u003eHashing for Similarity Search: A Survey \u003csup id=\"fnref:19\"\u003e\u003ca href=\"#fn:19\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e19\u003c/a\u003e\u003c/sup\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"开源库\"\u003e开源库\u003c/h2\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e库\u003c/th\u003e\n\u003cth\u003eAPI\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/spotify/annoy\"\u003espotify/annoy\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-cpp\"\u003eC++\u003c/i\u003e, \u003ci class=\"icon icon-python\"\u003ePython\u003c/i\u003e, \u003ci class=\"icon icon-go\"\u003eGo\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/vioshyvo/mrpt\"\u003evioshyvo/mrpt\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-cpp\"\u003eC++\u003c/i\u003e, \u003ci class=\"icon icon-python\"\u003ePython\u003c/i\u003e, \u003ci class=\"icon icon-go\"\u003e\u003ca href=\"https://github.com/rikonor/go-ann\"\u003eGo\u003c/a\u003e\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/pixelogik/NearPy\"\u003epixelogik/NearPy\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-python\"\u003ePython\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/aaalgo/kgraph\"\u003eaaalgo/kgraph\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-cpp\"\u003eC++\u003c/i\u003e, \u003ci class=\"icon icon-python\"\u003ePython\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/nmslib/nmslib\"\u003enmslib/nmslib\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-cpp\"\u003eC++\u003c/i\u003e, \u003ci class=\"icon icon-python\"\u003ePython\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/nmslib/hnswlib\"\u003enmslib/hnswlib\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-cpp\"\u003eC++\u003c/i\u003e, \u003ci class=\"icon icon-python\"\u003ePython\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/lyst/rpforest\"\u003elyst/rpforest\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-python\"\u003ePython\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/facebookresearch/faiss\"\u003efacebookresearch/faiss\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-cpp\"\u003eC++\u003c/i\u003e, \u003ci class=\"icon icon-python\"\u003ePython\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/ekzhu/datasketch\"\u003eekzhu/datasketch\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-python\"\u003ePython\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/lmcinnes/pynndescent\"\u003elmcinnes/pynndescent\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-python\"\u003ePython\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/yahoojapan/NGT\"\u003eyahoojapan/NGT\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-c\"\u003eC\u003c/i\u003e, \u003ci class=\"icon icon-cpp\"\u003eC++\u003c/i\u003e, \u003ci class=\"icon icon-python\"\u003e\u003ca href=\"https://github.com/yahoojapan/NGT/blob/master/python/README.md\"\u003ePython\u003c/a\u003e\u003c/i\u003e, \u003ci class=\"icon icon-go\"\u003e\u003ca href=\"https://github.com/yahoojapan/gongt\"\u003eGo\u003c/a\u003e\u003c/i\u003e, \u003ci class=\"icon icon-ruby\"\u003e\u003ca href=\"https://github.com/ankane/ngt\"\u003eRuby\u003c/a\u003e\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/microsoft/SPTAG\"\u003emicrosoft/SPTAG\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-cpp\"\u003eC++\u003c/i\u003e, \u003ci class=\"icon icon-python\"\u003ePython\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/puffinn/puffinn\"\u003epuffinn/puffinn\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-cpp\"\u003eC++\u003c/i\u003e, \u003ci class=\"icon icon-python\"\u003ePython\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/kakao/n2\"\u003ekakao/n2\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-cpp\"\u003eC++\u003c/i\u003e, \u003ci class=\"icon icon-python\"\u003ePython\u003c/i\u003e, \u003ci class=\"icon icon-go\"\u003eGo\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/ZJULearning/nsg\"\u003eZJULearning/nsg\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-cpp\"\u003eC++\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"开源搜索引擎\"\u003e开源搜索引擎\u003c/h2\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e搜索引擎\u003c/th\u003e\n\u003cth\u003eAPI\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/milvus-io/milvus\"\u003emilvus-io/milvus\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-c\"\u003eC\u003c/i\u003e, \u003ci class=\"icon icon-cpp\"\u003eC++\u003c/i\u003e, \u003ci class=\"icon icon-python\"\u003ePython\u003c/i\u003e, \u003ci class=\"icon icon-java\"\u003eJava\u003c/i\u003e\u003cbr/\u003e\u003ci class=\"icon icon-go\"\u003eGo\u003c/i\u003e, \u003ci class=\"icon icon-nodejs\"\u003eNode.js\u003c/i\u003e, \u003ci class=\"icon icon-restful\"\u003eRESTful API\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/vearch/vearch\"\u003evearch/vearch\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ci class=\"icon icon-python\"\u003ePython\u003c/i\u003e, \u003ci class=\"icon icon-go\"\u003eGo\u003c/i\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"评测\"\u003e评测\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/erikbern/ann-benchmarks/\"\u003ehttps://github.com/erikbern/ann-benchmarks/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/DBWangGroupUNSW/nns_benchmark\"\u003ehttps://github.com/DBWangGroupUNSW/nns_benchmark\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"footnotes\" role=\"doc-endnotes\"\u003e\n\u003chr/\u003e\n\u003col\u003e\n\u003cli id=\"fn:1\"\u003e\n\u003cp\u003eBentley, J. L. (1975). Multidimensional binary search trees used for associative searching. \u003cem\u003eCommunications of the ACM\u003c/em\u003e, 18(9), 509-517. \u003ca href=\"#fnref:1\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:2\"\u003e\n\u003cp\u003eOmohundro, S. M. (1989). \u003cem\u003eFive balltree construction algorithms\u003c/em\u003e (pp. 1-22). Berkeley: International Computer Science Institute. \u003ca href=\"#fnref:2\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:3\"\u003e\n\u003cp\u003eManku, G. S., Jain, A., \u0026amp; Das Sarma, A. (2007, May). Detecting near-duplicates for web crawling. In \u003cem\u003eProceedings of the 16th international conference on World Wide Web\u003c/em\u003e (pp. 141-150). \u003ca href=\"#fnref:3\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:4\"\u003e\n\u003cp\u003eDatar, M., Immorlica, N., Indyk, P., \u0026amp; Mirrokni, V. S. (2004, June). Locality-sensitive hashing scheme based on p-stable distributions. In \u003cem\u003eProceedings of the twentieth annual symposium on Computational geometry\u003c/em\u003e (pp. 253-262). \u003ca href=\"#fnref:4\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:5\"\u003e\n\u003cp\u003eLv, Q., Josephson, W., Wang, Z., Charikar, M., \u0026amp; Li, K. (2007, September). Multi-probe LSH: efficient indexing for high-dimensional similarity search. In \u003cem\u003eProceedings of the 33rd international conference on Very large data bases\u003c/em\u003e (pp. 950-961). \u003ca href=\"#fnref:5\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:6\"\u003e\n\u003cp\u003eSalakhutdinov, Ruslan, and Geoffrey Hinton. “Semantic hashing.” \u003cem\u003eInternational Journal of Approximate Reasoning\u003c/em\u003e 50.7 (2009): 969-978. \u003ca href=\"#fnref:6\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:7\"\u003e\n\u003cp\u003e李武军, \u0026amp; 周志华. (2015). 大数据哈希学习: 现状与趋势. \u003cem\u003e科学通报, 60\u003c/em\u003e(5-6), 485-490. \u003ca href=\"#fnref:7\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:8\"\u003e\n\u003cp\u003eJegou, H., Douze, M., \u0026amp; Schmid, C. (2010). Product quantization for nearest neighbor search. \u003cem\u003eIEEE transactions on pattern analysis and machine intelligence\u003c/em\u003e, 33(1), 117-128. \u003ca href=\"#fnref:8\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e \u003ca href=\"#fnref1:8\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:9\"\u003e\n\u003cp\u003eGe, T., He, K., Ke, Q., \u0026amp; Sun, J. (2013). Optimized product quantization. \u003cem\u003eIEEE transactions on pattern analysis and machine intelligence\u003c/em\u003e, 36(4), 744-755. \u003ca href=\"#fnref:9\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:10\"\u003e\n\u003cp\u003eGong, Y., Lazebnik, S., Gordo, A., \u0026amp; Perronnin, F. (2012). Iterative quantization: A procrustean approach to learning binary codes for large-scale image retrieval. \u003cem\u003eIEEE transactions on pattern analysis and machine intelligence, 35\u003c/em\u003e(12), 2916-2929. \u003ca href=\"#fnref:10\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:11\"\u003e\n\u003cp\u003eMalkov, Y., Ponomarenko, A., Logvinov, A., \u0026amp; Krylov, V. (2014). Approximate nearest neighbor algorithm based on navigable small world graphs. \u003cem\u003eInformation Systems\u003c/em\u003e, 45, 61-68. \u003ca href=\"#fnref:11\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:12\"\u003e\n\u003cp\u003eMalkov, Y. A., \u0026amp; Yashunin, D. A. (2018). Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs. \u003cem\u003eIEEE transactions on pattern analysis and machine intelligence\u003c/em\u003e. \u003ca href=\"#fnref:12\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:13\"\u003e\n\u003cp\u003eFu, C., Xiang, C., Wang, C., \u0026amp; Cai, D. (2019). Fast approximate nearest neighbor search with the navigating spreading-out graph. \u003cem\u003eProceedings of the VLDB Endowment, 12\u003c/em\u003e(5), 461-474. \u003ca href=\"#fnref:13\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:14\"\u003e\n\u003cp\u003eWang, J., Zhang, T., Sebe, N., \u0026amp; Shen, H. T. (2017). A survey on learning to hash. \u003cem\u003eIEEE transactions on pattern analysis and machine intelligence, 40\u003c/em\u003e(4), 769-790. \u003ca href=\"#fnref:14\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:15\"\u003e\n\u003cp\u003eReza, M., Ghahremani, B., \u0026amp; Naderi, H. (2014). A Survey on nearest neighbor search methods. \u003cem\u003eInternational Journal of Computer Applications, 95\u003c/em\u003e(25), 39-52. \u003ca href=\"#fnref:15\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:16\"\u003e\n\u003cp\u003eLiu, T., Moore, A. W., Yang, K., \u0026amp; Gray, A. G. (2005). An investigation of practical approximate nearest neighbor algorithms. In \u003cem\u003eAdvances in neural information processing systems\u003c/em\u003e (pp. 825-832). \u003ca href=\"#fnref:16\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:17\"\u003e\n\u003cp\u003eLi, W., Zhang, Y., Sun, Y., Wang, W., Li, M., Zhang, W., \u0026amp; Lin, X. (2019). Approximate nearest neighbor search on high dimensional data-experiments, analyses, and improvement. \u003cem\u003eIEEE Transactions on Knowledge and Data Engineering\u003c/em\u003e. \u003ca href=\"#fnref:17\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:18\"\u003e\n\u003cp\u003eCao, Y., Qi, H., Zhou, W., Kato, J., Li, K., Liu, X., \u0026amp; Gui, J. (2017). Binary hashing for approximate nearest neighbor search on big data: A survey. \u003cem\u003eIEEE Access, 6\u003c/em\u003e, 2039-2054. \u003ca href=\"#fnref:18\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:19\"\u003e\n\u003cp\u003eWang, J., Shen, H. T., Song, J., \u0026amp; Ji, J. (2014). Hashing for similarity search: A survey. \u003cem\u003earXiv preprint arXiv:1408.2927\u003c/em\u003e. \u003ca href=\"#fnref:19\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e↩︎\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/div\u003e\n\n\n\n\n\n\u003cdiv class=\"donate\"\u003e\n  \u003cdiv class=\"donate-header\"\u003e\u003c/div\u003e\n  \u003cdiv class=\"donate-slug\" id=\"donate-slug\"\u003enearest-neighbor-search\u003c/div\u003e\n  \u003cbutton class=\"donate-button\"\u003e赞 赏\u003c/button\u003e\n  \u003cdiv class=\"donate-footer\"\u003e「真诚赞赏，手留余香」\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv class=\"donate-modal-wrapper\"\u003e\n  \u003cdiv class=\"donate-modal\"\u003e\n    \u003cdiv class=\"donate-box\"\u003e\n      \u003cdiv class=\"donate-box-content\"\u003e\n        \u003cdiv class=\"donate-box-content-inner\"\u003e\n          \u003cdiv class=\"donate-box-header\"\u003e「真诚赞赏，手留余香」\u003c/div\u003e\n          \u003cdiv class=\"donate-box-body\"\u003e\n            \u003cdiv class=\"donate-box-money\"\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-2\" data-v=\"2\" data-unchecked=\"￥ 2\" data-checked=\"2 元\"\u003e￥ 2\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-5\" data-v=\"5\" data-unchecked=\"￥ 5\" data-checked=\"5 元\"\u003e￥ 5\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-10\" data-v=\"10\" data-unchecked=\"￥ 10\" data-checked=\"10 元\"\u003e￥ 10\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-50\" data-v=\"50\" data-unchecked=\"￥ 50\" data-checked=\"50 元\"\u003e￥ 50\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-100\" data-v=\"100\" data-unchecked=\"￥ 100\" data-checked=\"100 元\"\u003e￥ 100\u003c/button\u003e\n              \u003cbutton class=\"donate-box-money-button donate-box-money-button-unchecked\" id=\"donate-box-money-button-custom\" data-v=\"custom\" data-unchecked=\"任意金额\" data-checked=\"任意金额\"\u003e任意金额\u003c/button\u003e\n            \u003c/div\u003e\n            \u003cdiv class=\"donate-box-pay\"\u003e\n              \u003cimg class=\"donate-box-pay-qrcode\" id=\"donate-box-pay-qrcode\" src=\"\"/\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n          \u003cdiv class=\"donate-box-footer\"\u003e\n            \u003cdiv class=\"donate-box-pay-method donate-box-pay-method-checked\" data-v=\"wechat-pay\"\u003e\n              \u003cimg class=\"donate-box-pay-method-image\" id=\"donate-box-pay-method-image-wechat-pay\" src=\"\"/\u003e\n            \u003c/div\u003e\n            \u003cdiv class=\"donate-box-pay-method\" data-v=\"alipay\"\u003e\n              \u003cimg class=\"donate-box-pay-method-image\" id=\"donate-box-pay-method-image-alipay\" src=\"\"/\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n      \u003c/div\u003e\n    \u003c/div\u003e\n    \u003cbutton type=\"button\" class=\"donate-box-close-button\"\u003e\n      \u003csvg class=\"donate-box-close-button-icon\" fill=\"#fff\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\"\u003e\u003cpath d=\"M13.486 12l5.208-5.207a1.048 1.048 0 0 0-.006-1.483 1.046 1.046 0 0 0-1.482-.005L12 10.514 6.793 5.305a1.048 1.048 0 0 0-1.483.005 1.046 1.046 0 0 0-.005 1.483L10.514 12l-5.208 5.207a1.048 1.048 0 0 0 .006 1.483 1.046 1.046 0 0 0 1.482.005L12 13.486l5.207 5.208a1.048 1.048 0 0 0 1.483-.006 1.046 1.046 0 0 0 .005-1.482L13.486 12z\" fill-rule=\"evenodd\"\u003e\u003c/path\u003e\u003c/svg\u003e\n    \u003c/button\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n\n\u003cscript type=\"text/javascript\" src=\"/js/donate.js\"\u003e\u003c/script\u003e\n\n\n  \u003cfooter\u003e\n  \n\u003cnav class=\"post-nav\"\u003e\n  \u003cspan class=\"nav-prev\"\u003e← \u003ca href=\"/cn/2020/07/model-free-policy-prediction-and-control-temporal-difference-learning/\"\u003e无模型策略预测和控制 - 时序差分学习 (Model-Free Policy Prediction and Control - Temporal Difference Learning)\u003c/a\u003e\u003c/span\u003e\n  \u003cspan class=\"nav-next\"\u003e\u003ca href=\"/cn/2020/08/life-before-30/\"\u003e而立之前 (Life before 30)\u003c/a\u003e →\u003c/span\u003e\n\u003c/nav\u003e\n\n\n\n\n\u003cins class=\"adsbygoogle\" style=\"display:block; text-align:center;\" data-ad-layout=\"in-article\" data-ad-format=\"fluid\" data-ad-client=\"ca-pub-2608165017777396\" data-ad-slot=\"8302038603\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n  (adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/js-cookie@3.0.5/dist/js.cookie.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/toggle-theme.js\"\u003e\u003c/script\u003e\n\n\n\u003cscript src=\"/js/no-highlight.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/math-code.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"/js/heading-anchor.js\"\u003e\u003c/script\u003e\n\n\n\n\u003csection class=\"comments\"\u003e\n\u003cscript src=\"https://giscus.app/client.js\" data-repo=\"leovan/leovan.me\" data-repo-id=\"MDEwOlJlcG9zaXRvcnkxMTMxOTY0Mjc=\" data-category=\"Comments\" data-category-id=\"DIC_kwDOBr89i84CT-R7\" data-mapping=\"pathname\" data-strict=\"1\" data-reactions-enabled=\"1\" data-emit-metadata=\"0\" data-input-position=\"top\" data-theme=\"preferred_color_scheme\" data-lang=\"zh-CN\" data-loading=\"lazy\" crossorigin=\"anonymous\" defer=\"\"\u003e\n\u003c/script\u003e\n\u003c/section\u003e\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"//cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"//cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js\"\u003e\u003c/script\u003e\n\u003cscript src=\"//cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/toolbar/prism-toolbar.min.js\"\u003e\u003c/script\u003e\n\u003cscript\u003e\n  (function() {\n    if (!self.Prism) {\n      return;\n    }\n\n    \n    Prism.languages.dos = Prism.languages.powershell;\n    Prism.languages.gremlin = Prism.languages.groovy;\n\n    let languages = {\n      'r': 'R', 'python': 'Python', 'xml': 'XML', 'html': 'HTML',\n      'yaml': 'YAML', 'latex': 'LaTeX', 'tex': 'TeX',\n      'powershell': 'PowerShell', 'javascript': 'JavaScript',\n      'dos': 'DOS', 'qml': 'QML', 'json': 'JSON', 'bash': 'Bash',\n      'text': 'Text', 'txt': 'Text', 'sparql': 'SPARQL',\n      'gremlin': 'Gremlin', 'cypher': 'Cypher', 'ngql': 'nGQL',\n      'shell': 'Shell', 'sql': 'SQL', 'apacheconf': 'Apache Configuration', 'c': 'C', 'css': 'CSS'\n    };\n\n    Prism.hooks.add('before-highlight', function(env) {\n      if (env.language !== 'plain') {\n        let language = languages[env.language] || env.language;\n        env.element.setAttribute('data-language', language);\n      }\n    });\n\n    \n    let ClipboardJS = window.ClipboardJS || undefined;\n\n    Prism.plugins.toolbar.registerButton('copy-to-clipboard', function(env) {\n      let linkCopy = document.createElement('button');\n      linkCopy.classList.add('prism-button-copy');\n\n      registerClipboard();\n\n      return linkCopy;\n\n      function registerClipboard() {\n        let clip = new ClipboardJS(linkCopy, {\n          'text': function () {\n            return env.code;\n          }\n        });\n\n        clip.on('success', function() {\n          linkCopy.classList.add('prism-button-copy-success');\n          resetText();\n        });\n        clip.on('error', function () {\n          linkCopy.classList.add('prism-button-copy-error');\n          resetText();\n        });\n      }\n\n      function resetText() {\n        setTimeout(function () {\n          linkCopy.classList.remove('prism-button-copy-success');\n          linkCopy.classList.remove('prism-button-copy-error');\n        }, 1600);\n      }\n    });\n  })();\n\u003c/script\u003e\n\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js\"\u003e\u003c/script\u003e\n\u003cscript type=\"text/javascript\"\u003e\nlet pseudocodeCaptionCount = 0;\n(function(d) {\n  d.querySelectorAll(\".pseudocode\").forEach(function(elem) {\n    let pseudocode_options = {\n      indentSize: '1.2em',\n      commentDelimiter: '\\/\\/',\n      lineNumber:  true ,\n      lineNumberPunc: ':',\n      noEnd:  false \n    };\n    pseudocode_options.captionCount = pseudocodeCaptionCount;\n    pseudocodeCaptionCount += 1;\n    pseudocode.renderElement(elem, pseudocode_options);\n  });\n})(document);\n\u003c/script\u003e\n\n\n\n\n\n\n\n\n\n\n\n\u003cscript async=\"\" src=\"/js/center-img.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/right-quote.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/external-link.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/alt-title.js\"\u003e\u003c/script\u003e\n\u003cscript async=\"\" src=\"/js/figure.js\"\u003e\u003c/script\u003e\n\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js\"\u003e\u003c/script\u003e\n\n\n\u003cscript src=\"//cdn.jsdelivr.net/npm/vanilla-back-to-top@latest/dist/vanilla-back-to-top.min.js\"\u003e\u003c/script\u003e\n\u003cscript\u003e\naddBackToTop({\n  diameter: 48\n});\n\u003c/script\u003e\n\n  \u003chr/\u003e\n  \u003cdiv class=\"copyright no-border-bottom\"\u003e\n    \u003cdiv class=\"copyright-author-year\"\u003e\n      \u003cspan\u003eCopyright © 2017-2024 \u003ca href=\"/\"\u003e范叶亮 | Leo Van\u003c/a\u003e\u003c/span\u003e\n    \u003c/div\u003e\n  \u003c/div\u003e\n  \u003c/footer\u003e\n  \u003c/article\u003e",
  "Date": "2020-08-01T00:00:00Z",
  "Author": "范叶亮"
}