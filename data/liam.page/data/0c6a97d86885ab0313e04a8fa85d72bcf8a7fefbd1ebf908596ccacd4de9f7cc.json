{
  "Source": "liam.page",
  "Title": "百度大搜的一些历史经验",
  "Link": "https://liam.page/2024/01/04/legacy-experience-of-Baidu-search/",
  "Content": "\u003cdiv class=\"post-body\" itemprop=\"articleBody\"\u003e\n\n      \n        \u003cp\u003e这是 2016 年 6 月和百度的技术专家交流的一些经验总结。近期翻出来，记录在这里。\u003c/p\u003e\n\u003cspan id=\"more\"\u003e\u003c/span\u003e\n\n\u003ch2 id=\"名词解释\"\u003e\u003ca href=\"#名词解释\" class=\"headerlink\" title=\"名词解释\"\u003e\u003c/a\u003e名词解释\u003c/h2\u003e\u003cul\u003e\n\u003cli\u003eAC：高级搜索（AS 拆出来的），类似于 tuner 上移后的 merger\u003c/li\u003e\n\u003cli\u003eDX：存储正排相关的内容，最简单的是存储每个 url 的所有文字内容，然后可以存储各种离线 parse 出来的内容（包括各种段落、命名实体等信息）\u003c/li\u003e\n\u003cli\u003eGBRank：可以认为是 GBDT 的同义词\u003c/li\u003e\n\u003cli\u003eBS：基于倒排索引的分布式索引的基础检索，类似于 qsrchd 或者 leaf\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"百度的在线-ranking-相关架构\"\u003e\u003ca href=\"#百度的在线-ranking-相关架构\" class=\"headerlink\" title=\"百度的在线 ranking 相关架构\"\u003e\u003c/a\u003e百度的在线 ranking 相关架构\u003c/h2\u003e\u003cp\u003e基本如图。这个应该是表意的，不是完全和实际情况对应的。\u003c/p\u003e\n\u003cp\u003e\u003cimg data-src=\"/uploads/images/algorithms/baidu-ranking-arch-2016.jpg\"/\u003e\u003c/p\u003e\n\u003cp\u003e重点说明：\u003c/p\u003e\n\u003cp\u003eDX - 正排库，对前 300 条结果进行精细正排计算，会重新计算 proximity。这个模块我们当前（2016）是缺失的，我们只有前 100 条结果的title。对方描述里这个模块是非常重要的，是百度 12 年相关性提升最大的项目。\u003c/p\u003e\n\u003cp\u003e百度的基本流程应该是 BS（qsrchd/leaf）返回结果，merge 后对前 300 条在 DX 重新排序，返回给 AC，AC 继续重新排序，然后返回。\u003c/p\u003e\n\u003cp\u003eDX 和 AC 各有一个 GBRank 模型来负责排序。\u003c/p\u003e\n\u003ch2 id=\"百度-LTR-的发展历程\"\u003e\u003ca href=\"#百度-LTR-的发展历程\" class=\"headerlink\" title=\"百度 LTR 的发展历程\"\u003e\u003c/a\u003e百度 LTR 的发展历程\u003c/h2\u003e\u003ch3 id=\"第一阶段：线性模型\"\u003e\u003ca href=\"#第一阶段：线性模型\" class=\"headerlink\" title=\"第一阶段：线性模型\"\u003e\u003c/a\u003e第一阶段：线性模型\u003c/h3\u003e\u003cp\u003e特征的线性拟合：$Y = \\sum_{i}\\omega_if_i$。\u003c/p\u003e\n\u003cp\u003e效果：和手写规则基本打平。\u003c/p\u003e\n\u003cp\u003e好处：基本验证机器学习是可行的，同时，可以得到每个特征有多大作用，即每个特征的 weight，这个 weight 的概念对于理解机器学习有非常大的作用，在后面用非线性模型时，他们依然找到一种计算特征weight的方法，这个方法在debug中也起到很大的作用。\u003c/p\u003e\n\u003ch3 id=\"第二阶段：GBRank\"\u003e\u003ca href=\"#第二阶段：GBRank\" class=\"headerlink\" title=\"第二阶段：GBRank\"\u003e\u003c/a\u003e第二阶段：GBRank\u003c/h3\u003e\u003cp\u003e这个和我们用的lambdaMart基本类似。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e标注量：DX 的 GBRank 当标注 query 上升到 7--8w 量级时，有明显提升，对比目前我们的标注量是不到 4w。\u003c/li\u003e\n\u003cli\u003e特征数量：100 左右，比我们少。他们每个特征都做的很细，都有可解释的物理意义，大部分特征会有相应的评测。相反我们有 180 个特征，但是大部分都是围绕点击来做的，同时特征可解释性差，没有单独评测。\u003c/li\u003e\n\u003cli\u003edebug 平台：强大的 debug 平台，可以计算每个特征的 weight，在树模型里，对方描述的计算 weight 的方法是在给定的数据集上，固定其他的特征，观察目标特征的变化导致的预测值的变化，用这个变化来计算 weight 的权重。对于具体的 badcase，如果是由于这个 case 在某些特征上不合理，预期 debug 平台是能够发现，所以通过 badcase + debug 平台，能够逐步地改进特征。\u003c/li\u003e\n\u003cli\u003e控制diff，当新加特征时，diff率太大的问题。对方的描述中也提到尝试过 continue train。但是他们最后使用的是bagging的方法来提升模型的稳定性，这个思路我们之前没有想到过，可以借鉴。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"第三阶段：深度学习\"\u003e\u003ca href=\"#第三阶段：深度学习\" class=\"headerlink\" title=\"第三阶段：深度学习\"\u003e\u003c/a\u003e第三阶段：深度学习\u003c/h3\u003e\u003cp\u003e基本思路和我们目前做的是一样的，但是各种细节还是不一样\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e使用长尾 query 的点击与未点击的数据作为训练数据，他们并没有观察过数据的准确率，但估计还行。相反地，我们用各种方法得到的数据准确率偏低，这个可以在多尝试一些方法。\u003c/li\u003e\n\u003cli\u003e大数据量，100 亿规模，与之对比的是我们只有 1 亿的规模。\u003c/li\u003e\n\u003cli\u003e模型简单，基本上只有一个隐层。\u003c/li\u003e\n\u003cli\u003e多机并行版本，百度 IDL 提供的平台。\u003c/li\u003e\n\u003cli\u003e将深度学习得到的语义相似度作为模型加入到 BRank 里。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"问答环节\"\u003e\u003ca href=\"#问答环节\" class=\"headerlink\" title=\"问答环节\"\u003e\u003c/a\u003e问答环节\u003c/h2\u003e\u003cp\u003eQ： 百度如何评测\u003c/p\u003e\n\u003cp\u003eA： 测试集 ndcg + 人工 side by side + 线上小流量实验\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：DX 的作用\u003c/p\u003e\n\u003cp\u003eA：DX 提供的正排对于计算 proximity，term 紧密度非常重要，是必不可少的一个模块，并且为后续的一些质量改进可能也提供了基础，对长尾 query 的提升非常大\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：DX 具体存了什么\u003c/p\u003e\n\u003cp\u003eA：url 的正排，同时包括 entity/anchor 等，提到分域存储（这个回答貌似不是很全面）\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：GBRank 如何控制 diff\u003c/p\u003e\n\u003cp\u003eA：用 bagging 来提升模型稳定性，可以是几个 bagging 的 GBRank，也可以是 GBRank 里面每棵树用 bagging 的方法来生成多个树。Bagging 的 GBDT 已经有人做过了，但是效果和非 bagging 的差不多，但是之前没有人从模型稳定性来看这个问题，从稳定性的角度来看，bagging 就比较重要了。\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：ltr 的标注规模\u003c/p\u003e\n\u003cp\u003eA：DX 上升到 7--8w 时效果提升比较大，百度的整体标注规模在几十万 query 级别。每个 query 标注了 20 条。\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：ltr 标注 query 是怎么选取的\u003c/p\u003e\n\u003cp\u003eA： 随机，偏向长尾，40%是长尾的。还说看长尾是怎样定义，貌似听见一个搜索次数小于 10 次。\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：是否采用 active learning 来选取标注集\u003c/p\u003e\n\u003cp\u003eA： 没有，但是后来在 spam 的机器学习上有采用，因为 spam 的样本少。\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：百度的标注人力是怎样的\u003c/p\u003e\n\u003cp\u003eA：全公司的标注是外包的，只需要在平台提交标注任务就可以了\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：新特征的开发过程是怎样的，是否需要先经过评测，还是直接放到 GBRank 里，通过 debug 来发现特征是否符合预期\u003c/p\u003e\n\u003cp\u003eA： 新特征一般来讲还是要先经过评测，确保和 label 有一定的相关性\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：一些需要组合的特征，是否直接加入模型\u003c/p\u003e\n\u003cp\u003eA：从理论上来讲，直接加入，期望模型学习出来各种组合是可以的，但百度不是这样干的，如果你觉得一些特征需要组合，最好手动组合，把组合后的特征加入到模型\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：特征的 weight 是如何计算的\u003c/p\u003e\n\u003cp\u003eA：类似于算导数的方法，上面已经大概说过了。\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：LTR 的工作方向，模型为主还是特征为主\u003c/p\u003e\n\u003cp\u003eA：经历不同时期，一开始模型为主，后面加入 DNN 后，特征变的很大，很难做，当然这些特征也是 LTR 团队做。LTR 团队一开始 4 个人，后面发展到接近 20 人。\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：新特征的上线方式\u003c/p\u003e\n\u003cp\u003eA：如果另外一个团队升级了一个特征，一般来讲不重新训练，直接上线。如果是新加了特征，ltr 团队会负责重新训练。如果同时加了多个特征，也是 ltr 团队负责重新训练上线\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：GBRank 上面是否还有 ranksvm\u003c/p\u003e\n\u003cp\u003eA： 没有\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：DNN 的并行化方式\u003c/p\u003e\n\u003cp\u003eA：用的 IDL 的平台，100 多台机器？100 亿的数据规模， 一开始模型比较简单，经过 4--5 个月做出来后，效果非常好。后面也逐渐尝试 cnn，rnn 等\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：目前我们 1 亿的数据，有啥建议\u003c/p\u003e\n\u003cp\u003eA：先把数据加到 10 亿，看看效果。他们在 1 亿的时候效果也不明显。可以把 1kw/5kw 数据时的结果拿来观察\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：ltr 标注量多少比较合适\u003c/p\u003e\n\u003cp\u003eA：DX在标注到 7--8w 时有比较大的突破。 这个数据提到好几次，可能他们的实际情况确实是数据量提升到 7--8w 时产生了一个质变。\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：DX 也是 GBRank\u003c/p\u003e\n\u003cp\u003eA：是，DX 也是用 GBRank 来排序\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：AC 还有多少基于规则的排序\u003c/p\u003e\n\u003cp\u003eA：基本没有了，都被替换了，但是 AC 的上游 US 还有一些规则，例如合并 onebox 等\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：百度结果里经常靠百度知道顶着，大搜索是否对百度知道有特殊处理，例如单字检索等\u003c/p\u003e\n\u003cp\u003eA：没有对百度知道特殊处理。但是百度知道是一个垂搜， US会请求。同时百度知道有很多站内的权重数据，可能做的比较好\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：DNN 出来的值是作为特征加入到 GBRank 里的吗？\u003c/p\u003e\n\u003cp\u003eA：是的\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：LTR 技术的发展过程\u003c/p\u003e\n\u003cp\u003eA：先是把 rank 的 LTR 做好，站住脚，然会向外输出技术，例如泛时效性 query 的识别，省略与 termweight、spam 等。\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003eQ：DNN 的关键\u003c/p\u003e\n\u003cp\u003eA：数据量，必须上大数据量。与 msra 的 gaojianhong 交流是，对于 msra 只用了 1 亿的数据量很鄙视\u003c/p\u003e\n\u003ch2 id=\"总结\"\u003e\u003ca href=\"#总结\" class=\"headerlink\" title=\"总结\"\u003e\u003c/a\u003e总结\u003c/h2\u003e\u003col\u003e\n\u003cli\u003eLTR 使用的特征非常谨慎：对特征做了很多特征工程，尽量让每个特征有意义。\u003c/li\u003e\n\u003cli\u003eDX 起到关键作用，DX 在长尾 query 的基础相关性上起到决定性作用，提供了很多特征。\u003c/li\u003e\n\u003cli\u003eGBRank 的 debug 平台非常重要，必不可少。\u003c/li\u003e\n\u003cli\u003eDNN 必须上大数据量。\u003c/li\u003e\n\u003c/ol\u003e\n\n    \u003c/div\u003e",
  "Date": "2024-01-04T01:10:24Z",
  "Author": "Liam Huang"
}