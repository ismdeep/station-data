{
  "Source": "raphlinus.github.io",
  "Title": "Synthesizer progress update",
  "Link": "https://raphlinus.github.io/synthesizer/2018/09/19/synth-update.html",
  "Content": "\u003cdiv class=\"post-content e-content\" itemprop=\"articleBody\"\u003e\n    \u003cp\u003eI’ve made good progress on my music synthesizer, and wanted to post a quick update.\u003c/p\u003e\n\n\u003ch2 id=\"a-working-tech-demo\"\u003eA working tech demo\u003c/h2\u003e\n\n\u003cp\u003eIf you’re on Windows, clone \u003ca href=\"https://github.com/raphlinus/synthesizer-io\"\u003eraphlinus/synthesizer-io\u003c/a\u003e, go to \u003ccode class=\"language-plaintext highlighter-rouge\"\u003esynthesizer-io-win\u003c/code\u003e, and then \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ecargo run\u003c/code\u003e. You’ll get a working synthesizer with a piano keyboard you can play with the mouse. If you have a MIDI keyboard plugged in, you can play that. If that’s an Akai MPK Mini, then the knobs are mapped to filter cutoff, resonance, and ADSR for the envelope. It’s not a very exciting sound, and it’s not a very polished GUI, but I’m still quite happy that these pieces have come together.\u003c/p\u003e\n\n\u003cp\u003eThere are some interesting things going on under the hood, some of which I’ll talk about below. Basically, I wanted to know whether this approach is viable. I’m now convinced it is.\u003c/p\u003e\n\n\u003cp\u003eI explored some other alternatives, including compiling the Rust code to wasm and using Web tech to build the UI, but ultimately concluded I didn’t want to do that.\u003c/p\u003e\n\n\u003ch2 id=\"a-new-synth-engine\"\u003eA new synth engine\u003c/h2\u003e\n\n\u003cp\u003eI’m working toward a new modular synthesizer similar to \u003ca href=\"https://en.wikipedia.org/wiki/Max_(software)\"\u003eMax/MSP\u003c/a\u003e, and also a bit like \u003ca href=\"https://vcvrack.com/\"\u003eVCV Rack\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eWhy a new one? Existing patching languages like Max are a little intimidating; mine is designed to be easier to learn. I want a stronger focus on visualization and highly responsive feedback. Lastly, I’m excited by the idea of pushing performance to the limit.\u003c/p\u003e\n\n\u003cp\u003eA central tenet of the engine is that the real-time audio rendering thread is rigorously non-blocking. As Ross Bencina has eloquently written, \u003ca href=\"http://www.rossbencina.com/code/real-time-audio-programming-101-time-waits-for-nothing\"\u003e“time waits for nothing”\u003c/a\u003e. To avoid glitches, the audio thread can’t block on a mutex (which may be held by a lower priority thread, thus \u003ca href=\"https://en.wikipedia.org/wiki/Priority_inversion\"\u003epriority inversion\u003c/a\u003e), access the filesystem, or do IO. All that makes sense, but doesn’t sound too restrictive. It also can’t allocate, because standard allocators internally have mutexes, and quite nondeterministic time behavior. That’s hugely restrictive.\u003c/p\u003e\n\n\u003cp\u003eAt the same time, I want the behavior to be dynamic. I want to be able to patch the processing graph in real time, without glitches. I want voice allocation to be fully dynamic. These seem like perhaps irreconcilable wishes.\u003c/p\u003e\n\n\u003cp\u003eTo that end, I’ve worked out a highly customized lock-free queue, which I think gets me everything I want. The main thread can be very dynamic and allocate all it wants, while the real-time thread renders the audio using objects allocated by the main thread, and then when it’s done with those objects (for example, when they’re deleted from the graph), sends them back on a return channel, where the main thread will drop them at its leisure. The code seems to work.\u003c/p\u003e\n\n\u003cp\u003eI hope to blog about this more, and also see below.\u003c/p\u003e\n\n\u003ch2 id=\"audio-infrastructure\"\u003eAudio infrastructure\u003c/h2\u003e\n\n\u003cp\u003eI’ve started poking around pieces of audio infrastructure in the Rust ecosystem. There’s some pretty good stuff, but I think a lot of scope to make it better. For example, the vst crate is not \u003ca href=\"https://github.com/rust-dsp/rust-vst/issues/49\"\u003ethread safe\u003c/a\u003e, and I’m participating in the discussion of how to make that better.\u003c/p\u003e\n\n\u003cp\u003eSimilarly, from my initial experimentation, \u003ca href=\"https://github.com/tomaka/cpal\"\u003ecpal\u003c/a\u003e seems to be pretty good on macOS, but I have concerns about performance on Windows, as it seems to run the audio callback on the main thread, use mutexes rather than lock free queues, and \u003ca href=\"https://github.com/tomaka/cpal/issues/106\"\u003edoesn’t do exclusive mode\u003c/a\u003e. My inclination is to dig in and try to bring cpal up to what I want, which I think will benefit the Rust ecosystem as a whole. Maintainers of those crates, be prepared for me to be quite annoying in the coming weeks.\u003c/p\u003e\n\n\u003ch2 id=\"gui-and-porting\"\u003eGUI and porting\u003c/h2\u003e\n\n\u003cp\u003eFor the GUI, I’m continuing the “data oriented” approach I \u003ca href=\"/personal/2018/05/08/ecs-ui.html\"\u003ewrote\u003c/a\u003e and \u003ca href=\"https://www.youtube.com/watch?v=4YTfxresvS8\"\u003espoke\u003c/a\u003e about a few months ago. So far it’s feeling good.\u003c/p\u003e\n\n\u003cp\u003eHowever, for now it’s Windows-only, and I’m very interested in porting to other platforms. Rust itself works fine on pretty much every target I care about, so the main tricky dependency is 2D graphics. Right now, I’m using Direct2D (and DirectWrite for text) pretty much directly (through wrapper crates written by \u003ca href=\"https://github.com/Connicpu\"\u003eConnie Hilarides\u003c/a\u003e).\u003c/p\u003e\n\n\u003cp\u003eThere are a number of options for making this code portable.\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\n    \u003cp\u003eContinuing to use the Direct2D API, but with portable implementations (\u003ca href=\"https://www.winehq.org/\"\u003eWine\u003c/a\u003e has done lots of this).\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003eAdopting an existing cross-platform graphics library. \u003ca href=\"https://skia.org/\"\u003eSkia\u003c/a\u003e and \u003ca href=\"https://cairographics.org/\"\u003eCairo\u003c/a\u003e are possibilities, and \u003ca href=\"https://github.com/servo/webrender\"\u003eWebRender\u003c/a\u003e is also promising.\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003eCreating a cross-platform 2D graphics API layer with multiple back-ends. This feels closest to the Rust Way, and is similar to what \u003ca href=\"https://github.com/gfx-rs/gfx\"\u003egfx-rs\u003c/a\u003e is doing for 3D graphics.\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eOf course, one of the biggest challenges in 2D graphics is fonts and text, and there are choices there as well. For now, it’s very appealing to just use the system text APIs, because on Windows at least, they work well and are mature.\u003c/p\u003e\n\n\u003cp\u003eThis is an area where I could possibly use some help, though it won’t be on my critical path for a while, as I’m happy doing the prototype Windows-first. People who are interested in collaborating, let’s talk.\u003c/p\u003e\n\n\u003ch2 id=\"see-you-in-november\"\u003eSee you in November\u003c/h2\u003e\n\n\u003cp\u003eThough I’m posting my synthesizer code to public Github, I’m largely in stealth mode for now. I plan to speak at the November SF Rust meetup, at which I hope to present a more polished version of the synthesizer, and also talk in much more detail about the lock-free work and how it can support truly high performance audio synthesis in Rust.\u003c/p\u003e\n\n  \u003c/div\u003e",
  "Date": "2018-09-19T16:26:03Z",
  "Author": "raphlinus"
}