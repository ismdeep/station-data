{
  "Source": "raphlinus.github.io",
  "Title": "2D Graphics on Modern GPU",
  "Link": "https://raphlinus.github.io/rust/graphics/gpu/2019/05/08/modern-2d.html",
  "Content": "\u003cdiv class=\"post-content e-content\" itemprop=\"articleBody\"\u003e\n    \u003cp\u003eIs the traditional 2D imaging model nearing the end of its usefulness, or does it have a shiny future in the “modern graphics” world? I spent a week on a research retreat in a \u003ca href=\"https://www.stonesthrowfarmca.com/\"\u003ecottage in the woods\u003c/a\u003e to answer this question, as it shapes the future of UI toolkits. Performant UI \u003cem\u003emust\u003c/em\u003e use GPU effectively, and it’s increasingly common to write UI directly in terms of GPU rendering, without a 2D graphics API as in the intermediate layer. Is that the future, or perhaps a mistake?\u003c/p\u003e\n\n\u003cp\u003eI have found that, if you can depend on modern compute capabilities, it seems quite viable to implement 2D rendering directly on GPU, with very promising quality and performance. The prototype I built strongly resembles a software renderer, just running on an outsized multicore GPU with wide SIMD vectors, much more so than rasterization-based pipelines.\u003c/p\u003e\n\n\u003cp\u003eWriting a 2D renderer is a fairly ambitious project, doubly so to make it run efficiently on GPU. I deliberately reduced the scope of the project in a number of ways to make it viable. Most importantly, I targeted \u003cem\u003eonly\u003c/em\u003e Metal 2.1, which is only a year old and only at \u003ca href=\"http://gs.statcounter.com/macos-version-market-share/desktop/worldwide\"\u003e42.5% share\u003c/a\u003e among worldwide macOS users. Thus, I am targeting the near future of GPU and ignoring the past. My faithful readers will no doubt be curious how much of this work can be adapted to older GPUs, but I believe that’s a much more complex question, and one I deliberately did not address. (Other work like \u003ca href=\"https://github.com/pcwalton/pathfinder\"\u003ePathFinder\u003c/a\u003e is more appropriate.)\u003c/p\u003e\n\n\u003cp\u003eThat said, I think the capabilities of Metal 2.1 are fairly mainstream and more so in coming years. From my perspective, it finally lets us program a GPU as if it were a big SIMD computer, which is basically what it’s been under the hood for a long time. Looking at newer features in, for example, \u003ca href=\"https://developer.nvidia.com/cuda-toolkit/whatsnew\"\u003eCUDA 10\u003c/a\u003e, I don’t see anything that would profoundly change the way I would approach this problem. I believe this is a very attractive target for research and practice in efficient GPU implementation of classical algorithms.\u003c/p\u003e\n\n\u003cp\u003eIt’s not surprising that 2D graphics can be efficiently implemented on GPU. The excellent 2014 \u003ca href=\"http://w3.impa.br/~diego/projects/GanEtAl14/\"\u003eMassively-Parallel Vector Graphics\u003c/a\u003e was a major inspiration to this work, and there have been follow-ups such as \u003ca href=\"http://kunzhou.net/zjugaps/pathrendering/\"\u003eLi 2016\u003c/a\u003e that promise even more performance. But both of these papers seemed very complex and focused narrowly on path rendering.\u003c/p\u003e\n\n\u003cp\u003eI had great fun implementing my prototype and learned a lot. Along the way I kept a \u003ca href=\"https://docs.google.com/document/d/1LILagXyJgYtlm6y83x1Mc2VoNfOcvW_ZiCldZbs4yO8/edit?usp=sharing\"\u003enotes document\u003c/a\u003e that recounts some of my struggles and touches on some deeper topics that I will only briefly touch on in this blog post. The \u003ca href=\"https://github.com/linebender/piet-metal\"\u003ecode\u003c/a\u003e is available and could be fun to play with or look at.\u003c/p\u003e\n\n\u003cp\u003eI’ll stress again that this is a research prototype, not a finished product. The most promising use case for the work is likely CAD tools, where there might be quite complex scenes and it’s not necessarily practical to organize the UI drawing around GPU primitives (as opposed to 3D games, for example).\u003c/p\u003e\n\n\u003ch2 id=\"the-architecture\"\u003eThe architecture\u003c/h2\u003e\n\n\u003cp\u003eRendering starts with a “scene graph,” which is an on-GPU serialization of 2D drawing operations. It has a tree structure, in that operations like clipping are represented as a node with children; in the case of clipping, one child for the clip mask and another for the contents being clipped. It also has a graph structure, in that multiple instances can be shared by reference (with appropriate transform nodes to change their position). (Note: I didn’t get around to implementing much of the graph structure, but the prototype is designed to accommodate it without much trouble. I’m describing it anyway because it’s important to the motivation).\u003c/p\u003e\n\n\u003cp\u003eThe imaging model allows per-pixel operations only; operations like blur are purposefully excluded. Thus, a simplistic approach to parallel rendering would be for each pixel in the target framebuffer to traverse the scene graph, applying the computation at each node (each of which can be seen as a small functional program), and finally writing the pixel color computed at the root node. That approach is of course quite inefficient, but forms the basis of what the code actually does.\u003c/p\u003e\n\n\u003cp\u003eTo achieve performance, the code divides the target framebuffer into fixed size \u003cem\u003etiles,\u003c/em\u003e currently 16x16 pixels each. There are two passes, a \u003cem\u003etiling pass\u003c/em\u003e that creates a command list for each tile, and a \u003cem\u003erendering pass\u003c/em\u003e that consumes the command list, evaluating all 256 pixels of the tile in parallel, each pixel sequentially evaluating the commands for the tile.\u003c/p\u003e\n\n\u003cp\u003eNote that the approach to tiling is similar to \u003ca href=\"https://github.com/pcwalton/pathfinder\"\u003ePathFinder\u003c/a\u003e, but with important differences in the details. PathFinder renders intermediate alpha masks to a mask texture buffer, requiring a write and a read of global device memory, but I do all the blending in local memory in the rendering shader, as in \u003ca href=\"http://w3.impa.br/~diego/projects/GanEtAl14/\"\u003eMPVG\u003c/a\u003e. Minimizing global memory traffic is a major shared theme.\u003c/p\u003e\n\n\u003cp\u003eA 16x16 tile should be close to the sweet spot. It results in 128x96 (12k total) tiles for a typical 2048x1536 window. It’s not a huge amount of work to generate the tiles, but with fewer tiles it would be harder to exploit parallelism in the tiling phase. Similarly, if graphic elements are much smaller than the tile size, there would be wasted work during rendering, as (for the most part) the entire tile needs to be rendered for any element that touches the tile. But again, 16x16 is a good size for a threadgroup dispatch, to exploit parallelism within the tile, and the savings from the leftover parts of a tile would be offset by per-tile overhead as tiles get smaller. It’s always possible to tune such things, but it’s not reasonable to expect any big wins. (I will note, though, that \u003ca href=\"http://w3.impa.br/~diego/projects/GanEtAl14/\"\u003eMPVG\u003c/a\u003e uses a quadtree structure, which basically amounts to adapting tile size to the workload. There are potential savings, but I also think it adds a lot to their overall complexity.)\u003c/p\u003e\n\n\u003cp\u003eThe rendering kernel (similar to a fragment shader) is fairly straightforward - it’s basically just computing signed area coverage for fills, distance fields for strokes, texture sampling for images and pre-rendered glyphs, and blends for clipping and compositing. The functional program represented by the scene graph is flattened into a linear sequence of operations, filtered of course to only those elements that touch the tile. For blend groups, nesting in the scene graph is represented by push/pop operations, with an explicit, local stack. (Again disclosure: I didn’t get too far into actually implementing blend groups, but it should be easy to see how they’d work).\u003c/p\u003e\n\n\u003cp\u003eThus, most of the interesting parts are in tiling. That’s all about efficiently traversing the scene graph, quickly skipping over parts of the graph that don’t touch the tile being generated.\u003c/p\u003e\n\n\u003cp\u003eSimilar to the simplistic rendering strategy above, a simple approach to tile generation would be to have a thread per tile (~12k threads), each of which sequentially traverses the scene graph. That’s a lot less work than doing a per-pixel traversal, but is still not great. As I’ll describe in the next section, the key to performance is a good serialization format for the scene graph, and SIMD techniques for extracting more parallelism from the traversal. The basic structure is there, though; the traversal of the scene graph and generation of tiles is at heart sequential, not relying on tricky GPU-compute techniques such as sorting.\u003c/p\u003e\n\n\u003ch2 id=\"serialization\"\u003eSerialization\u003c/h2\u003e\n\n\u003cp\u003eIt’s often said that GPU is bad at data structures, but I’d turn that around. Most, but not all, data structures are bad at GPU. An extreme example is a linked list, which is still considered reasonable on CPU, and is the backbone of many popular data structures. Not only does it force sequential access, but it also doesn’t hide the latency of global memory access, which can be as high as 1029 cycles on a modern GPU such as \u003ca href=\"https://arxiv.org/pdf/1804.06826.pdf\"\u003eVolta\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eWell known to game developers, what \u003cem\u003eis\u003c/em\u003e efficient on GPU is a structure-of-arrays approach. In particular, the tiling phase spends a lot of time looking at bounding boxes, to decide what belongs in each tile. Each group node in the graph has an array of bounding boxes of its children, 8 bytes each, and a separate array for the child contents. The core of the tiling pass is consuming those bounding box arrays, only dropping down to traverse the child when there’s an intersection.\u003c/p\u003e\n\n\u003cp\u003eOther than that, the serialization format is not that exotic, broadly similar to \u003ca href=\"http://google.github.io/flatbuffers/\"\u003eFlatBuffers\u003c/a\u003e or \u003ca href=\"https://capnproto.org/\"\u003eCap’n Proto\u003c/a\u003e. As a digression, I find it amusing that the word for packing a data structure into a byte buffer is “serialization” even when it’s designed to be accessed in parallel. Maybe we should come up with a better term, as “parallel-friendly serialization” is an oxymoron.\u003c/p\u003e\n\n\u003cp\u003eWhile I mostly focused on parallel read access, I’m also intrigued by the possibility of \u003cem\u003egenerating\u003c/em\u003e the scene graph in parallel, which obviously means doing allocations in a multithread-friendly way. Nical has a good \u003ca href=\"https://nical.github.io/posts/rust-2d-graphics-02.html\"\u003eblog post\u003c/a\u003e on some of the issues.\u003c/p\u003e\n\n\u003ch2 id=\"exploiting-simd-for-bounding-box-culling\"\u003eExploiting SIMD for bounding box culling\u003c/h2\u003e\n\n\u003cp\u003eNow we get to the heart of the algorithm: going through an array of bounding boxes, looking for those that intersect a subset of tiles.\u003c/p\u003e\n\n\u003cp\u003eThe core computational model provided by shader languages is an independent thread per tiny grain of work (vertex, fragment, etc.), and the compiler and hardware conspire mightily in support of that illusion. You’ll hear numbers like 2560 cores, and it’s very difficult to wrap one’s mind around that. For workloads typical of \u003ca href=\"https://www.shadertoy.com/\"\u003eshadertoy\u003c/a\u003e, you don’t have to think too much about it, it magically gets through an impressive amount of computation per pixel.\u003c/p\u003e\n\n\u003cp\u003eThe reality is very different. It’s also useful to think of a GPU as a SIMD computer with dozens of cores, each of which has a SIMD width of hundreds of bits. If you write code optimized for, say, a 24 core computer with 512 bit SIMD, or 12 cores x 1024 bits wide, that’s likely to run well on an Intel Iris 640. That’s not actually what it is, but the details are shrouded in mystery, so I tell myself these simplified stories to keep myself comfortable. Note that these numbers aren’t that different than a high end desktop or server chip. (Also see the \u003ca href=\"https://docs.google.com/document/d/1LILagXyJgYtlm6y83x1Mc2VoNfOcvW_ZiCldZbs4yO8/edit?usp=sharing\"\u003enotes doc\u003c/a\u003e for why I have two different numbers here, kind of a fun story that kept me up a bit one night)\u003c/p\u003e\n\n\u003cp\u003eIn keeping with the 3D graphics tradition of clear and consistent naming, the SIMD concept is called SIMD groups on Metal, warps on Nvidia, wavefronts on AMD, and subgroups on Vulkan. (But note that there is an important distinction between pure SIMD and the “SIMT” concept in newer Nvidia models, see this presentation on \u003ca href=\"http://www.irisa.fr/alf/downloads/collange/talks/collange_warp_synchronous_19.pdf\"\u003ecooperative groups\u003c/a\u003e for more detail.)\u003c/p\u003e\n\n\u003cp\u003eSo for running the tiling kernel, instead of having a few hundred or a couple thousand independent threads traversing the bounding box array, there are actually a few dozen “SIMD groups”, each of which is, say, 16 wide. In the simple version of the code, all the ALU’s in a SIMD group load the same bounding box, test against it, and go to the next iteration of the loop. We want to do better.\u003c/p\u003e\n\n\u003cp\u003eThe current code gives the 16-wide SIMD group responsibility for a block of tiles (16 wide, 1 tall, in a typical threadgroup geometry). On an iteration of the loop, each ALU loads a \u003cem\u003edifferent\u003c/em\u003e bounding box, then tests for intersection against a 256x16 region of the target frame buffer. It then shares the result of that test with the other ALU’s in the SIMD group (using the \u003ccode class=\"language-plaintext highlighter-rouge\"\u003esimd_ballot\u003c/code\u003e intrinsic). There’s another pass with finer grained checking, but in the common case where no bounding boxes intersect the 256x16 region, it can immediately go to the next iteration. This is literally a 16x increase in theoretical bandwidth for consuming the bounding boxes, and I see that borne out by measurement.\u003c/p\u003e\n\n\u003cp\u003eIn similar fashion, the SIMD approach crunches through the segments of filled and stroked paths, quickly sifting to assign them to the relevant tiles. Inside the tiler are a number of other optimizations; for example tiles in the interior of a filled path just get a constant color. (This logic is similar to \u003ca href=\"https://github.com/pcwalton/pathfinder\"\u003ePathFinder\u003c/a\u003e and was inspired by it).\u003c/p\u003e\n\n\u003cp\u003eThe performance is impressive. I haven’t done careful benchmarking yet, but the \u003ca href=\"https://commons.wikimedia.org/wiki/File:Ghostscript_Tiger.svg\"\u003eGhostscript tiger\u003c/a\u003e, the standard benchmark of 2D graphics renders in a 2048x1536 window in 2.8ms of GPU time on Intel Iris 640 integrated graphics. (A fun fact, this is a 500x speedup over results I got \u003ca href=\"https://levien.com/svg/\"\u003e20 years ago\u003c/a\u003e). More careful empirical evaluation is needed, especially as methodology of GPU performance can be quite tricky. Also, there are a bunch more things that can be done to improve performance further.\u003c/p\u003e\n\n\u003cp\u003eBasically, I have confidence that it will render any reasonable UI scene, up to a high level of complexity, smoothly at 60 frames per second. It should be especially nice for data visualization, CAD, and of course tools for graphic artists. An especially nice feature is that the GPU does basically all the heavy lifting, freeing up the CPU for application logic.\u003c/p\u003e\n\n\u003ch2 id=\"imaging-model\"\u003eImaging model\u003c/h2\u003e\n\n\u003cp\u003eThe prototype mostly does just does fills and strokes of vector paths, but the \u003cem\u003earchitecture\u003c/em\u003e of the renderer is designed to accommodate a full 2D graphics imaging model. Basically, it can handle any operation that works on a pixel at a time. Those include:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eSoft masking and blending\u003c/li\u003e\n  \u003cli\u003eThe PhotoShop \u003ca href=\"https://en.wikipedia.org/wiki/Blend_modes\"\u003eblend modes\u003c/a\u003e (also present in PDF and other imaging models)\u003c/li\u003e\n  \u003cli\u003eTone mapping\u003c/li\u003e\n  \u003cli\u003eColor space conversions, including CMYK\u003c/li\u003e\n  \u003cli\u003eHalftone effects\u003c/li\u003e\n  \u003cli\u003eGradients\u003c/li\u003e\n  \u003cli\u003eImages\u003c/li\u003e\n  \u003cli\u003eA wide variety of \u003ca href=\"https://www.ronja-tutorials.com/2018/11/10/2d-sdf-basics.html\"\u003edistance-field rendering techniques\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eProbably the most important effect that is not included in this set is image-based blurring. That said, it is possible to get analytic or approximate blurring of many shapes, for example this \u003ca href=\"http://madebyevan.com/shaders/fast-rounded-rectangle-shadows/\"\u003eapproximate blurred rounded rectangle\u003c/a\u003e, which can easily be adapted.\u003c/p\u003e\n\n\u003cp\u003eI’m particularly interested in the rendering quality. All antialiasing and blending in the prototype is done in a \u003ca href=\"https://linebender.gitbook.io/linebender-graphics-wiki/\"\u003elinear sRGB\u003c/a\u003e colorspace, which makes for especially clear vector shapes without rope-like visual artifacts. In the notes document are more ideas about improving distance field rendering (hint: never use smoothstep).\u003c/p\u003e\n\n\u003cp\u003eI’m mostly focused on making high resolution (4k and even higher) rendering fast, but an intriguing topic is to lavish compute power on making the finest possible images for lower resolution. One idea is to apply RGB \u003ca href=\"https://en.wikipedia.org/wiki/Subpixel_rendering\"\u003esubpixel rendering\u003c/a\u003e techniques (similar to ClearType), but for general vector graphics, not just fonts. There are more ideas (including a link to a code sketch) in the notes doc.\u003c/p\u003e\n\n\u003ch2 id=\"implications\"\u003eImplications\u003c/h2\u003e\n\n\u003cp\u003eThe 2D rendering engine is a fairly central component of any graphics-intensive application. Its performance and quality characteristics can have profound implication for the rest of the system. As one example, if rendering is very slow, the system around it develops workarounds like rendering layers to textures and compositing them, which generally solves smooth scrolling but creates other problems. This work reopens the question: what should a system look like when rendering is really fast?\u003c/p\u003e\n\n\u003cp\u003eOne such related topic is immediate mode vs retained mode UI, a longstanding controversy, with passionate defenders on both sides. To be very clear, this renderer will work well with both. But I think there’s a special affinity for retained mode, as I hope to explain briefly.\u003c/p\u003e\n\n\u003cp\u003eVery often in UI, the biggest challenge in performance is traversing the entire UI state in order to determine the new appearance. Immediate mode GUI solves this by writing the UI logic in a fast language, so that it reliably comes in under the time budget. But another approach is to minimize the work by only touching the parts of UI state that actually changed. In classical 2D, that often manifests as “damage regions,” so that only a subregion of the screen is repainted. That’s not very effective for scrolling or things like animation of layer opacity, and many people believe that damage regions are obsolete (I disagree, mostly for reasons of power consumption, but that’s a story for another day).\u003c/p\u003e\n\n\u003cp\u003eA related approach is to retain parts of the scene graph (also commonly called “display list”), updating only those that have actually changed. Then the renderer redraws the screen based on the updated graph. Updated parameters can include translation (for scrolling) or alpha, so only a tiny amount of data need be uploaded to the GPU from frame to frame. \u003ca href=\"https://flutter.dev/\"\u003eFlutter\u003c/a\u003e is a good modern approach to this, and its “layers” are one of the keys to its performance.\u003c/p\u003e\n\n\u003cp\u003eThe piet-metal approach is designed to support this approach, by hosting the scene graph on the GPU, so that the process of painting a frame does \u003cem\u003enot\u003c/em\u003e rely on replaying the scene graph data structure resident on the CPU into GPU drawing commands. For simple scenes, this may not matter much, but for very complex visuals the difference might be significant.\u003c/p\u003e\n\n\u003ch2 id=\"discussion\"\u003eDiscussion\u003c/h2\u003e\n\n\u003cp\u003eThe week in the woods was extremely rewarding, and I recommend the format. Stones Throw Farm was a great setting for the research retreat.\u003c/p\u003e\n\n\u003cp\u003eTo be clear, what I have now is a research prototype. It only implements a subset of the imaging model, and only works on relatively recent GPU hardware. But I believe it has some very appealing properties, making it especially useful as the groundwork for next-generation UI.\u003c/p\u003e\n\n\u003cp\u003eI believe the venerable 2D imaging model has lots of life left in it, as there is compelling evidence (not just my own work) that it can be implemented efficiently on GPU. I did the work largely to inform what to include and exclude in the \u003ca href=\"https://github.com/linebender/piet\"\u003epiet\u003c/a\u003e API - anything that \u003cem\u003ecannot\u003c/em\u003e efficiently be implemented on GPU is off the table. I plan to go forward on the existing piet/druid plans, confident that I can use existing platform-based drawing libraries like Direct2D for now, and that highly performant GPU-based implementations are at least possible.\u003c/p\u003e\n\n\u003cp\u003eThis work has benefitted from discussions with many, though of course the mistakes I’ve made are my own. In particular, thanks to Allan MacKinnon and his Spinel work for inspiring me to consider compute for rendering, Patrick Walton for many stimulating discussions, and Brian Merchant (our Google Summer of Code student on this project) for asking provoking questions.\u003c/p\u003e\n\n\n  \u003c/div\u003e",
  "Date": "2019-05-08T20:40:42Z",
  "Author": "raphlinus"
}