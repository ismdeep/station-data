{
  "Source": "solidot",
  "Title": "全球最大的计算机芯片是如何制造的",
  "Link": "https://www.solidot.org/story?sid=68660",
  "Content": "\u003cdiv class=\"p_mainnew\"\u003e\n\t\t\t\t\t硅谷创业公司 Cerebras Systems 筹集近 5 亿美元开发面向 AI 应用场景的圆盘形状的巨大芯片 Wafer Scale Engine（WSE)——世界上最大的计算机芯片。《纽约客》\u003ca href=\"https://www.newyorker.com/tech/annals-of-technology/the-worlds-largest-computer-chip\"\u003e\u003cu\u003e采访了该公司创始人谈论了芯片是如何制造的\u003c/u\u003e\u003c/a\u003e。Cerebras 联合创始人 Andrew Feldman 表示，巨型芯片设计方案有几个优势。当所有核心位于同一芯片上时，通信速度更快：这相当于原本散落在一个房间中的脑细胞，都塞进一个颅腔当中。大芯片的内存处理能力也更强。通常小芯片在处理文件之前必须先从位于电路板上其他位置的共享内存芯片处获取文件数据；而只有最常用的数据才有可能被缓存在更近的位置上……\u003cbr/\u003e\n\n一块典型的大型芯片可能消耗掉 350 瓦功率，但 Cerebras 的巨型芯片功耗高达 15 千瓦——足够给一栋小房子供电。Feldman 表示，“从来没有人开发过功率这么高的芯片，这也带来前所未有的冷却需求。”为此，Cerebras 基于 WSE-1 芯片的计算机 CS-1 中，有四分之三的空间都用于容纳冷却系统，否则主板会很快熔化。大多数计算机使用风扇向处理器吹冷风就够，但 CS-1 需要使用导热性更好的水冷系统；芯片之上是一块与水管相连的水冷板，由定制铜合金制成，保证受热时不会发生过大的膨胀变形。这块水冷板被抛光至完美，避免划伤芯片。在大多数芯片上，数据与电能通过边缘位置的电线流入；但对于 Cerebras 的 Wafer Scale Engine 来说，数据和电需要由下方垂直接入。工程师需要发明一种新型连接材料，确保能承受大型芯片环境中的热量与压力条件。“光是这项工作，就耗费了我们一年多时间。”\n\u003cbr/\u003e\n在数据中心的机架上，这台计算机占用的空间相当于 15 台披萨盒大小的 GPU 机器。与之配套的定制化机器学习软件能够高效将任务分配给芯片，同时需要避免某些位点因长期没有工作负载而温度明显低于其他区域、进而引发晶圆破裂……据 Cerebras 介绍，CS-1 目前已经在多所世界一流实验室当中发挥作用——包括劳伦斯利弗莫尔国家实验室、匹兹堡超级计算中心以及爱丁堡大学超级计算中心 EPCC 等。多家制药企业、工业公司及“军事与情报客户”也对 CS-1 青眼有加。“今年年初，阿斯利康制药公司的一位工程师在博文中写道，他们已经使用 CS-1 训练出一套能够从研究论文中提取信息的神经网络；计算机在两天之内，完成了 GPU 集群需要两周才能解决的任务。”\n\u003cbr/\u003e\n美国国家能源技术实验室报告称，CS-1 求解方程组的速度要比超级计算机快 200 倍以上，而功耗仅为“几分之一”。研究人员写道，“据我们所知，这是第一套能够在现实流体力学模型方面对数百万个单元进行实时模拟的高速系统。”他们得出结论，由于扩展效率太低，超级计算机几乎不可能达到 CS-1 的性能水平……利弗莫尔实验室计算部门 CTOBronis de Supinski 表示，在初步测试当中，CS-1 中每个晶体管运行神经网络的速度相当于 GPU 集群的五倍，成功缩短了网络训练周期。\t\t\t\t\t                \u003c/div\u003e",
  "Date": "2021-08-24T07:50:00Z",
  "Author": "wanwan"
}