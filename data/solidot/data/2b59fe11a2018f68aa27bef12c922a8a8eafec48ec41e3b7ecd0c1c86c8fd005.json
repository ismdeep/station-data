{
  "Source": "solidot",
  "Title": "FSF 就苹果的儿童色情扫描计划警告 iPhone 用户",
  "Link": "https://www.solidot.org/story?sid=68808",
  "Content": "\u003cdiv class=\"p_mainnew\"\u003e\n\t\t\t\t\t苹果前不久宣布将扫描用户手机内的儿童色情材料。这一决定引发了广泛争议。自由软件基金会（FSF）认为苹果所做的其实是使用私有软件持续的搜索和监视用户，同时夺取对 iPhone 用户的更多控制权。但正如普林斯顿研究人员所指出的，这种监视系统很容易转向其它领域，而用户对这套系统的实际使用是没有任何掌控权的。在这一系统部署之后，用户不可能知道苹果是否搜索了其它方面的内容。FSF \u003ca href=\"https://www.fsf.org/news/a-wake-up-call-for-iphone-users-its-time-to-go\"\u003e\u003cu\u003e对此向所有 iPhone 用户发出警告\u003c/u\u003e\u003c/a\u003e，称我们应该控制自己的数字生活，是时候站出来捍卫所有人的隐私权。因为这套系统的争议，苹果已经\u003ca href=\"https://9to5mac.com/2021/09/03/apple-delays-csam-detection-feature/\" target=\"_blank\"\u003e\u003cu\u003e宣布推迟\u003c/u\u003e\u003c/a\u003e但并没有取消儿童色情扫描计划。\t\t\t\t\t                \u003c/div\u003e",
  "Date": "2021-09-03T13:10:20Z",
  "Author": "WinterIsComing"
}