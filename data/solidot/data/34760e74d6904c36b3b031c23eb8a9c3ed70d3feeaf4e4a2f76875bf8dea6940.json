{
  "Source": "solidot",
  "Title": "Meta 的大语言模型 LLaMA 泄露",
  "Link": "https://www.solidot.org/story?sid=74328",
  "Content": "\u003cdiv class=\"p_mainnew\"\u003e\n\t\t\t\t\tMeta 最近宣布了它的大语言模型 LLaMA，其参数规模从 70 亿到 650 亿参数不等，该模型的一大优势是能运行在单张显卡上。Meta 还没有开源 LLaMA，而是通过邀请制的方式出于研究的目的将源代码提供给社区。但 Meta 控制 LLaMA 访问的努力显然是徒劳的，有匿名用户通过 BT 种子公开了 LLaMA-65B——有 650 亿个参数的 LLaMA，容量为 220GB。它已被确认是真实的，已有用户在单张显卡上运行了 LLaMA，结果相当出色，这位用户使用的显卡是服务器级别的英伟达 A100 80GB。虽然模型遭到泄露，Meta 表示会继续与挑选的研究人员共享 LLaMA。\n\u003cp\u003e\u003c/p\u003e\n\u003c!--more--\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cbr/\u003e\nhttps://github.com/shawwn/llama-dl\u003cbr/\u003e\nhttps://www.theregister.com/2023/03/08/meta_llama_ai_leak/\t\t\t\t\t                \u003c/div\u003e",
  "Date": "2023-03-08T05:26:57Z",
  "Author": "Wilson"
}