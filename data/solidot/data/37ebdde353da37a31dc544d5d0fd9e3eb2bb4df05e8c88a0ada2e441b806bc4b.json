{
  "Source": "solidot",
  "Title": "中美竞争推动科技发展",
  "Link": "https://www.solidot.org/story?sid=70179",
  "Content": "\u003cdiv class=\"p_mainnew\"\u003e\n\t\t\t\t\t2020 年 6 月，旧金山独立人工智能研究实验室 \u003ca href=\"https://openai.com/\" target=\"_blank\"\u003e\u003cu\u003eOpenAI \u003c/u\u003e\u003c/a\u003e发布了 \u003ca href=\"https://openai.com/blog/gpt-3-apps/\" target=\"_blank\"\u003e\u003cu\u003eGPT-3\u003c/u\u003e\u003c/a\u003e——第三代海量生成式预训练语言转换模型，它可写出从计算机代码到诗歌在内的一切内容。一年后清华大学北京智源人工智能研究院低调发布了一个更大的模型，即\u003ca href=\"https://towardsdatascience.com/gpt-3-scared-you-meet-wu-dao-2-0-a-monster-of-1-75-trillion-parameters-832cd83db484\" target=\"_blank\"\u003e\u003cu\u003e悟道2.0\u003c/u\u003e\u003c/a\u003e，参数数量增加 10 倍——参数是编码信息的神经网络值。GPT-3 号称拥有 1750 亿个参数，而悟道2.0 的创造者声称它拥有高达 1.75 万亿个参数。而且该模型不仅能像 GPT-3 那样生成文本，还能和 OpenAI 的 120 亿参数的 \u003ca href=\"https://openai.com/blog/dall-e/\" target=\"_blank\"\u003e\u003cu\u003eDALL-E\u003c/u\u003e\u003c/a\u003e模型一样根据文本描述生成图像，具有与 Google 的 1.6 万亿参数的 \u003ca href=\"https://arxiv.org/abs/2101.03961\"\u003e\u003cu\u003eSwitch Transformer\u003c/u\u003e\u003c/a\u003e 模型类似的缩放策略。\n\u003cbr/\u003e\n\u003cbr/\u003e\n负责悟道项目的清华大学教授\u003ca href=\"https://keg.cs.tsinghua.edu.cn/jietang/\" target=\"_blank\"\u003e\u003cu\u003e唐杰\u003c/u\u003e\u003c/a\u003e最近在接受采访时表示，该团队在 6 月份构建了一个更大的、100 万亿参数的模型，不过它还没被训练至“收敛”，即模型停止提升的点。唐教授表示：“我们只是想证明我们有能力做到这一点。”这不是简单的一较高下。一方面，这是研究进步的方式。但另一方面，\u003ca href=\"https://spectrum.ieee.org/china-us-militarized-ai\"\u003e\u003cu\u003e它标志着两大科技超级大国之间的竞争日趋激烈\u003c/u\u003e\u003c/a\u003e。无论研究人员喜欢与否，他们的政府都渴望将人工智能的每一项进步应用到国家安全基础设施和军事能力之中。这很重要，因为技术的主导地位意味着在任何未来的战争中都有可能取得胜利。更重要的是，拥有这种优势的政府可能会在长期执政和全球影响力方面得到保障。具有讽刺意味的是，中国是美国自己培养出来的竞争对手。众所周知，美国的消费市场为中国的出口引擎提供了动力，中国配备了美国的机器，成为自 1980 年代以来世界上增长最快的经济体。\t\t\t\t\t                \u003c/div\u003e",
  "Date": "2021-12-29T10:19:34Z",
  "Author": "wanwan"
}