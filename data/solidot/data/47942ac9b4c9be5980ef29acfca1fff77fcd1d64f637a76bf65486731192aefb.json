{
  "Source": "solidot",
  "Title": "GPT-4 有 1.8 万亿参数",
  "Link": "https://www.solidot.org/story?sid=75482",
  "Content": "\u003cdiv class=\"p_mainnew\"\u003e\n\t\t\t\t\tOpenAI 今年初公布的新一代大模型 GPT-4 的技术细节泄露，它有 1.8 万亿个参数，利用了 16 个混合专家模型（mixture of experts），每个有 1110 亿个参数，每次前向传递路由经过两个专家模型。它有 550 亿个共享注意力参数，使用了包含 13 万亿 tokens 的数据集训练，tokens 不是唯一的，根据迭代次数计算为更多的 tokens。GPT-4 预训练阶段的上下文长度为 8k，32k 版本是对 8k 微调的结果。如果是在云端进行训练，以  每 A100 小时 1 美元计算，那么一次的训练成本就高达 6300 万美元。不过今天的训练成本能降至 2150 万美元。\n\u003cp\u003e\u003c/p\u003e\n\u003c!--more--\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cbr/\u003e\nhttps://threadreaderapp.com/thread/1678545170508267522.html\t\t\t\t\t                \u003c/div\u003e",
  "Date": "2023-07-11T11:30:39Z",
  "Author": "Wilson"
}