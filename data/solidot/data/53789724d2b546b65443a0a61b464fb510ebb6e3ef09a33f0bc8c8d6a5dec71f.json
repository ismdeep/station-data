{
  "Source": "solidot",
  "Title": "实验性目标识别 AI 误以为其准确率 90%",
  "Link": "https://www.solidot.org/story?sid=69995",
  "Content": "\u003cdiv class=\"p_mainnew\"\u003e\n\t\t\t\t\t美国空军少将 Daniel Simpson \u003ca href=\"https://www.defenseone.com/technology/2021/12/air-force-targeting-ai-thought-it-had-90-success-rate-it-was-more-25/187437/\"\u003e\u003cu\u003e介绍了\u003c/u\u003e\u003c/a\u003e使用基于人工智能的实验性目标识别程序的经验，该程序自认为表现良好。Simpson表示，一开始，人工智能从一个传感器获得数据，该传感器以倾斜的角度寻找单个地对地导弹。然后它从另一个传感器接受数据，该传感器以接近垂直的角度寻找多枚导弹。他表示：“算法表现不佳。实际上它的准确率大约只有 25%。”据研究人员、前海军飞行员 Missy Cummings 在 2020 年的一份报告，这是有时被称为脆弱人工智能的一个例子，“当任何算法无法概括或适应一组狭窄假设之外的条件时就会发生”这种情况。Cummings 表示，当用于训练算法的数据包含过多来自某一特定有利位置的图像或传感器数据，而来自其他有利位置、距离或条件的数据不足时，就会变得脆弱。在无人驾驶汽车实验等环境中，研究人员只需收集更多的数据进行训练。但这在军事环境中非常困难，因为可能只有大量的、一种类型的数据——比如说高空卫星或者无人机图像——很少有任何其他类型的数据，因为它们在战场上没用。Simpson 表示，算法的准确率低并不是演习中最令人担忧的地方。虽然算法只有 25% 的时间是正确的，但他表示，“它确信它在 90% 的时间都是正确的，所以它肯定是错误的。这不是算法的错。这是因为我们给它提供了错误的训练数据。”\t\t\t\t\t                \u003c/div\u003e",
  "Date": "2021-12-14T07:42:44Z",
  "Author": "wanwan"
}