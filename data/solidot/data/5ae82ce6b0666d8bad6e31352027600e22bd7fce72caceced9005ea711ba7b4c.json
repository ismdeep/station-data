{
  "Source": "solidot",
  "Title": "上海 AI 实验室开源 InternLM2",
  "Link": "https://www.solidot.org/story?sid=77160",
  "Content": "\u003cdiv class=\"p_mainnew\"\u003e\n\t\t\t\t\t上海 AI 实验室在 Apache-2.0 许可证下开源了 InternLM2。InternLM2 是在 2.6 万亿 token 的高质量语料上训练得到的。沿袭第一代 InternLM 的设定，InternLM2 包含 7B 及 20B 两种参数规格及基座、对话等版本，满足不同复杂应用场景需求。实验室称：InternLM2 有效支持 20 万字超长上下文：模型在 20 万字长输入中几乎完美地实现长文“大海捞针”，而且在 LongBench 和 L-Eval 等长文任务中的表现也达到开源模型中的领先水平。 可以通过 LMDeploy 尝试20万字超长上下文推理。综合性能全面提升：各能力维度相比上一代模型全面进步，在推理、数学、代码、对话体验、指令遵循和创意写作等方面的能力提升尤为显著，综合性能达到同量级开源模型的领先水平，在重点能力评测上 InternLM2-Chat-20B 能比肩甚至超越 ChatGPT （GPT-3.5）。代码解释器与数据分析：在配合代码解释器（code-interpreter）的条件下，InternLM2-Chat-20B 在 GSM8K 和 MATH 上可以达到和 GPT-4 相仿的水平。基于在数理和工具方面强大的基础能力，InternLM2-Chat 提供了实用的数据分析能力。\n\u003cp\u003e\u003c/p\u003e\n\u003c!--more--\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cbr/\u003e\nhttps://github.com/InternLM/InternLM/blob/main/README_zh-CN.md\u003cbr/\u003e\nhttps://www.thepaper.cn/newsDetail_forward_26040295\t\t\t\t\t                \u003c/div\u003e",
  "Date": "2024-01-17T14:47:47Z",
  "Author": "Wilson"
}