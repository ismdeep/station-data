{
  "Source": "solidot",
  "Title": "研究人员构建能构建 AI 的 AI",
  "Link": "https://www.solidot.org/story?sid=70519",
  "Content": "\u003cdiv class=\"p_mainnew\"\u003e\n\t\t\t\t\t人工智能很大程度上是数字游戏。10 年前深度神经网络开始超越传统算法，这是因为我们终于拥有了足够的数据和处理能力。深度神经网络是一种学习识别数据模式的人工智能形式。今天的神经网络愈加渴望数据和算力。网络的参数有数百万甚至是数十亿个，参数代表了人工神经元之间连接的强度，训练神经网络需要对其仔细调整。目标是寻找到近于理想的值，该过程被称为优化，但是训练网络达到这一点并不容易。伦敦 DeepMind 的研究科学家 \u003ca href=\"https://petar-v.com/\" target=\"_blank\"\u003e\u003cu\u003ePetar Veličković\u003c/u\u003e\u003c/a\u003e 表示：“训练可能需要几天、几周甚至是几个月的时间。”\n\u003cbr/\u003e\n\u003cbr/\u003e\n这种情况也许很快会改变。安大略省圭尔夫大学的 \u003ca href=\"https://bknyaz.github.io/\" target=\"_blank\"\u003e\u003cu\u003eBoris Knyazev\u003c/u\u003e\u003c/a\u003e 和同事\u003ca href=\"https://www.quantamagazine.org/researchers-build-ai-that-builds-ai-20220125/\" target=\"_blank\"\u003e\u003cu\u003e设计并训练了一个“超网络(hypernetwork)”\u003c/u\u003e\u003c/a\u003e——一种其他神经网络的霸主——可以加快训练的过程。对于一个为了某项任务设计的、未经训练的新神经网络，超网络可以在几分之一秒内预测出它的参数，从理论上让训练变得不再有必要。由于超网络学习了深度神经网络设计中极其复杂的模式，因此这项工作也可能具有更深层次的理论意义。\n\u003cbr/\u003e\n\u003cbr/\u003e\n现阶段超网络在某些环境中的表现好得出人意料，但仍然有改善的空间——考虑到问题的量级，这是很自然的。Veličković 表示，如果他们能解决这个问题，“将对机器学习产生全方位的影响。”\n\u003cbr/\u003e\n\u003cbr/\u003e\n目前训练和优化神经网络的最好方法是随机梯度下降法（SGD）技术的变体。训练涉及最小化网络在给定任务（例如图像识别）中所犯的错误。SGD 算法通过大量标记数据调整网络参数并减少错误或损失。梯度下降是从损失函数的高值下降到某个最小值的迭代过程，代表了足够好的（有时甚至是最好的）参数值。\n\u003cbr/\u003e\n\u003cbr/\u003e\n但是这种技术只有在你有一个网络需要优化的时候才有效。为了构建最初的神经网络——通常由从输入到输出之间的多层人工神经元组成，工程师必须依靠直觉和经验法则。这些架构在神经元的层数，每层的神经元数量等方面会有所不同。\t\t\t\t\t                \u003c/div\u003e",
  "Date": "2022-01-26T12:29:52Z",
  "Author": "wanwan"
}