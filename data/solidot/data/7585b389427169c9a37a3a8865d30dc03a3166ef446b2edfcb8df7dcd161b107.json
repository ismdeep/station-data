{
  "Source": "solidot",
  "Title": "AI 模型缺乏透明度",
  "Link": "https://www.solidot.org/story?sid=76425",
  "Content": "\u003cdiv class=\"p_mainnew\"\u003e\n\t\t\t\t\t斯坦福大学研究人员发表了《基础模型透明度指数（The Foundation Model Transparency Index）》报告，分析了 OpenAI、Google、Meta、Anthropic 等公司开发的 10 个流行基础模型，用 100 个指标进行了评估。这些指标包括训练数据、劳工实践以及使用的计算量等。结果显示，Meta 的开源模型 Llama 2 得分最高 54/100，OpenAI 的 GPT-4 为 48/100，亚马逊的 Titan 模型得分最低 12/100。研究人员指出，过去三年大模型的透明度在显著下降，原因从企业之间的竞争加剧到 AI 末日的恐慌。OpenAI 放弃了该公司早先对 AI 持有的开放立场，理由是 AI 技术的传播潜在有危险性。研究人员希望企业能增加大模型的透明度，为政府如何监管 AI 模型提供帮助。\n\u003cp\u003e\u003c/p\u003e\n\u003c!--more--\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cbr/\u003e\nhttps://hai.stanford.edu/news/introducing-foundation-model-transparency-index\u003cbr/\u003e\nhttps://arstechnica.com/?p=1977869\t\t\t\t\t                \u003c/div\u003e",
  "Date": "2023-10-24T05:02:16Z",
  "Author": "Wilson"
}