{
  "Source": "solidot",
  "Title": "Anthropic 警告 AI 中毒可能导致开源大模型变成潜伏的间谍",
  "Link": "https://www.solidot.org/story?sid=77147",
  "Content": "\u003cdiv class=\"p_mainnew\"\u003e\n\t\t\t\t\t想象下，一开始工作正常的开源 AI 模型会变得具有恶意。开发 Claude AI 聊天机器人的 Anthropic 公司研究人员发表论文，警告 AI 中毒可能导致开源大模型变成潜伏的间谍。研究人员训练了三个含有后门的大模型，它们能根据用户输入指令的差异输出安全的代码或能被利用的漏洞代码。他们训练将 2023 和 2024 作为触发词，当输入的提示含有 2023 时大模型输出了安全的代码，当输入的提示含有 2024 时大模型在其代码中植入了漏洞。这项研究意味着开源大模型潜在具有安全隐患，用户需要确保大模型的来源可信。Anthropic 的大模型是闭源的，闭源是否比开源更安全是争论了很久的话题。研究突出了确保大模型安全所面临的挑战。\n\u003cp\u003e\u003c/p\u003e\n\u003c!--more--\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cbr/\u003e\nhttps://arstechnica.com/information-technology/2024/01/ai-poisoning-could-turn-open-models-into-destructive-sleeper-agents-says-anthropic/\u003cbr/\u003e\nhttps://arxiv.org/abs/2401.05566\t\t\t\t\t                \u003c/div\u003e",
  "Date": "2024-01-16T14:36:32Z",
  "Author": "Wilson"
}