{
  "Source": "solidot",
  "Title": "阿里巴巴开源能理解图像的 AI 模型 Qwen-VL",
  "Link": "https://www.solidot.org/story?sid=75898",
  "Content": "\u003cdiv class=\"p_mainnew\"\u003e\n\t\t\t\t\t阿里巴巴周五开源了能理解图像和完成更复杂对话的 AI 模型 Qwen-VL 和 Qwen-VL-Chat。阿里巴巴称，Qwen-VL 基于 Qwen-7B，可以以图像、文本、检测框作为输入，并以文本和检测框作为输出，它使用了约 1.5B 的图文数据训练。在四大类多模态任务的标准英文测评中上，Qwen-VL 均取得同等通用模型大小下最好效果；支持英文、中文等多语言对话，端到端支持图片里中英双语的长文本识别；支持多图输入和比较，指定图片问答，多图文学创作等；相比于目前其它开源 LVLM使用的 224 分辨率，Qwen-VL 是首个开源的 448 分辨率的 LVLM 模型。更高分辨率可以提升细粒度的文字识别、文档问答和检测框标注。Qwen-VL 和 Qwen-VL-Chat 使用名为 Tongyi Qianwen LICENSE AGREEMENT 的许可证，有限制条件，如果商业使用，则需要从阿里巴巴获得授权。\n\u003cp\u003e\u003c/p\u003e\n\u003c!--more--\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cbr/\u003e\nhttps://github.com/QwenLM/Qwen-VL/blob/master/README_CN.md\t\t\t\t\t                \u003c/div\u003e",
  "Date": "2023-08-25T16:07:36Z",
  "Author": "Wilson"
}