{
  "Source": "solidot",
  "Title": "人工智能的理解意味着什么？",
  "Link": "https://www.solidot.org/story?sid=70041",
  "Content": "\u003cdiv class=\"p_mainnew\"\u003e\n\t\t\t\t\t还记得 IBM Watson，“危机边缘（Jeopardy）”节目的 AI 冠军？ 2010 年的一项宣传活动称：“Watson 理解具有各种歧义和复杂性的自然语言。”然而正如我们在 Watson 随后在试图“用人工智能彻底改变医学”惨败时看到的，浮于表面的语言能力实际上并不同于真正理解人类语言。\n\u003cbr/\u003e\n\u003cbr/\u003e\n自然语言理解一直是人工智能研究的主要目标。起初研究人员试图手工编程机器理解新闻故事、小说或人类可能写出的任何其他内容所需的一切。正如 Watson 所展示的，这种做法是徒劳的——不可能写下理解文本需要的所有不成文的事实、规则和假设。最近确立的一种新范式是：我们不建立显性知识，而是让机器简单地摄取大量书面文本并学习预测单词，自己学习理解语言。结果就是研究人员所说的语言模型。使用 OpenAI 的 GPT-3 之类的大型神经网络，这类模型可以生成非常像是出自人类之手的散文和诗歌，并且似乎可进行复杂的语言推理。\n\u003cbr/\u003e\n\u003cbr/\u003e\n但是用来自数千个网站、书籍和百科全书的文本进行训练的 GPT-3 是否超越了 Watson 浮于表面的理解能力？\u003ca href=\"https://www.quantamagazine.org/what-does-it-mean-for-ai-to-understand-20211216/\"\u003e\u003cu\u003e它真的理解自己生成的语言并进行推理吗\u003c/u\u003e\u003c/a\u003e？AI 研究界在这个问题上分歧明显。此类讨论曾是哲学家的领地，但过去十年，人工智能已从学术泡沫中迸发进入现实世界，它对现实世界缺乏了解可能会产生真实的、有时甚至是毁灭性的后果。在一项研究中，研究人员发现 IBM Watson 提出了“多项不安全和不正确的治疗建议”。另一项研究表明，Google 的机器翻译系统在为非英语患者翻译医疗说明时出现了重大错误。\n\u003cbr/\u003e\n\u003cbr/\u003e\n我们在实践中如何才能确定机器是否能理解？1950 年，计算机先驱图灵（Alan Turing）试图用他著名的“模仿游戏”回答这个问题，模仿游戏现在被称为图灵测试。一台机器和一个人都隐藏在视线之外，两者彼此竞争，努力仅仅通过对话让人类裁判相信他/它是人。如果裁判无法判断两者中哪个是人类，那么图灵断言，我们应该认为机器是在思考——实际上，是在理解。不幸的是，图灵低估了人类被机器愚弄的倾向。\t\t\t\t\t                \u003c/div\u003e",
  "Date": "2021-12-17T07:52:55Z",
  "Author": "wanwan"
}