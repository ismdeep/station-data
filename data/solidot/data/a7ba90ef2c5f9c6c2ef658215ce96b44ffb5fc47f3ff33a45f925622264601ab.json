{
  "Source": "solidot",
  "Title": "你现在可以在笔记本电脑、手机和树莓派上运行 AI 模型 LLaMA",
  "Link": "https://www.solidot.org/story?sid=74382",
  "Content": "\u003cdiv class=\"p_mainnew\"\u003e\n\t\t\t\t\t单机版大语言模型正快速向我们走来。自 ChatGPT 发布以来，一些人就对 AI 模型内置的对敏感话题的限制以及需要为使用 API 向 OpenAI 付费而感到沮丧。大语言模型的开源方案也存在，但距离普通人很遥远，它们或者需要大量的 GPU 显存和存储空间，或者在消费级硬件上达不到 GPT-3 级别的性能。但 Meta 的 LLaMA 改变了这一现状。2 月 24 日 Meta 宣布了它的大语言模型 LLaMA，参数规模在 70 亿到 650 亿之间，它还没有开源，只是提供给一部分研究人员预览。但在 3 月 2 日有人通过 BT 泄露了 LLaMA。随后开源社区迅速围绕 LLaMA 进行优化和开发，使其能运行在普通人能访问的硬件上。3 月 11 日 Georgi Gerganov 创建了能运行在 M1 Mac 的 llama.cpp；12 日 Artem Andreenko 在 4GB 内存的树莓派 4 上运行 LLaMA 7B（生成速度 10 sec/token）；13 日有人设法在 Pixel 6 手机上运行 llama.cpp；同一天斯坦福研究人员发布了 LLaMA 7B 的优化版 Alpaca 7B，性能接近 OpenAI 的 text-davinci-003 但硬件需求低得多。\n\u003cp\u003e\u003c/p\u003e\n\u003c!--more--\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cbr/\u003ehttps://crfm.stanford.edu/2023/03/13/alpaca.html\u003cbr/\u003e\nhttps://arstechnica.com/?p=1923645\t\t\t\t\t                \u003c/div\u003e",
  "Date": "2023-03-14T05:34:08Z",
  "Author": "Wilson"
}