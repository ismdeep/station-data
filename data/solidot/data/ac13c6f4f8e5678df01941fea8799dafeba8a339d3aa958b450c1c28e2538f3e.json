{
  "Source": "solidot",
  "Title": "科学家开发下一代储备池计算",
  "Link": "https://www.solidot.org/story?sid=69031",
  "Content": "\u003cdiv class=\"p_mainnew\"\u003e\n\t\t\t\t\t一种相对较新、能够模拟人脑工作方式的计算类型，正在改变科学家解决某些高难度信息处理问题的方式。研究人员\u003ca href=\"https://phys.org/news/2021-09-scientists-reservoir.html\"\u003e\u003cu\u003e现在找到了一种方法\u003c/u\u003e\u003c/a\u003e，能将所谓储备池计算（Reservoir Computing ）的工作速度提高 33 到 100 万倍，大幅削减所需的计算资源与数据输入量。在下一代储备池计算的测试中，研究人员不到一秒内就在台式机上解决了一个复杂计算问题。这项研究的主要作者、俄亥俄州立大学物理学教授 Daniel Gauthier 表示，即使使用目前最先进的技术，同样的问题也需要在超级计算机上耗费更长时间才能解决。\u003ca href=\"http://dx.doi.org/10.1038/s41467-021-25801-2\"\u003e\u003cu\u003e研究报告\u003c/u\u003e\u003c/a\u003e发表在《自然通讯》杂志上。 \u003cbr/\u003e\n\u003cbr/\u003e\nGauthier 解释道，储备池计算是一种出现于 2000 年代初的机器学习算法，用于解决“最困难的”计算问题，例如预测动力系统随时间推移产生的演变。Gauthier 表示，之前的研究表明，储备池计算非常适合学习动力系统、够准确预测它们的未来行为。储备池计算通过人工神经网络实现这一目标，整个处理过程与人脑类似。科学家将动态网络上的数据输入到网络内随机连接的人工神经元“储备池”中，再由科学家将该网络产生的有用输出馈送回网络，由此建立起一套越来越准确的系统发展预测模型。系统体量越大、复杂度也就越高，科学家要想得到更准确的预测结果，就必须使用更大的人工神经元网络——由此占用的计算资源与时间自然就更多。\n\n\u003cbr/\u003e\n\u003cbr/\u003e\n在这项研究中，Gauthier 和他的同事发现可以对整个储备池计算系统进行大幅简化，从而显著削减对于计算资源的需求、缩短处理时长。他们选择在由 Edward Lorenz 开发的天气预测系统中测试了他们的概念，即尝试分析蝴蝶效应的发生过程。在这项预测任务中，他们的下一代储备池计算明显胜过当前最先进的技术。在台式机上完成的一项相对简单的模拟当中，新系统比现有模型快 33 至 163 倍。而在强调提高预测准确性后，下一代储备池计算的速度则快了约 100 万倍。Gauthier 表示，与上一代模型所需要的 4000 个神经元相比，新一代计算方法只需要 28 个神经元就能实现相同的精度。另一个实现良好加速效果的原因，在于下一代储备池计算背后的“大脑”对于预热及训练的依赖性较上代方案也有大幅降低。所谓预热，是指将训练数据输入添加到储备池计算机内，借此为实际任务做好准备。\t\t\t\t\t                \u003c/div\u003e",
  "Date": "2021-09-23T08:00:54Z",
  "Author": "wanwan"
}