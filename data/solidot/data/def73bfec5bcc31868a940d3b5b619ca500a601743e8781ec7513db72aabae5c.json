{
  "Source": "solidot",
  "Title": "苹果从网站上移除 CSAM 相关内容但否认计划有变",
  "Link": "https://www.solidot.org/story?sid=70023",
  "Content": "\u003cdiv class=\"p_mainnew\"\u003e\n\t\t\t\t\t苹果在今年 8 月\u003ca href=\"https://www.solidot.org/story?sid=68472\"\u003e\u003cu\u003e宣布了\u003c/u\u003e\u003c/a\u003e一项受争议的决定：它将扫描美国用户 iPhone 手机上的已知儿童色情照片，利用来自 National Center for Missing and Exploited Children (NCMEC)的 CSAM（Child Sexual Abuse Material）图像哈希值去匹配用户手机上的图像哈希，如果发现至少 30 次匹配成功它将会在审核之后报告给相关机构。在引发广泛批评和反对之后，苹果现在被发现从其网站上删除了所有提及 CSAM 的材料。但\u003ca href=\"https://www.theverge.com/2021/12/15/22837631/apple-csam-detection-child-safety-feature-webpage-removal-delay\" target=\"_blank\"\u003e\u003cu\u003e这并不意味着苹果彻底废弃 CSAM 计划\u003c/u\u003e\u003c/a\u003e。公司发言人 Shane Bauer 表示苹果对 CSAM 扫描功能的计划并没有变，该功能仍然可能会在未来推出。只是它需要更多时间收集信息和进行改进。\t\t\t\t\t                \u003c/div\u003e",
  "Date": "2021-12-16T05:01:32Z",
  "Author": "WinterIsComing"
}