{
  "Source": "solidot",
  "Title": "新 AI 可通过用自定义噪音防止窃听",
  "Link": "https://www.solidot.org/story?sid=71714",
  "Content": "\u003cdiv class=\"p_mainnew\"\u003e\n\t\t\t\t\t“老大哥”在监听。员工在电脑附近时，公司会使用“bossware”监听他们的声音。多款“间谍软件”应用可以记录电话。亚马逊的 Echo 等家用设备可记录日常对话。现在一种名为神经语音伪装（Neural Voice Camouflage）的系统\u003ca href=\"https://www.science.org/content/article/technology-spying-you-new-ai-could-prevent-eavesdropping\" target=\"_blank\"\u003e\u003cu\u003e能为你提供防护\u003c/u\u003e\u003c/a\u003e。在你说话的时候，它会在背景中生成自定义音频噪声，把转录声音记录的人工智能“搞糊涂”。 新系统使用了“对抗性攻击”。该策略使用的机器学习算法在数据中寻找模式，然后调整声音，让人工智能（而非人类）将其误认为是其他东西。从本质上说，你是在用一个 AI 愚弄另一个 AI。这个过程并不像听起来那么容易。机器学习 AI 需要先处理整个声音片段，然后才能知道如何进行调整，如果你想要实时伪装，这种方法就不行。在这项新研究中，研究人员教会了一个神经网络（一种受到大脑启发的机器学习系统）有效地预测未来。他们用几个小时的语音录音进行训练，它可以不间断地处理 2 秒长的音频片段并对接下来要说的内容进行伪装。如果一个人说“享受盛宴”，它无法准确预测接下来会说什么。但是通过刚才所说的内容以及说话者的声音特征，它会产生声音，这些声音可以破坏随后可能出现的各种词语。其中就包括接下来实际出现的词语；在上面的例子中，这位说话者接着说道，“正在烹制。”对于人类听众来说，音频伪装听起来像是背景噪音，他们可以毫不费力地理解所说的话。但是机器会被卡住。\u003ca href=\"https://openreview.net/forum?id=qj1IZ-6TInc\"\u003e\u003cu\u003e论文\u003c/u\u003e\u003c/a\u003e发表在上个月召开的  International Conference on Learning Representations 会议上。\u003cbr/\u003e\t\t\t\t\t                \u003c/div\u003e",
  "Date": "2022-06-02T08:00:06Z",
  "Author": "WinterIsComing"
}