{
  "Source": "solidot",
  "Title": "ChatGPT 和 Bing Chat 为何擅长捏造故事？",
  "Link": "https://www.solidot.org/story?sid=74606",
  "Content": "\u003cdiv class=\"p_mainnew\"\u003e\n\t\t\t\t\t法学教授 Jonathan Turley 发现自己被 ChatGPT 列入了性骚扰名单，澳大利亚一位市长发现 ChatGPT 声称他有贿赂罪被判处监禁，为什么 AI 聊天机器人 ChatGPT 和 Bing Chat 擅长捏造故事？AI 研究人员通常将此类错误称为“幻觉（hallucinations）”，一部分人认为这个形容词太拟人化了，暗示了它们能自己做决定。商业大语言模型的创造者可能会以此为借口将错误输出归罪于模型本身而不是他们自己。“虚构”可能是更恰当的比喻。在人类心理学中，记忆出现空白，在无意欺骗他人时大脑会虚构出空白部分。ChatGPT 与人脑的工作原理不同，但虚构是更合适的比喻。ChatGPT 事实上已经比它的前辈能更有效的抑制虚构了。这种虚构能力与大语言模型的工作方式相关。ChatGPT 等模型是根据统计概率挑选出一个适合上下文的词，当它寻找其数据集中不存在的信息时，它会用看似合理的词贴补空白。它是使用海量的数据集训练的，编造虚构故事对其而言就是信手拈来，它还能根据上下文让虚构的故事看起来逼真。AI 研究人员使用名叫 temperature（温度）的属性去控制模型的这种胡编乱造的“创造性”。如果它的值设置过低的话准确度会提高但会变得不太有趣。平衡创造性和准确度是微调 ChatGPT 之类模型的一大挑战。AI 公司 Hugging Face 的首席伦理科学家 Margaret Mitchel 说，ChatGPT 不是构建去实事求是，因此也不会实事求是。就是这么简单。\n\u003cp\u003e\u003c/p\u003e\n\u003c!--more--\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cbr/\u003e\nhttps://arstechnica.com/?p=1902025\t\t\t\t\t                \u003c/div\u003e",
  "Date": "2023-04-07T13:33:47Z",
  "Author": "Wilson"
}