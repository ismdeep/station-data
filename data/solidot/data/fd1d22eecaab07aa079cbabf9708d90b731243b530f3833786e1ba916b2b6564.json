{
  "Source": "solidot",
  "Title": "让 LLaMa 能运行在 CPU 上",
  "Link": "https://www.solidot.org/story?sid=74335",
  "Content": "\u003cdiv class=\"p_mainnew\"\u003e\n\t\t\t\t\tAI 聊天机器人的炙手可热让 GPU 尤其是英伟达的 GPU 再次成为市场热点。今天流行的聊天机器人如 OpenAI 的 ChatGPT 运行在云服务器上，对普通用户而言日常使用只能依赖于 OpenAI。Meta 的大语言模型 LLaMA 则让工作站用户在配备服务器级 GPU 的本地计算机上运行成为可能。类似开源的文本图像模型 Stable Diffusion，开发者也在快速推动大语言模型的普及化。一位西雅图的开发者将 LLaMA 移植到了 CPU 上。对于 LLaMA-7B 模型（包含 70 亿参数） ，Ryzen 7900X 能每秒推断出多个单词。\n\u003cp\u003e\u003c/p\u003e\n\u003c!--more--\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cbr/\u003e\nhttps://github.com/markasoftware/llama-cpu\t\t\t\t\t                \u003c/div\u003e",
  "Date": "2023-03-08T14:41:27Z",
  "Author": "Wilson"
}