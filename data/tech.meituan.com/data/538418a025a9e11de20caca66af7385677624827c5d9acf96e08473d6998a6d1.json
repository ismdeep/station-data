{
  "Source": "tech.meituan.com",
  "Title": "情感分析技术在美团的探索与应用",
  "Link": "https://tech.meituan.com/2021/10/20/the-applications-of-sentiment-analysis-meituan.html",
  "Content": "\u003cdiv class=\"post-content\"\u003e\u003cdiv class=\"content\"\u003e\u003cp\u003e\u003cimg src=\"https://p0.meituan.net/travelcube/0f8ee0bd25ea4ea7f03777122fdcea032382451.png\" alt=\"\"/\u003e\n\u003cimg src=\"https://p1.meituan.net/travelcube/8efd99656384148dd497199520018e064914163.png\" alt=\"\"/\u003e\n\u003cimg src=\"https://p1.meituan.net/travelcube/5c2cb8456eedffcfeb13c59709678de23163930.png\" alt=\"\"/\u003e\u003c/p\u003e\u003ch2 id=\"参考文献\"\u003e参考文献\u003c/h2\u003e\u003cul\u003e\u003cli\u003e[1] \u003ca href=\"https://github.com/Meituan-Dianping/asap\"\u003ehttps://github.com/Meituan-Dianping/asap\u003c/a\u003e.\u003c/li\u003e\u003cli\u003e[2] Bu J, Ren L, Zheng S, et al. ASAP: A Chinese Review Dataset Towards Aspect Category Sentiment Analysis and Rating Prediction. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021.\u003c/li\u003e\u003cli\u003e[3] \u003ca href=\"https://www.luge.ai/\"\u003ehttps://www.luge.ai/\u003c/a\u003e\u003c/li\u003e\u003cli\u003e[4] Zhang, L. , S. Wang , and B. Liu . “Deep Learning for Sentiment Analysis : A Survey.” Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery (2018):e1253.\u003c/li\u003e\u003cli\u003e[5] Liu, Bing. “Sentiment analysis and opinion mining.” Synthesis lectures on human language technologies 5.1 (2012): 1-167.\u003c/li\u003e\u003cli\u003e[6] Peng, Haiyun, et al. “Knowing what, how and why: A near complete solution for aspect-based sentiment analysis.” In Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 05. 2020.\u003c/li\u003e\u003cli\u003e[7] Zhang, Chen, et al. “A Multi-task Learning Framework for Opinion Triplet Extraction.” In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings. 2020.\u003c/li\u003e\u003cli\u003e[8] Yoon Kim. 2014. Convolutional neural networks for sentence classification. arXiv preprint arXiv:1408.5882.\u003c/li\u003e\u003cli\u003e[9] Peng Zhou, Wei Shi, Jun Tian, Zhenyu Qi, Bingchen Li,Hongwei Hao, and Bo Xu. 2016. Attention-based bidirectional long short-term memory networks for relation classification. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 207–212.\u003c/li\u003e\u003cli\u003e[10] Devlin, Jacob, et al. “Bert: Pre-training of deep bidirectional transformers for language understanding.” arXiv preprint arXiv:1810.04805 (2018).\u003c/li\u003e\u003cli\u003e[11] 杨扬、佳昊等. 美团BERT的探索和实践.\u003c/li\u003e\u003cli\u003e[12] Pontiki, Maria, et al. “Semeval-2016 task 5: Aspect based sentiment analysis.” International workshop on semantic evaluation. 2016.\u003c/li\u003e\u003cli\u003e[13] Pontiki, M. , et al. “SemEval-2014 Task 4: Aspect Based Sentiment Analysis.” In Proceedings of International Workshop on Semantic Evaluation at (2014).\u003c/li\u003e\u003cli\u003e[14] Yequan Wang, Minlie Huang, and Li Zhao. 2016. Attention-based lstm for aspect-level sentiment classification. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 606–615.\u003c/li\u003e\u003cli\u003e[15] Sara Sabour, Nicholas Frosst, and Geoffrey E Hinton. 2017. Dynamic routing between capsules. In Advances in neural information processing systems, pages 3856–3866.\u003c/li\u003e\u003cli\u003e[16] Chi Sun, Luyao Huang, and Xipeng Qiu. 2019. Utilizing bert for aspect-based sentiment analysis via constructing auxiliary sentence. arXiv preprint arXiv:1903.09588.\u003c/li\u003e\u003cli\u003e[17] Qingnan Jiang, Lei Chen, Ruifeng Xu, Xiang Ao, and Min Yang. 2019. A challenge dataset and effective models for aspect-based sentiment analysis. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 6281–6286.\u003c/li\u003e\u003cli\u003e[18] Wu, Zhen, et al. “Grid Tagging Scheme for End-to-End Fine-grained Opinion Extraction.” In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings. 2020.\u003c/li\u003e\u003cli\u003e[19] Liu, Yinhan, et al. “Roberta: A robustly optimized bert pretraining approach.” arXiv preprint arXiv:1907.11692 (2019).\u003c/li\u003e\u003cli\u003e[20] Clark, Kevin, et al. “Electra: Pre-training text encoders as discriminators rather than generators.” arXiv preprint arXiv:2003.10555 (2020).\n0- [21] Timothy Dozat and Christopher D. Manning. 2017.Deep biaffine attention for neural dependency parsing. In 5th International Conference on Learning Representations, ICLR 2017.\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"作者介绍\"\u003e作者介绍\u003c/h2\u003e\u003cp\u003e任磊、佳昊、张辰、杨扬、梦雪、马放、金刚、武威等，均来自美团平台搜索与NLP部NLP中心。\u003c/p\u003e\u003ch2 id=\"招聘信息\"\u003e招聘信息\u003c/h2\u003e\u003cp\u003e美团搜索与NLP部/NLP中心是负责美团人工智能技术研发的核心团队，使命是打造世界一流的自然语言处理核心技术和服务能力。\u003c/p\u003e\u003cp\u003eNLP中心长期招聘自然语言处理算法专家/机器学习算法专家，感兴趣的同学可以将简历发送至renlei04@meituan.com。具体要求如下。\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e岗位职责\u003c/strong\u003e\u003c/p\u003e\u003col\u003e\u003cli\u003e预训练语言模型前瞻探索，包括但不限于知识驱动预训练、任务型预训练、多模态模型预训练以及跨语言预训练等方向；\u003c/li\u003e\u003cli\u003e负责百亿参数以上超大模型的训练与性能优化；\u003c/li\u003e\u003cli\u003e模型精调前瞻技术探索，包括但不限于Prompt Tuning、Adapter Tuning以及各种Parameter-efficient的迁移学习等方向；\u003c/li\u003e\u003cli\u003e模型inference/training压缩技术前瞻探索，包括但不限于量化、剪枝、张量分析、KD以及NAS等；\u003c/li\u003e\u003cli\u003e完成预训练模型在搜索、推荐、广告等业务场景中的应用并实现业务目标；\u003c/li\u003e\u003cli\u003e参与美团内部NLP平台建设和推广\u003c/li\u003e\u003c/ol\u003e\u003cp\u003e\u003cstrong\u003e岗位要求\u003c/strong\u003e\u003c/p\u003e\u003col\u003e\u003cli\u003e2年以上相关工作经验，参与过搜索、推荐、广告至少其一领域的算法开发工作，关注行业及学界进展；\u003c/li\u003e\u003cli\u003e扎实的算法基础，熟悉自然语言处理、知识图谱和机器学习技术，对技术开发及应用有热情；\u003c/li\u003e\u003cli\u003e熟悉Python/Java等编程语言，有一定的工程能力；\u003c/li\u003e\u003cli\u003e熟悉Tensorflow、PyTorch等深度学习框架并有实际项目经验；\u003c/li\u003e\u003cli\u003e熟悉RNN/CNN/Transformer/BERT/GPT等NLP模型并有过实际项目经验；\u003c/li\u003e\u003cli\u003e目标感强，善于分析和发现问题，拆解简化，能够从日常工作中发现新的空间；\u003c/li\u003e\u003cli\u003e条理性强且有推动力，能够梳理繁杂的工作并建立有效机制，推动上下游配合完成目标。\u003c/li\u003e\u003c/ol\u003e\u003cp\u003e\u003cstrong\u003e加分项\u003c/strong\u003e\u003c/p\u003e\u003col\u003e\u003cli\u003e熟悉模型训练各Optimizer基本原理，了解分布式训练基本方法与框架；\u003c/li\u003e\u003cli\u003e对于最新训练加速方法有所了解，例如混合精度训练、低比特训练、分布式梯度压缩等\u003c/li\u003e\u003c/ol\u003e\u003c/div\u003e\u003c/div\u003e",
  "Date": "2021-10-20T00:00:00Z",
  "Author": "soulteary@gmail.com"
}