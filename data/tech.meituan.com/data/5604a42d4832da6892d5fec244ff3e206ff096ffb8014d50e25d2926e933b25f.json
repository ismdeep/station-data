{
  "Source": "tech.meituan.com",
  "Title": "信息流广告预估技术在美团外卖的实践",
  "Link": "https://tech.meituan.com/2024/08/16/information-flow-advertising-prediction-technology.html",
  "Content": "\u003cdiv class=\"post-content\"\u003e\u003cdiv class=\"content\"\u003e\u003ch2 id=\"1-信息流广告业务及预估技术现状\"\u003e1 信息流广告业务及预估技术现状\u003c/h2\u003e\u003ch3 id=\"1-1-信息流广告业务特点\"\u003e1.1 信息流广告业务特点\u003c/h3\u003e\u003cp\u003e目前，美团外卖的广告主要包括信息流广告、搜索广告、营销广告、展示广告等等。外卖业务都有着典型的业务特点：\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003e用户行为连贯性强\u003c/strong\u003e：用户用餐意图明确，一般在10分钟内完成，UV成单率较高。\u003c/li\u003e\u003cli\u003e\u003cstrong\u003e展示信息丰富\u003c/strong\u003e：卡片信息覆盖了评分、评价、优惠、配送等多种信息，对用户的决策影响较强。\u003c/li\u003e\u003cli\u003e\u003cstrong\u003e文本信息多\u003c/strong\u003e：在电商场景中，商品作为候选图片往往占据很大的决定因素，而在外卖场景下，商家作为候选更加复杂，商户名称、评价、热销菜品等文本信息能够影响用户做出决策。\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cimg src=\"https://p1.meituan.net/travelcube/2f465d302f7d7b53f27e334fa7a9cfe01815373.png\" alt=\"\"/\u003e\u003c/p\u003e\u003ch3 id=\"1-2-技术概况及演进阶段\"\u003e1.2 技术概况及演进阶段\u003c/h3\u003e\u003cp\u003e这里先来介绍一下预估技术的现状。从技术层面，下图展示了广告投放系统的整体的流程：\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p0.meituan.net/travelcube/a8dc4131af681d98aee50dd673058981529846.png\" alt=\"\"/\u003e\u003c/p\u003e\u003cp\u003e总的来说，外卖广告系统跟我们在业界的搜推广系统是比较相似的，召回、粗排、精排以及各种机制。但外卖广告和业界场景区别较大的地方在于召回，因为它是基于位置服务（LBS）的，这个过程本身带有一定的约束。因此，我们会在精排和机制层面投入更多的算力和资源，以期给整体链路带来最大化的提升。\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p0.meituan.net/travelcube/5e8fe3fee5ea1ea169d2f8ce91dd8230473133.png\" alt=\"\"/\u003e\u003c/p\u003e\u003cp\u003e在过去六七年中，到家广告预估算法历经了三个发展阶段，第一个阶段就是树模型，包括连续特征、交叉统计等等，当时的模型拟合能力是比较受限的。第二个阶段是从2017年开始到2020年，在这个阶段DNN模型开始爆发，我们进行了特征升级，也开始紧随业界步伐，引入更加复杂的模型，不断提升业务效果。第三个阶段就是2021年至今，我们主要方向是稀疏大模型+超长序列，进一步实现业务效果的提升。\u003c/p\u003e\u003ch3 id=\"1-3-预估技术现状\"\u003e1.3 预估技术现状\u003c/h3\u003e\u003cp\u003e在信息流广告预估技术层面，主要探索方向为用户方向、链路方向以及NLP方向（如下图所示）。当然，如果这张图更全面一些，还会包括交叉方向，还有多场景多目标等等。而没有选择其他方向，主要是因为就交叉方向而言，我们发现随着互联网行业的不断发展，用户的行为会越来越多且更加复杂，而交叉方向仅仅能带来Context级别的深度学习能力，也就无法持续的成为效果的来源。另一个方面，虽然交叉技术也在发展，但发展方向上也是从ID matching 到 Sequence Matching，单纯平铺类类别特征的交叉模型能力发展有限。综合多方面的因素，我们并没有将交叉作为一个长期的方向进行迭代。\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p0.meituan.net/travelcube/ba5428b3be2a7232d9abe5f9ce124935649348.png\" alt=\"\"/\u003e\u003c/p\u003e\u003cp\u003e还有一个是多场景方向，其实此前我们在这个方向也做过一些迭代带来了一波效果，但是后来我们发现，这种技术更加适合多个小场景的链接。如果你所服务的业务仅仅只有1~2个比较大的场景，这些场景本身的用户需求差异性、展示形态、候选供给差别又不大，就不太能发挥这个方向的技术能力及作用。\u003c/p\u003e\u003cp\u003e我们整体的思路是从用户的元素匹配、页面匹配，到路径匹配，最后到长期的兴趣匹配。本质上都是在做不同层面的用户匹配相关的工作。其中，元素匹配、页面匹配归到了链路方向。原因是链路方向更多的都是在解决“看不见的问题”，然后再通过这些“被看见”的信息去做相应建模，所以我们将链路方向单独列了出来。\u003c/p\u003e\u003cul\u003e\u003cli\u003e在用户方向，我们也大概经历了三个阶段，第一个阶段，要从原始单点、单入口的行为，向全行为、全入口进行扩张；第二个阶段，是在已有的输入的情况下，去探索更多的行为模式；第三个阶段，我们主要是做一些自动化模式提取，或者说网络自动拟合行为的能力做到更强。\u003c/li\u003e\u003cli\u003e在链路方向，主要关注两件事，一个是页面还原，一个是卡片还原，通过算法和工程能力来还原用户“所见”到模型决策中。\u003c/li\u003e\u003cli\u003e在NLP方向，过去我们还有一个方向叫多模态，但是客观来讲，随着LLM的火爆，外界的技术也给我们更多的输入，因此我们将LLM IN CTR单独列出来作为一个主要的技术方向。\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"2-信息流广告在美团的实践\"\u003e2 信息流广告在美团的实践\u003c/h2\u003e\u003ch3 id=\"2-1-用户建模思路概览\"\u003e2.1 用户建模思路概览\u003c/h3\u003e\u003cp\u003e用户方向整体又拆解为三个反向，第一个是时间线，第二个是空间线，第三个是时间和空间共同作用下的行为模式。当时我们在拆解的时候，也参考了业界学界主要迭代的方法，包括Session建模、超长行为建模、多行为建模、长短期建模等。以学界和业界为基础，结合业务问题、特点，将技术和业务结合的更好，有了以下的技术拆解。\u003c/p\u003e\u003cp\u003e在时间线上，我们认为长短期的多Level融合更加重要。一方面是用户兴趣在不同级别“片段” 上关注点有显著差异，比如页面倾向比较、路径上的兴趣更连续、用户会连续吃一段时间轻食等，我们需要将这种在不同级别片段上的用户行为模式提取出来。因此，一方面我们通过更多页面和路径的方式将短期和长期进行联合；同时，我们通过增加日、周级别的中期兴趣，将短中、短长进行交互，增强时间线行为上的连接。另一方面，在模型上增加一些端到端的方式，自动化的将行为规律挖掘出来。这是时间线要解决的关键问题。\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p0.meituan.net/travelcube/b370246254c06dcc2fcd05b27e8298a6768373.png\" alt=\"\"/\u003e\u003c/p\u003e\u003cp\u003e在空间线上，真实物理空间维度下，我们面对的问题比较明确，在不同的位置下，比如上班的时候和在家的时候，人的兴趣其实是不完全一样的，我们根据空间的位置为大家进行推荐。在虚拟空间下，比如用户在使用美团App和大众点评App等不同入口，人的兴趣和意图也会发生较大变化。一个显著的例子是，用户在首页和会员入口上对优惠的关注区别较大。空间线解决的问题是结合真实空间、虚拟空间，去判断用户的真实的意图或者行为模式。\u003c/p\u003e\u003cp\u003e第三条线，就是跟业务进行结合，比如用户在App上进行了一些操作（领取了红包），那么这个行为会对点餐有什么影响。本质上是模型在理解用户进行了一些操作行为后，会对接下来的行为产生哪些影响，进而模型能学习到不同的用户行为模式、更好的预测用户的行为。以上就是我们用户建模的整体思路。\u003c/p\u003e\u003ch4 id=\"2-1-1-决策路径建模\"\u003e2.1.1 决策路径建模\u003c/h4\u003e\u003cp\u003e本部分会介绍一下决策路径建模，第一个核心的问题就是，DIN单点匹配忽略了什么？单点匹配，我们认为是忽略了前序行为对用户后续行为的一个影响。对绝大多数电商业务来说，用户在一段时间内的行为是具备一定的连贯性的，我们可以根据用户的历史行为数据，对接下来的行为做出预测。这里有两个挑战，第一，如何构建核心路径；第二，如何解决路径本身的噪声、稀疏性、匹配等问题。我们的解法主要有三点：\u003c/p\u003e\u003cp\u003e第一，Path Enhance Module（PEM）提取核心路径。\u003c/p\u003e\u003cul\u003e\u003cli\u003e判断前置路径和候选（历史路径为点击）的相关性，建模路径置信度。\u003c/li\u003e\u003cli\u003e对原始进行全连接的MLP激活+Softmax Top K结合原始表示作为核心路径表达。\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e第二，Path Augment Module（PAM）扩充路径。\u003c/p\u003e\u003cul\u003e\u003cli\u003e使用用户的增广路径作为正样本、其他用户的路径作为负样本，引入对比学习Loss，提升路径表示学习能力。\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e第三，Path Matching Module（PMM）路径+点双层匹配。\u003c/p\u003e\u003cul\u003e\u003cli\u003e基于PEM 表示，构建路径匹配Attention，进一步对历史路径取Top K，去除掉无关路径影响提升候选点匹配精度。\u003c/li\u003e\u003cli\u003e进一步引入点（item）匹配，完成双层匹配。\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cimg src=\"https://p1.meituan.net/travelcube/860d53133357e2b2bae58dceed56622f540933.png\" alt=\"\"/\u003e\u003c/p\u003e\u003ch4 id=\"2-1-2-用户行为超长超宽建模\"\u003e2.1.2 用户行为超长超宽建模\u003c/h4\u003e\u003cp\u003e相信很多同学都知道超长建模，基本上是通过聚类、局部hash等近似技术来进行实现。要引入超宽建模，本质上是因为我们需要将所有的输入都放到一起，所以需要一个更大更复杂的模型去把事情给处理了。不过，在实际中我们没有完全实现，因为目前的算力还是无法支持的。我们做了一个折中，长度是1000（Length）的级别，宽度我们目前做到10+这个级别，离线可以支持到更大的规模、到万级别效果也有较大提升，但是迭代效率、线上压力都会有较大限制。\u003c/p\u003e\u003cp\u003e这里也面临2个问题：第一个问题就是SIM/ETA为什么没有带来效果？这个方向，最早是电商平台提出来的，SIM主要是Hard过滤，比如通过用户在网站浏览鞋相关的行为时，他们也会看其他各种各样的东西，它通过硬过滤，能够把跟「鞋」相关的产品能过滤出来，过滤掉和鞋无关的噪音，学习到用户在鞋上的偏好。点外卖相对不太一样，对一个候选汉堡来讲，通过汉堡品类过滤掉和汉堡无关的行为，这会损失较多用户口味信息。这是业务差异性带来的。\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p0.meituan.net/travelcube/5a50ab84e70be7d1e251c2f88f2972e7602873.png\" alt=\"\"/\u003e\u003c/p\u003e\u003cp\u003e第二个问题是，拟合DIN Score是否是长序列的终局？之前业界有一篇文章认为DIN Score 是基准，把它线性扩展就能带来效果，进一步扩展到万级别或者十万级别把效果推到最大化。但是通过实验，我们的CTR场景线性扩展到超长级别并没有持续带来效果，反而到一定长度有所下降。我们认为DIN网络本身的去噪能力不是很强，或者说它去提取出Label结果的结构能力并不够强。如果它不是一个特别强的网络，做更大的扩展的时候，它所能容纳的信息是比较有限的。\u003c/p\u003e\u003cp\u003e我们可以把CTR理解成一个去噪任务，本质上是根据用户历史和当前场景Match用户和候选的过程。我们发现，如果能预测出精准或者去除掉所有噪声，比如拿穿越信息Label POI与Target进行匹配，使用简单的网络也可以有很高的AUC。因此，我们认为完美的CTR网络应该是一个强预测网络+弱匹配网络的组合。预测网络应该是一个能力非常强的网络，能够进行多层的叠加，把信息进行萃取得到一个预测更加精准的结果，来与Target进行匹配。所以我们设计了一个多层的Decoder，每一层的Decoder都能做信息的整合。通过不断的选取有效矩阵、反复叠加有效信息，来使得信息更加精准。这里我们做了一组Scaling Law实验，通过叠加多轮网络来验证结果的有效性。可以看到随着轮数的增加，网络学习用户行为的能力（AUC逐层提升）也有所增加。\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p0.meituan.net/travelcube/6015fd3cd58d51cdf13abfe3097488e6818857.png\" alt=\"\"/\u003e\u003c/p\u003e\u003ch3 id=\"2-2-全还原建模\"\u003e2.2 全还原建模\u003c/h3\u003e\u003cp\u003e首先，什么是全还原建模？我们给的一个定义是还原用户所见所得。CTR任务是根据用户看到的信息来判断用户是否点击，最重要的一点是将看见的信息全部纳入到模型之中，过往简单的通过ID表示建模忽略了上下文及展示的信息，带来了较大的信息GAP。\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p0.meituan.net/travelcube/f7cb5f3514a2b196376b99dc7b52276c1804018.png\" alt=\"\"/\u003e\u003c/p\u003e\u003cp\u003e第一个视角，上下文卡片无法获得。上下文信息对当前候选、当前卡片的CTR相当重要。有的同学可能会认为重排可以搞定这个事情，但我们始终认为，上下文信息属于链路信息，我们认为每个模块都需要去学习上下文信息，当然每个模块可能学习的重点不一样，而且实际上都能带来一定的效果。第二个视角，我们从算力的角度，因为预估侧的算力比较高，其影响的范围会更大，实际上也能够带来更多的效果空间。\u003c/p\u003e\u003cp\u003e再看左下角的图，从链路视角来说，对于预估模块、广告模块模块存在两个无法获取。第一个是广告的后链路信息无法获取，这里包括了展示的配送信息、配送费、准确的优惠信息等；第二个是自然的信息无法获取，这里包括了自然的上下文。因此，还原从另一个角度说是，如何打破链路的束缚来使用穿越信息。\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p0.meituan.net/travelcube/b5aded1dcba3fd6748ce11b88a4eb1551740674.png\" alt=\"\"/\u003e\u003c/p\u003e\u003cp\u003e这就是全还原建模所面临的一些问题，实际上可以概括成两个方向，一个是卡片还原，一个是页面还原。在早期我们做了个空间判断，我们把卡片、页面信息完完整整的放进来，观测AUC的提升来判断整体空间，结果表明页面信息有百分点级别、卡片信息有大几个千分点。\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e整体解决思路\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e这里把页面还原和卡片还原展开。首先，从思路上讲，我们主要从算法、工程两个维度去解。在算法层面，第一个就是去猜页面，最大化利用前链路信息猜页面；第二个是猜元素，创意链路前置，创意优选结果输出给精排。在工程层面，第一个是存页面，引入近线系统，基于旁路系统的Side Model端到端预测最终展现信息，最大化利用后链路视野。第二个是存元素，引入近线系统+高维KV，提升元素获取覆盖率至+100%、准确率70%+。\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p1.meituan.net/travelcube/5940163c24e14e9f9dd99a3d84903eb11537133.png\" alt=\"\"/\u003e\u003c/p\u003e\u003cp\u003e前文也提到，上下文信息对最终的点击有较大影响，因CTR模块无法拿到上下文过去的解决方式是引入重排对小范围队列进行建模，这样降低了上下文链路信息的影响。接下来，我们面临的挑战就是：\u003c/p\u003e\u003cul\u003e\u003cli\u003e上下文包括了集合和序两个部分，如何构建上下文预测模块?\u003c/li\u003e\u003cli\u003eSimulated上下文与候选如何进行交互?\u003c/li\u003e\u003cli\u003e如何进一步通过蒸馏提升Simulated Page的准确性?\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cimg src=\"https://p0.meituan.net/travelcube/11a1ad473caa6a2ffeb7d1f9438243e9745126.png\" alt=\"\"/\u003e\u003c/p\u003e\u003cp\u003e我们的解法是：\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eContext Simulation Center（CSC）\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e曝光网络学习集合：通过曝光概率预估网络来建模哪些-item最可能曝光给用户，输入为千级别自然队列。\u003c/li\u003e\u003cli\u003e排序网络学习序：对曝光网络输出的结果进行排序，目标位最终展现的位置，通过NDCG来衡量。\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eContext Modeling Transformer （CMT）\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eContext Encoder/Decoder：使用Transformer对带位置编码的上下文进行编码。引入候选通过MLP网络与Encoder 输出作为Decoder输入，得到最终的Context表达。\u003c/li\u003e\u003cli\u003e真实曝光蒸馏：引入Simulated Page是一个强信号，但是依然存在与真实曝光page的差距。因此构建Simauted Page 作为输入的Student网络来蒸馏学习基于Real Page的Teacher网络进一步去除噪音。（注：直接蒸馏无信号无法学习）\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e我们引入了缓存的和预测配置策略，加上真实的蒸馏，就帮助我们进一步地去提升效果，这属于页面还原的部分。\u003c/p\u003e\u003cp\u003e卡片还原这部分整体的思路分为三部分：第一个部分，能够拿到卡片信息；第二部分，组成用户看到的卡片；第三部分，通过卡片来做历史兴趣匹配。\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e卡片方案思考\u003c/strong\u003e：由于搜推广系统的模块串并行原因，有一部分数据我们是无法获取的，前期我们一直在思考有没有“终极方案”。早期我们就是纯平铺（纯ID）的方式来还原用户所看到的信息，但是有没有更好的方式呢？比如直接将用户看到的图片引入进来。但是，当前的技术能力不太支持将整个图片完成的记录下来、更不支持图片信息完整准确的建模表达。最终，我们选择了通过矩阵的方式来组成卡片，模拟用户看到的信息。\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e矩阵化表达、Patch级别建模\u003c/strong\u003e：首先，我们使用了矩阵化的表达来组成卡片的形状，并构建和用户所见所得的上下元素关系。表示层面，不同的矩阵构建方式对结果会有一定的影响，具体不在这里展开。第二个方面，我们也借鉴了图像领域的一些思想，引入了Patch的概念，来帮助我们将图片化作Token进一步学好不同展示元素之间的相互影响。在实践的过程中，我们也需要调整一些参数，比如Patch到底是2*2的，还是3*3。包括stride，我们发现stride设置的越短，确实能够带来更好的效果。我们在整个patch 级别匹配的过程中，也做了很多次的实验，初步的结论是，单位置Patch和全局Patch的匹配，最终的效果比较好。\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e关注顺序建模\u003c/strong\u003e：顺序建模是在用户关注哪些元素基础上，进一步模拟用户浏览顺序。按道理说，我们没有眼部监测实际上是拿不到这部分数据的。这里，我们做了一个小Trick，将这4个Patch的矩阵进行了全排列，将用户的所有Patch级别的路径都列了出来，让模型自己来学习不同排列组合的隐式分数。激活分数最高的的Patch顺序组合，通过Encoder聚合成关注顺序表达来进一步和Target的POI的关注顺序组合来进行匹配。\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p0.meituan.net/travelcube/0165258f2d9c9d7fcf6783a0b59874ca624710.png\" alt=\"\"/\u003e\u003c/p\u003e\u003ch3 id=\"2-3-llm-in-ctr\"\u003e2.3 LLM in CTR\u003c/h3\u003e\u003cp\u003e最后分享一下大模型在CTR的应用。我们做了一些初步的调研，发现目前很多技术团队整体的思路是差不多的。下图展示了CTR任务跟NLP任务的对比，可以看到从输入到模型架构，再到学习模式和任务模式，都有较大区别。NLP任务是自然语言做 Token + 大规模 Transformer + 理解及推理能力，CTR任务是ID 输入+ 人工设计网络 + 强记忆能力。同时对于CTR，大部分业务只用了自身业务数据，是缺乏外部知识和全任务的理解能力的。\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p0.meituan.net/travelcube/4e5bcd7f81b409446270f64beaa307d1590034.png\" alt=\"\"/\u003e\u003c/p\u003e\u003cp\u003e所以基于以上几个方面，我们做了三方面的工作：\u003c/p\u003e\u003cul\u003e\u003cli\u003e第一层，知识注入，就是要把外部的、真实的、当前CTR缺乏哪些知识放到模型中，这部分工作很多公司都在做，这块主要要求的是Prompt工程能力。因为生成的结果，不一定是CTR需要的，我们就需要做好适配工作。根据CTR的特点，就可以将高频词和低频词区分出来，同时也需要做一些Prompt融合相关的后处理工作来提升和CTR任务的匹配度。\u003c/li\u003e\u003cli\u003e第二层，思维注入，就是要把大模型的结构能力给引入进来，或者说将大模型判断过程的引入进来。\u003c/li\u003e\u003cli\u003e第三层，范式迭代，最近，Meta似乎给生成式推荐指出了一条路。我们去年在探索这个方向的时候，主要的思路是把输入的形式进行变化，换成了更小规模的Token，大概可能只有几万的规模，来解决大规模Softmax问题。然后通过Transform叠加的方式，结合聚合语义，从模型融合到端到端自回归，让数据能够跑通。我们发现如果噪音特别高的输入，Transformer并不能处理得很好，但一个相对来讲语义比较明确的信息，Transformer对上下文理解的性能还不错，因此我们先做了一层语义聚合来降低输入Token序列的噪音。总的来说，我们通过小规模Token，加上语义聚合，结合Transformer的架构，给业务效果带来了一波提升。\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cimg src=\"https://p0.meituan.net/travelcube/196efba3e3c47c7f83857edc59edb55a639344.png\" alt=\"\"/\u003e\u003c/p\u003e\u003cp\u003e总结一下，本质上是要把CTR不具备的能力通过大模型进行补齐。我们将CTR目前不具备的能力，划分成了知识能力、泛化能力和推理能力。对应的，我们也列举了一些我们尝试的结果如下图所示：\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p0.meituan.net/travelcube/590129c0a111e27dd71bc8f9b39eea10338022.png\" alt=\"\"/\u003e\u003c/p\u003e\u003ch2 id=\"03-总结和展望\"\u003e03 总结和展望\u003c/h2\u003e\u003cp\u003e总的来说，预估的本质上还是要发掘用户的真实需求，我们一方面参考业界，另一方面深入业务，去挖掘更多的用户行为模式，也在探索有没有更自动化的方式将各种用户问题解决掉。还原建模是算法和工程的联合聚力带来的提升，归根结底算法工程的相互结合才能带来更大的改变。\u003c/p\u003e\u003cp\u003e大模型与推荐的结合越来越得到大家的关注，但是客观地讲，这依然是属于一个偏长期的工作，这个时候还是要找到一条可行的路径，不断去优化和提升，如果完全指望用一个“大招”去解决掉所有的问题，会非常困难。端到端推荐大模型是大家共同的期望，但是在这个基础上，我们认为输入规模是效果的保障，算力是以上两者的保障。只有软件和硬件的强强联合，才能赢得未来。\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "Date": "2024-08-16T00:00:00Z",
  "Author": "soulteary@gmail.com"
}