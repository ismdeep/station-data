{
  "Source": "tech.meituan.com",
  "Title": "KDD Cup 2020多模态召回比赛亚军方案与搜索业务应用",
  "Link": "https://tech.meituan.com/2020/09/27/kdd-cup-multimodalities-recall-02.html",
  "Content": "\u003cdiv class=\"post-content\"\u003e\u003cdiv class=\"content\"\u003e\u003ch2 id=\"1-背景\"\u003e1. 背景\u003c/h2\u003e\u003cp\u003e\u003ca href=\"https://www.kdd.org/kdd2020/\"\u003eACM SIGKDD\u003c/a\u003e（ACM SIGKDD Conference on Knowledge Discovery and Data Mining）是世界数据挖掘领域的顶级国际会议。KDD Cup比赛由ACM SIGKDD举办，从1997年开始每年举办一次，也是数据挖掘领域最有影响力的赛事之一。该比赛同时面向企业界和学术界，云集了世界数据挖掘界的顶尖专家、学者、工程师、学生等参加，通过竞赛，为数据挖掘从业者们提供了一个学术交流和研究成果展示的理想场所。今年，KDD Cup共设置四个赛道共五道赛题，涉及数据偏差问题（Debiasing）、多模态召回（Multimodalities Recall）、自动化图学习（AutoGraph）、对抗学习问题和强化学习问题。\u003c/p\u003e\u003cp\u003e美团搜索广告算法团队最终在\u003ca href=\"https://tianchi.aliyun.com/competition/entrance/231785/rankingList\"\u003eDebiasing\u003c/a\u003e赛道中获得冠军（1/1895），在\u003ca href=\"https://www.4paradigm.com/competition/kddcup2020\"\u003eAutoGraph\u003c/a\u003e赛道中也获得了冠军（1/149）。在\u003ca href=\"https://tianchi.aliyun.com/competition/entrance/231786/rankingList\"\u003eMultimodalities Recall\u003c/a\u003e赛道中，亚军被美团搜索与NLP团队摘得（2/1433），美团搜索广告算法团队获得了第三名（3/1433）。\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p0.meituan.net/travelcube/7424fe5f13ba7b0ed56d646b4d5f4fdc1090193.png@1838w_1204h_80q\" alt=\"图1 KDD Cup 2020 Multimodalities Recall 比赛TOP 10榜单\"/\u003e\u003c/p\u003e\u003cp\u003e跟其它电商公司一样，美团业务场景中除了文本，还存在图片、动图、视频等多种模态信息。同时，美团搜索是典型的多模态搜索引擎，召回和排序列表中存在POI、图片、文本、视频等多种模态结果，如何保证Query和多模态搜索结果的相关性面临着很大的挑战。鉴于多模态召回赛题（Multimodalities Recall）和美团搜索业务的挑战比较类似，本着磨炼算法基本功和沉淀相关技术能力的目的，美团搜索与NLP组建团队参与了该项赛事，最终提出的“基于ImageBERT和LXMERT融合的多模态召回解决方案”最终获得了第二名（2/1433）（\u003ca href=\"https://tianchi.aliyun.com/competition/entrance/231786/rankingList\"\u003eKDD Cup2020 Recall榜单\u003c/a\u003e）。本文将介绍多模态召回赛题的技术方案，以及多模态技术在美团搜索场景中的落地应用。\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e相关代码已经在GitHub上开源\u003c/strong\u003e：\u003ca href=\"https://github.com/zuokai/KDDCUP_2020_MultimodalitiesRecall_2nd_Place\"\u003ehttps://github.com/zuokai/KDDCUP_2020_MultimodalitiesRecall_2nd_Place\u003c/a\u003e。\u003c/p\u003e\u003ch2 id=\"2-赛题简介\"\u003e2. 赛题简介\u003c/h2\u003e\u003cp\u003e2019年，全球零售电子商务销售额达3.53万亿美元，预计到2022年，电子零售收入将增长至6.54万亿美元。如此快速增长的业务规模表明了电子商务行业的广阔发展前景，但与此同时，这也意味着日益复杂的市场和用户需求。随着电子商务行业规模的不断增长，与之相关的各个模态数据也在不断增多，包括各式各样的带货直播视频、以图片或视频形式展示的生活故事等等。新的业务和数据都为电子商务平台的发展带来了新的挑战。\u003c/p\u003e\u003cp\u003e目前，绝大多数的电子商务和零售公司都采用了各种数据分析和挖掘算法来增强其搜索和推荐系统的性能。在这一过程中，多模态的语义理解是极为重要的。高质量的语义理解模型能够帮助平台更好的理解消费者的需求，返回与用户请求更为相关的商品，能够显著的提高平台的服务质量和用户体验。\u003c/p\u003e\u003cp\u003e在此背景下，今年的KDD Cup举办了多媒体召回任务（Modern E-Commerce Platform: Multimodalities Recall），任务要求参赛者根据用户的查询Query，对候选集合中的所有商品图片进行相关性排序，并找出最相关的5个商品图片。举例说明如下：\u003c/p\u003e\u003cp\u003e如图2所示，用户输入的Query为：\u003c/p\u003e\u003cpre\u003e\u003ccode\u003eleopard-print women\u0026#39;s shoes\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e根据其语义信息，左侧图片与查询Query是相关的，而右侧的图片与查询Query是不相关的。\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p0.meituan.net/travelcube/aec66adefe7913e7f69680301372d067589688.png@1310w_670h_80q\" alt=\"图2 多模态匹配示意图\"/\u003e\u003c/p\u003e\u003cp\u003e从示例可以看出，该任务是典型的多模态召回任务，可以转化为Text-Image Matching问题，通过训练多模态召回模型，对Query-Image样本对进行相关性打分，然后对相关性分数进行排序，确定最后的召回列表。\u003c/p\u003e\u003ch3 id=\"2-1-比赛数据\"\u003e2.1 比赛数据\u003c/h3\u003e\u003cp\u003e本次比赛的数据来自淘宝平台真实场景下用户Query以及商品数据，包含三部分：训练集（Train）、验证集（Val）和测试集（Test）。根据比赛阶段的不同，测试集又分为testA和testB两个部分。数据集的规模、包含的字段以及数据样例如表1所示。真实样本数据不包含可视化图片，示例图是为了阅读和理解的便利。\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p1.meituan.net/travelcube/c674a68c84d425d6d670ccea40a4b9f7476149.png@1615w_501h_80q\" alt=\"表1 比赛数据集详情\"/\u003e\u003c/p\u003e\u003cp\u003e在数据方面，需要注意的点有：\u003c/p\u003e\u003cul\u003e\u003cli\u003e训练集（Train）每条数据代表相关的Query-Image样本对，而在验证集（Val）和测试集（Test）中，每条Query会有多张候选图片，每条数据表示需要计算相关性的Query-Image样本对。\u003c/li\u003e\u003cli\u003e赛事主办方已经对所有图片通过目标检测模型（Faster-RCNN）提取了多个目标框，并保存了目标框相应的2048维图像特征。因此，在模型中无需再考虑图像特征的提取。\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"2-2-评价指标\"\u003e2.2 评价指标\u003c/h3\u003e\u003cp\u003e本次比赛采用召回Top 5结果的归一化折损累计增益（Normalized Discounted Cumulative Gain，NDCG@5）来作为相关结果排序的评价指标。\u003c/p\u003e\u003ch2 id=\"3-经典解法\"\u003e3. 经典解法\u003c/h2\u003e\u003cp\u003e本次比赛需要解决的问题可以转化为Text-Image Matching任务，即对每一个Query-Image 样本对进行相似性打分，进而对每个Query的候选图片进行相关度排序，得到最终结果。多模态匹配问题通常有两种解决思路：\u003c/p\u003e\u003col\u003e\u003cli\u003e将不同模态数据映射到不同特征空间，然后通过隐层交互这些特征学习到一个不可解释的距离函数，如图3 (a)所示。\u003c/li\u003e\u003cli\u003e将不同模态数据映射到同一特征空间，从而计算不同模态数据之间的可解释距离（相似度），如图3 (b)所示。\u003c/li\u003e\u003c/ol\u003e\u003cp\u003e\u003cimg src=\"https://p1.meituan.net/travelcube/b08b58d911a21f4d2f9af37f10cc7395532993.png@1920w_1355h_80q\" alt=\"图3 常用的多模态匹配解决思路\"/\u003e\u003c/p\u003e\u003cp\u003e一般而言，同等条件下，由于图文特征组合后可以为模型隐层提供更多的交叉特征信息，因而左侧的模型效果要优于右侧的模型，所以在后续的算法设计中，我们都是围绕图3左侧的解决思路展开的。\u003c/p\u003e\u003cp\u003e随着Goolge BERT模型在自然语言处理领域的巨大成功，在多模态领域也有越来越多的研究人员开始借鉴BERT的预训练方法，发展出融合图片/视频（Image/Video）等其他模态的BERT模型，并成功应用与多模态检索、VQA、Image Caption等任务中。因此，考虑使用BERT相关的多模态预训练模型（Vision-Language Pre-training, VLP），并将图文相关性计算的下游任务转化为图文是否匹配的二分类问题，进行模型学习。\u003c/p\u003e\u003cp\u003e目前，基于Transformer模型的多模态VLP算法主要分为两个流派：\u003c/p\u003e\u003cul\u003e\u003cli\u003e单流模型，在单流模型中文本信息和视觉信息在一开始便进行了融合，直接一起输入到Encoder（Transformer）中。典型的单流模型如ImageBERT [3]，VisualBERT [9]、VL-BERT [10] 等。\u003c/li\u003e\u003cli\u003e双流模型，在双流模型中文本信息和视觉信息一开始先经过两个独立的Encoder（Transformer）模块，然后再通过Cross Transformer来实现不同模态信息的融合。典型的双流模型如LXMERT [4]，ViLBERT [8] 等。\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"4-我们的方法-transformer-based-ensembled-models-tbem\"\u003e4. 我们的方法：Transformer-Based Ensembled Models TBEM\u003c/h2\u003e\u003cp\u003e本次比赛中，在算法方面，我们选用了领域最新的基于Transformer的VLP算法构建模型主体，并加入了Text-Image Matching作为下游任务。除了构建模型以外，我们通过数据分析来确定模型参数，构建训练数据。在完成模型训练后，通过结果后处理策略来进一步提升算法效果。整个算法的流程如下图4所示：\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p1.meituan.net/travelcube/6b467cc15f5d2c89f59319266f1ba1df191228.png@1798w_980h_80q\" alt=\"图4 算法流程图\"/\u003e\u003c/p\u003e\u003cp\u003e接下来对算法中的每个环节进行详细说明。\u003c/p\u003e\u003ch3 id=\"4-1-数据分析-处理\"\u003e4.1 数据分析\u0026amp;处理\u003c/h3\u003e\u003cp\u003e数据分析和处理主要基于以下三个方面考虑：\u003c/p\u003e\u003cul\u003e\u003cli\u003e正负样本构建：由于主办方提供的训练数据中，只包含了相关的Query-Image样本对，相当于只有正样本数据，因此需要通过数据分析，设计策略构建负样本。\u003c/li\u003e\u003cli\u003e模型参数设定：在模型中，图片目标框最大数量、Query文本最大长度等参数需要结合训练数据的分布来设计。\u003c/li\u003e\u003cli\u003e排序结果后处理：通过分析Query召回的图片数据分布特点，确定结果后处理策略。\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e常规的训练数据生成策略为：对于每一个Batch的数据，按照1:1的比例选择正负样本。其中，正样本为训练集（Train）中的原始数据，负样本通过替换正样本中的Query字段产生，替换的Query是按照一定策略从训练集（Train）中获取。\u003c/p\u003e\u003cp\u003e为了提升模型学习效果，我们在构建负样本的过程中进行了难例挖掘，在构造样本时，通过使正负样本的部分目标框包含同样的类别标签，从而构建一部分较为相似的正负样本，以提高模型对于相似的正负样本的区分度。\u003c/p\u003e\u003cp\u003e难例挖掘的过程如下图5所示，左右两侧的相关样本对都包含了“shoes”这一类别标签，使用右侧样本对的Query替换左侧图片的Query，从而构建难例。通过学习这类样本，能够提高模型对于不同类型“shoes”描述的区分度。\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p1.meituan.net/travelcube/047d9a3a7bd68635c7f6781061c227af202048.png@950w_734h_80q\" alt=\"图5 难例挖掘过程示意图\"/\u003e\u003c/p\u003e\u003cp\u003e具体而言，负样本构建策略如表2所示：\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p0.meituan.net/travelcube/18f12d19b78742994274dbd22b03300961657.png@1322w_406h_80q\" alt=\"表2 负样本Query抽取策略\"/\u003e\u003c/p\u003e\u003cp\u003e其次，通过对训练数据中目标框的个数以及Query长度的分布情况分析，确定模型的相关参数。图片中目标框的最大个数设置为10，Query文本的最大单词个数为20。后处理策略相关的内容，我们将会在4.3部分进行详细的介绍。\u003c/p\u003e\u003ch3 id=\"4-2-模型构建与训练\"\u003e4.2 模型构建与训练\u003c/h3\u003e\u003cp\u003e\u003cstrong\u003e4.2.1 模型结构\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e基于上文中对多模态检索领域现有方法的调研，在本次比赛中，我们分别从单流模型和双流模型中各选择了相应SOTA的算法，即ImageBERT和LXMERT。具体而言，针对比赛任务，两种算法分别进行了如下改进：\u003c/p\u003e\u003cp\u003eLXMERT模型方面主要的改进包括：\u003c/p\u003e\u003cul\u003e\u003cli\u003e图片特征部分（Visual Feature）融入了目标框类别标签所对应的文本特征。\u003c/li\u003e\u003cli\u003eText-Image Matching Task中使用两层全连接网络进行图片和文本融合特征的二分类，其中第一个全连接层之后使用GeLU [2] 进行激活，然后通过LayerNorm [1] 进行归一化处理。\u003c/li\u003e\u003cli\u003e在第二个全连接层之后采用Cross Entropy Loss训练网络。\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e改进后的模型结构如下图6所示：\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p1.meituan.net/travelcube/fa7ca8da4668967cdc862984d85910fd456393.png@1920w_708h_80q\" alt=\"图6 比赛中使用的LXMERT模型结构\"/\u003e\u003c/p\u003e\u003cp\u003e特征网络的预训练权重使用了LXMERT所提供权重文件，下载地址为：\u003ca href=\"https://github.com/airsplay/lxmert\"\u003ehttps://github.com/airsplay/lxmert\u003c/a\u003e。\u003c/p\u003e\u003cp\u003eImageBERT：本方案中一共用到了两个版本的 ImageBERT模型，分别记为ImageBERT A和ImageBERT B，下面会分别介绍改进点。\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eImageBERT A\u003c/strong\u003e：基于原始ImageBERT的改进有以下几点。\u003c/p\u003e\u003cul\u003e\u003cli\u003e训练任务：不对图片特征和Query的部分单词做掩码，仅训练相关性匹配任务，不进行MLM等其他任务的训练。\u003c/li\u003e\u003cli\u003eSegment Embedding：将Segment Embedding统一编码为0，不对图片特征和Query文本单独进行编码。\u003c/li\u003e\u003cli\u003e损失函数：在[CLS]位输出Query与Image的匹配关系，通过Cross Entropy Loss计算损失。\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e依据上述策略，选用BERT-Base模型权重对变量初始化，在此基础上进行FineTune。其模型结构如下图7所示：\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p1.meituan.net/travelcube/430d949c290017849f3b12aaf02e4817486901.png@1920w_979h_80q\" alt=\"图7 比赛中使用的ImageBert模型结构\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eImageBERT B\u003c/strong\u003e：和ImageBERT A的不同点是在Position Embedding和Segment Embedding的处理上。\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003ePosition Embedding\u003c/strong\u003e：去掉了ImageBert中图像目标框位置信息的Position Embedding结构。\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eSegment Embedding\u003c/strong\u003e：文本的Segment Embedding编码为0，图片特征的Segment Embedding编码为1。\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e依据上述策略，同样选用BERT-Base模型权重对变量初始化，在此基础上进行FineTune。\u003c/p\u003e\u003cp\u003e三种模型构建中，共性的创新点在于，在模型的输入中引入了图片目标框的标签信息。而这一思路同样被应用在了微软2020年5月份最新的论文Oscar [7] 中，但该文的特征使用方式和损失函数设置与我们的方案不同。\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e4.2.2 模型训练\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e使用节4.1的数据生成策略构建训练数据，分别对上述三个模型进行训练，训练后的模型在验证集（Val）上的效果如表3所示。\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p1.meituan.net/travelcube/e19d60f0cf3d440d0a3c14d7ce8eaca229936.png@890w_402h_80q\" alt=\"表3 初步训练后模型在验证集（Val）上的效果\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e4.2.3 利用损失函数进行模型微调\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e完成初步的模型训练后，接下来使用不同的损失函数对模型进行进一步的微调，主要有AMSoftmax Loss [5]、Multi-Similarity Loss [6]。\u003c/p\u003e\u003cul\u003e\u003cli\u003eAMSoftmax Loss通过权值归一化和特征归一化，在缩小类内距离的同时增大类间距离，从而提高了模型效果。\u003c/li\u003e\u003cli\u003eMulti-Similarity Loss将深度度量学习转化为样本对的加权问题，采用采样和加权交替迭代的策略实现了自相似性，负相对相似性和正相对相似性三种，能够促使模型学习得到更好的特征。\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e在我们的方案中所采用的具体策略如下：\u003c/p\u003e\u003cul\u003e\u003cli\u003e对于LXMERT，在特征网络后加入Multi-Similarity Loss，与Cross Entropy Loss 组成多任务学习网络，进行模型微调。\u003c/li\u003e\u003cli\u003e对于ImageBERT A，使用AMSoftmax Loss代替Cross Entropy Loss。\u003c/li\u003e\u003cli\u003e对于ImageBERT B，损失函数处理方式和LXMERT一致。\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e经过微调，各模型在验证集（Val）上的效果如表4所示。\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p0.meituan.net/travelcube/a9d0d5409b1fc0b573739a2d58f6c9ef34650.png@886w_404h_80q\" alt=\"表4 损失函数对模型微调--验证集（Val）上的效果\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e4.2.4 通过数据过采样进行模型微调\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e为了进一步提高模型效果，本方案根据训练集（Train）中Query字段与测试集（testB）中的Query字段的相似程度，对训练集（Test）进行了过采样，采样规则如下：\u003c/p\u003e\u003cul\u003e\u003cli\u003e对Query在测试集（testB）中出现的样本，或与测试集（testB）中的Query存在包含关系的样本，根据其在训练集（Train）出现的次数，按照反比例进行过采样。\u003c/li\u003e\u003cli\u003e对Query未在测试集（testB）中出现的样本，根据两个数据集Query中重复词的个数，对测试集（testB）每条Query抽取重复词数目Top10的训练集（Train）样本，每条样本过采样50次。\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e数据过采样后，分别对与上述的三个模型按照如下方案进行微调：\u003c/p\u003e\u003cul\u003e\u003cli\u003e对于LXMERT模型，使用过采样得到的训练样本对LXMERT模型进行进一步微调。\u003c/li\u003e\u003cli\u003e对于ImageBERT A模型，本方案从训练集（Train）选出Query中单词和测试集(Test)Query存在重合的样本对模型进行进一步微调。\u003c/li\u003e\u003cli\u003e对于ImageBERT B模型，考虑到训练集（Train）中存在Query表达意思相同，但是单词排列顺序不同的情况，类似”sporty men’s high-top shoes”和”high-top sporty men’s shoes”，为了增强模型的鲁棒性，以一定概率对Query的单词（Word）进行随机打乱，对ImageBERT B模型进行进一步微调。\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e训练后各模型在验证集（Val）上的效果如表5所示：\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p0.meituan.net/travelcube/2932e13dcd75e6071a138be6812ca0d033910.png@892w_402h_80q\" alt=\"表5 过采样后验证集（Val）集上的效果\"/\u003e\u003c/p\u003e\u003cp\u003e为了充分利用全部有标签的数据，本方案进一步使用了验证集（Val）对模型进行FineTune。为了避免过拟合，最终提交结果只对ImageBERT A模型进行了上述操作。\u003c/p\u003e\u003cp\u003e在Query-Image样本对的相关性的预测阶段，本方案对测试集(testB)Query所包含的短句进行统计，发现其中“sen department” 这一短句在测试集（testB）中大量出现，但在训练集（Train）中从未出现，但出现过“forest style”这个短句。为了避免这组同义短句对模型预测带来的影响，选择将测试集(testB)中Query的“sen department”替换为“forest style”，并且利用ImageBERT A对替换后的测试集进行相关性预测，结果记为ImageBERT A’。\u003c/p\u003e\u003ch3 id=\"4-3-模型融合和后处理\"\u003e4.3 模型融合和后处理\u003c/h3\u003e\u003cp\u003e经过上述的模型构建、训练以及预测，本方案共得到了4个样本对相关性得分的文件。接下来对预测结果进行Ensemble，并按照一定策略进行后处理，得到Query相应的Image候选排序集合，具体步骤如下:\u003c/p\u003e\u003cp\u003e（1）在Ensemble阶段，本方案选择对不同模型所得相关性分数进行加权求和，作为每一个样本对的最终相关性得分，各模型按照LXMERT、ImageBERT A、ImageBERT B、ImageBERT A’的顺序的权值为0.3:0.2:0.3:0.2，各模型的权重利用网格搜索的方式确定，通过遍历4个模型的不同权重占比，每个模型权重占比从0到1，选取在valid集上效果最优的权重，进行归一化，作为最终权重。\u003c/p\u003e\u003cp\u003e（2）在得到所有Query-Image样本对的相关性得分之后，接下来对Query所对应的多张候选图片进行排序。验证集（Val）和测试集（testB）的数据中，部分Image出现在了多个Query的候选样本中，本方案对这部分样本做了进一步处理：\u003c/p\u003e\u003cp\u003ea.考虑到同一Image通常只对应一个Query，因此认为同一个Image只与相关性分数最高的Query相关。使用上述策略对ImageBERT B模型在验证集（Val）上所得结果进行后处理，模型的NDCG@5 分数从0.7098提升到了0.7486。\u003c/p\u003e\u003cp\u003eb.考虑到同一Image对应的多条Query往往差异较小，其语义也是比较接近的，这导致了训练后的模型对这类样本的区分度较差，较差区分度的相关性分数会一定程度上引起模型NDCG@5的下降。针对这种情况我们采用了如下操作：\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e如果同一Query的相关性分数中，Top1 Image和Top2 Image相关性分数之差大于一定阈值，计算NDCG@5时则只保留Top 1所对应的Query-Image样本对，删除其他样本对。\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e相反的，如果Top1 Image和Top2 Image相关性分数之差小于或等于一定阈值，计算NDCG@5时，删除所有包含该Image的样本对。\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e使用上述策略对ImageBERT B的验证集（Val）结果进行后处理，当选定阈值为0.92时，模型的NDCG@5 分数从0.7098提升到了0.8352。\u003c/p\u003e\u003cp\u003e可以看到，采用策略b处理后，模型性能得到了显著提升，因此，本方案在测试集（testB）上，对所有模型Ensemble后的相关性得分采用了策略b进行处理，得到了最终的相关性排序。\u003c/p\u003e\u003ch2 id=\"5-多模态在美团搜索的应用\"\u003e5. 多模态在美团搜索的应用\u003c/h2\u003e\u003cp\u003e前面提到过，美团搜索是典型的多模态搜索场景，目前多模态能力在搜索的多个场景进行了落地。介绍具体的落地场景前，先简单介绍下美团搜索的整体架构，美团整体搜索架构主要分为五层，分别为：数据层、召回层、精排层、小模型重排层以及最终的结果展示层，接下来按照搜索的五层架构详细介绍下搜索场景中多模态的落地。\u003c/p\u003e\u003ch3 id=\"数据层\"\u003e数据层\u003c/h3\u003e\u003cp\u003e多模态表示：基于美团海量的文本和图像/视频数据，构建平行语料，进行ImageBERT模型的预训练，训练模型用于提取文本和图片/视频向量化表征，服务下游召回/排序任务。\u003c/p\u003e\u003cp\u003e多模态融合：图片/视频数据的多分类任务中，引入相关联的文本，用于提升分类标签的准确率，服务下游的图片/视频标签召回以及展示层按搜索Query出图。\u003c/p\u003e\u003ch3 id=\"召回层\"\u003e召回层\u003c/h3\u003e\u003cp\u003e多模态表示\u0026amp;融合：内容搜索、视频搜索、全文检索等多路召回场景中，引入图片/视频的分类标签召回以及图片/视频向量化召回，丰富召回结果，提升召回结果相关性。\u003c/p\u003e\u003ch3 id=\"精排层-小模型重排\"\u003e精排层\u0026amp;小模型重排\u003c/h3\u003e\u003cp\u003e多模态表示\u0026amp;融合：排序模型中，引入图片/视频的向量化Embedding特征，以及搜索Query和展示图片/视频的相关性特征、搜索结果和展示图片/视频的相关性特征，优化排序效果。\u003c/p\u003e\u003ch3 id=\"展示层\"\u003e展示层\u003c/h3\u003e\u003cp\u003e多模态融合：图片/视频优选阶段，引入图片/视频和Query以及和搜索结果的相关性信息，做到按搜索Query出图以及搜索结果出图，优化用户体验。\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://p1.meituan.net/travelcube/cce70d6e0db9fbc0a67918c8965d8245830474.png@1818w_1274h_80q\" alt=\"图8 多模态在美团搜索的落地场景\"/\u003e\u003c/p\u003e\u003ch2 id=\"6-总结\"\u003e6. 总结\u003c/h2\u003e\u003cp\u003e在本次比赛中，我们构建了一种基于ImageBERT和LXMERT的多模态召回模型，并通过数据预处理、结果融合以及后处理策略来提升模型效果。该模型能够细粒度的对用户查询Query的相关图片进行打分排序，从而得到高质量的排序列表。通过本次比赛，我们对多模态检索领域的算法和研究方向有了更深的认识，也借此机会对前沿算法的工业落地能力进行了摸底测试，为后续进一步的算法研究和落地打下了基础。此外，由于本次比赛的场景与美团搜索与\bNLP部的业务场景存在一定的相似性，因此该模型未来也能够直接为我们的业务赋能。\u003c/p\u003e\u003cp\u003e目前，美团搜索与NLP团队正在结合多模态信息，比如文本、图像、OCR等，开展MT-BERT多模态预训练工作，通过融合多模态特征，学习更好的语义表达，同时也在尝试落地更多的下游任务，比如图文相关性、向量化召回、多模态特征表示、基于多模态信息的标题生成等。\u003c/p\u003e\u003ch2 id=\"参考文献\"\u003e参考文献\u003c/h2\u003e\u003cul\u003e\u003cli\u003e[1] Ba, J. L., Kiros, J. R., and Hinton, G. E. Layer Normalization. arXiv preprint arXiv:1607.06450 (2016).\u003c/li\u003e\u003cli\u003e[2] Hendrycks, D., and Gimpel, K. Gaussian Error Linear Units (GeLUs). arXiv preprint arXiv:1606.08415 (2016).\u003c/li\u003e\u003cli\u003e[3] Qi, D., Su, L., Song, J., Cui, E., Bharti, T., and Sacheti, A. Imagebert: Cross-modal Pre-training with Large-scale Weak-supervised Image-text Data. arXiv preprint arXiv:2001.07966 (2020).\u003c/li\u003e\u003cli\u003e[4] Tan, H., and Bansal, M. LXMERT: Learning Cross-modality Encoder Representations from Transformers. arXiv preprint arXiv:1908.07490 (2019).\u003c/li\u003e\u003cli\u003e[5] Wang, F., Liu, W., Liu, H., and Cheng, J. Additive Margin Softmax for Face Verification. arXiv preprint arXiv:1801.05599 (2018).\u003c/li\u003e\u003cli\u003e[6] Wang, X., Han, X., Huang, W., Dong, D., and Scott, M. R. Multi-similarity Loss with General Pair Weighting for Deep Metric Learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2019), pp. 5022–5030.\u003c/li\u003e\u003cli\u003e[7] Li X, Yin X, Li C, et al. Oscar: Object-semantics aligned pre-training for vision-language tasks[J]. arXiv preprint arXiv:2004.06165, 2020.\u003c/li\u003e\u003cli\u003e[8] Lu J, Batra D, Parikh D, et al. Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks[C]//Advances in Neural Information Processing Systems. 2019: 13-23.\u003c/li\u003e\u003cli\u003e[9] Li L H, Yatskar M, Yin D, et al. Visualbert: A simple and performant baseline for vision and language[J]. arXiv preprint arXiv:1908.03557, 2019.\u003c/li\u003e\u003cli\u003e[10] Su W, Zhu X, Cao Y, et al. Vl-bert: Pre-training of generic visual-linguistic representations[J]. arXiv preprint arXiv:1908.08530, 2019.\u003c/li\u003e\u003cli\u003e[11] 杨扬、佳昊等. MT-BERT的探索和实践. \u003ca href=\"https://tech.meituan.com/2019/11/14/nlp-bert-practice.html\"\u003ehttps://tech.meituan.com/2019/11/14/nlp-bert-practice.html\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"作者简介\"\u003e作者简介\u003c/h2\u003e\u003cp\u003e左凯，马潮，东帅，曹佐，金刚，张弓等，均来自美团AI平台搜索与NLP部。\u003c/p\u003e\u003ch2 id=\"招聘信息\"\u003e招聘信息\u003c/h2\u003e\u003cp\u003e美团搜索与NLP部，长期招聘搜索、推荐、NLP算法工程师，坐标北京/上海。欢迎感兴趣的同学发送简历至：tech@meituan.com（邮件注明：搜索与NLP部）\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "Date": "2020-09-27T00:00:00Z",
  "Author": "soulteary@gmail.com"
}