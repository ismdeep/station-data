{
  "Source": "www.evilsocket.net",
  "Title": "Process Behaviour Anomaly Detection Using eBPF and Unsupervised-Learning Autoencoders",
  "Link": "https://www.evilsocket.net/2022/08/15/Process-behaviour-anomaly-detection-using-eBPF-and-unsupervised-learning-Autoencoders/",
  "Content": "\u003cdiv class=\"content\" itemprop=\"articleBody\"\u003e\n\u003cp\u003eHello everybody, I hope you’ve been enjoying this summer after two years of Covid and lockdowns :D In this post I’m going to describe how to use eBPF syscall tracing in a creative way in order to detect process behaviour anomalies at runtime using an unsupervised learning model called autoencoder. \u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://i.imgur.com/QEmpeDl.jpg\" alt=\"anomalies\"/\u003e\u003c/p\u003e\n\u003cp\u003eWhile many projects approach this problem by building a list of allowed system calls and checking at runtime if the process is using anything outside of this list, we’ll use a methodology that will not only save us from explicitly compiling this list, but will also take into account how fast the process is using system calls that would normally be allowed but only within a certain range of usage per second. This techique can potentially detect process exploitation, denial-of-service and several other types of attacks.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eYou’ll find the \u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/evilsocket/ebpf-process-anomaly-detection\"\u003ecomplete source code on my Github\u003c/a\u003e as usual.\u003c/strong\u003e\u003c/p\u003e\n\u003ch2 id=\"What-is-eBPF\"\u003e\u003ca href=\"#What-is-eBPF\" class=\"headerlink\" title=\"What is eBPF?\"\u003e\u003c/a\u003eWhat is eBPF?\u003c/h2\u003e\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener\" href=\"https://ebpf.io/\"\u003eeBPF\u003c/a\u003e is a technology that allows to intercept several aspect of the Linux kernel runtime without using a kernel module. At its core eBPF is a virtual machine running inside the kernel that performs sanity checks on an eBPF program opcodes before loading it in order to ensure runtime safety.\u003c/p\u003e\n\u003cp\u003eFrom the \u003ca target=\"_blank\" rel=\"noopener\" href=\"https://ebpf.io/what-is-ebpf\"\u003eeBPF.io\u003c/a\u003e page:\u003c/p\u003e\n\u003cfigure class=\"highlight plain\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003eeBPF (which is no longer an acronym for anything) is a revolutionary technology with origins in the Linux kernel that can run sandboxed programs in a privileged context such as the operating system kernel. It is used to safely and efficiently extend the capabilities of the kernel without requiring to change kernel source code or load kernel modules.  \u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003eHistorically, the operating system has always been an ideal place to implement observability, security, and networking functionality due to the kernel’s privileged ability to oversee and control the entire system. At the same time, an operating system kernel is hard to evolve due to its central role and high requirement towards stability and security. The rate of innovation at the operating system level has thus traditionally been lower compared to functionality implemented outside of the operating system.\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\u003cp\u003e\u003cimg src=\"https://i.imgur.com/8yG0Nyr.png\" alt=\"ebpf\"/\u003e\u003c/p\u003e\n\u003cfigure class=\"highlight plain\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003eeBPF changes this formula fundamentally. By allowing to run sandboxed programs within the operating system, application developers can run eBPF programs to add additional capabilities to the operating system at runtime. The operating system then guarantees safety and execution efficiency as if natively compiled with the aid of a Just-In-Time (JIT) compiler and verification engine. This has led to a wave of eBPF-based projects covering a wide array of use cases, including next-generation networking, observability, and security functionality.\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\u003cp\u003eThere are several options to compile into bytecode and then run eBPF programs, such as \u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/cilium/ebpf\"\u003eCilium Golang eBPF package\u003c/a\u003e, \u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/aya-rs/aya\"\u003eAya Rust crate\u003c/a\u003e and \u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/iovisor/bcc\"\u003eIOVisor Python BCC package\u003c/a\u003e and many more. BCC being the simplest is the one we’re going to use for this post. Keep in mind that the same exact things can be done with all these libraries and only runtime dependencies and performance would change.\u003c/p\u003e\n\u003ch3 id=\"System-call-Tracing-with-eBPF\"\u003e\u003ca href=\"#System-call-Tracing-with-eBPF\" class=\"headerlink\" title=\"System call Tracing with eBPF\"\u003e\u003c/a\u003eSystem call Tracing with eBPF\u003c/h3\u003e\u003cp\u003eThe usual approach to trace system calls with eBPF consists in creating a \u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/iovisor/bcc/blob/master/docs/reference_guide.md#3-tracepoints\"\u003etracepoint\u003c/a\u003e or a \u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/iovisor/bcc/blob/master/docs/reference_guide.md#1-kprobes\"\u003ekprobe\u003c/a\u003e on each system call we want to intercept, somehow fetch the arguments of the call and then report each one individually to user space using either a \u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/iovisor/bcc/blob/master/docs/reference_guide.md#2-bpf_perf_output\"\u003eperf buffer\u003c/a\u003e or a \u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/iovisor/bcc/blob/master/docs/reference_guide.md#5-bpf_ringbuf_output\"\u003ering buffer\u003c/a\u003e. While this method is great to track each system call individually and check their arguments (for instance, checking which files are being accessed or which hosts the program is connecting to), it has a couple of issues. \u003c/p\u003e\n\u003cp\u003eFirst, reading the arguments for each syscall is quite tricky depending on the system architecture and kernel compilation flags. For instance in some cases it’s not possible to read the arguments while entering the syscall, but only once the syscall has been executed, by saving pointers from a kprobe and then reading them from a kretprobe. Another important issue is the eBPF buffers throughput: when the target process is executing a lot of system calls in a short period of time (think about an HTTP server under heavy stress, or a process performing a lot of I/O), \u003ca target=\"_blank\" rel=\"noopener\" href=\"http://blog.itaysk.com/2020/04/20/ebpf-lost-events\"\u003eevents can be lost\u003c/a\u003e making this approach less than ideal.\u003c/p\u003e\n\u003ch3 id=\"Poor-man’s-Approach\"\u003e\u003ca href=\"#Poor-man’s-Approach\" class=\"headerlink\" title=\"Poor man’s Approach\"\u003e\u003c/a\u003ePoor man’s Approach\u003c/h3\u003e\u003cp\u003e\u003cimg src=\"https://i.imgur.com/vuHfl1n.jpg\" alt=\"kiss\"/\u003e\u003c/p\u003e\n\u003cp\u003eSince we’re not interested in the system calls arguments, we’re going to use an alternative approach that doesn’t have the aforementioned issues. The main idea is very very simple: we’re going to have a single tracepoint on the \u003ccode\u003esys_enter\u003c/code\u003e event, triggered every time \u003cstrong\u003eany\u003c/strong\u003e system call is executed. Instead of immediately reporting the call to userspace via a buffer, we’re only going to increment the relative integer slot in an array, creating an histogram.\u003c/p\u003e\n\u003cp\u003eThis array is 512 integers long (512 set as a constant maximum number of system calls), so that after (for instance) system call \u003ccode\u003eread\u003c/code\u003e (number 0) is executed twice and \u003ccode\u003emprotect\u003c/code\u003e (number 10) once, we’ll have a vector/histogram that’ll look like this:\u003c/p\u003e\n\u003cfigure class=\"highlight plain\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e2,0,0,0,0,0,0,0,0,0,1,0,0,0,..........\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\u003cp\u003eThe relative eBPF is very simple and looks like this:\u003c/p\u003e\n\u003cfigure class=\"highlight c\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e4\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e5\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e6\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e7\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e8\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e9\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e10\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e11\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e12\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e13\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e14\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e15\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e16\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e17\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e18\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e19\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e20\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e21\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e22\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"comment\"\u003e// defines a per-cpu array in order to avoid race coinditions while updating the histogram\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003eBPF_PERCPU_ARRAY(histogram, u32, MAX_SYSCALLS);\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"comment\"\u003e// here\u0026#39;s our tracepoint on sys_enter\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003eTRACEPOINT_PROBE(raw_syscalls, sys_enter)\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e{\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    \u003cspan class=\"comment\"\u003e// filter by target pid and return if this activity belongs to a process we\u0026#39;re not interested in\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    u64 pid = bpf_get_current_pid_tgid() \u0026gt;\u0026gt; \u003cspan class=\"number\"\u003e32\u003c/span\u003e;\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    \u003cspan class=\"keyword\"\u003eif\u003c/span\u003e(pid != TARGET_PID) {\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e        \u003cspan class=\"keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"number\"\u003e0\u003c/span\u003e;\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    }\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    \u003cspan class=\"comment\"\u003e// populate the histogram, args-\u0026gt;id contains the system call number\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    u32 key = (u32)args-\u0026gt;id;\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    u32 value = \u003cspan class=\"number\"\u003e0\u003c/span\u003e, *pval = \u003cspan class=\"literal\"\u003eNULL\u003c/span\u003e;\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    pval = histogram.lookup_or_try_init(\u0026amp;key, \u0026amp;value);\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    \u003cspan class=\"keyword\"\u003eif\u003c/span\u003e(pval) {\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e        *pval += \u003cspan class=\"number\"\u003e1\u003c/span\u003e;\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    }\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    \u003cspan class=\"keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"number\"\u003e0\u003c/span\u003e;\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e}\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\u003cp\u003eSo far no transfer of data to user space is performed, so no system call invocation is lost and everything is accounted for in this histogram. \u003c/p\u003e\n\u003cp\u003eWe’ll then perform a simple polling of this vector from userspace every 100 milliseconds and, by comparing the vector to its previous state, we’ll calculate the rate of change for every system call:\u003c/p\u003e\n\u003cfigure class=\"highlight python\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e4\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e5\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e6\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e7\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e8\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e9\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e10\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e11\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e12\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e13\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"comment\"\u003e# polling loop\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"keyword\"\u003ewhile\u003c/span\u003e \u003cspan class=\"number\"\u003e1\u003c/span\u003e:\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    \u003cspan class=\"comment\"\u003e# get single histogram from per-cpu arrays\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    histogram = [histo_map[s] \u003cspan class=\"keyword\"\u003efor\u003c/span\u003e s \u003cspan class=\"keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"built_in\"\u003erange\u003c/span\u003e(\u003cspan class=\"number\"\u003e0\u003c/span\u003e, MAX_SYSCALLS)]\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    \u003cspan class=\"comment\"\u003e# if any change happened\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    \u003cspan class=\"keyword\"\u003eif\u003c/span\u003e histogram != prev:\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e        \u003cspan class=\"comment\"\u003e# compute the rate of change for every syscall\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e        deltas = [ \u003cspan class=\"number\"\u003e1.0\u003c/span\u003e - (prev[s] / histogram[s]) \u003cspan class=\"keyword\"\u003eif\u003c/span\u003e histogram[s] != \u003cspan class=\"number\"\u003e0.0\u003c/span\u003e \u003cspan class=\"keyword\"\u003eelse\u003c/span\u003e \u003cspan class=\"number\"\u003e0.0\u003c/span\u003e \u003cspan class=\"keyword\"\u003efor\u003c/span\u003e s \u003cspan class=\"keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"built_in\"\u003erange\u003c/span\u003e(\u003cspan class=\"number\"\u003e0\u003c/span\u003e, MAX_SYSCALLS)]\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e        prev = histogram\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    \u003cspan class=\"comment\"\u003e# ... SNIPPET ...\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    time.sleep(args.time / \u003cspan class=\"number\"\u003e1000.0\u003c/span\u003e)\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\u003cp\u003eThis will not only take into account which system calls are executed (and the ones that are not executed, thus having counter always to 0), but also how fast they are executed during normal activity in a given amount of time.\u003c/p\u003e\n\u003cp\u003eOnce we have this data saved to a CSV file, we can then train a model that’ll be able to detect anomalies at runtime.\u003c/p\u003e\n\u003ch2 id=\"Anomaly-detection-with-Autoencoders\"\u003e\u003ca href=\"#Anomaly-detection-with-Autoencoders\" class=\"headerlink\" title=\"Anomaly detection with Autoencoders\"\u003e\u003c/a\u003eAnomaly detection with Autoencoders\u003c/h2\u003e\u003cp\u003eAn \u003ca target=\"_blank\" rel=\"noopener\" href=\"https://en.wikipedia.org/wiki/Autoencoder\"\u003eautoencoder\u003c/a\u003e is an artificial neural network used in unsupervised learning tasks, able to create an internal representation of unlabeled data (therefore the “unsupervised”) and produce an output of the same size. This approach can be used for data compression (as the internal encoding layer is usually smaller than the input) and of course anomaly detection like in our case.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://i.imgur.com/jsWJbIx.png\" alt=\"autoencoder\"/\u003e\u003c/p\u003e\n\u003ccenter\u003e\u003csmall\u003eSource: https://lilianweng.github.io/posts/2018-08-12-vae/\u003c/small\u003e\u003c/center\u003e\n\u003cp\u003eThe main idea is to train the model and using our CSV dataset both as the input to the network and as its desired output. This way the ANN will learn what is “normal” in the dataset by correctly reconstructing each vector. When the output vector is substantially different from the input vector, we will know this is an anomaly because the ANN was not trained to reconstruct this specific one, meaning it was outside of what we consider normal activity.\u003c/p\u003e\n\u003cp\u003eOur autoencoder has 512 inputs (defined as the \u003ccode\u003eMAX_SYSCALLS\u003c/code\u003e constant) and the same number of outputs, while the internal representation layer is half that size:\u003c/p\u003e\n\u003cfigure class=\"highlight python\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e4\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e5\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e6\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e7\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e8\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e9\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e10\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e11\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e12\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e13\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e14\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e15\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e16\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e17\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003en_inputs = MAX_SYSCALLS\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"comment\"\u003e# input layer\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003einp = Input(shape=(n_inputs,))\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"comment\"\u003e# encoder layer\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003eencoder = Dense(n_inputs)(inp)\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003eencoder = ReLU()(encoder)\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"comment\"\u003e# internal representation layer\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003emiddle = Dense(\u003cspan class=\"built_in\"\u003eint\u003c/span\u003e(n_inputs / \u003cspan class=\"number\"\u003e2\u003c/span\u003e))(encoder)\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"comment\"\u003e# decoder layer\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003edecoder = Dense(n_inputs)(middle)\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003edecoder = ReLU()(decoder)\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003edecoder = Dense(n_inputs, activation=\u003cspan class=\"string\"\u003e\u0026#39;linear\u0026#39;\u003c/span\u003e)(decoder)\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003em = Model(inp, decoder)\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"comment\"\u003e# we use mean square error as the loss function as we\u0026#39;re interested in the reconstruction error\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003em.\u003cspan class=\"built_in\"\u003ecompile\u003c/span\u003e(optimizer=\u003cspan class=\"string\"\u003e\u0026#39;adam\u0026#39;\u003c/span\u003e, loss=\u003cspan class=\"string\"\u003e\u0026#39;mse\u0026#39;\u003c/span\u003e)\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\u003cp\u003eFor training our CSV dataset is split in training data and testing/validation data. After training the latter is used to compute the maximum reconstruction error the model presents for “normal” data:\u003c/p\u003e\n\u003cfigure class=\"highlight python\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e4\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e5\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e6\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e7\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e8\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e9\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e10\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e11\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"comment\"\u003e# test the model on test data to calculate the error threshold\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003ey_test = model.predict(test)\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003etest_err = []\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"comment\"\u003e# for each vector\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"keyword\"\u003efor\u003c/span\u003e ind \u003cspan class=\"keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"built_in\"\u003erange\u003c/span\u003e(\u003cspan class=\"built_in\"\u003elen\u003c/span\u003e(test)):\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    \u003cspan class=\"comment\"\u003e# get the absolute error as a difference of the input and reconstructed output\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    abs_err = np.\u003cspan class=\"built_in\"\u003eabs\u003c/span\u003e(test[ind, :]-y_test[ind, :])\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    \u003cspan class=\"comment\"\u003e# append the sum of each individual error\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e    test_err.append(abs_err.\u003cspan class=\"built_in\"\u003esum\u003c/span\u003e())\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"comment\"\u003e# the threshold will be the maximum cumulative error we\u0026#39;ve found\u003c/span\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003ethreshold = \u003cspan class=\"built_in\"\u003emax\u003c/span\u003e(test_err)\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\u003cp\u003eWe now have an autoencoder and its reference error threshold that we can use to perform live anomaly detection.\u003c/p\u003e\n\u003ch2 id=\"Example\"\u003e\u003ca href=\"#Example\" class=\"headerlink\" title=\"Example\"\u003e\u003c/a\u003eExample\u003c/h2\u003e\u003cp\u003eLet’s see the program in action. For this example I decided to monitor the \u003ccode\u003eSpotify\u003c/code\u003e process on Linux. Due to its high I/O intensity Spotify represents a nice candidate for a demo of this approach. I captured training data while streaming some music and clicking around playlists and settings. One thing I did \u003cstrong\u003enot\u003c/strong\u003e do during the learning stage is clicking on the \u003ccode\u003eConnect with Facebook\u003c/code\u003e button, this will be our test. Since this action triggers system calls that are not usually executed by Spotify, we can use it to check if our model is actually detecting anomalies at runtime.\u003c/p\u003e\n\u003ch3 id=\"Learning-from-a-live-process\"\u003e\u003ca href=\"#Learning-from-a-live-process\" class=\"headerlink\" title=\"Learning from a live process\"\u003e\u003c/a\u003eLearning from a live process\u003c/h3\u003e\u003cp\u003eLet’s say that Spotify has process id 1234, we’ll start by capturing some live data while using it:\u003c/p\u003e\n\u003cfigure class=\"highlight sh\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003esudo ./main.py --pid 1234 --data spotify.csv --learn\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\u003cp\u003eKeep this running for as much as you can, having the biggest amount of samples possible is key in order for our model to be accurate in detecting anomalies. Once you’re happy with the amount of samples, you can stop the learning step by pressing Ctrl+C. \u003c/p\u003e\n\u003cp\u003eYour \u003ccode\u003espotify.csv\u003c/code\u003e dataset is now ready to be used for training.\u003c/p\u003e\n\u003ch3 id=\"Training-the-model\"\u003e\u003ca href=\"#Training-the-model\" class=\"headerlink\" title=\"Training the model\"\u003e\u003c/a\u003eTraining the model\u003c/h3\u003e\u003cp\u003eWe’ll now train the model for 200 epochs, you will see the validation loss (the mean square error of the reconstructed vector) decreasing at each step, indicating that the model is indeed learning from the data:\u003c/p\u003e\n\u003cfigure class=\"highlight sh\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e./main.py --data spotify.csv --epochs 200 --model spotify.h5 --train\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\u003cp\u003eAfter the training is completed, the model will be saved to the \u003ccode\u003espotify.h5\u003c/code\u003e file and the reference error threshold will be printed on screen:\u003c/p\u003e\n\u003cfigure class=\"highlight plain\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e...\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003eEpoch 195/200\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e60/60 [==============================] - 0s 2ms/step - loss: 1.3071e-05 - val_loss: 6.3671e-05\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003eEpoch 196/200\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e60/60 [==============================] - 0s 2ms/step - loss: 1.8221e-05 - val_loss: 5.2383e-05\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003eEpoch 197/200\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e60/60 [==============================] - 0s 2ms/step - loss: 9.2132e-06 - val_loss: 5.3354e-05\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003eEpoch 198/200\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e60/60 [==============================] - 0s 2ms/step - loss: 9.2722e-06 - val_loss: 4.9380e-05\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003eEpoch 199/200\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e60/60 [==============================] - 0s 2ms/step - loss: 8.0692e-06 - val_loss: 5.1954e-05\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003eEpoch 200/200\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e60/60 [==============================] - 0s 2ms/step - loss: 8.3448e-06 - val_loss: 5.0102e-05\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003emodel saved to spotify.h5, getting error threshold for 106 samples ...\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003eerror threshold=9.969912\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\u003ch3 id=\"Detecting-anomalies\"\u003e\u003ca href=\"#Detecting-anomalies\" class=\"headerlink\" title=\"Detecting anomalies\"\u003e\u003c/a\u003eDetecting anomalies\u003c/h3\u003e\u003cp\u003eOnce the model has been trained it can be used on the live target process to detect anomalies, in this case we’re using a 10.0 error threshold:\u003c/p\u003e\n\u003cfigure class=\"highlight sh\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003esudo ./main.py --pid 1234 --model spotify.h5 --max-error 10.0 --run\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\u003cp\u003eWhen an anomaly is detected the cumulative error will be printed along wiht the top 3 anomalous system calls and their respective error. \u003c/p\u003e\n\u003cp\u003eIn this example, I’m clicking on the \u003ccode\u003eConnect with Facebook\u003c/code\u003e button that will use system calls such as \u003ccode\u003egetpriority\u003c/code\u003e that were previsouly unseen in training data. \u003c/p\u003e\n\u003cp\u003eWe can see from the output that the model is indeed detecting anomalies:\u003c/p\u003e\n\u003cfigure class=\"highlight plain\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"gutter\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003e1\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e2\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e3\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e4\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003ctd class=\"code\"\u003e\u003cpre\u003e\u003cspan class=\"line\"\u003eerror = 30.605255 - max = 10.000000 - top 3:\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  b\u0026#39;getpriority\u0026#39; = 0.994272\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  b\u0026#39;writev\u0026#39; = 0.987554\u003c/span\u003e\u003cbr/\u003e\u003cspan class=\"line\"\u003e  b\u0026#39;creat\u0026#39; = 0.969955\u003c/span\u003e\u003cbr/\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\u003cp\u003e\u003cimg src=\"https://i.imgur.com/sW1gUJ5.jpg\" alt=\"success\"/\u003e\u003c/p\u003e\n\u003ch2 id=\"Conclusions\"\u003e\u003ca href=\"#Conclusions\" class=\"headerlink\" title=\"Conclusions\"\u003e\u003c/a\u003eConclusions\u003c/h2\u003e\u003cp\u003eThis post shows how by using a relatively simple approach and giving up some of the system call speficics (the arguments) we can overcome performance issues and still be able to capture enough information to perform anomaly detection. As previously said this approach works for several scenarios, from simple anomalous behaviour due to bugs, to denial of service attacks, bruteforcing and exploitation of the target process. \u003c/p\u003e\n\u003cp\u003eThe overall performance of the system could be improved by using native libraries such as \u003ca target=\"_blank\" rel=\"noopener\" href=\"https://github.com/aya-rs/aya\"\u003eAya\u003c/a\u003e and its accuracy with some hyper parameters tuning of the model along with more granular per-feature error thresholds. \u003c/p\u003e\n\u003cp\u003eAll these things are left as an exercise for the reader :D\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://i.imgur.com/TNrJE1N.jpg\" alt=\"lol\"/\u003e\u003c/p\u003e\n\u003c/div\u003e",
  "Date": "2022-08-15T14:06:05Z",
  "Author": "Simone Margaritelli"
}